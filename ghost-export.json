{"db":[{"meta":{"exported_on":1766510310159,"version":"4.8.4"},"data":{"posts":[{"id":"5ad44f4c27dc680f0fe26875","uuid":"95d342b5-6192-47f7-981b-1e78368f2b47","title":"You Don't Understand Compound Growth","slug":"you-dont-understand-compound-growth","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"cardName\":\"card-markdown\",\"markdown\":\"Einstein once ([supposedly](https://www.snopes.com/fact-check/compound-interest/)) said:\\n\\n> Compound interest is the most powerful force in the universe\\n\\nOf compound interest, Warren Buffet [proclaims](https://www.marketwatch.com/story/this-warren-buffett-rule-can-work-wonders-on-your-portfolio-2016-04-26):\\n\\n> Over time it accomplishes extraordinary things\\n\\nCompound interest, or growth, is one of the, if not the most, powerful and impactful forces in nature.\\n\\nAnd yet, it is also one of the **most consistently misunderstood** in the world of business.\\n\\nHow so?\\n\\nSimply, we misapply the term \\\"compound growth\\\" to things that do not actually grow in compound fashion.\\n\\nLet's first establish what \\\"compound growth\\\" even means.\\n\\nI propose the following operative definition:\\n\\n> Compound growth ~ constant growth\\n\\nThe fact is, very few objects, organisms or organizations can sustain truly compounding growth over any extended period.\\n\\nFrom an observer's or investor's perspective, it's quite easy to fool yourself into thinking compound, exponential growth is much more common than it really is. And it's understandable given how often the term is thrown around. Firms in fleeting phases of fast growth can visually demonstrate their breakneck pace with the ubiquitous, infamous \\\"[hockey stick](https://andrewchen.co/the-most-common-mistake-when-forecasting-growth-for-new-products-and-how-to-fix-it/)\\\" chart.\\n\\nWho could argue with that?\\n\\nAs an entrepreneur or operator, you too can fall prey to your own fictions - convincing yourself you've \\\"cracked the code\\\" when you've only really cracked the piggy bank. Irrational exuberance eventually turns concave, finally ending in a plateau of linearity.\\n\\nThrough some examples, I hope to demonstrate that compound growth 1) implies constant growth 2) is exceedingly rare and 3) is incredibly important to building a large, valuable business.\\n\\nBut before we get to business, let's talk about - bacteria.\\n\\n## Bacteria and Bricklayers\\n![Bacteria](https://upload.wikimedia.org/wikipedia/commons/3/32/EscherichiaColi_NIAID.jpg)\\n\\nIn bacteria populations, growth is **fixed**. Subject to the resource constraints of the environment they inhabit, bacteria grow at a constant rate indefinitely.\\n\\nA simple example to illustrate the point:\\n\\nLet's say we have some bacteria that reproduce on a fixed time schedule, one doubling per minute to keep the numbers simple.\\n\\nWe start with a single bacteria cell. After one minute, we'll have two bacteria. With time, the population grows as such:\\n* 1\\n* 2\\n* 4\\n* 8\\n* 16\\n* ...\\n\\nNow we ask the question, how fast does our bacteria population grow (in percentage terms)?\\n\\nThe number of bacteria cells one minute from now is:\\n\\n$$n_{t+1} = 2n_t$$\\n\\nWhich implies the minute-over-minute growth rate is:\\n\\n$$\\\\frac{n_{t+1}}{n_t} - 1 = \\\\frac{2n_t}{n_t} - 1 = 2 - 1 = 1$$\\n\\nor 100%.\\n\\nThis is an example of perfectly compounding growth, also referred to as **exponential** or **geometric growth**.\\n\\nPut simply, how fast the bacteria grow is entirely independent of population size. In other words, growth and scale are perfectly uncorrelated.\\n\\nImportantly, **most things do not work this way**.\\n\\n### Layering on\\n\\nLet's look at another example - constructing a brick wall.\\n\\nAssume a bricklayer can lay 10 bricks per hour. The brick count will proceed as follows\\n* 0\\n* 10\\n* 20\\n* 30\\n* 40\\n* ...\\n\\nThe brick count grows by 10 bricks per hour.\\n\\nGoing through the same growth rate calculations from above:\\n\\nThe number of bricks 1 hour from now will be:\\n\\n$$n_{t+1} = n_t + 10$$\\n\\nWhich implies hour-over-hour growth is:\\n\\n$$\\\\frac{n_{t+1}}{n_t} - 1 = \\\\frac{n_t + 10 - n_t}{n_t}= \\\\frac{10}{n_t}$$\\n\\nNotice that the growth rate depends on how many bricks we've already laid. This is **linear** or **arithmetic growth**. Because the number of bricks laid each hour is static through time, growth (in percentage terms) necessarily slows down. Scale is in the denominator. Therefore, growth and scale are negatively correlated: more scale -> less growth.\\n\\nSure, initially we are growing the brick count quite fast - 100% in fact. But by the time we reach 30 bricks, our forward-looking growth rate has fallen to 33%. At 100 bricks, we'll only be growing 10% - which is a far cry from our halcyon days of tech reporters and venture capitalists gawking at our growing (tech enabled) bricklaying operation.\\n\\n## Two flavors of growth\\n\\nThe key difference between the bricks and the bacteria is that one has **scale invariant growth (SIG)** and the other... doesn't.\\n\\nOK OK, friends who reviewed this before publishing said that was a big word/phrase to suddenly drop. So let's take a step back and examine this phenomenon visually before moving forward.\\n\\nA great way to do this is plot the growth rate of the bacteria and bricks over time:\\n\\n![bacteria-bricklayer-1](/content/images/2018/09/bacteria-bricklayer-1.png)\\n\\nThe bacteria grow at a constant rate over time. For the bricklayer, growth simply... collapses.\\n\\nI've plotted this chart hundreds of times over the years, and for most startups the growth plot looks *eerily* similar to the bricks here.\\n\\nGrowth is not the natural order; growth cannot be taken for granted. As we get **larger**, we get *slower*.\\n\\nI mentioned correlation earlier. The correlation between growth and scale in the case of the bacteria is **0** - perfectly uncorrelated.\\n\\nFor the brick count, the correlation is **-0.7**, a very strong negative correlation.\\n\\nWe've now established two ends of a spectrum we can use to characterize various forms of growth.\\n\\nOn one side, we have linear/additive/arithmetic/correlated growth, and on the other we have exponential/multiplicative/geometric/uncorrelated growth.\\n\\n<p align=\\\"center\\\"><img src=\\\"/content/images/2018/09/growthspectrum.png\\\"></p>\\n\\nThe question now is, where do various things fall along this spectrum? Said another way, how accurate is it to say that \\\"XYZ\\\" grows in compounding fashion?\\n\\nLet's walk through some more examples.\\n\\n### Debt\\n\\nCompound growth is often used in reference to compound interest earned on a financial instrument of some sort. \\n\\nAnyone who has ever suffered through mounting credit card debt knows this quite well. **Debt grows like bacteria** - it multiplies without end at a rate that depends entirely on the interest rate and not at all on the current balance.\\n\\n1%, 5%, 10% - whatever the interest rate, unless paid off, debt continues to grow without end. If only paid off partially, the remaining balance will continue to grow.\\n\\nNot a bad business model if you ask me.\\n\\n### World GDP Per Capita\\n\\nGrowth is not the natural state of affairs. For most of human history there was no meaningful economic growth or improvement in livings standards for the average person. Until recently, Life was nasty, brutish, short and... static:\\n\\n![gdp-world](/content/images/2018/06/gdp-world.jpg)\\n\\nUnless growth is literally contractual, as in the case of debt and interest, we can't take it for granted, as history plainly shows.\\n\\nAnd it's not simply a question of the scale of the axis. If you zoomed into that long straight line, you wouldn't see a hockey stick growth pattern. Living standards actually **did not** improve meaningfully over time for the vast majority of human existence on this planet.\\n\\nA few years of bad weather, major epidemics like the Black Death (the bacteria strike again), social upheaval - these events drastically impacted the day-to-day well-being and lives of our ancestors, often erasing decades of progress.\\n\\nEven today, many parts of the world experience major swings in their rates of growth, especially within the developing world. Regions and countries can end up in severe economic doldrums, leading to entire lost generations.\\n\\nMany stops and starts, fits and spurts.\\n\\nHowever, before we get too depressed, let's look at a best case scenario.\\n\\n### U.S. GDP\\n\\nThe good ol' US of A ('s real GDP):\\n\\n<p align=\\\"center\\\"><img src=\\\"/content/images/2018/06/real-gdp.png\\\"></p>\\n\\nLooks pretty good huh? Let's look at the growth plot:\\n\\n![realgdpgrowth](/content/images/2018/09/realgdpgrowth.png)\\n\\nUgh, this is pretty noisy. It's difficult to tell if growth is changing in significant ways year-to-year or if it is generally variation around a certain value.\\n\\nThis view hides some interesting detail. One neat math trick - taking the natural log rescales a metric such that, when graphed, *linearity implies constant growth*.\\n\\nDo this, and the real GDP chart becomes:\\n\\n<p align=\\\"center\\\"><img src=\\\"/content/images/2018/06/logrealgdp.png\\\"></p>\\n\\nOver this period, we can make a few interesting observations:\\n* Log real GDP is impressively linear - one could fit a linear line to the above data fairly well, implying reasonably constant growth\\n* That said, it is not perfectly linear, and therefore not perfectly compounding, per our earlier definition\\n* We can see multiple distinct inflection points where growth changed, in connection with recessions (1970, 2008)\\n\\nTaking advantage of these kinks in the curve, let's estimate the growth during each period through piecewise linear regression (i.e. the \\\"line of best fit\\\" for each period):\\n\\n![logrealgdp-piecewisereg](/content/images/2018/06/logrealgdp-piecewisereg.png)\\n\\nAnnual real growth goes from **3.9%** in the 1947-1970 period, to **3.1%** in the 1970-2008 period, to **2.1%** in the 2008-2017 period.\\n\\nThe economists yelling and screaming that we are on [permanently lower trajectory](https://www.youtube.com/watch?v=1eCYq2vD5GY) after the most recent recession may have a point.\\n\\nSo not exactly constant growth, but still impressive given the real economy grew 8x+ over this period. Growth has roughly halved over a 70-year period.\\n\\nIn terms of the connection between growth and scale, the correlation here is **-0.3**, which certainly indicates a relationship, but not a strong one.\\n\\nWe can therefore conclude that U.S. GDP grows in reasonably compound fashion.\\n\\n### Revenue\\n\\nMost businesses see their revenue growth rate tick down over time. This is even more true for companies that are growing quickly today.\\n\\nOn the other hand, some exceptional businesses have managed to drive truly compound growth over long periods.\\n\\nTake Amazon for example, which has exhibited incredible revenue growth over time ($B):\\n\\n![amzn-revenue](/content/images/2018/06/amzn-revenue.png)\\n\\nThis is an impressive chart in its own right. But I am actually more impressed by the log-transformed chart, which is nearly a straight line:\\n\\n![amzn-logrev](/content/images/2018/06/amzn-logrev.png)\\n\\n**Amazon has grown at a nearly constant rate over almost two decades**, despite increasing scale by 64x over the period.\\n\\nAt best, one could identify a slight kink in growth in 2011. Replicating the piecewise analysis, we can see that Amazon grew ~30% year-over-year from 2000 to 2011 and ~23% year-over-year from 2011 to 2017.\\n\\n![amzn-logrev-piecewisereg](/content/images/2018/06/amzn-logrev-piecewisereg.png)\\n\\nAmazon's growth-scale correlation? **-0.1**!\\n\\nIt's hard to put into words how impressive that single number is. Worth reiterating: **most things do not work this way**.\\n\\nAmazon is an exceptional business that has evidently identified a way to grow at a nearly constant rate over many years. A combination of tapping into the long-run secular growth of e-commerce and deft expansion into seemingly orthogonal spaces (for example, via Amazon Web Services) that in fact leverage the core infrastructure the company's built up over time has enabled it to grow in bacteria-like fashion.\\n\\n## Growth functions: Are you adding or multiplying?\\n\\nEvery growing business needs an honest answer to this question: Is your business growing through multiplication, like the Amazonian bacteria, or addition, like the brick wall?\\n\\n**Businesses that simply \\\"add\\\" must necessarily slow down**, by the simple math we outlined earlier. Scale begins to work against you, making it harder and harder to maintain a rapid growth pace. **Eventually, you will, figuratively, hit a wall**.\\n\\nAn example of an additive growth function is paid customer acquisition through a channel like Google Adwords.\\n\\nSpending $100 on Adwords is going to generate some number of users. Spending another $100 is probably going to generate a similar number of users, and so on.\\n\\n**There's no \\\"magic\\\" here**. This is \\\"buying growth\\\" in the most direct manner.\\n\\nIf anything, customer acquisition through paid channels that you do not control (and Adwords is the epitome of this) tends to get *less* efficient over time as you saturate keywords etc.\\n\\nLike a bricklayer at the end of a long day, businesses reliant on this form of growth tend to run out of gas sooner or later.\\n\\nSure, you can attempt to stack bricks at a faster and faster rate, raising venture capital when you can no longer self-fund the endeavour, building the wall ever higher...\\n\\n*But this too will pass*. Eventually, some proportion of those users *must* stick around and continue to buy from you without meaningful additional spend on your part, otherwise you'll find yourself on the proverbial **\\\"acquisition treadmill\\\"**, unable to jump off without significant disruption to the business.\\n\\nA number of companies in the subscription e-commerce \\\"send me a box with a psuedo-random assortment of goods\\\" space fall squarely into this category. Users churn at high rates, requiring more and more fuel to be poured on the paid acquisition fire to keep the train going.\\n\\nOn the other hand, **businesses that \\\"multiply\\\" can grow indefinitely**. Their \\\"growth functions\\\" are inherently multiplicative. Users beget more users. Revenue begets more revenue.\\n\\nThe classic exponential, multiplicative growth function is the **viral word-of-mouth (WOM)** or **referral program**.\\n\\nPayPal built a viral engine in its early days, giving users money for each additional friend they referred to the service:\\n\\n<p align=\\\"center\\\"><img src=\\\"/content/images/2018/06/paypal-viral.png\\\"></p>\\n\\nDropbox replicated this, giving out additional space for signing up friends:\\n\\n<p align=\\\"center\\\"><img src=\\\"/content/images/2018/06/dropbox-viral.png\\\"></p>\\n\\nThe act of sharing a Dropbox file or folder with someone who wasn't yet a user generated even more sign-ups:\\n\\n<p align=\\\"center\\\"><img src=\\\"/content/images/2018/09/dropboxshare.png\\\"></p>\\n\\nWhatever the approach, it is *vitally* important that every business vigorously search for and identify exponential growth opportunities. It is mathematically inevitable that an additive, linear growth engine that does not compound on itself will eventually peter out, or even collapse like a wall built too high.\\n\\nLikewise, investors must diligently sift through the noise to find the few bacteria-in-a-hay-stack that will drive true, long-term value creation. Ignore the steep trajectory in the short-run. Instead, focus on the **curvature of the horizon**.\\n\\n**Scale invariant growth** is the key to building a large, meaningful business.\\n\\nGo find it.\"}],[\"html\",{\"html\":\"<script>\\n    MathJax.Hub.Queue([\\\"Typeset\\\",MathJax.Hub]);\\n</script>\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}","html":"<!--kg-card-begin: markdown--><p>Einstein once (<a href=\"https://www.snopes.com/fact-check/compound-interest/\">supposedly</a>) said:</p>\n<blockquote>\n<p>Compound interest is the most powerful force in the universe</p>\n</blockquote>\n<p>Of compound interest, Warren Buffet <a href=\"https://www.marketwatch.com/story/this-warren-buffett-rule-can-work-wonders-on-your-portfolio-2016-04-26\">proclaims</a>:</p>\n<blockquote>\n<p>Over time it accomplishes extraordinary things</p>\n</blockquote>\n<p>Compound interest, or growth, is one of the, if not the most, powerful and impactful forces in nature.</p>\n<p>And yet, it is also one of the <strong>most consistently misunderstood</strong> in the world of business.</p>\n<p>How so?</p>\n<p>Simply, we misapply the term &quot;compound growth&quot; to things that do not actually grow in compound fashion.</p>\n<p>Let's first establish what &quot;compound growth&quot; even means.</p>\n<p>I propose the following operative definition:</p>\n<blockquote>\n<p>Compound growth ~ constant growth</p>\n</blockquote>\n<p>The fact is, very few objects, organisms or organizations can sustain truly compounding growth over any extended period.</p>\n<p>From an observer's or investor's perspective, it's quite easy to fool yourself into thinking compound, exponential growth is much more common than it really is. And it's understandable given how often the term is thrown around. Firms in fleeting phases of fast growth can visually demonstrate their breakneck pace with the ubiquitous, infamous &quot;<a href=\"https://andrewchen.co/the-most-common-mistake-when-forecasting-growth-for-new-products-and-how-to-fix-it/\">hockey stick</a>&quot; chart.</p>\n<p>Who could argue with that?</p>\n<p>As an entrepreneur or operator, you too can fall prey to your own fictions - convincing yourself you've &quot;cracked the code&quot; when you've only really cracked the piggy bank. Irrational exuberance eventually turns concave, finally ending in a plateau of linearity.</p>\n<p>Through some examples, I hope to demonstrate that compound growth 1) implies constant growth 2) is exceedingly rare and 3) is incredibly important to building a large, valuable business.</p>\n<p>But before we get to business, let's talk about - bacteria.</p>\n<h2 id=\"bacteriaandbricklayers\">Bacteria and Bricklayers</h2>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/3/32/EscherichiaColi_NIAID.jpg\" alt=\"Bacteria\" loading=\"lazy\"></p>\n<p>In bacteria populations, growth is <strong>fixed</strong>. Subject to the resource constraints of the environment they inhabit, bacteria grow at a constant rate indefinitely.</p>\n<p>A simple example to illustrate the point:</p>\n<p>Let's say we have some bacteria that reproduce on a fixed time schedule, one doubling per minute to keep the numbers simple.</p>\n<p>We start with a single bacteria cell. After one minute, we'll have two bacteria. With time, the population grows as such:</p>\n<ul>\n<li>1</li>\n<li>2</li>\n<li>4</li>\n<li>8</li>\n<li>16</li>\n<li>...</li>\n</ul>\n<p>Now we ask the question, how fast does our bacteria population grow (in percentage terms)?</p>\n<p>The number of bacteria cells one minute from now is:</p>\n<p>$$n_{t+1} = 2n_t$$</p>\n<p>Which implies the minute-over-minute growth rate is:</p>\n<p>$$\\frac{n_{t+1}}{n_t} - 1 = \\frac{2n_t}{n_t} - 1 = 2 - 1 = 1$$</p>\n<p>or 100%.</p>\n<p>This is an example of perfectly compounding growth, also referred to as <strong>exponential</strong> or <strong>geometric growth</strong>.</p>\n<p>Put simply, how fast the bacteria grow is entirely independent of population size. In other words, growth and scale are perfectly uncorrelated.</p>\n<p>Importantly, <strong>most things do not work this way</strong>.</p>\n<h3 id=\"layeringon\">Layering on</h3>\n<p>Let's look at another example - constructing a brick wall.</p>\n<p>Assume a bricklayer can lay 10 bricks per hour. The brick count will proceed as follows</p>\n<ul>\n<li>0</li>\n<li>10</li>\n<li>20</li>\n<li>30</li>\n<li>40</li>\n<li>...</li>\n</ul>\n<p>The brick count grows by 10 bricks per hour.</p>\n<p>Going through the same growth rate calculations from above:</p>\n<p>The number of bricks 1 hour from now will be:</p>\n<p>$$n_{t+1} = n_t + 10$$</p>\n<p>Which implies hour-over-hour growth is:</p>\n<p>$$\\frac{n_{t+1}}{n_t} - 1 = \\frac{n_t + 10 - n_t}{n_t}= \\frac{10}{n_t}$$</p>\n<p>Notice that the growth rate depends on how many bricks we've already laid. This is <strong>linear</strong> or <strong>arithmetic growth</strong>. Because the number of bricks laid each hour is static through time, growth (in percentage terms) necessarily slows down. Scale is in the denominator. Therefore, growth and scale are negatively correlated: more scale -&gt; less growth.</p>\n<p>Sure, initially we are growing the brick count quite fast - 100% in fact. But by the time we reach 30 bricks, our forward-looking growth rate has fallen to 33%. At 100 bricks, we'll only be growing 10% - which is a far cry from our halcyon days of tech reporters and venture capitalists gawking at our growing (tech enabled) bricklaying operation.</p>\n<h2 id=\"twoflavorsofgrowth\">Two flavors of growth</h2>\n<p>The key difference between the bricks and the bacteria is that one has <strong>scale invariant growth (SIG)</strong> and the other... doesn't.</p>\n<p>OK OK, friends who reviewed this before publishing said that was a big word/phrase to suddenly drop. So let's take a step back and examine this phenomenon visually before moving forward.</p>\n<p>A great way to do this is plot the growth rate of the bacteria and bricks over time:</p>\n<p><img src=\"/content/images/2018/09/bacteria-bricklayer-1.png\" alt=\"bacteria-bricklayer-1\" loading=\"lazy\"></p>\n<p>The bacteria grow at a constant rate over time. For the bricklayer, growth simply... collapses.</p>\n<p>I've plotted this chart hundreds of times over the years, and for most startups the growth plot looks <em>eerily</em> similar to the bricks here.</p>\n<p>Growth is not the natural order; growth cannot be taken for granted. As we get <strong>larger</strong>, we get <em>slower</em>.</p>\n<p>I mentioned correlation earlier. The correlation between growth and scale in the case of the bacteria is <strong>0</strong> - perfectly uncorrelated.</p>\n<p>For the brick count, the correlation is <strong>-0.7</strong>, a very strong negative correlation.</p>\n<p>We've now established two ends of a spectrum we can use to characterize various forms of growth.</p>\n<p>On one side, we have linear/additive/arithmetic/correlated growth, and on the other we have exponential/multiplicative/geometric/uncorrelated growth.</p>\n<p align=\"center\"><img src=\"/content/images/2018/09/growthspectrum.png\"></p>\n<p>The question now is, where do various things fall along this spectrum? Said another way, how accurate is it to say that &quot;XYZ&quot; grows in compounding fashion?</p>\n<p>Let's walk through some more examples.</p>\n<h3 id=\"debt\">Debt</h3>\n<p>Compound growth is often used in reference to compound interest earned on a financial instrument of some sort.</p>\n<p>Anyone who has ever suffered through mounting credit card debt knows this quite well. <strong>Debt grows like bacteria</strong> - it multiplies without end at a rate that depends entirely on the interest rate and not at all on the current balance.</p>\n<p>1%, 5%, 10% - whatever the interest rate, unless paid off, debt continues to grow without end. If only paid off partially, the remaining balance will continue to grow.</p>\n<p>Not a bad business model if you ask me.</p>\n<h3 id=\"worldgdppercapita\">World GDP Per Capita</h3>\n<p>Growth is not the natural state of affairs. For most of human history there was no meaningful economic growth or improvement in livings standards for the average person. Until recently, Life was nasty, brutish, short and... static:</p>\n<p><img src=\"/content/images/2018/06/gdp-world.jpg\" alt=\"gdp-world\" loading=\"lazy\"></p>\n<p>Unless growth is literally contractual, as in the case of debt and interest, we can't take it for granted, as history plainly shows.</p>\n<p>And it's not simply a question of the scale of the axis. If you zoomed into that long straight line, you wouldn't see a hockey stick growth pattern. Living standards actually <strong>did not</strong> improve meaningfully over time for the vast majority of human existence on this planet.</p>\n<p>A few years of bad weather, major epidemics like the Black Death (the bacteria strike again), social upheaval - these events drastically impacted the day-to-day well-being and lives of our ancestors, often erasing decades of progress.</p>\n<p>Even today, many parts of the world experience major swings in their rates of growth, especially within the developing world. Regions and countries can end up in severe economic doldrums, leading to entire lost generations.</p>\n<p>Many stops and starts, fits and spurts.</p>\n<p>However, before we get too depressed, let's look at a best case scenario.</p>\n<h3 id=\"usgdp\">U.S. GDP</h3>\n<p>The good ol' US of A ('s real GDP):</p>\n<p align=\"center\"><img src=\"/content/images/2018/06/real-gdp.png\"></p>\n<p>Looks pretty good huh? Let's look at the growth plot:</p>\n<p><img src=\"/content/images/2018/09/realgdpgrowth.png\" alt=\"realgdpgrowth\" loading=\"lazy\"></p>\n<p>Ugh, this is pretty noisy. It's difficult to tell if growth is changing in significant ways year-to-year or if it is generally variation around a certain value.</p>\n<p>This view hides some interesting detail. One neat math trick - taking the natural log rescales a metric such that, when graphed, <em>linearity implies constant growth</em>.</p>\n<p>Do this, and the real GDP chart becomes:</p>\n<p align=\"center\"><img src=\"/content/images/2018/06/logrealgdp.png\"></p>\n<p>Over this period, we can make a few interesting observations:</p>\n<ul>\n<li>Log real GDP is impressively linear - one could fit a linear line to the above data fairly well, implying reasonably constant growth</li>\n<li>That said, it is not perfectly linear, and therefore not perfectly compounding, per our earlier definition</li>\n<li>We can see multiple distinct inflection points where growth changed, in connection with recessions (1970, 2008)</li>\n</ul>\n<p>Taking advantage of these kinks in the curve, let's estimate the growth during each period through piecewise linear regression (i.e. the &quot;line of best fit&quot; for each period):</p>\n<p><img src=\"/content/images/2018/06/logrealgdp-piecewisereg.png\" alt=\"logrealgdp-piecewisereg\" loading=\"lazy\"></p>\n<p>Annual real growth goes from <strong>3.9%</strong> in the 1947-1970 period, to <strong>3.1%</strong> in the 1970-2008 period, to <strong>2.1%</strong> in the 2008-2017 period.</p>\n<p>The economists yelling and screaming that we are on <a href=\"https://www.youtube.com/watch?v=1eCYq2vD5GY\">permanently lower trajectory</a> after the most recent recession may have a point.</p>\n<p>So not exactly constant growth, but still impressive given the real economy grew 8x+ over this period. Growth has roughly halved over a 70-year period.</p>\n<p>In terms of the connection between growth and scale, the correlation here is <strong>-0.3</strong>, which certainly indicates a relationship, but not a strong one.</p>\n<p>We can therefore conclude that U.S. GDP grows in reasonably compound fashion.</p>\n<h3 id=\"revenue\">Revenue</h3>\n<p>Most businesses see their revenue growth rate tick down over time. This is even more true for companies that are growing quickly today.</p>\n<p>On the other hand, some exceptional businesses have managed to drive truly compound growth over long periods.</p>\n<p>Take Amazon for example, which has exhibited incredible revenue growth over time ($B):</p>\n<p><img src=\"/content/images/2018/06/amzn-revenue.png\" alt=\"amzn-revenue\" loading=\"lazy\"></p>\n<p>This is an impressive chart in its own right. But I am actually more impressed by the log-transformed chart, which is nearly a straight line:</p>\n<p><img src=\"/content/images/2018/06/amzn-logrev.png\" alt=\"amzn-logrev\" loading=\"lazy\"></p>\n<p><strong>Amazon has grown at a nearly constant rate over almost two decades</strong>, despite increasing scale by 64x over the period.</p>\n<p>At best, one could identify a slight kink in growth in 2011. Replicating the piecewise analysis, we can see that Amazon grew ~30% year-over-year from 2000 to 2011 and ~23% year-over-year from 2011 to 2017.</p>\n<p><img src=\"/content/images/2018/06/amzn-logrev-piecewisereg.png\" alt=\"amzn-logrev-piecewisereg\" loading=\"lazy\"></p>\n<p>Amazon's growth-scale correlation? <strong>-0.1</strong>!</p>\n<p>It's hard to put into words how impressive that single number is. Worth reiterating: <strong>most things do not work this way</strong>.</p>\n<p>Amazon is an exceptional business that has evidently identified a way to grow at a nearly constant rate over many years. A combination of tapping into the long-run secular growth of e-commerce and deft expansion into seemingly orthogonal spaces (for example, via Amazon Web Services) that in fact leverage the core infrastructure the company's built up over time has enabled it to grow in bacteria-like fashion.</p>\n<h2 id=\"growthfunctionsareyouaddingormultiplying\">Growth functions: Are you adding or multiplying?</h2>\n<p>Every growing business needs an honest answer to this question: Is your business growing through multiplication, like the Amazonian bacteria, or addition, like the brick wall?</p>\n<p><strong>Businesses that simply &quot;add&quot; must necessarily slow down</strong>, by the simple math we outlined earlier. Scale begins to work against you, making it harder and harder to maintain a rapid growth pace. <strong>Eventually, you will, figuratively, hit a wall</strong>.</p>\n<p>An example of an additive growth function is paid customer acquisition through a channel like Google Adwords.</p>\n<p>Spending $100 on Adwords is going to generate some number of users. Spending another $100 is probably going to generate a similar number of users, and so on.</p>\n<p><strong>There's no &quot;magic&quot; here</strong>. This is &quot;buying growth&quot; in the most direct manner.</p>\n<p>If anything, customer acquisition through paid channels that you do not control (and Adwords is the epitome of this) tends to get <em>less</em> efficient over time as you saturate keywords etc.</p>\n<p>Like a bricklayer at the end of a long day, businesses reliant on this form of growth tend to run out of gas sooner or later.</p>\n<p>Sure, you can attempt to stack bricks at a faster and faster rate, raising venture capital when you can no longer self-fund the endeavour, building the wall ever higher...</p>\n<p><em>But this too will pass</em>. Eventually, some proportion of those users <em>must</em> stick around and continue to buy from you without meaningful additional spend on your part, otherwise you'll find yourself on the proverbial <strong>&quot;acquisition treadmill&quot;</strong>, unable to jump off without significant disruption to the business.</p>\n<p>A number of companies in the subscription e-commerce &quot;send me a box with a psuedo-random assortment of goods&quot; space fall squarely into this category. Users churn at high rates, requiring more and more fuel to be poured on the paid acquisition fire to keep the train going.</p>\n<p>On the other hand, <strong>businesses that &quot;multiply&quot; can grow indefinitely</strong>. Their &quot;growth functions&quot; are inherently multiplicative. Users beget more users. Revenue begets more revenue.</p>\n<p>The classic exponential, multiplicative growth function is the <strong>viral word-of-mouth (WOM)</strong> or <strong>referral program</strong>.</p>\n<p>PayPal built a viral engine in its early days, giving users money for each additional friend they referred to the service:</p>\n<p align=\"center\"><img src=\"/content/images/2018/06/paypal-viral.png\"></p>\n<p>Dropbox replicated this, giving out additional space for signing up friends:</p>\n<p align=\"center\"><img src=\"/content/images/2018/06/dropbox-viral.png\"></p>\n<p>The act of sharing a Dropbox file or folder with someone who wasn't yet a user generated even more sign-ups:</p>\n<p align=\"center\"><img src=\"/content/images/2018/09/dropboxshare.png\"></p>\n<p>Whatever the approach, it is <em>vitally</em> important that every business vigorously search for and identify exponential growth opportunities. It is mathematically inevitable that an additive, linear growth engine that does not compound on itself will eventually peter out, or even collapse like a wall built too high.</p>\n<p>Likewise, investors must diligently sift through the noise to find the few bacteria-in-a-hay-stack that will drive true, long-term value creation. Ignore the steep trajectory in the short-run. Instead, focus on the <strong>curvature of the horizon</strong>.</p>\n<p><strong>Scale invariant growth</strong> is the key to building a large, meaningful business.</p>\n<p>Go find it.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: html--><script>\n    MathJax.Hub.Queue([\"Typeset\",MathJax.Hub]);\n</script><!--kg-card-end: html-->","comment_id":"5ad44f4c27dc680f0fe26875","plaintext":"Einstein once (supposedly [https://www.snopes.com/fact-check/compound-interest/]\n) said:\n\n> Compound interest is the most powerful force in the universe\n\n\nOf compound interest, Warren Buffet proclaims\n[https://www.marketwatch.com/story/this-warren-buffett-rule-can-work-wonders-on-your-portfolio-2016-04-26]\n:\n\n> Over time it accomplishes extraordinary things\n\n\nCompound interest, or growth, is one of the, if not the most, powerful and\nimpactful forces in nature.\n\nAnd yet, it is also one of the most consistently misunderstood in the world of\nbusiness.\n\nHow so?\n\nSimply, we misapply the term \"compound growth\" to things that do not actually\ngrow in compound fashion.\n\nLet's first establish what \"compound growth\" even means.\n\nI propose the following operative definition:\n\n> Compound growth ~ constant growth\n\n\nThe fact is, very few objects, organisms or organizations can sustain truly\ncompounding growth over any extended period.\n\nFrom an observer's or investor's perspective, it's quite easy to fool yourself\ninto thinking compound, exponential growth is much more common than it really\nis. And it's understandable given how often the term is thrown around. Firms in\nfleeting phases of fast growth can visually demonstrate their breakneck pace\nwith the ubiquitous, infamous \"hockey stick\n[https://andrewchen.co/the-most-common-mistake-when-forecasting-growth-for-new-products-and-how-to-fix-it/]\n\" chart.\n\nWho could argue with that?\n\nAs an entrepreneur or operator, you too can fall prey to your own fictions -\nconvincing yourself you've \"cracked the code\" when you've only really cracked\nthe piggy bank. Irrational exuberance eventually turns concave, finally ending\nin a plateau of linearity.\n\nThrough some examples, I hope to demonstrate that compound growth 1) implies\nconstant growth 2) is exceedingly rare and 3) is incredibly important to\nbuilding a large, valuable business.\n\nBut before we get to business, let's talk about - bacteria.\n\nBacteria and Bricklayers\n\n\nIn bacteria populations, growth is fixed. Subject to the resource constraints of\nthe environment they inhabit, bacteria grow at a constant rate indefinitely.\n\nA simple example to illustrate the point:\n\nLet's say we have some bacteria that reproduce on a fixed time schedule, one\ndoubling per minute to keep the numbers simple.\n\nWe start with a single bacteria cell. After one minute, we'll have two bacteria.\nWith time, the population grows as such:\n\n * 1\n * 2\n * 4\n * 8\n * 16\n * ...\n\nNow we ask the question, how fast does our bacteria population grow (in\npercentage terms)?\n\nThe number of bacteria cells one minute from now is:\n\n$$n_{t+1} = 2n_t$$\n\nWhich implies the minute-over-minute growth rate is:\n\n$$\\frac{n_{t+1}}{n_t} - 1 = \\frac{2n_t}{n_t} - 1 = 2 - 1 = 1$$\n\nor 100%.\n\nThis is an example of perfectly compounding growth, also referred to as \nexponential or geometric growth.\n\nPut simply, how fast the bacteria grow is entirely independent of population\nsize. In other words, growth and scale are perfectly uncorrelated.\n\nImportantly, most things do not work this way.\n\nLayering on\nLet's look at another example - constructing a brick wall.\n\nAssume a bricklayer can lay 10 bricks per hour. The brick count will proceed as\nfollows\n\n * 0\n * 10\n * 20\n * 30\n * 40\n * ...\n\nThe brick count grows by 10 bricks per hour.\n\nGoing through the same growth rate calculations from above:\n\nThe number of bricks 1 hour from now will be:\n\n$$n_{t+1} = n_t + 10$$\n\nWhich implies hour-over-hour growth is:\n\n$$\\frac{n_{t+1}}{n_t} - 1 = \\frac{n_t + 10 - n_t}{n_t}= \\frac{10}{n_t}$$\n\nNotice that the growth rate depends on how many bricks we've already laid. This\nis linear or arithmetic growth. Because the number of bricks laid each hour is\nstatic through time, growth (in percentage terms) necessarily slows down. Scale\nis in the denominator. Therefore, growth and scale are negatively correlated:\nmore scale -> less growth.\n\nSure, initially we are growing the brick count quite fast - 100% in fact. But by\nthe time we reach 30 bricks, our forward-looking growth rate has fallen to 33%.\nAt 100 bricks, we'll only be growing 10% - which is a far cry from our halcyon\ndays of tech reporters and venture capitalists gawking at our growing (tech\nenabled) bricklaying operation.\n\nTwo flavors of growth\nThe key difference between the bricks and the bacteria is that one has scale\ninvariant growth (SIG) and the other... doesn't.\n\nOK OK, friends who reviewed this before publishing said that was a big\nword/phrase to suddenly drop. So let's take a step back and examine this\nphenomenon visually before moving forward.\n\nA great way to do this is plot the growth rate of the bacteria and bricks over\ntime:\n\n\n\nThe bacteria grow at a constant rate over time. For the bricklayer, growth\nsimply... collapses.\n\nI've plotted this chart hundreds of times over the years, and for most startups\nthe growth plot looks eerily similar to the bricks here.\n\nGrowth is not the natural order; growth cannot be taken for granted. As we get \nlarger, we get slower.\n\nI mentioned correlation earlier. The correlation between growth and scale in the\ncase of the bacteria is 0 - perfectly uncorrelated.\n\nFor the brick count, the correlation is -0.7, a very strong negative\ncorrelation.\n\nWe've now established two ends of a spectrum we can use to characterize various\nforms of growth.\n\nOn one side, we have linear/additive/arithmetic/correlated growth, and on the\nother we have exponential/multiplicative/geometric/uncorrelated growth.\n\n\n\nThe question now is, where do various things fall along this spectrum? Said\nanother way, how accurate is it to say that \"XYZ\" grows in compounding fashion?\n\nLet's walk through some more examples.\n\nDebt\nCompound growth is often used in reference to compound interest earned on a\nfinancial instrument of some sort.\n\nAnyone who has ever suffered through mounting credit card debt knows this quite\nwell. Debt grows like bacteria - it multiplies without end at a rate that\ndepends entirely on the interest rate and not at all on the current balance.\n\n1%, 5%, 10% - whatever the interest rate, unless paid off, debt continues to\ngrow without end. If only paid off partially, the remaining balance will\ncontinue to grow.\n\nNot a bad business model if you ask me.\n\nWorld GDP Per Capita\nGrowth is not the natural state of affairs. For most of human history there was\nno meaningful economic growth or improvement in livings standards for the\naverage person. Until recently, Life was nasty, brutish, short and... static:\n\n\n\nUnless growth is literally contractual, as in the case of debt and interest, we\ncan't take it for granted, as history plainly shows.\n\nAnd it's not simply a question of the scale of the axis. If you zoomed into that\nlong straight line, you wouldn't see a hockey stick growth pattern. Living\nstandards actually did not improve meaningfully over time for the vast majority\nof human existence on this planet.\n\nA few years of bad weather, major epidemics like the Black Death (the bacteria\nstrike again), social upheaval - these events drastically impacted the\nday-to-day well-being and lives of our ancestors, often erasing decades of\nprogress.\n\nEven today, many parts of the world experience major swings in their rates of\ngrowth, especially within the developing world. Regions and countries can end up\nin severe economic doldrums, leading to entire lost generations.\n\nMany stops and starts, fits and spurts.\n\nHowever, before we get too depressed, let's look at a best case scenario.\n\nU.S. GDP\nThe good ol' US of A ('s real GDP):\n\n\n\nLooks pretty good huh? Let's look at the growth plot:\n\n\n\nUgh, this is pretty noisy. It's difficult to tell if growth is changing in\nsignificant ways year-to-year or if it is generally variation around a certain\nvalue.\n\nThis view hides some interesting detail. One neat math trick - taking the\nnatural log rescales a metric such that, when graphed, linearity implies\nconstant growth.\n\nDo this, and the real GDP chart becomes:\n\n\n\nOver this period, we can make a few interesting observations:\n\n * Log real GDP is impressively linear - one could fit a linear line to the\n   above data fairly well, implying reasonably constant growth\n * That said, it is not perfectly linear, and therefore not perfectly\n   compounding, per our earlier definition\n * We can see multiple distinct inflection points where growth changed, in\n   connection with recessions (1970, 2008)\n\nTaking advantage of these kinks in the curve, let's estimate the growth during\neach period through piecewise linear regression (i.e. the \"line of best fit\" for\neach period):\n\n\n\nAnnual real growth goes from 3.9% in the 1947-1970 period, to 3.1% in the\n1970-2008 period, to 2.1% in the 2008-2017 period.\n\nThe economists yelling and screaming that we are on permanently lower trajectory\n[https://www.youtube.com/watch?v=1eCYq2vD5GY] after the most recent recession\nmay have a point.\n\nSo not exactly constant growth, but still impressive given the real economy grew\n8x+ over this period. Growth has roughly halved over a 70-year period.\n\nIn terms of the connection between growth and scale, the correlation here is \n-0.3, which certainly indicates a relationship, but not a strong one.\n\nWe can therefore conclude that U.S. GDP grows in reasonably compound fashion.\n\nRevenue\nMost businesses see their revenue growth rate tick down over time. This is even\nmore true for companies that are growing quickly today.\n\nOn the other hand, some exceptional businesses have managed to drive truly\ncompound growth over long periods.\n\nTake Amazon for example, which has exhibited incredible revenue growth over time\n($B):\n\n\n\nThis is an impressive chart in its own right. But I am actually more impressed\nby the log-transformed chart, which is nearly a straight line:\n\n\n\nAmazon has grown at a nearly constant rate over almost two decades, despite\nincreasing scale by 64x over the period.\n\nAt best, one could identify a slight kink in growth in 2011. Replicating the\npiecewise analysis, we can see that Amazon grew ~30% year-over-year from 2000 to\n2011 and ~23% year-over-year from 2011 to 2017.\n\n\n\nAmazon's growth-scale correlation? -0.1!\n\nIt's hard to put into words how impressive that single number is. Worth\nreiterating: most things do not work this way.\n\nAmazon is an exceptional business that has evidently identified a way to grow at\na nearly constant rate over many years. A combination of tapping into the\nlong-run secular growth of e-commerce and deft expansion into seemingly\northogonal spaces (for example, via Amazon Web Services) that in fact leverage\nthe core infrastructure the company's built up over time has enabled it to grow\nin bacteria-like fashion.\n\nGrowth functions: Are you adding or multiplying?\nEvery growing business needs an honest answer to this question: Is your business\ngrowing through multiplication, like the Amazonian bacteria, or addition, like\nthe brick wall?\n\nBusinesses that simply \"add\" must necessarily slow down, by the simple math we\noutlined earlier. Scale begins to work against you, making it harder and harder\nto maintain a rapid growth pace. Eventually, you will, figuratively, hit a wall.\n\nAn example of an additive growth function is paid customer acquisition through a\nchannel like Google Adwords.\n\nSpending $100 on Adwords is going to generate some number of users. Spending\nanother $100 is probably going to generate a similar number of users, and so on.\n\nThere's no \"magic\" here. This is \"buying growth\" in the most direct manner.\n\nIf anything, customer acquisition through paid channels that you do not control\n(and Adwords is the epitome of this) tends to get less efficient over time as\nyou saturate keywords etc.\n\nLike a bricklayer at the end of a long day, businesses reliant on this form of\ngrowth tend to run out of gas sooner or later.\n\nSure, you can attempt to stack bricks at a faster and faster rate, raising\nventure capital when you can no longer self-fund the endeavour, building the\nwall ever higher...\n\nBut this too will pass. Eventually, some proportion of those users must stick\naround and continue to buy from you without meaningful additional spend on your\npart, otherwise you'll find yourself on the proverbial \"acquisition treadmill\",\nunable to jump off without significant disruption to the business.\n\nA number of companies in the subscription e-commerce \"send me a box with a\npsuedo-random assortment of goods\" space fall squarely into this category. Users\nchurn at high rates, requiring more and more fuel to be poured on the paid\nacquisition fire to keep the train going.\n\nOn the other hand, businesses that \"multiply\" can grow indefinitely. Their\n\"growth functions\" are inherently multiplicative. Users beget more users.\nRevenue begets more revenue.\n\nThe classic exponential, multiplicative growth function is the viral\nword-of-mouth (WOM) or referral program.\n\nPayPal built a viral engine in its early days, giving users money for each\nadditional friend they referred to the service:\n\n\n\nDropbox replicated this, giving out additional space for signing up friends:\n\n\n\nThe act of sharing a Dropbox file or folder with someone who wasn't yet a user\ngenerated even more sign-ups:\n\n\n\nWhatever the approach, it is vitally important that every business vigorously\nsearch for and identify exponential growth opportunities. It is mathematically\ninevitable that an additive, linear growth engine that does not compound on\nitself will eventually peter out, or even collapse like a wall built too high.\n\nLikewise, investors must diligently sift through the noise to find the few\nbacteria-in-a-hay-stack that will drive true, long-term value creation. Ignore\nthe steep trajectory in the short-run. Instead, focus on the curvature of the\nhorizon.\n\nScale invariant growth is the key to building a large, meaningful business.\n\nGo find it.","feature_image":"__GHOST_URL__/content/images/2018/10/einstein.jpg","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2018-04-16T07:22:52.000Z","updated_at":"2021-06-24T18:59:10.000Z","published_at":"2018-10-02T08:13:00.000Z","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5bb11e148a06ff33062ced72","uuid":"2d0c5b54-26f1-4f24-9fff-57ac7abe581f","title":"About Me","slug":"about-me","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2019/12/headshot_500_cropped.jpeg\"}],[\"html\",{\"html\":\"<h2 style=\\\"text-align: center\\\">My mission:</h2>\\n<p style=\\\"text-align:center; font-weight: bold\\\">To increase total software output by supporting entrepreneurs building technical tools for technical people</p>\"}],[\"hr\",{}],[\"hr\",{}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Sign-up to receive my latest essays</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Your Email Address\\\" id=\\\"mce-EMAIL\\\" required>\\n<input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: About Me\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span>Go âš¡</span></button>\\n</form>\\n            </section>\"}]],\"markups\":[[\"a\",[\"href\",\"__GHOST_URL__/never-enough-developers/\"]],[\"a\",[\"href\",\"__GHOST_URL__/software-fat-tailed/\"]],[\"a\",[\"href\",\"https://whoisnnamdi.com/grow-valuation/\"]],[\"a\",[\"href\",\"https://whoisnnamdi.com/the-developer-productivity-flywheel/\"]],[\"a\",[\"href\",\"__GHOST_URL__/remote-software-developers-earn-more/\"]],[\"a\",[\"href\",\"__GHOST_URL__/high-retention-high-volatility/\"]],[\"a\",[\"href\",\"__GHOST_URL__/you-dont-understand-compound-growth/\"]],[\"s\"],[\"a\",[\"href\",\"http://web.stanford.edu/class/cs224n/\"]],[\"a\",[\"href\",\"http://cs231n.stanford.edu/\"]],[\"a\",[\"href\",\"__GHOST_URL__/developer-productivity-trends/\"]],[\"a\",[\"href\",\"https://lsvp.com/team/nnamdi-iregbulem/\"]],[\"a\",[\"href\",\"https://lsvp.com\"]],[\"a\",[\"href\",\"https://whoisnnamdi.com/portfolio/\"]],[\"a\",[\"href\",\"https://redpanda.com/\"]],[\"a\",[\"href\",\"https://materialize.com/\"]],[\"a\",[\"href\",\"http://iconiqcapital.com/\"]],[\"a\",[\"href\",\"https://about.gitlab.com/\"]],[\"a\",[\"href\",\"https://www.epicgames.com\"]],[\"a\",[\"href\",\"https://www.ezcater.com/\"]],[\"a\",[\"href\",\"https://mybrightwheel.com/\"]],[\"a\",[\"href\",\"https://www.ageoflearning.com/\"]],[\"a\",[\"href\",\"https://www.alteryx.com/\"]],[\"a\",[\"href\",\"https://www.fastly.com/\"]],[\"a\",[\"href\",\"https://www.relativity.com/\"]],[\"a\",[\"href\",\"https://www.surveymonkey.com/\"]],[\"a\",[\"href\",\"https://www.uber.com/\"]],[\"a\",[\"href\",\"https://www.jpmorgan.com/\"]],[\"a\",[\"href\",\"https://www.gsb.stanford.edu/\"]],[\"a\",[\"href\",\"https://www.confluent.io/\"]],[\"a\",[\"href\",\"https://www.yale.edu/\"]],[\"a\",[\"href\",\"https://www.mckinsey.com/\"]],[\"a\",[\"href\",\"https://www.forbes.com/profile/nnamdi-iregbulem/?sh=2774f2426190\"]],[\"a\",[\"href\",\"https://www.venturecapitaljournal.com/40-rising-stars-to-tap-into-in-2022/\"]],[\"a\",[\"href\",\"https://www.linkedin.com/in/nnamdiiregbulem/\"]],[\"a\",[\"href\",\"https://twitter.com/whoisnnamdi\"]]],\"sections\":[[10,0],[10,1],[10,2],[1,\"h3\",[[0,[],0,\"My most popular essays:\"]]],[3,\"ul\",[[[0,[0],1,\"Why We Will Never Have Enough Software Developers\"],[0,[],0,\" (Popular on Reddit)\"]],[[0,[1],1,\"Enterprise Software Monetization is Fat-Tailed\"]],[[0,[2],1,\"Companies Rarely Grow Into Their Valuations\"]],[[0,[3],1,\"The Developer Productivity Manifesto\"]],[[0,[4],1,\"Remote Software Developers Earn 22% More Than Non-Remote Developers\"],[0,[],0,\" (#1 on Hacker News)\"]],[[0,[5],1,\"High Retention = High Volatility\"]],[[0,[6],1,\"You Don't Understand Compound Growth\"]]]],[10,3],[1,\"h3\",[[0,[],0,\"More about me:\"]]],[1,\"p\",[[0,[],0,\"I'm a geek at heart.\"]]],[1,\"p\",[[0,[],0,\"I've been fascinated by technology for as long as I can remember. I spent countless hours as a teenager building computers (currently rocking a \"],[0,[7],1,\"7700K\"],[0,[],0,\" 8700K / \"],[0,[7],1,\"7800 \"],[0,[],0,\" \"],[0,[7],1,\"980 Ti\"],[0,[],0,\" \"],[0,[7],1,\"1080 Ti\"],[0,[],0,\" 3090 combo), coding up websites (R.I.P. PHP), and finding ways to game Google search (SEO is not what it used to be though). These days I spend just as many hours doing statistical analysis in Python, toying with neural networks (highly recommend Stanford's deep learning-based NLP class \"],[0,[8],1,\"CS 224N\"],[0,[],0,\" and computer vision class \"],[0,[9],1,\"CS 231N\"],[0,[],0,\"), experimenting with open source software, and advising startups on product and growth initiatives.\"]]],[1,\"p\",[[0,[],0,\"I love applying rigorous analytical frameworks and mental models to tough problems at the center of technology, business, and life. In the last few years I've been exploring \"],[0,[10],1,\"developer productivity tools\"],[0,[],0,\", application infrastructure, and machine learning in the enterprise.\"]]],[1,\"p\",[[0,[],0,\"I'm a \"],[0,[11],1,\"Partner\"],[0,[],0,\" at \"],[0,[12],1,\"Lightspeed Venture Partners\"],[0,[],0,\", where I work with \"],[0,[13],1,\"companies\"],[0,[],0,\" like \"],[0,[14],1,\"Redpanda\"],[0,[],0,\", \"],[0,[15],1,\"Materialize\"],[0,[],0,\", and others. I spent four formative years investing in growth-stage technology businesses at \"],[0,[16],1,\"ICONIQ Capital\"],[0,[],0,\", where I sourced and co-led investments in leading B2B software and internet companies like \"],[0,[17],1,\"GitLab\"],[0,[],0,\", \"],[0,[18],1,\"Epic Games (Fortnite)\"],[0,[],0,\", \"],[0,[19],1,\"ezCater\"],[0,[],0,\", and \"],[0,[20],1,\"Brightwheel\"],[0,[],0,\" and and additionally invested in others like \"],[0,[21],1,\"Age of Learning\"],[0,[],0,\", \"],[0,[22],1,\"Alteryx (AYX)\"],[0,[],0,\", \"],[0,[23],1,\"Fastly (FSLY)\"],[0,[],0,\", \"],[0,[24],1,\"Relativity\"],[0,[],0,\", \"],[0,[25],1,\"SurveyMonkey (SVMK)\"],[0,[],0,\", and \"],[0,[26],1,\"Uber (UBER)\"],[0,[],0,\". My first gig out of school was Technology, Media, and Telecommunications investment banking at \"],[0,[27],1,\"J.P. Morgan\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"I got my MBA from the \"],[0,[28],1,\"Stanford Graduate School of Business\"],[0,[],0,\". As a grad student, I worked at \"],[0,[29],1,\"Confluent\"],[0,[],0,\" as a product manager, took advanced computer science courses, and served as Co-President and Vice President of the Venture Capital and Tech Clubs, respectively.\"]]],[1,\"p\",[[0,[],0,\"I studied Economics at \"],[0,[30],1,\"Yale University\"],[0,[],0,\". While there, I worked at \"],[0,[31],1,\"McKinsey & Company\"],[0,[],0,\" and on campus as a Student Tech, helping my fellow students solve their most dire computer problems.\"]]],[1,\"p\",[[0,[],0,\"I was selected for \"],[0,[32],1,\"Forbes 30 Under 30 Venture Capital\"],[0,[],0,\" and \"],[0,[33],1,\"Venture Capital Journal 40 Under 40\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Connect with me on \"],[0,[34],1,\"LinkedIn\"],[0,[],0,\" or \"],[0,[35],1,\"Twitter\"],[0,[],0,\".\"]]],[10,4],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}","html":"<figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2019/12/headshot_500_cropped.jpeg\" class=\"kg-image\" alt loading=\"lazy\"></figure><!--kg-card-begin: html--><h2 style=\"text-align: center\">My mission:</h2>\n<p style=\"text-align:center; font-weight: bold\">To increase total software output by supporting entrepreneurs building technical tools for technical people</p><!--kg-card-end: html--><hr><h3 id=\"my-most-popular-essays-\">My most popular essays:</h3><ul><li><a href=\"__GHOST_URL__/never-enough-developers/\">Why We Will Never Have Enough Software Developers</a> (Popular on Reddit)</li><li><a href=\"__GHOST_URL__/software-fat-tailed/\">Enterprise Software Monetization is Fat-Tailed</a></li><li><a href=\"https://whoisnnamdi.com/grow-valuation/\">Companies Rarely Grow Into Their Valuations</a></li><li><a href=\"https://whoisnnamdi.com/the-developer-productivity-flywheel/\">The Developer Productivity Manifesto</a></li><li><a href=\"__GHOST_URL__/remote-software-developers-earn-more/\">Remote Software Developers Earn 22% More Than Non-Remote Developers</a> (#1 on Hacker News)</li><li><a href=\"__GHOST_URL__/high-retention-high-volatility/\">High Retention = High Volatility</a></li><li><a href=\"__GHOST_URL__/you-dont-understand-compound-growth/\">You Don't Understand Compound Growth</a></li></ul><hr><h3 id=\"more-about-me-\">More about me:</h3><p>I'm a geek at heart.</p><p>I've been fascinated by technology for as long as I can remember. I spent countless hours as a teenager building computers (currently rocking a <s>7700K</s> 8700K / <s>7800 </s> <s>980 Ti</s> <s>1080 Ti</s> 3090 combo), coding up websites (R.I.P. PHP), and finding ways to game Google search (SEO is not what it used to be though). These days I spend just as many hours doing statistical analysis in Python, toying with neural networks (highly recommend Stanford's deep learning-based NLP class <a href=\"http://web.stanford.edu/class/cs224n/\">CS 224N</a> and computer vision class <a href=\"http://cs231n.stanford.edu/\">CS 231N</a>), experimenting with open source software, and advising startups on product and growth initiatives.</p><p>I love applying rigorous analytical frameworks and mental models to tough problems at the center of technology, business, and life. In the last few years I've been exploring <a href=\"__GHOST_URL__/developer-productivity-trends/\">developer productivity tools</a>, application infrastructure, and machine learning in the enterprise.</p><p>I'm a <a href=\"https://lsvp.com/team/nnamdi-iregbulem/\">Partner</a> at <a href=\"https://lsvp.com\">Lightspeed Venture Partners</a>, where I work with <a href=\"https://whoisnnamdi.com/portfolio/\">companies</a> like <a href=\"https://redpanda.com/\">Redpanda</a>, <a href=\"https://materialize.com/\">Materialize</a>, and others. I spent four formative years investing in growth-stage technology businesses at <a href=\"http://iconiqcapital.com/\">ICONIQ Capital</a>, where I sourced and co-led investments in leading B2B software and internet companies like <a href=\"https://about.gitlab.com/\">GitLab</a>, <a href=\"https://www.epicgames.com\">Epic Games (Fortnite)</a>, <a href=\"https://www.ezcater.com/\">ezCater</a>, and <a href=\"https://mybrightwheel.com/\">Brightwheel</a> and and additionally invested in others like <a href=\"https://www.ageoflearning.com/\">Age of Learning</a>, <a href=\"https://www.alteryx.com/\">Alteryx (AYX)</a>, <a href=\"https://www.fastly.com/\">Fastly (FSLY)</a>, <a href=\"https://www.relativity.com/\">Relativity</a>, <a href=\"https://www.surveymonkey.com/\">SurveyMonkey (SVMK)</a>, and <a href=\"https://www.uber.com/\">Uber (UBER)</a>. My first gig out of school was Technology, Media, and Telecommunications investment banking at <a href=\"https://www.jpmorgan.com/\">J.P. Morgan</a>.</p><p>I got my MBA from the <a href=\"https://www.gsb.stanford.edu/\">Stanford Graduate School of Business</a>. As a grad student, I worked at <a href=\"https://www.confluent.io/\">Confluent</a> as a product manager, took advanced computer science courses, and served as Co-President and Vice President of the Venture Capital and Tech Clubs, respectively.</p><p>I studied Economics at <a href=\"https://www.yale.edu/\">Yale University</a>. While there, I worked at <a href=\"https://www.mckinsey.com/\">McKinsey &amp; Company</a> and on campus as a Student Tech, helping my fellow students solve their most dire computer problems.</p><p>I was selected for <a href=\"https://www.forbes.com/profile/nnamdi-iregbulem/?sh=2774f2426190\">Forbes 30 Under 30 Venture Capital</a> and <a href=\"https://www.venturecapitaljournal.com/40-rising-stars-to-tap-into-in-2022/\">Venture Capital Journal 40 Under 40</a>.</p><p>Connect with me on <a href=\"https://www.linkedin.com/in/nnamdiiregbulem/\">LinkedIn</a> or <a href=\"https://twitter.com/whoisnnamdi\">Twitter</a>.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Sign-up to receive my latest essays</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Your Email Address\" id=\"mce-EMAIL\" required>\n<input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: About Me\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span>Go âš¡</span></button>\n</form>\n            </section><!--kg-card-end: html-->","comment_id":"5bb11e148a06ff33062ced72","plaintext":"My mission:\nTo increase total software output by supporting entrepreneurs building technical\ntools for technical people\n\n\n--------------------------------------------------------------------------------\n\nMy most popular essays:\n * Why We Will Never Have Enough Software Developers\n   [__GHOST_URL__/never-enough-developers/] (Popular on Reddit)\n * Enterprise Software Monetization is Fat-Tailed\n   [__GHOST_URL__/software-fat-tailed/]\n * Companies Rarely Grow Into Their Valuations\n   [https://whoisnnamdi.com/grow-valuation/]\n * The Developer Productivity Manifesto\n   [https://whoisnnamdi.com/the-developer-productivity-flywheel/]\n * Remote Software Developers Earn 22% More Than Non-Remote Developers\n   [__GHOST_URL__/remote-software-developers-earn-more/] (#1 on Hacker\n   News)\n * High Retention = High Volatility\n   [__GHOST_URL__/high-retention-high-volatility/]\n * You Don't Understand Compound Growth\n   [__GHOST_URL__/you-dont-understand-compound-growth/]\n\n\n--------------------------------------------------------------------------------\n\nMore about me:\nI'm a geek at heart.\n\nI've been fascinated by technology for as long as I can remember. I spent\ncountless hours as a teenager building computers (currently rocking a 7700K \n8700K / 7800 980 Ti 1080 Ti 3090 combo), coding up websites (R.I.P. PHP), and\nfinding ways to game Google search (SEO is not what it used to be though). These\ndays I spend just as many hours doing statistical analysis in Python, toying\nwith neural networks (highly recommend Stanford's deep learning-based NLP class \nCS 224N [http://web.stanford.edu/class/cs224n/] and computer vision class CS\n231N [http://cs231n.stanford.edu/]), experimenting with open source software,\nand advising startups on product and growth initiatives.\n\nI love applying rigorous analytical frameworks and mental models to tough\nproblems at the center of technology, business, and life. In the last few years\nI've been exploring developer productivity tools\n[https://nnamdi.net/developer-productivity-trends/], application infrastructure,\nand machine learning in the enterprise.\n\nI'm a Partner [https://lsvp.com/team/nnamdi-iregbulem/] at Lightspeed Venture\nPartners [https://lsvp.com], where I work with companies\n[https://whoisnnamdi.com/portfolio/] like Redpanda [https://redpanda.com/], \nMaterialize [https://materialize.com/], and others. I spent four formative years\ninvesting in growth-stage technology businesses at ICONIQ Capital\n[http://iconiqcapital.com/], where I sourced and co-led investments in leading\nB2B software and internet companies like GitLab [https://about.gitlab.com/], \nEpic Games (Fortnite) [https://www.epicgames.com], ezCater\n[https://www.ezcater.com/], and Brightwheel [https://mybrightwheel.com/] and and\nadditionally invested in others like Age of Learning\n[https://www.ageoflearning.com/], Alteryx (AYX) [https://www.alteryx.com/], \nFastly (FSLY) [https://www.fastly.com/], Relativity\n[https://www.relativity.com/], SurveyMonkey (SVMK)\n[https://www.surveymonkey.com/], and Uber (UBER) [https://www.uber.com/]. My\nfirst gig out of school was Technology, Media, and Telecommunications investment\nbanking at J.P. Morgan [https://www.jpmorgan.com/].\n\nI got my MBA from the Stanford Graduate School of Business\n[https://www.gsb.stanford.edu/]. As a grad student, I worked at Confluent\n[https://www.confluent.io/] as a product manager, took advanced computer science\ncourses, and served as Co-President and Vice President of the Venture Capital\nand Tech Clubs, respectively.\n\nI studied Economics at Yale University [https://www.yale.edu/]. While there, I\nworked at McKinsey & Company [https://www.mckinsey.com/] and on campus as a\nStudent Tech, helping my fellow students solve their most dire computer\nproblems.\n\nI was selected for Forbes 30 Under 30 Venture Capital\n[https://www.forbes.com/profile/nnamdi-iregbulem/?sh=2774f2426190] and Venture\nCapital Journal 40 Under 40\n[https://www.venturecapitaljournal.com/40-rising-stars-to-tap-into-in-2022/].\n\nConnect with me on LinkedIn [https://www.linkedin.com/in/nnamdiiregbulem/] or \nTwitter [https://twitter.com/whoisnnamdi].\n\nSign-up to receive my latest essays\n\n\nGo âš¡","feature_image":null,"featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2018-09-30T19:03:48.000Z","updated_at":"2024-03-11T22:53:55.000Z","published_at":"2018-09-30T19:21:25.000Z","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"page","email_recipient_filter":"none"},{"id":"5be9ff528307ee772c1bbb06","uuid":"4f0158b4-5627-4da0-9f7b-54dd710e4174","title":"The Growth-Share Matrix of Software Development","slug":"the-growth-share-matrix-of-software-development","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"caption\":\"\",\"src\":\"https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ&s=59773981c4a4762fe474590959ddf064\",\"alt\":\"Matrix movie still\"}],[\"image\",{\"src\":\"/content/images/2018/11/growth_share_matrix-3.png\"}],[\"html\",{\"html\":\"<!-- Begin Mailchimp Signup Form -->\\n<link href=\\\"//cdn-images.mailchimp.com/embedcode/horizontal-slim-10_7.css\\\" rel=\\\"stylesheet\\\" type=\\\"text/css\\\">\\n<style type=\\\"text/css\\\">\\n\\t#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\\n</style>\\n<div id=\\\"mc_embed_signup\\\">\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div id=\\\"mc_embed_signup_scroll\\\" align=\\\"center\\\">\\n\\t<label for=\\\"mce-EMAIL\\\" style=\\\"font-size:20px\\\">Receive more long-form posts on the business of tech</label>\\n\\t<input type=\\\"email\\\" value=\\\"\\\" name=\\\"EMAIL\\\" class=\\\"email\\\" id=\\\"mce-EMAIL\\\" placeholder=\\\"email address\\\" required>\\n    <div style=\\\"position: absolute; left: -5000px;\\\" aria-hidden=\\\"true\\\"><input type=\\\"text\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" value=\\\"\\\"></div>\\n    <div class=\\\"clear\\\"><input type=\\\"submit\\\" value=\\\"Subscribe\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\" class=\\\"button\\\" style=\\\"background-color:#bf3939\\\"></div>\\n    </div>\\n</form>\\n</div>\\n\\n<!--End mc_embed_signup-->\"}],[\"image\",{\"src\":\"https://images.unsplash.com/photo-1481015172496-8cfcb0d85e59?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ&s=c67577076a4f8934b61e78fa16a91909\",\"caption\":\"\",\"alt\":\"pink star ornament decor\"}],[\"image\",{\"src\":\"https://images.unsplash.com/photo-1446126102442-f6b2b73257fd?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ&s=7147b447746e0bd07fed39b36de70c9a\",\"caption\":\"\",\"alt\":\"black and white dairy cow on green grasses during daytime\"}],[\"html\",{\"html\":\"<!-- Begin Mailchimp Signup Form -->\\n<link href=\\\"//cdn-images.mailchimp.com/embedcode/horizontal-slim-10_7.css\\\" rel=\\\"stylesheet\\\" type=\\\"text/css\\\">\\n<style type=\\\"text/css\\\">\\n\\t#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\\n</style>\\n<div id=\\\"mc_embed_signup\\\">\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div id=\\\"mc_embed_signup_scroll\\\" align=\\\"center\\\">\\n\\t<label for=\\\"mce-EMAIL\\\" style=\\\"font-size:20px\\\">Receive more long-form posts on the business of tech</label>\\n\\t<input type=\\\"email\\\" value=\\\"\\\" name=\\\"EMAIL\\\" class=\\\"email\\\" id=\\\"mce-EMAIL\\\" placeholder=\\\"email address\\\" required>\\n    <div style=\\\"position: absolute; left: -5000px;\\\" aria-hidden=\\\"true\\\"><input type=\\\"text\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" value=\\\"\\\"></div>\\n    <div class=\\\"clear\\\"><input type=\\\"submit\\\" value=\\\"Subscribe\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\" class=\\\"button\\\" style=\\\"background-color:#bf3939\\\"></div>\\n    </div>\\n</form>\\n</div>\\n\\n<!--End mc_embed_signup-->\"}],[\"image\",{\"src\":\"https://images.unsplash.com/photo-1484069560501-87d72b0c3669?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ&s=8248324d302ce16e516054824000b147\",\"caption\":\"\",\"alt\":\"question mark neon signage\"}],[\"image\",{\"src\":\"/content/images/2018/11/doge.jpg\"}],[\"image\",{\"src\":\"https://images.unsplash.com/photo-1523006520266-d3a4a8152803?ixlib=rb-0.3.5&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=1080&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ&s=fc3154037ad3cd02837b7591d6dc1424\",\"caption\":\"\",\"alt\":\"person holding pen\"}]],\"markups\":[[\"strong\"],[\"a\",[\"href\",\"__GHOST_URL__/you-dont-understand-compound-growth/\"]],[\"a\",[\"href\",\"https://www.economist.com/news/2009/09/11/growth-share-matrix\"]],[\"em\"],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Lingua_franca\"]],[\"a\",[\"href\",\"https://insights.stackoverflow.com/survey/\"]],[\"a\",[\"href\",\"https://insights.stackoverflow.com/survey/2018/\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Python_(programming_language)\"]],[\"a\",[\"href\",\"https://rubyonrails.org/\"]],[\"a\",[\"href\",\"https://www.techrepublic.com/article/the-death-of-ruby-developers-should-learn-these-languages-instead/\"]],[\"a\",[\"href\",\"https://medium.com/@kevalpatel2106/why-should-you-learn-go-f607681fad65\"]],[\"a\",[\"href\",\"https://thenewstack.io/typescript-getting-popular/\"]],[\"a\",[\"href\",\"https://www.simplytechnologies.net/blog/2018/4/11/why-is-javascript-so-popular\"]],[\"a\",[\"href\",\"https://raygun.com/blog/popular-javascript-frameworks/\"]],[\"a\",[\"href\",\"https://www.geeksforgeeks.org/difference-between-java-and-javascript/\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Write_once,_run_anywhere\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Bytecode\"]],[\"a\",[\"href\",\"https://www.mongodb.com/nosql-explained\"]],[\"a\",[\"href\",\"https://stackify.com/popular-programming-languages-2018/\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Programming_languages_used_in_most_popular_websites\"]],[\"a\",[\"href\",\"https://eev.ee/blog/2012/04/09/php-a-fractal-of-bad-design/\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/SQL_injection\"]],[\"a\",[\"href\",\"https://9to5mac.com/2018/03/09/swift-ranking-programming-languages/\"]],[\"a\",[\"href\",\"https://medium.com/mozilla-tech/why-rust-is-the-most-loved-language-by-developers-666add782563\"]],[\"a\",[\"href\",\"https://dzone.com/articles/the-rise-and-fall-of-scala\"]],[\"a\",[\"href\",\"https://www.datacamp.com/community/tutorials/r-or-python-for-data-analysis\"]],[\"a\",[\"href\",\"https://blog.revolutionanalytics.com/2018/08/r-generation.html\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Purely_functional_programming\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Lazy_evaluation\"]],[\"a\",[\"href\",\"https://arstechnica.com/information-technology/2017/02/microsofts-developer-strategy-c-for-fancy-features-visual-basic-for-beginners/\"]],[\"a\",[\"href\",\"https://docs.microsoft.com/en-us/previous-versions/visualstudio/visual-basic-6/visual-basic-6-support-policy\"]],[\"a\",[\"href\",\"https://gitlab.com/whoisnnamdi/growth-share-matrix\"]],[\"a\",[\"href\",\"https://github.com/whoisnnamdi/growth-share-matrix\"]],[\"a\",[\"href\",\"http://www.productschool.com\"]]],\"sections\":[[1,\"p\",[[0,[0],1,\"Human capital is our greatest asset.\"]]],[1,\"p\",[[0,[],0,\"Like financial capital, \"],[0,[1],1,\"the all-powerful force of compound growth\"],[0,[],0,\" means that a small difference in the rate of skill acquisition over time can lead to massive differences in career outcomes.\"]]],[1,\"p\",[[0,[],0,\"Choosing which skills to hone is therefore one of the most important keys to professional growth and success in any arena.\"]]],[1,\"p\",[[0,[],0,\"Among various forms of human capital, \"],[0,[0],1,\"technical aptitude\"],[0,[],0,\" is quickly becoming \"],[0,[0],1,\"the\"],[0,[],0,\" mission-critical skill for 21st century knowledge work.\"]]],[1,\"p\",[[0,[],0,\"However, there are any number of technologies that one could dive deep into and attempt to master, with varying usefulness and practical applicability.\"]]],[1,\"p\",[[0,[0],1,\"So how does one decide where to \\\"invest\\\" among a sea of options?\"]]],[1,\"p\",[[0,[],0,\"A mental model I've found surprisingly helpful for this task is the \"],[0,[2],1,\"growth-share matrix\"],[0,[],0,\", a framework concocted 50 years ago by the Boston Consulting Group.\"]]],[1,\"p\",[[0,[],0,\"The framework was originally conceived as a tool to help executives prioritize different business units based on their respective relative market shares and growth. The two dimensions separate the market landscape into quadrants, each with certain characteristics:\"]]],[3,\"ul\",[[[0,[],0,\"Stars (High Growth / High Share)\"]],[[0,[],0,\"Cash cows (Low Growth / High Share)\"]],[[0,[],0,\"Question marks (High Growth / Low Share)\"]],[[0,[],0,\"Dogs (Low Growth / Low Share)\"]]]],[1,\"p\",[[0,[],0,\"BCG advised clients to invest in the stars, exploit the cows for their cash flow, evaluate the potential of the question marks, and exit or sell the dogs ASAP.\"]]],[1,\"p\",[[0,[],0,\"The growth-share matrix was originally intended to apply to product lines or business units - an asset a corporation could \"],[0,[3],1,\"own\"],[0,[],0,\". In that respect, you might imagine this framework has limited applicability to programming languages, given no single person \\\"owns\\\" any given language.\"]]],[1,\"p\",[[0,[],0,\"Not so fast!\"]]],[1,\"p\",[[0,[],0,\"I argue that we each \"],[0,[3],1,\"do\"],[0,[],0,\" own a little piece of a programming language, not in the form of equity or stock, but in the form of \"],[0,[0],1,\"human capital\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Through careful curation of a \\\"portfolio\\\" of useful skills, we earn a return on our learning efforts - rewards for our time and effort.\"]]],[1,\"p\",[[0,[],0,\"Learning a programming language is a \"],[0,[3],1,\"perfect\"],[0,[],0,\" example of this.\"]]],[1,\"p\",[[0,[],0,\"But what makes a programming language \"],[0,[3],1,\"useful\"],[0,[],0,\"?\"]]],[1,\"p\",[[0,[0],1,\"The value of any given programming language is a direct derivative of the number of other individuals who know that language and the number of companies using that language to develop and ship products.\"]]],[1,\"p\",[[0,[],0,\"That may sound obvious to some, but it is in fact quite counter-intuitive.\"]]],[1,\"p\",[[0,[],0,\"In most of life's skills we seek to master the rare things - the things no one else can do. We think that by differentiating ourselves through a unique set of talents we will shine brighter in an increasingly competitive world. Learning that which is rare will pay meaningful dividends, so the thinking goes.\"]]],[1,\"p\",[[0,[],0,\"While yes, knowing an obscure language that few others have familiarity with might carve out a nice niche in the market for you to charge highly for your rare talents, I would argue that, for most, it is actually \"],[0,[3],1,\"more \"],[0,[],0,\"valuable to know a language that \"],[0,[0],1,\"lots of other people also know\"],[0,[],0,\", rather than one only a few have ever worked with.\"]]],[1,\"p\",[[0,[],0,\"Most people think that programming is how you speak to \"],[0,[3],1,\"computers\"],[0,[],0,\". Really, it's how you speak to \"],[0,[0],1,\"other developers\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Due to network effects and the increasing size, scale, and scope of software development projects and teams, knowing the \\\"\"],[0,[4],1,\"lingua franca\"],[0,[],0,\"\\\" is \"],[0,[0],1,\"much more\"],[0,[],0,\" valuable than being an expert in some endangered language, soon to be discarded to the trash bin on the desktop of history.\"]]],[1,\"p\",[[0,[],0,\"Paradoxically, having low \"],[0,[3],1,\"personal\"],[0,[],0,\" market share in a high market share \"],[0,[3],1,\"language\"],[0,[],0,\" is actually not such a bad thing.\"]]],[1,\"h2\",[[0,[],0,\"Building the Matrix\"]]],[10,0],[1,\"p\",[[0,[],0,\"To construct the growth-share matrix for programming languages, we will leverage StackOverflow's \"],[0,[5],1,\"annual developer survey\"],[0,[],0,\". For the \"],[0,[6],1,\"2018 edition\"],[0,[],0,\", they surveyed over 100,000 developers from around the world, covering a wide range of topics from job satisfaction to salary. Here we'll focus on US-based developers.\"]]],[1,\"p\",[[0,[],0,\"The key question for our purposes is:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"Which of the following programming, scripting, and markup languages have you done extensive development work in over the past year?â€\"]]],[1,\"p\",[[0,[],0,\"Answers to this question should give us a rough proxy of the popularity of any given language, as defined by the proportion of developers who have worked with a particular language.\"]]],[1,\"p\",[[0,[],0,\"For growth, we can compare the answers to this question across 2017 and 2018 to come up with an estimate of the growth of each language. We'll define growth as the % growth rate of the proportion of respondents who've worked with the language in the past year. So, a language that went from 10% coverage to 13% would be considered to have grown 30% (rather than 3 percentage points).\"]]],[1,\"p\",[[0,[],0,\"Quadrant boundaries will be set at the median growth rate and relative market share.\"]]],[1,\"p\",[[0,[],0,\"One final piece - as is convention with the growth-share matrix, we will show market share relative to the language with the most market share. Therefore, the axis will end at 100% (representing the most popular language). We will also show this on a log scale to better showcase the distribution, which tends to be quite crowded below 10% relative market share.\"]]],[1,\"p\",[[0,[],0,\"We now have all we need to build our growth-share matrix!\"]]],[1,\"h2\",[[0,[],0,\"Inside the Matrix\"]]],[1,\"p\",[[0,[],0,\"Take a look at the results:\"]]],[10,1],[1,\"p\",[[0,[],0,\"One striking feature that immediately jumps out - very few languages saw a net decline in popularity. \"],[0,[0],1,\"Almost every language grew\"],[0,[],0,\", which by definition implies that the average developer is using an increasingly wide array of languages in their work.\"]]],[1,\"p\",[[0,[],0,\"Letâ€™s spin through each quadrant and discuss some of the highlights.\"]]],[10,2],[1,\"p\",[[0,[],0,\" \"]]],[1,\"h2\",[[0,[],0,\"Stars\"]]],[10,3],[1,\"p\",[[0,[0,3],2,\"Python\"],[0,[3],1,\" - \"],[0,[7],1,\"Python has existed for decades\"],[0,[],0,\" but only recently hit its stride as a go-to language for data analytics and machine learning use cases. Python is widely-regarded as one of the best languages for data-driven analysis given its relative ease of use and massive set of open source libraries that simplify and accelerate analytics. Python's syntax is quite simple compared to other languages. Ease of use and speed are especially important in data science, as data scientists often run and re-run numerous iterations of a model before settling on a preferred specification. The growing popularity of interactive and replicable computing environments like Jupyter notebooks dovetails nicely with Python's surging share among developers. I'm personally quite pleased to see Python's high popularity given I've spent the past 2 years self-teaching myself the language!\"]]],[1,\"p\",[[0,[0,3],2,\"Ruby\"],[0,[3],1,\" - \"],[0,[],0,\"Ruby has historically been known for its extreme ease of use and strength within web development. Many a web developer wrote their first web app in Ruby. \"],[0,[8],1,\"The Ruby on Rails framework\"],[0,[],0,\" only extended this user-friendliness further, making Ruby incredibly popular among developers who want a no-frills way to quickly develop and deploy functional web applications. For several reasons however, Ruby's growth is slowing and has been for a few years now. \"],[0,[9],1,\"No, Ruby is not â€œdeadâ€\"],[0,[],0,\", but it will likely migrate to the cash cow zone soon as the initial fanfare wears off. Ruby continues to be a great language that serves developers well.\"]]],[1,\"p\",[[0,[0,3],2,\"Go\"],[0,[3],1,\" - \"],[0,[],0,\"A new language seeing \"],[0,[10],1,\"rapid adoption\"],[0,[],0,\" among developers, Go simplifies the process of writing code, thereby making developers more efficient. Go was initially birthed at Google, where technical teams were trying to solve engineering problems that only seemed to be multiplying in an era of increasingly large codebases, multicore processors, and network-aware applications. Go is built with concurrency in mind, making it relatively easy to build multi-threaded applications. Outside of Google, major companies making use of Go include Uber, Netflix, Adobe, IBM, Intel, Dropbox, CloudFlare, and more.\"]]],[1,\"p\",[[0,[0,3],2,\"TypeScript\"],[0,[3],1,\" - \"],[0,[],0,\"I debated including TypeScript as its own language here given its strong similarities to and overlap with JavaScript, but developers with experience in the language seem to be a distinct group worth highlighting. The language has also seen a \"],[0,[11],1,\"surge of growth\"],[0,[],0,\" in the past few years. The fundamental goal of TypeScript is to ease development of large-scale applications that would otherwise be written in vanilla JavaScript. Accordingly, TypeScript is a superset of JavaScript that also compiles to simple JavaScript. Why the distinction then? Typescript adds a number of features to core JavaScript common to other languages, such as classes and modules, in addition to strong typing, generics and interfaces. TypeScript is developed and maintained by Microsoft.\"]]],[1,\"p\",[[0,[0],1,\"Takeaway\"],[0,[],0,\" - These languages are highly popular and would constitute a solid foundation any budding developer or product manager. If you don't already have basic proficiency in at least some of the stars - I implore you: \"],[0,[0],1,\"learn these growing tools of the trade\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"Cash Cows\"]]],[10,4],[1,\"p\",[[0,[0,3],2,\"JavaScript\"],[0,[3],1,\" - \"],[0,[12],1,\"JavaScript has become the go-to language\"],[0,[],0,\" for modern web development, with a number of \"],[0,[13],1,\"spin-off frameworks\"],[0,[],0,\" that leverage its core elements. JavaScript is more popular than Java today, due to the ubiquity of web applications today and the move SaaS and other web-based models for application consumption. Here, JavaScript is leading the charge, and the numbers reflect that. However, it should be noted that, despite similar nomenclature, \"],[0,[14],1,\"Java and JavaScript are not closely related\"],[0,[],0,\" (it's a long story). Both are object-oriented, but the similarities end there.\"]]],[1,\"p\",[[0,[0,3],2,\"Java\"],[0,[],0,\" - Java has long been a popular language for cross-platform development, and this flexibility has continued as new platforms have emerged, such as mobile. One of Java's many conventions is the idea of \\\"\"],[0,[15],1,\"write once, run anywhere\"],[0,[],0,\"\\\", meaning that code written in Java can be run on any other platform that supports Java with no recompiling. When complete, Java applications are compiled into \"],[0,[16],1,\"bytecode\"],[0,[],0,\" which runs on a Java Virtual Machine. Originally built by Sun Microsystems, through acquisitions it's ended up in the hands of Oracle today.\"]]],[1,\"p\",[[0,[0,3],2,\"SQL\"],[0,[3],1,\" - \"],[0,[],0,\"SQL (Structured Query Language) is an old workhorse that needs no introduction. It has existed for quite some time and is the main means by which analysts query and pull data from relational databases and data warehouses. Despite the popularity of â€œ\"],[0,[17],1,\"NoSQL\"],[0,[],0,\"â€ and other non-relational frameworks, \"],[0,[13],1,\"SQL remains king\"],[0,[],0,\", and in recent years many of these other frameworks have bolted on SQL-like interfaces in order to ease data extraction and transformation. As companies collect data from a greater range of diverse sources and continue to store this information in central databases, SQL will only increase in importance.\"]]],[1,\"p\",[[0,[0,3],2,\"The C Family \"],[0,[3],1,\"- \"],[0,[],0,\"No big surprise here - the extended family of C languages has held a strong position within the software development community for some time and continues to serve as the backbone for many critical applications we know and love today. Further, C has found its way into other languages as well. For example, the reference implementation of Python, CPython, is written in C and Python, and significant chunks of the core Python codebase are actually written in C due to it being a compiled (rather than interpreted) language and thus having faster performance at runtime. \"],[0,[18],1,\"C is a hugely influential language\"],[0,[],0,\" that will not be going away any time soon.\"]]],[1,\"p\",[[0,[0,3],2,\"PHP\"],[0,[3],1,\" - \"],[0,[],0,\"PHP lands squarely in the cash cow category. PHP is a server-side scripting language primarily suited for web development, as evidenced by its original meaning of â€œpersonal home page\\\". \"],[0,[19],1,\"Numerous popular websites and web applications are built on PHP\"],[0,[],0,\", including, perhaps mostly famously, WordPress. However, the language has stagnated in terms of popularity, in part to due to its \"],[0,[20],1,\"clunkiness\"],[0,[],0,\" and security vulnerabilities, where PHP has historically suffered from a number of severe exploits (ex: \"],[0,[21],1,\"SQL injection\"],[0,[],0,\"). That said, this is another language with incredible market share that will continue to see broad use for quite some time.\"]]],[1,\"p\",[[0,[3,0],2,\"Swift\"],[0,[],0,\" - The popularity of Swift derives directly from the underlying popularity of macOS and iOS devices which, though a minority of overall smartphone shipments, represents a massive install base, especially among more affluent western populations. Launched in 2014, Swift initially saw massive growth, \"],[0,[22],1,\"becoming one of the fastest growing languages in history\"],[0,[],0,\". Swift is heavily influenced by Objective-C, another cash cow, which it recently surpassed in popularity. As the brainchild of Apple, Swift will live or die by Apple's own success, so plan accordingly.\"]]],[1,\"p\",[[0,[0],1,\"Takeaway\"],[0,[],0,\" - These languages really pay the bills. If you are already proficient in any of the above languages, great, leverage that saved time to pick up some skills in the rising stars. If you do not know these languages well today, evaluate how practical / necessary they are for the specific set of projects you want to work on now or in the near future.\"]]],[10,5],[1,\"p\",[]],[1,\"h2\",[[0,[],0,\"Question marks\"]]],[10,6],[1,\"p\",[[0,[0,3],2,\"Rust\"],[0,[3],1,\" - \"],[0,[],0,\"Rust is a relatively new programming language that only appeared on the scene in the last decade. While Rust is technically a general-purpose language, due to its low-level nature, it is best used for embedded systems running close to bare metal. Comparisons are often made between Rust and C++, in part driven by their syntactic similarities. \"],[0,[23],1,\"Rust is often known to create enthusiastic fans among its users\"],[0,[],0,\". Though far from being one of the more popular languages, it is truly loved by the people who use it most. Development on Rust is quite active today, ensuring the language will stay on the bleeding edge for the foreseeable future.\"]]],[1,\"p\",[[0,[3,0],1,\"Scala\"],[0,[],1,\" - \"],[0,[],0,\"Like Go, Scala is language oriented towards improving developer productivity. The name Scala is a portmanteau of \\\"scalable\\\" and \\\"language\\\", which hints at original intent of the language to enable high performance of large-scale applications and userbases. Scala is built on JVM and JavaScript runtimes and combines elements of object-oriented and functional programming. Due to these strong connections, Scala is often seen as \\\"next-gen\\\" Java. Scala is uniquely suited for parallel and distributed computing, providing a level of future-proofing that many legacy languages lack. Though popular among a certain subset of developers, its growth appears to have \"],[0,[24],1,\"prematurely slowed\"],[0,[],0,\" relative to languages like Go or Rust. Its boosters hope that Scala may one day overtake Java, but this won't happen for some time, if ever.\"]]],[1,\"p\",[[0,[3,0],2,\"R\"],[0,[],0,\" - R slightly missed the cutoff for star status, but given its incredible ~40% growth rate the language will easily cross the boundary next year. R is exploding in popularity for the same reasons as Python, though \"],[0,[25],1,\"most consider Python to be relative winner\"],[0,[],0,\" in terms of speed, ease of use and general applicability. R's historical strength in data science and statistical analysis is now powering a major renaissance for R. Enthusiasts celebrated \"],[0,[26],1,\"R's 25th anniversary\"],[0,[],0,\" earlier this year, and with the helpful tailwind of data science, the language shows no signs of slowing down.\"]]],[1,\"p\",[[0,[3,0],2,\"Haskell\"],[0,[],0,\" - Function over form, or in the case of Haskell, have both. Haskell is a \"],[0,[27],1,\"purely functional\"],[0,[],0,\" programming language, meaning that the language focuses on functions that take immutable values as input and produce the exact same output every single time. It's also \"],[0,[28],1,\"lazy\"],[0,[],0,\", which simply means results are not evaluated until absolutely necessary. These and other features make Haskell a very powerful and efficient language in the right hands but also potentially limit its applicability. Haskell's cult following is growing rapidly from its small base, but it's hard to say how long this will continue.\"]]],[1,\"p\",[[0,[0],1,\"Takeaway\"],[0,[],0,\" - They're called \"],[0,[3],1,\"question marks\"],[0,[],0,\" for a reason. No one really knows how the future will play out for these emerging technologies. They are probably not worth betting the farm on today, but they are also prime candidates for becoming the next \\\"must-know\\\" tools among forward-looking dev teams. Keep an eye on them.\"]]],[1,\"h2\",[[0,[],0,\"Dogs\"]]],[10,7],[1,\"p\",[[0,[0,3],2,\"Visual Basic (All Flavors) \"],[0,[],0,\"- VB.NET, VBA, VB6 - whichever your flavor, the Visual Basic ecosystem has clearly fallen from grace. VB.NET is one of only two languages in the growth-share matrix to actually lose share in 2018. \"],[0,[29],1,\"Significant chunks of VB's functionality exist in C# now\"],[0,[],0,\", and Microsoft's stance towards the languages has not been 100% clear, having gone from originally planning to end support for the language in 2008 to recently declaring that \"],[0,[30],1,\"Windows 10 will support the VB runtime\"],[0,[],0,\" for the lifetime of the OS. This is great for legacy applications built using Visual Basic, but these will inevitably need to be rewritten in a modern language or be end-of-lifed.\"]]],[1,\"p\",[[0,[0],1,\"Takeaway\"],[0,[],0,\" - Unlike real dogs, dogs within the growth-share matrix are bound to be controversial. Developers and development teams need to seriously grapple with the current state of affairs these languages face and whether or not it's advisable to spend significant time and resources building applications powered by these less popular languages.\"]]],[1,\"h2\",[[0,[],0,\"(Human) Capital Allocation\"]]],[10,8],[1,\"p\",[[0,[],0,\"The moral of the story - \"],[0,[0],1,\"think critically about where to invest your time\"],[0,[],0,\". \"]]],[1,\"p\",[[0,[],0,\"To be clear - itâ€™s not the end of the world if you pick the â€œwrongâ€ language. In fact, there really arenâ€™t any wrong choices here, even the \\\"dogs\\\". \"],[0,[0],1,\"Use the best tool for the job. \"],[0,[],0,\"However, it certainly helps to avoid the transition costs inherent in trying to reposition oneself or play catch up later on.\"]]],[1,\"p\",[[0,[],0,\"If anything, donâ€™t try to reposition yourself \"],[0,[3],1,\"per se\"],[0,[],0,\", but rather, seek to enhance your overall value and breadth of capabilities by acquiring at least intermediate mastery in several different languages. Again, similar to spoken languages, people who can converse in multiple valuable languages often gain disproportionate value from their learning efforts, which tend to \"],[0,[1],1,\"compound on one another\"],[0,[],0,\", especially when learning the basic features which form the building blocks of many dialects.\"]]],[1,\"p\",[[0,[],0,\"Remember, this mental model, though imperfect, is arguably flexible enough to accommodate many skills, \"],[0,[3],1,\"not just programming\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"I hope this framework is useful to you as you decide where to grow your human capital as a technically savvy individual.\"]]],[1,\"p\",[[0,[3],0,\"You can find the full backup to this analysis in both Jupyter notebook and .py script format at my \"],[0,[31],1,\"GitLab\"],[0,[],0,\" or \"],[0,[32],1,\"GitHub\"],[0,[],1,\".\"]]],[1,\"p\",[[0,[3],0,\"This post has been published on \"],[0,[33],1,\"www.productschool.com\"],[0,[],1,\" communities\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p><strong>Human capital is our greatest asset.</strong></p><p>Like financial capital, <a href=\"__GHOST_URL__/you-dont-understand-compound-growth/\">the all-powerful force of compound growth</a> means that a small difference in the rate of skill acquisition over time can lead to massive differences in career outcomes.</p><p>Choosing which skills to hone is therefore one of the most important keys to professional growth and success in any arena.</p><p>Among various forms of human capital, <strong>technical aptitude</strong> is quickly becoming <strong>the</strong> mission-critical skill for 21st century knowledge work.</p><p>However, there are any number of technologies that one could dive deep into and attempt to master, with varying usefulness and practical applicability.</p><p><strong>So how does one decide where to \"invest\" among a sea of options?</strong></p><p>A mental model I've found surprisingly helpful for this task is the <a href=\"https://www.economist.com/news/2009/09/11/growth-share-matrix\">growth-share matrix</a>, a framework concocted 50 years ago by the Boston Consulting Group.</p><p>The framework was originally conceived as a tool to help executives prioritize different business units based on their respective relative market shares and growth. The two dimensions separate the market landscape into quadrants, each with certain characteristics:</p><ul><li>Stars (High Growth / High Share)</li><li>Cash cows (Low Growth / High Share)</li><li>Question marks (High Growth / Low Share)</li><li>Dogs (Low Growth / Low Share)</li></ul><p>BCG advised clients to invest in the stars, exploit the cows for their cash flow, evaluate the potential of the question marks, and exit or sell the dogs ASAP.</p><p>The growth-share matrix was originally intended to apply to product lines or business units - an asset a corporation could <em>own</em>. In that respect, you might imagine this framework has limited applicability to programming languages, given no single person \"owns\" any given language.</p><p>Not so fast!</p><p>I argue that we each <em>do</em> own a little piece of a programming language, not in the form of equity or stock, but in the form of <strong>human capital</strong>.</p><p>Through careful curation of a \"portfolio\" of useful skills, we earn a return on our learning efforts - rewards for our time and effort.</p><p>Learning a programming language is a <em>perfect</em> example of this.</p><p>But what makes a programming language <em>useful</em>?</p><p><strong>The value of any given programming language is a direct derivative of the number of other individuals who know that language and the number of companies using that language to develop and ship products.</strong></p><p>That may sound obvious to some, but it is in fact quite counter-intuitive.</p><p>In most of life's skills we seek to master the rare things - the things no one else can do. We think that by differentiating ourselves through a unique set of talents we will shine brighter in an increasingly competitive world. Learning that which is rare will pay meaningful dividends, so the thinking goes.</p><p>While yes, knowing an obscure language that few others have familiarity with might carve out a nice niche in the market for you to charge highly for your rare talents, I would argue that, for most, it is actually <em>more </em>valuable to know a language that <strong>lots of other people also know</strong>, rather than one only a few have ever worked with.</p><p>Most people think that programming is how you speak to <em>computers</em>. Really, it's how you speak to <strong>other developers</strong>.</p><p>Due to network effects and the increasing size, scale, and scope of software development projects and teams, knowing the \"<a href=\"https://en.wikipedia.org/wiki/Lingua_franca\">lingua franca</a>\" is <strong>much more</strong> valuable than being an expert in some endangered language, soon to be discarded to the trash bin on the desktop of history.</p><p>Paradoxically, having low <em>personal</em> market share in a high market share <em>language</em> is actually not such a bad thing.</p><h2 id=\"building-the-matrix\">Building the Matrix</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://images.unsplash.com/photo-1526374965328-7f61d4dc18c5?ixlib=rb-0.3.5&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ&amp;s=59773981c4a4762fe474590959ddf064\" class=\"kg-image\" alt=\"Matrix movie still\" loading=\"lazy\"></figure><p>To construct the growth-share matrix for programming languages, we will leverage StackOverflow's <a href=\"https://insights.stackoverflow.com/survey/\">annual developer survey</a>. For the <a href=\"https://insights.stackoverflow.com/survey/2018/\">2018 edition</a>, they surveyed over 100,000 developers from around the world, covering a wide range of topics from job satisfaction to salary. Here we'll focus on US-based developers.</p><p>The key question for our purposes is:</p><blockquote>\"Which of the following programming, scripting, and markup languages have you done extensive development work in over the past year?â€</blockquote><p>Answers to this question should give us a rough proxy of the popularity of any given language, as defined by the proportion of developers who have worked with a particular language.</p><p>For growth, we can compare the answers to this question across 2017 and 2018 to come up with an estimate of the growth of each language. We'll define growth as the % growth rate of the proportion of respondents who've worked with the language in the past year. So, a language that went from 10% coverage to 13% would be considered to have grown 30% (rather than 3 percentage points).</p><p>Quadrant boundaries will be set at the median growth rate and relative market share.</p><p>One final piece - as is convention with the growth-share matrix, we will show market share relative to the language with the most market share. Therefore, the axis will end at 100% (representing the most popular language). We will also show this on a log scale to better showcase the distribution, which tends to be quite crowded below 10% relative market share.</p><p>We now have all we need to build our growth-share matrix!</p><h2 id=\"inside-the-matrix\">Inside the Matrix</h2><p>Take a look at the results:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2018/11/growth_share_matrix-3.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>One striking feature that immediately jumps out - very few languages saw a net decline in popularity. <strong>Almost every language grew</strong>, which by definition implies that the average developer is using an increasingly wide array of languages in their work.</p><p>Letâ€™s spin through each quadrant and discuss some of the highlights.</p><!--kg-card-begin: html--><!-- Begin Mailchimp Signup Form -->\n<link href=\"//cdn-images.mailchimp.com/embedcode/horizontal-slim-10_7.css\" rel=\"stylesheet\" type=\"text/css\">\n<style type=\"text/css\">\n\t#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\n</style>\n<div id=\"mc_embed_signup\">\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div id=\"mc_embed_signup_scroll\" align=\"center\">\n\t<label for=\"mce-EMAIL\" style=\"font-size:20px\">Receive more long-form posts on the business of tech</label>\n\t<input type=\"email\" value=\"\" name=\"EMAIL\" class=\"email\" id=\"mce-EMAIL\" placeholder=\"email address\" required>\n    <div style=\"position: absolute; left: -5000px;\" aria-hidden=\"true\"><input type=\"text\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" value=\"\"></div>\n    <div class=\"clear\"><input type=\"submit\" value=\"Subscribe\" name=\"subscribe\" id=\"mc-embedded-subscribe\" class=\"button\" style=\"background-color:#bf3939\"></div>\n    </div>\n</form>\n</div>\n\n<!--End mc_embed_signup--><!--kg-card-end: html--><p> </p><h2 id=\"stars\">Stars</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://images.unsplash.com/photo-1481015172496-8cfcb0d85e59?ixlib=rb-0.3.5&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ&amp;s=c67577076a4f8934b61e78fa16a91909\" class=\"kg-image\" alt=\"pink star ornament decor\" loading=\"lazy\"></figure><p><strong><em>Python</em></strong><em> - </em><a href=\"https://en.wikipedia.org/wiki/Python_(programming_language)\">Python has existed for decades</a> but only recently hit its stride as a go-to language for data analytics and machine learning use cases. Python is widely-regarded as one of the best languages for data-driven analysis given its relative ease of use and massive set of open source libraries that simplify and accelerate analytics. Python's syntax is quite simple compared to other languages. Ease of use and speed are especially important in data science, as data scientists often run and re-run numerous iterations of a model before settling on a preferred specification. The growing popularity of interactive and replicable computing environments like Jupyter notebooks dovetails nicely with Python's surging share among developers. I'm personally quite pleased to see Python's high popularity given I've spent the past 2 years self-teaching myself the language!</p><p><strong><em>Ruby</em></strong><em> - </em>Ruby has historically been known for its extreme ease of use and strength within web development. Many a web developer wrote their first web app in Ruby. <a href=\"https://rubyonrails.org/\">The Ruby on Rails framework</a> only extended this user-friendliness further, making Ruby incredibly popular among developers who want a no-frills way to quickly develop and deploy functional web applications. For several reasons however, Ruby's growth is slowing and has been for a few years now. <a href=\"https://www.techrepublic.com/article/the-death-of-ruby-developers-should-learn-these-languages-instead/\">No, Ruby is not â€œdeadâ€</a>, but it will likely migrate to the cash cow zone soon as the initial fanfare wears off. Ruby continues to be a great language that serves developers well.</p><p><strong><em>Go</em></strong><em> - </em>A new language seeing <a href=\"https://medium.com/@kevalpatel2106/why-should-you-learn-go-f607681fad65\">rapid adoption</a> among developers, Go simplifies the process of writing code, thereby making developers more efficient. Go was initially birthed at Google, where technical teams were trying to solve engineering problems that only seemed to be multiplying in an era of increasingly large codebases, multicore processors, and network-aware applications. Go is built with concurrency in mind, making it relatively easy to build multi-threaded applications. Outside of Google, major companies making use of Go include Uber, Netflix, Adobe, IBM, Intel, Dropbox, CloudFlare, and more.</p><p><strong><em>TypeScript</em></strong><em> - </em>I debated including TypeScript as its own language here given its strong similarities to and overlap with JavaScript, but developers with experience in the language seem to be a distinct group worth highlighting. The language has also seen a <a href=\"https://thenewstack.io/typescript-getting-popular/\">surge of growth</a> in the past few years. The fundamental goal of TypeScript is to ease development of large-scale applications that would otherwise be written in vanilla JavaScript. Accordingly, TypeScript is a superset of JavaScript that also compiles to simple JavaScript. Why the distinction then? Typescript adds a number of features to core JavaScript common to other languages, such as classes and modules, in addition to strong typing, generics and interfaces. TypeScript is developed and maintained by Microsoft.</p><p><strong>Takeaway</strong> - These languages are highly popular and would constitute a solid foundation any budding developer or product manager. If you don't already have basic proficiency in at least some of the stars - I implore you: <strong>learn these growing tools of the trade</strong>.</p><h2 id=\"cash-cows\">Cash Cows</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://images.unsplash.com/photo-1446126102442-f6b2b73257fd?ixlib=rb-0.3.5&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ&amp;s=7147b447746e0bd07fed39b36de70c9a\" class=\"kg-image\" alt=\"black and white dairy cow on green grasses during daytime\" loading=\"lazy\"></figure><p><strong><em>JavaScript</em></strong><em> - </em><a href=\"https://www.simplytechnologies.net/blog/2018/4/11/why-is-javascript-so-popular\">JavaScript has become the go-to language</a> for modern web development, with a number of <a href=\"https://raygun.com/blog/popular-javascript-frameworks/\">spin-off frameworks</a> that leverage its core elements. JavaScript is more popular than Java today, due to the ubiquity of web applications today and the move SaaS and other web-based models for application consumption. Here, JavaScript is leading the charge, and the numbers reflect that. However, it should be noted that, despite similar nomenclature, <a href=\"https://www.geeksforgeeks.org/difference-between-java-and-javascript/\">Java and JavaScript are not closely related</a> (it's a long story). Both are object-oriented, but the similarities end there.</p><p><strong><em>Java</em></strong> - Java has long been a popular language for cross-platform development, and this flexibility has continued as new platforms have emerged, such as mobile. One of Java's many conventions is the idea of \"<a href=\"https://en.wikipedia.org/wiki/Write_once,_run_anywhere\">write once, run anywhere</a>\", meaning that code written in Java can be run on any other platform that supports Java with no recompiling. When complete, Java applications are compiled into <a href=\"https://en.wikipedia.org/wiki/Bytecode\">bytecode</a> which runs on a Java Virtual Machine. Originally built by Sun Microsystems, through acquisitions it's ended up in the hands of Oracle today.</p><p><strong><em>SQL</em></strong><em> - </em>SQL (Structured Query Language) is an old workhorse that needs no introduction. It has existed for quite some time and is the main means by which analysts query and pull data from relational databases and data warehouses. Despite the popularity of â€œ<a href=\"https://www.mongodb.com/nosql-explained\">NoSQL</a>â€ and other non-relational frameworks, <a href=\"https://raygun.com/blog/popular-javascript-frameworks/\">SQL remains king</a>, and in recent years many of these other frameworks have bolted on SQL-like interfaces in order to ease data extraction and transformation. As companies collect data from a greater range of diverse sources and continue to store this information in central databases, SQL will only increase in importance.</p><p><strong><em>The C Family </em></strong><em>- </em>No big surprise here - the extended family of C languages has held a strong position within the software development community for some time and continues to serve as the backbone for many critical applications we know and love today. Further, C has found its way into other languages as well. For example, the reference implementation of Python, CPython, is written in C and Python, and significant chunks of the core Python codebase are actually written in C due to it being a compiled (rather than interpreted) language and thus having faster performance at runtime. <a href=\"https://stackify.com/popular-programming-languages-2018/\">C is a hugely influential language</a> that will not be going away any time soon.</p><p><strong><em>PHP</em></strong><em> - </em>PHP lands squarely in the cash cow category. PHP is a server-side scripting language primarily suited for web development, as evidenced by its original meaning of â€œpersonal home page\". <a href=\"https://en.wikipedia.org/wiki/Programming_languages_used_in_most_popular_websites\">Numerous popular websites and web applications are built on PHP</a>, including, perhaps mostly famously, WordPress. However, the language has stagnated in terms of popularity, in part to due to its <a href=\"https://eev.ee/blog/2012/04/09/php-a-fractal-of-bad-design/\">clunkiness</a> and security vulnerabilities, where PHP has historically suffered from a number of severe exploits (ex: <a href=\"https://en.wikipedia.org/wiki/SQL_injection\">SQL injection</a>). That said, this is another language with incredible market share that will continue to see broad use for quite some time.</p><p><em><strong>Swift</strong></em> - The popularity of Swift derives directly from the underlying popularity of macOS and iOS devices which, though a minority of overall smartphone shipments, represents a massive install base, especially among more affluent western populations. Launched in 2014, Swift initially saw massive growth, <a href=\"https://9to5mac.com/2018/03/09/swift-ranking-programming-languages/\">becoming one of the fastest growing languages in history</a>. Swift is heavily influenced by Objective-C, another cash cow, which it recently surpassed in popularity. As the brainchild of Apple, Swift will live or die by Apple's own success, so plan accordingly.</p><p><strong>Takeaway</strong> - These languages really pay the bills. If you are already proficient in any of the above languages, great, leverage that saved time to pick up some skills in the rising stars. If you do not know these languages well today, evaluate how practical / necessary they are for the specific set of projects you want to work on now or in the near future.</p><!--kg-card-begin: html--><!-- Begin Mailchimp Signup Form -->\n<link href=\"//cdn-images.mailchimp.com/embedcode/horizontal-slim-10_7.css\" rel=\"stylesheet\" type=\"text/css\">\n<style type=\"text/css\">\n\t#mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;}\n</style>\n<div id=\"mc_embed_signup\">\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div id=\"mc_embed_signup_scroll\" align=\"center\">\n\t<label for=\"mce-EMAIL\" style=\"font-size:20px\">Receive more long-form posts on the business of tech</label>\n\t<input type=\"email\" value=\"\" name=\"EMAIL\" class=\"email\" id=\"mce-EMAIL\" placeholder=\"email address\" required>\n    <div style=\"position: absolute; left: -5000px;\" aria-hidden=\"true\"><input type=\"text\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" value=\"\"></div>\n    <div class=\"clear\"><input type=\"submit\" value=\"Subscribe\" name=\"subscribe\" id=\"mc-embedded-subscribe\" class=\"button\" style=\"background-color:#bf3939\"></div>\n    </div>\n</form>\n</div>\n\n<!--End mc_embed_signup--><!--kg-card-end: html--><p></p><h2 id=\"question-marks\">Question marks</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://images.unsplash.com/photo-1484069560501-87d72b0c3669?ixlib=rb-0.3.5&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ&amp;s=8248324d302ce16e516054824000b147\" class=\"kg-image\" alt=\"question mark neon signage\" loading=\"lazy\"></figure><p><strong><em>Rust</em></strong><em> - </em>Rust is a relatively new programming language that only appeared on the scene in the last decade. While Rust is technically a general-purpose language, due to its low-level nature, it is best used for embedded systems running close to bare metal. Comparisons are often made between Rust and C++, in part driven by their syntactic similarities. <a href=\"https://medium.com/mozilla-tech/why-rust-is-the-most-loved-language-by-developers-666add782563\">Rust is often known to create enthusiastic fans among its users</a>. Though far from being one of the more popular languages, it is truly loved by the people who use it most. Development on Rust is quite active today, ensuring the language will stay on the bleeding edge for the foreseeable future.</p><p><em><strong>Scala</strong> - </em>Like Go, Scala is language oriented towards improving developer productivity. The name Scala is a portmanteau of \"scalable\" and \"language\", which hints at original intent of the language to enable high performance of large-scale applications and userbases. Scala is built on JVM and JavaScript runtimes and combines elements of object-oriented and functional programming. Due to these strong connections, Scala is often seen as \"next-gen\" Java. Scala is uniquely suited for parallel and distributed computing, providing a level of future-proofing that many legacy languages lack. Though popular among a certain subset of developers, its growth appears to have <a href=\"https://dzone.com/articles/the-rise-and-fall-of-scala\">prematurely slowed</a> relative to languages like Go or Rust. Its boosters hope that Scala may one day overtake Java, but this won't happen for some time, if ever.</p><p><em><strong>R</strong></em> - R slightly missed the cutoff for star status, but given its incredible ~40% growth rate the language will easily cross the boundary next year. R is exploding in popularity for the same reasons as Python, though <a href=\"https://www.datacamp.com/community/tutorials/r-or-python-for-data-analysis\">most consider Python to be relative winner</a> in terms of speed, ease of use and general applicability. R's historical strength in data science and statistical analysis is now powering a major renaissance for R. Enthusiasts celebrated <a href=\"https://blog.revolutionanalytics.com/2018/08/r-generation.html\">R's 25th anniversary</a> earlier this year, and with the helpful tailwind of data science, the language shows no signs of slowing down.</p><p><em><strong>Haskell</strong></em> - Function over form, or in the case of Haskell, have both. Haskell is a <a href=\"https://en.wikipedia.org/wiki/Purely_functional_programming\">purely functional</a> programming language, meaning that the language focuses on functions that take immutable values as input and produce the exact same output every single time. It's also <a href=\"https://en.wikipedia.org/wiki/Lazy_evaluation\">lazy</a>, which simply means results are not evaluated until absolutely necessary. These and other features make Haskell a very powerful and efficient language in the right hands but also potentially limit its applicability. Haskell's cult following is growing rapidly from its small base, but it's hard to say how long this will continue.</p><p><strong>Takeaway</strong> - They're called <em>question marks</em> for a reason. No one really knows how the future will play out for these emerging technologies. They are probably not worth betting the farm on today, but they are also prime candidates for becoming the next \"must-know\" tools among forward-looking dev teams. Keep an eye on them.</p><h2 id=\"dogs\">Dogs</h2><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2018/11/doge.jpg\" class=\"kg-image\" alt loading=\"lazy\"></figure><p><strong><em>Visual Basic (All Flavors) </em></strong>- VB.NET, VBA, VB6 - whichever your flavor, the Visual Basic ecosystem has clearly fallen from grace. VB.NET is one of only two languages in the growth-share matrix to actually lose share in 2018. <a href=\"https://arstechnica.com/information-technology/2017/02/microsofts-developer-strategy-c-for-fancy-features-visual-basic-for-beginners/\">Significant chunks of VB's functionality exist in C# now</a>, and Microsoft's stance towards the languages has not been 100% clear, having gone from originally planning to end support for the language in 2008 to recently declaring that <a href=\"https://docs.microsoft.com/en-us/previous-versions/visualstudio/visual-basic-6/visual-basic-6-support-policy\">Windows 10 will support the VB runtime</a> for the lifetime of the OS. This is great for legacy applications built using Visual Basic, but these will inevitably need to be rewritten in a modern language or be end-of-lifed.</p><p><strong>Takeaway</strong> - Unlike real dogs, dogs within the growth-share matrix are bound to be controversial. Developers and development teams need to seriously grapple with the current state of affairs these languages face and whether or not it's advisable to spend significant time and resources building applications powered by these less popular languages.</p><h2 id=\"-human-capital-allocation\">(Human) Capital Allocation</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://images.unsplash.com/photo-1523006520266-d3a4a8152803?ixlib=rb-0.3.5&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=1080&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ&amp;s=fc3154037ad3cd02837b7591d6dc1424\" class=\"kg-image\" alt=\"person holding pen\" loading=\"lazy\"></figure><p>The moral of the story - <strong>think critically about where to invest your time</strong>. </p><p>To be clear - itâ€™s not the end of the world if you pick the â€œwrongâ€ language. In fact, there really arenâ€™t any wrong choices here, even the \"dogs\". <strong>Use the best tool for the job. </strong>However, it certainly helps to avoid the transition costs inherent in trying to reposition oneself or play catch up later on.</p><p>If anything, donâ€™t try to reposition yourself <em>per se</em>, but rather, seek to enhance your overall value and breadth of capabilities by acquiring at least intermediate mastery in several different languages. Again, similar to spoken languages, people who can converse in multiple valuable languages often gain disproportionate value from their learning efforts, which tend to <a href=\"__GHOST_URL__/you-dont-understand-compound-growth/\">compound on one another</a>, especially when learning the basic features which form the building blocks of many dialects.</p><p>Remember, this mental model, though imperfect, is arguably flexible enough to accommodate many skills, <em>not just programming</em>.</p><p>I hope this framework is useful to you as you decide where to grow your human capital as a technically savvy individual.</p><p><em>You can find the full backup to this analysis in both Jupyter notebook and .py script format at my <a href=\"https://gitlab.com/whoisnnamdi/growth-share-matrix\">GitLab</a> or <a href=\"https://github.com/whoisnnamdi/growth-share-matrix\">GitHub</a>.</em></p><p><em>This post has been published on <a href=\"http://www.productschool.com\">www.productschool.com</a> communities</em></p>","comment_id":"5be9ff528307ee772c1bbb06","plaintext":"Human capital is our greatest asset.\n\nLike financial capital, the all-powerful force of compound growth\n[__GHOST_URL__/you-dont-understand-compound-growth/] means that a small\ndifference in the rate of skill acquisition over time can lead to massive\ndifferences in career outcomes.\n\nChoosing which skills to hone is therefore one of the most important keys to\nprofessional growth and success in any arena.\n\nAmong various forms of human capital, technical aptitude is quickly becoming the \nmission-critical skill for 21st century knowledge work.\n\nHowever, there are any number of technologies that one could dive deep into and\nattempt to master, with varying usefulness and practical applicability.\n\nSo how does one decide where to \"invest\" among a sea of options?\n\nA mental model I've found surprisingly helpful for this task is the \ngrowth-share\nmatrix [https://www.economist.com/news/2009/09/11/growth-share-matrix], a\nframework concocted 50 years ago by the Boston Consulting Group.\n\nThe framework was originally conceived as a tool to help executives prioritize\ndifferent business units based on their respective relative market shares and\ngrowth. The two dimensions separate the market landscape into quadrants, each\nwith certain characteristics:\n\n * Stars (High Growth / High Share)\n * Cash cows (Low Growth / High Share)\n * Question marks (High Growth / Low Share)\n * Dogs (Low Growth / Low Share)\n\nBCG advised clients to invest in the stars, exploit the cows for their cash\nflow, evaluate the potential of the question marks, and exit or sell the dogs\nASAP.\n\nThe growth-share matrix was originally intended to apply to product lines or\nbusiness units - an asset a corporation could own. In that respect, you might\nimagine this framework has limited applicability to programming languages, given\nno single person \"owns\" any given language.\n\nNot so fast!\n\nI argue that we each do own a little piece of a programming language, not in the\nform of equity or stock, but in the form of human capital.\n\nThrough careful curation of a \"portfolio\" of useful skills, we earn a return on\nour learning efforts - rewards for our time and effort.\n\nLearning a programming language is a perfect example of this.\n\nBut what makes a programming language useful?\n\nThe value of any given programming language is a direct derivative of the number\nof other individuals who know that language and the number of companies using\nthat language to develop and ship products.\n\nThat may sound obvious to some, but it is in fact quite counter-intuitive.\n\nIn most of life's skills we seek to master the rare things - the things no one\nelse can do. We think that by differentiating ourselves through a unique set of\ntalents we will shine brighter in an increasingly competitive world. Learning\nthat which is rare will pay meaningful dividends, so the thinking goes.\n\nWhile yes, knowing an obscure language that few others have familiarity with\nmight carve out a nice niche in the market for you to charge highly for your\nrare talents, I would argue that, for most, it is actually more valuable to know\na language that lots of other people also know, rather than one only a few have\never worked with.\n\nMost people think that programming is how you speak to computers. Really, it's\nhow you speak to other developers.\n\nDue to network effects and the increasing size, scale, and scope of software\ndevelopment projects and teams, knowing the \"lingua franca\n[https://en.wikipedia.org/wiki/Lingua_franca]\" is much more valuable than being\nan expert in some endangered language, soon to be discarded to the trash bin on\nthe desktop of history.\n\nParadoxically, having low personal market share in a high market share language \nis actually not such a bad thing.\n\nBuilding the Matrix\nTo construct the growth-share matrix for programming languages, we will leverage\nStackOverflow's annual developer survey\n[https://insights.stackoverflow.com/survey/]. For the 2018 edition\n[https://insights.stackoverflow.com/survey/2018/], they surveyed over 100,000\ndevelopers from around the world, covering a wide range of topics from job\nsatisfaction to salary. Here we'll focus on US-based developers.\n\nThe key question for our purposes is:\n\n> \"Which of the following programming, scripting, and markup languages have you\ndone extensive development work in over the past year?â€\nAnswers to this question should give us a rough proxy of the popularity of any\ngiven language, as defined by the proportion of developers who have worked with\na particular language.\n\nFor growth, we can compare the answers to this question across 2017 and 2018 to\ncome up with an estimate of the growth of each language. We'll define growth as\nthe % growth rate of the proportion of respondents who've worked with the\nlanguage in the past year. So, a language that went from 10% coverage to 13%\nwould be considered to have grown 30% (rather than 3 percentage points).\n\nQuadrant boundaries will be set at the median growth rate and relative market\nshare.\n\nOne final piece - as is convention with the growth-share matrix, we will show\nmarket share relative to the language with the most market share. Therefore, the\naxis will end at 100% (representing the most popular language). We will also\nshow this on a log scale to better showcase the distribution, which tends to be\nquite crowded below 10% relative market share.\n\nWe now have all we need to build our growth-share matrix!\n\nInside the Matrix\nTake a look at the results:\n\nOne striking feature that immediately jumps out - very few languages saw a net\ndecline in popularity. Almost every language grew, which by definition implies\nthat the average developer is using an increasingly wide array of languages in\ntheir work.\n\nLetâ€™s spin through each quadrant and discuss some of the highlights.\n\nReceive more long-form posts on the business of tech  \n\nStars\nPython - Python has existed for decades\n[https://en.wikipedia.org/wiki/Python_(programming_language)] but only recently\nhit its stride as a go-to language for data analytics and machine learning use\ncases. Python is widely-regarded as one of the best languages for data-driven\nanalysis given its relative ease of use and massive set of open source libraries\nthat simplify and accelerate analytics. Python's syntax is quite simple compared\nto other languages. Ease of use and speed are especially important in data\nscience, as data scientists often run and re-run numerous iterations of a model\nbefore settling on a preferred specification. The growing popularity of\ninteractive and replicable computing environments like Jupyter notebooks\ndovetails nicely with Python's surging share among developers. I'm personally\nquite pleased to see Python's high popularity given I've spent the past 2 years\nself-teaching myself the language!\n\nRuby - Ruby has historically been known for its extreme ease of use and strength\nwithin web development. Many a web developer wrote their first web app in Ruby. \nThe Ruby on Rails framework [https://rubyonrails.org/] only extended this\nuser-friendliness further, making Ruby incredibly popular among developers who\nwant a no-frills way to quickly develop and deploy functional web applications.\nFor several reasons however, Ruby's growth is slowing and has been for a few\nyears now. No, Ruby is not â€œdeadâ€\n[https://www.techrepublic.com/article/the-death-of-ruby-developers-should-learn-these-languages-instead/]\n, but it will likely migrate to the cash cow zone soon as the initial fanfare\nwears off. Ruby continues to be a great language that serves developers well.\n\nGo - A new language seeing rapid adoption\n[https://medium.com/@kevalpatel2106/why-should-you-learn-go-f607681fad65] among\ndevelopers, Go simplifies the process of writing code, thereby making developers\nmore efficient. Go was initially birthed at Google, where technical teams were\ntrying to solve engineering problems that only seemed to be multiplying in an\nera of increasingly large codebases, multicore processors, and network-aware\napplications. Go is built with concurrency in mind, making it relatively easy to\nbuild multi-threaded applications. Outside of Google, major companies making use\nof Go include Uber, Netflix, Adobe, IBM, Intel, Dropbox, CloudFlare, and more.\n\nTypeScript - I debated including TypeScript as its own language here given its\nstrong similarities to and overlap with JavaScript, but developers with\nexperience in the language seem to be a distinct group worth highlighting. The\nlanguage has also seen a surge of growth\n[https://thenewstack.io/typescript-getting-popular/] in the past few years. The\nfundamental goal of TypeScript is to ease development of large-scale\napplications that would otherwise be written in vanilla JavaScript. Accordingly,\nTypeScript is a superset of JavaScript that also compiles to simple JavaScript.\nWhy the distinction then? Typescript adds a number of features to core\nJavaScript common to other languages, such as classes and modules, in addition\nto strong typing, generics and interfaces. TypeScript is developed and\nmaintained by Microsoft.\n\nTakeaway - These languages are highly popular and would constitute a solid\nfoundation any budding developer or product manager. If you don't already have\nbasic proficiency in at least some of the stars - I implore you: learn these\ngrowing tools of the trade.\n\nCash Cows\nJavaScript - JavaScript has become the go-to language\n[https://www.simplytechnologies.net/blog/2018/4/11/why-is-javascript-so-popular] \nfor modern web development, with a number of spin-off frameworks\n[https://raygun.com/blog/popular-javascript-frameworks/] that leverage its core\nelements. JavaScript is more popular than Java today, due to the ubiquity of web\napplications today and the move SaaS and other web-based models for application\nconsumption. Here, JavaScript is leading the charge, and the numbers reflect\nthat. However, it should be noted that, despite similar nomenclature, Java and\nJavaScript are not closely related\n[https://www.geeksforgeeks.org/difference-between-java-and-javascript/] (it's a\nlong story). Both are object-oriented, but the similarities end there.\n\nJava - Java has long been a popular language for cross-platform development, and\nthis flexibility has continued as new platforms have emerged, such as mobile.\nOne of Java's many conventions is the idea of \"write once, run anywhere\n[https://en.wikipedia.org/wiki/Write_once,_run_anywhere]\", meaning that code\nwritten in Java can be run on any other platform that supports Java with no\nrecompiling. When complete, Java applications are compiled into bytecode\n[https://en.wikipedia.org/wiki/Bytecode] which runs on a Java Virtual Machine.\nOriginally built by Sun Microsystems, through acquisitions it's ended up in the\nhands of Oracle today.\n\nSQL - SQL (Structured Query Language) is an old workhorse that needs no\nintroduction. It has existed for quite some time and is the main means by which\nanalysts query and pull data from relational databases and data warehouses.\nDespite the popularity of â€œNoSQL [https://www.mongodb.com/nosql-explained]â€ and\nother non-relational frameworks, SQL remains king\n[https://raygun.com/blog/popular-javascript-frameworks/], and in recent years\nmany of these other frameworks have bolted on SQL-like interfaces in order to\nease data extraction and transformation. As companies collect data from a\ngreater range of diverse sources and continue to store this information in\ncentral databases, SQL will only increase in importance.\n\nThe C Family - No big surprise here - the extended family of C languages has\nheld a strong position within the software development community for some time\nand continues to serve as the backbone for many critical applications we know\nand love today. Further, C has found its way into other languages as well. For\nexample, the reference implementation of Python, CPython, is written in C and\nPython, and significant chunks of the core Python codebase are actually written\nin C due to it being a compiled (rather than interpreted) language and thus\nhaving faster performance at runtime. C is a hugely influential language\n[https://stackify.com/popular-programming-languages-2018/] that will not be\ngoing away any time soon.\n\nPHP - PHP lands squarely in the cash cow category. PHP is a server-side\nscripting language primarily suited for web development, as evidenced by its\noriginal meaning of â€œpersonal home page\". Numerous popular websites and web\napplications are built on PHP\n[https://en.wikipedia.org/wiki/Programming_languages_used_in_most_popular_websites]\n, including, perhaps mostly famously, WordPress. However, the language has\nstagnated in terms of popularity, in part to due to its clunkiness\n[https://eev.ee/blog/2012/04/09/php-a-fractal-of-bad-design/] and security\nvulnerabilities, where PHP has historically suffered from a number of severe\nexploits (ex: SQL injection [https://en.wikipedia.org/wiki/SQL_injection]). That\nsaid, this is another language with incredible market share that will continue\nto see broad use for quite some time.\n\nSwift - The popularity of Swift derives directly from the underlying popularity\nof macOS and iOS devices which, though a minority of overall smartphone\nshipments, represents a massive install base, especially among more affluent\nwestern populations. Launched in 2014, Swift initially saw massive growth, \nbecoming one of the fastest growing languages in history\n[https://9to5mac.com/2018/03/09/swift-ranking-programming-languages/]. Swift is\nheavily influenced by Objective-C, another cash cow, which it recently surpassed\nin popularity. As the brainchild of Apple, Swift will live or die by Apple's own\nsuccess, so plan accordingly.\n\nTakeaway - These languages really pay the bills. If you are already proficient\nin any of the above languages, great, leverage that saved time to pick up some\nskills in the rising stars. If you do not know these languages well today,\nevaluate how practical / necessary they are for the specific set of projects you\nwant to work on now or in the near future.\n\nReceive more long-form posts on the business of tech \n\nQuestion marks\nRust - Rust is a relatively new programming language that only appeared on the\nscene in the last decade. While Rust is technically a general-purpose language,\ndue to its low-level nature, it is best used for embedded systems running close\nto bare metal. Comparisons are often made between Rust and C++, in part driven\nby their syntactic similarities. Rust is often known to create enthusiastic\nfans\namong its users\n[https://medium.com/mozilla-tech/why-rust-is-the-most-loved-language-by-developers-666add782563]\n. Though far from being one of the more popular languages, it is truly loved by\nthe people who use it most. Development on Rust is quite active today, ensuring\nthe language will stay on the bleeding edge for the foreseeable future.\n\nScala - Like Go, Scala is language oriented towards improving developer\nproductivity. The name Scala is a portmanteau of \"scalable\" and \"language\",\nwhich hints at original intent of the language to enable high performance of\nlarge-scale applications and userbases. Scala is built on JVM and JavaScript\nruntimes and combines elements of object-oriented and functional programming.\nDue to these strong connections, Scala is often seen as \"next-gen\" Java. Scala\nis uniquely suited for parallel and distributed computing, providing a level of\nfuture-proofing that many legacy languages lack. Though popular among a certain\nsubset of developers, its growth appears to have prematurely slowed\n[https://dzone.com/articles/the-rise-and-fall-of-scala] relative to languages\nlike Go or Rust. Its boosters hope that Scala may one day overtake Java, but\nthis won't happen for some time, if ever.\n\nR - R slightly missed the cutoff for star status, but given its incredible ~40%\ngrowth rate the language will easily cross the boundary next year. R is\nexploding in popularity for the same reasons as Python, though most consider\nPython to be relative winner\n[https://www.datacamp.com/community/tutorials/r-or-python-for-data-analysis] in\nterms of speed, ease of use and general applicability. R's historical strength\nin data science and statistical analysis is now powering a major renaissance for\nR. Enthusiasts celebrated R's 25th anniversary\n[https://blog.revolutionanalytics.com/2018/08/r-generation.html] earlier this\nyear, and with the helpful tailwind of data science, the language shows no signs\nof slowing down.\n\nHaskell - Function over form, or in the case of Haskell, have both. Haskell is a \npurely functional [https://en.wikipedia.org/wiki/Purely_functional_programming] \nprogramming language, meaning that the language focuses on functions that take\nimmutable values as input and produce the exact same output every single time.\nIt's also lazy [https://en.wikipedia.org/wiki/Lazy_evaluation], which simply\nmeans results are not evaluated until absolutely necessary. These and other\nfeatures make Haskell a very powerful and efficient language in the right hands\nbut also potentially limit its applicability. Haskell's cult following is\ngrowing rapidly from its small base, but it's hard to say how long this will\ncontinue.\n\nTakeaway - They're called question marks for a reason. No one really knows how\nthe future will play out for these emerging technologies. They are probably not\nworth betting the farm on today, but they are also prime candidates for becoming\nthe next \"must-know\" tools among forward-looking dev teams. Keep an eye on them.\n\nDogs\nVisual Basic (All Flavors) - VB.NET, VBA, VB6 - whichever your flavor, the\nVisual Basic ecosystem has clearly fallen from grace. VB.NET is one of only two\nlanguages in the growth-share matrix to actually lose share in 2018. \nSignificant\nchunks of VB's functionality exist in C# now\n[https://arstechnica.com/information-technology/2017/02/microsofts-developer-strategy-c-for-fancy-features-visual-basic-for-beginners/]\n, and Microsoft's stance towards the languages has not been 100% clear, having\ngone from originally planning to end support for the language in 2008 to\nrecently declaring that Windows 10 will support the VB runtime\n[https://docs.microsoft.com/en-us/previous-versions/visualstudio/visual-basic-6/visual-basic-6-support-policy] \nfor the lifetime of the OS. This is great for legacy applications built using\nVisual Basic, but these will inevitably need to be rewritten in a modern\nlanguage or be end-of-lifed.\n\nTakeaway - Unlike real dogs, dogs within the growth-share matrix are bound to be\ncontroversial. Developers and development teams need to seriously grapple with\nthe current state of affairs these languages face and whether or not it's\nadvisable to spend significant time and resources building applications powered\nby these less popular languages.\n\n(Human) Capital Allocation\nThe moral of the story - think critically about where to invest your time. \n\nTo be clear - itâ€™s not the end of the world if you pick the â€œwrongâ€ language. In\nfact, there really arenâ€™t any wrong choices here, even the \"dogs\". Use the best\ntool for the job. However, it certainly helps to avoid the transition costs\ninherent in trying to reposition oneself or play catch up later on.\n\nIf anything, donâ€™t try to reposition yourself per se, but rather, seek to\nenhance your overall value and breadth of capabilities by acquiring at least\nintermediate mastery in several different languages. Again, similar to spoken\nlanguages, people who can converse in multiple valuable languages often gain\ndisproportionate value from their learning efforts, which tend to compound on\none another [__GHOST_URL__/you-dont-understand-compound-growth/], especially\nwhen learning the basic features which form the building blocks of many\ndialects.\n\nRemember, this mental model, though imperfect, is arguably flexible enough to\naccommodate many skills, not just programming.\n\nI hope this framework is useful to you as you decide where to grow your human\ncapital as a technically savvy individual.\n\nYou can find the full backup to this analysis in both Jupyter notebook and .py\nscript format at my GitLab [https://gitlab.com/whoisnnamdi/growth-share-matrix] \nor GitHub [https://github.com/whoisnnamdi/growth-share-matrix].\n\nThis post has been published on www.productschool.com\n[http://www.productschool.com] communities","feature_image":"__GHOST_URL__/content/images/2018/11/growth_share_matrix_no_title.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2018-11-12T22:31:46.000Z","updated_at":"2021-06-24T18:59:04.000Z","published_at":"2018-11-22T23:45:00.000Z","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5c3705e19e310a4f2c5532b6","uuid":"d371b1f1-04e3-4351-b9a4-4827cf797ec0","title":"Meet Dev, the Highest-Paid Software Developer in America","slug":"highest-paid-software-developer","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"/content/images/2019/01/stack_overflow_salary-1.png\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive a report with the full results</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"youremail@example.com\\\" id=\\\"mce-EMAIL\\\" required>\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span>Send Report</span></button>\\n</form>\\n            </section>\"}],[\"image\",{\"src\":\"/content/images/2019/01/annie-spratt-608001-unsplash-2.jpg\",\"cardWidth\":\"full\"}],[\"image\",{\"src\":\"/content/images/2019/01/age.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/race.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/gender-1.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/sexual_orientation.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/dependents.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/military_us.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/vasily-koloda-620886-unsplash.jpg\",\"cardWidth\":\"full\"}],[\"image\",{\"src\":\"/content/images/2019/01/formal_education.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/undergrad_major.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/education_parents.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/education_types.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/self_taught_types.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/nesa-by-makers-701360-unsplash.jpg\",\"cardWidth\":\"full\"}],[\"image\",{\"src\":\"/content/images/2019/01/years_coding.png\",\"cardWidth\":\"wide\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2019/01/employment.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/dev_type.png\",\"cardWidth\":\"wide\",\"caption\":\"<em>(Read: â€œDevOps specialists make 2% more than non-DevOps specialists, all else equalâ€)</em>\"}],[\"image\",{\"src\":\"/content/images/2019/01/ilya-pavlov-87438-unsplash.jpg\",\"cardWidth\":\"full\"}],[\"image\",{\"src\":\"/content/images/2019/01/languages-1.png\",\"cardWidth\":\"wide\",\"caption\":\"<em>(Read: â€œDevelopers who have done extensive development work involving Golang earn more than those who havenâ€™tâ€)</em>\"}],[\"image\",{\"src\":\"/content/images/2019/01/frameworks.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/databases.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/platforms.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/ide.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/methodology.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/version_control.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/check_in_code.png\",\"cardWidth\":\"wide\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2019/01/communication_tools.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/number_monitors.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"caption\":\"\",\"src\":\"/content/images/2019/01/marion-michele-191320-unsplash.jpg\",\"cardWidth\":\"full\"}],[\"image\",{\"src\":\"/content/images/2019/01/wake_time.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"caption\":\"\",\"src\":\"/content/images/2019/01/exercise.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/skip_meals.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/ergonomic_devices.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/hours_computer.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/hours_outside.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2019/01/hans-peter-gauster-252751-unsplash.jpg\",\"cardWidth\":\"full\"}]],\"markups\":[[\"em\"],[\"strong\"],[\"a\",[\"href\",\"__GHOST_URL__/highest-paid-software-engineers-2020/\"]],[\"a\",[\"href\",\"https://www.navy.com/careers/cyber-warfare-engineer\"]],[\"a\",[\"href\",\"https://online.stanford.edu/programs/computer-science-ms-degree\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/C%2B%2B\"]],[\"a\",[\"href\",\"https://www.agilealliance.org/agile101/\"]],[\"a\",[\"href\",\"http://www.piedpiper.com/\"]],[\"a\",[\"href\",\"https://www.atlassian.com/agile/scrum/sprints\"]],[\"a\",[\"href\",\"http://blog.indeed.com/2017/10/19/tech-ageism-report/\"]],[\"a\",[\"href\",\"__GHOST_URL__/the-growth-share-matrix-of-software-development/\"]],[\"a\",[\"href\",\"https://insights.stackoverflow.com/survey/2018/\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Ceteris_paribus\"]],[\"a\",[\"href\",\"https://www.khanacademy.org/math/ap-statistics/estimating-confidence-ap/introduction-confidence-intervals/v/confidence-intervals-and-margin-of-error\"]],[\"a\",[\"href\",\"https://www.process.st/p-value/\"]],[\"a\",[\"href\",\"__GHOST_URL__/you-dont-understand-compound-growth/\"]],[\"a\",[\"href\",\"https://www.techrepublic.com/article/tech-companies-admit-to-actively-targeting-younger-workers-for-jobs/\"]],[\"a\",[\"href\",\"https://www.eeoc.gov/eeoc/publications/fs-epa.cfm\"]],[\"a\",[\"href\",\"https://www.nytimes.com/2015/08/02/opinion/sunday/were-making-life-too-hard-for-millennials.html\"]],[\"a\",[\"href\",\"https://lambdaschool.com/\"]],[\"a\",[\"href\",\"https://www.cio.com/article/3293010/hiring-and-staffing/10-reasons-to-ignore-computer-science-degrees.html\"]],[\"a\",[\"href\",\"https://www.nytimes.com/2016/09/18/business/itt-educational-services-files-for-bankruptcy-after-aid-crackdown.html\"]],[\"a\",[\"href\",\"https://hackathon.guide/\"]],[\"a\",[\"href\",\"https://www.coursereport.com/reports/2018-coding-bootcamp-market-size-research\"]],[\"a\",[\"href\",\"https://www.creativebloq.com/web-design/online-coding-courses-11513890\"]],[\"a\",[\"href\",\"https://qz.com/766658/the-highest-paid-workers-in-silicon-valley-are-not-software-engineers/\"]],[\"a\",[\"href\",\"https://reactjs.org/\"]],[\"a\",[\"href\",\"https://code.fb.com/ai-research/announcing-pytorch-1-0-for-both-research-and-production/\"]],[\"a\",[\"href\",\"https://www.arduino.cc/\"]],[\"a\",[\"href\",\"https://www.arduino.cc/en/main/education\"]],[\"a\",[\"href\",\"https://trends.google.com/trends/explore?date=all&geo=US&q=drupal\"]],[\"a\",[\"href\",\"https://www.reddit.com/\"]],[\"a\",[\"href\",\"https://thewirecutter.com/reviews/best-standing-desk/\"]],[\"a\",[\"href\",\"https://gitlab.com/whoisnnamdi/highest-paid-software-developer\"]],[\"a\",[\"href\",\"https://github.com/whoisnnamdi/highest-paid-software-developer\"]],[\"a\",[\"href\",\"https://www.cnbc.com/2018/09/06/companies-worry-more-about-access-to-software-developers-than-capital.html\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/1201.0224\"]],[\"a\",[\"href\",\"https://medium.com/teconomics-blog/using-ml-to-resolve-experiments-faster-bd8053ff602e\"]],[\"a\",[\"href\",\"http://www.productschool.com\"]]],\"sections\":[[1,\"p\",[[0,[0,1],0,\"Note: You can find this analysis updated for 2020 \"],[0,[2],1,\"here\"],[0,[],2,\".\"]]],[1,\"p\",[[0,[],0,\"Dev fell in love with code at a young age.\"]]],[1,\"p\",[[0,[],0,\"He graduated from college with an engineering degree and then joined the Navy as a \"],[0,[3],1,\"cyber warfare engineer\"],[0,[],0,\". Pressured by his highly educated Persian parents, Dev returned to school after military service to complete a \"],[0,[4],1,\"master's in computer science\"],[0,[],0,\". He has spent his entire career since in software development, mostly coding in \"],[0,[5],1,\"C++\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"He realized early on that workloads were moving to the cloud and spent years retooling and upgrading his skill set, familiarizing himself with each of the major cloud vendors. He championed his team's transition from an on-premise Oracle database to a next-gen database hosted in the public cloud.\"]]],[1,\"p\",[[0,[],0,\"Always on the cutting edge, Dev regularly attends employer-sponsored training sessions and hackathons.\"]]],[1,\"p\",[[0,[],0,\"Dev worked with all of the major programming methodologies over the years but eventually settled on \"],[0,[6],1,\"Agile\"],[0,[],0,\", becoming a big fan.\"]]],[1,\"p\",[[0,[],0,\"Now a manager at a large, 15,000+ employee \"],[0,[7],1,\"technology giant\"],[0,[],0,\", he takes time to work out 3-4 times per week at the free company gym. Even after completing an \"],[0,[8],1,\"agile sprint\"],[0,[],0,\" he keeps moving - jogging home after work most days.\"]]],[1,\"p\",[[0,[],0,\"After promotion, Dev gave his second monitor to one of his younger direct reports. He wasn't spending as many hours furiously coding as he used to, so the extra real estate felt unnecessary.\"]]],[1,\"p\",[[0,[],0,\"A big proponent of healthy work habits, last year he procured a full set of standing desks for his entire team and required that all team members eat lunch away from their workstations. Rarely rushed himself, he never skips meals.\"]]],[1,\"p\",[[0,[],0,\"During the week, Dev wakes up just after 11am. Every. Single. Day.\"]]],[1,\"p\",[[0,[],0,\"Must be nice right?\"]]],[1,\"p\",[[0,[],0,\"However, at 50 years of age, Dev worries if his career has already peaked. He has no plans to retire any time soon, but whispers of \"],[0,[9],1,\"ageism in tech\"],[0,[],0,\" and seeing his older colleagues being laid off have him wondering if he's next.\"]]],[1,\"p\",[[0,[],0,\"That said, he knows he could make up lost income working independently as a freelancer. He has a hunch he'd make even more running solo.\"]]],[1,\"p\",[[0,[],0,\"A proud, loving father, Dev hopes his daughter follows in his footsteps. He sees a bright, better future for her. As far as he's concerned, the world is her oyster.\"]]],[1,\"h2\",[[0,[],0,\"Who is this guy?\"]]],[1,\"p\",[[0,[],0,\"If it's not clear already, Dev's not a real person.\"]]],[1,\"p\",[[0,[],0,\"But his personal and professional characteristics really do correlate with higher income.\"]]],[1,\"p\",[[0,[],0,\"Age. Gender. Race.\"]]],[1,\"p\",[[0,[],0,\"Education. Professional experience. Programming languages.\"]]],[1,\"p\",[[0,[],0,\"Methodology. Hackathons. Even how many monitors he uses.\"]]],[1,\"p\",[[0,[],0,\"The traits that correspond with higher pay are not always what we would expect - nor necessarily what we'd hope.\"]]],[1,\"p\",[[0,[],0,\"The economics of developer pay is an important topic for me. Developers are \"],[0,[1],1,\"the\"],[0,[],0,\" key input in the production of software. You cannot understand tech unless you understand how developers get paidâ€”\"],[0,[1],1,\"you just can't\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"However, the publicly available analysis of this important issue is quite poor.\"]]],[1,\"h2\",[[0,[],0,\"The problem with most pay analyses\"]]],[1,\"p\",[[0,[10],1,\"As covered in my last post\"],[0,[],0,\", Stack Overflow conducts an annual survey of software developers, asking about various aspects of their careers, like income, job title, etc.\"]]],[1,\"p\",[[0,[],0,\"One disappointing feature of most pay analyses is that they show the data without controlling for any other variables. Avoiding any math more complex than simple averages, \"],[0,[1],1,\"the typical analyses of pay have no way to understand a multivariate world\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[11],1,\"Stack Overflowâ€™s own write-up\"],[0,[],0,\" of the survey results does this at times, taking the simple average of income across all full-stack developers, for example, and comparing the same metric for DevOps specialists:\"]]],[10,0],[1,\"p\",[[0,[],0,\"Statements like \\\"Engineering managers, DevOps specialists, and data scientists command the highest salariesâ€ are then made, which, though \"],[0,[0],1,\"technically true\"],[0,[],0,\", tend to mislead readers who are not well-versed in statistics into thinking that these are \"],[0,[0,12],2,\"ceteris paribus\"],[0,[],0,\" (all things equal) comparisons (\\\"X makes more than Y, all else equal\\\"), \"],[0,[1],1,\"which they are not\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"To their credit, Stack Overflow at least takes the additional step of comparing these salaries against years of professional experience, but that is just one of many possible controls. In fact, the entire survey provides a rich set of potential controls to â€œhold equalâ€ and thereby generate more intuitively accurate statements about potential relationships (â€œX developers make more than Ys who are otherwise similarâ€, which is a qualitatively and likely quantitatively different statement than â€œXs make more than Ys\\\").\"]]],[1,\"p\",[[0,[],0,\"Unfortunately, most public discussion of pay does not control for \"],[0,[0],1,\"even a single variable\"],[0,[],0,\". This isnâ€™t lying with statistics so much as it is misleading with them.\"]]],[1,\"p\",[[0,[],0,\"Said simplyâ€”we donâ€™t only want to know â€œhow much more or less do 45-year-old developers make compared to 25-year-old developers.â€ More importantly:\"]]],[1,\"blockquote\",[[0,[],0,\"â€œHow much does a 45-year-old developer earn relative to a 25-year-old developer who is otherwise equivalent (in skills, experience, age, company size, country etc.)?â€\"]]],[1,\"p\",[[0,[],0,\"Both are important questions, but to me, the latter is much more interesting and intuitive. It also happens to be much more difficult to answerâ€”hence it is rarely attempted.\"]]],[1,\"p\",[[0,[],0,\"This is an attempt do better. Not perfect, but much better.\"]]],[1,\"h2\",[[0,[],0,\"Results\"]]],[1,\"p\",[[0,[],0,\"I break down the results by survey question, with a chart displaying the controlled effect of each trait on income, in addition to \"],[0,[13],1,\"95% confidence intervals\"],[0,[],0,\". Correspondingly, any references to statistical significance represent \"],[0,[14],1,\"p-values\"],[0,[],0,\" < 0.05.\"]]],[1,\"p\",[[0,[],0,\"The results represent a subset of approximately 11,000 U.S-based developers from the Stack Overflow survey.\"]]],[1,\"p\",[[0,[],0,\"If youâ€™d like a nicely formatted report with the full set of results, enter your email below and youâ€™ll receive an email with a download link when ready.\"]]],[10,1],[1,\"p\",[[0,[],0,\"For more detail on the methodology, please see the appendix at the end.\"]]],[10,2],[1,\"h3\",[[0,[],0,\"Demographics\"]]],[10,3],[1,\"p\",[[0,[],0,\"Initially, age increases earnings. That said, the annualized \"],[0,[15],1,\"compound\"],[0,[],0,\" gain is quite meagerâ€”about 0.2% through 45-54 years of ageâ€”with most of that happening before a developer turns 25.\"]]],[1,\"p\",[[0,[],0,\"More interesting is how the impact of age declines and turns negative (relative to a developer of 18-24 years of age) as a developer approaches 65:\"]]],[3,\"ul\",[[[0,[],0,\"At this level of precision, \"],[0,[1],1,\"I cannot distinguish the pay of a developer 55 or older from an otherwise similar one younger than 25\"]],[[0,[],0,\"I can say with reasonable certainty that \"],[0,[1],1,\"a developer over the age of 65 makes less than one of 18-25 years of age\"],[0,[],0,\" who is otherwise similar.\"]]]],[1,\"p\",[[0,[],0,\"Ageism could be playing a role. Tech companies, especially startups, are perceived to have a \"],[0,[16],1,\"preference for younger employees\"],[0,[],0,\". Evidence of ageism is often anecdotal, but this data is at least suggestive that there may be something real behind this concern.\"]]],[1,\"p\",[[0,[],0,\"Unfortunately, \"],[0,[1],1,\"ageism is notoriously difficult to prove or disprove\"],[0,[],0,\", exactly because it is exceedingly rare to find a 25-year-old who is, in every way other than age, the same as a 65-year-old.\"]]],[3,\"ul\",[[[0,[],0,\"For starters, a 25-year-old developer cannot possibly have much more than 5 years of professional development experience, while a 65-year-old developer almost certainly does. And that is just one variable.\"]]]],[1,\"p\",[[0,[],0,\"This is certainly an issue worth exploring further.\"]]],[10,4],[1,\"p\",[[0,[],0,\"Asian and middle eastern developers are paid much more than similar white developers, and the pay \"],[0,[0],1,\"premium\"],[0,[],0,\" is likely larger than the pay \"],[0,[0],1,\"discount\"],[0,[],0,\" faced by other minorities.\"]]],[1,\"p\",[[0,[],0,\"Black developers appear to earn 0.8% less than white developers with similar traits, though with a wide enough confidence interval to lose statistical significance.\"]]],[3,\"ul\",[[[0,[],0,\"The lack of precision (plus or minus 5%) is frustrating but inevitable given the low proportion of black software developers in the population and the dataset\"]],[[0,[1],1,\"Note: Only 1.5% of developers in my dataset are black\"],[0,[],0,\" (not significantly different than the overall developer population)\"]]]],[1,\"p\",[[0,[],0,\"Hispanic or latino/a developers earn 1.5% less than similar whites. Again, we see reasonably large confidence intervals due to lack of sufficient data.\"]]],[1,\"p\",[[0,[],0,\"That there is such a large pay premium for asian and middle eastern developers is an interesting factoid in itself and one that warrants further exploration\"]]],[3,\"ul\",[[[0,[],0,\"The estimates range from 5% to 10%, and all are statistically significant.\"]]]],[1,\"p\",[[0,[],0,\"The size of these effects are especially impressive given the small proportion of the dataset these minority groups respectively represent:\"]]],[3,\"ul\",[[[0,[1],1,\"East Asianâ€”2.8%\"]],[[0,[1],1,\"Middle Easternâ€”0.6%\"]],[[0,[1],1,\"South Asianâ€”3.6%\"]]]],[1,\"p\",[[0,[],0,\"That they are statistically significant even with few data points suggests these effects are quite real.\"]]],[1,\"p\",[[0,[17],1,\"Pay discrimination is a serious issue\"],[0,[],0,\" that warrants rigorous analysis, much more than what Iâ€™ve done here.\"]]],[3,\"ul\",[[[0,[],0,\"All in all, the results suggest that attempts to level the â€œpayingâ€ field should also focus on equalizing pay across various racial minority groups, not simply between minority groups and the majority\"]]]],[10,5],[1,\"p\",[[0,[],0,\"The pay gap for female software developers is similar in magnitude and low statistical significance to that of black developersâ€”roughly 1.3% plus or minus 2.4%.\"]]],[1,\"p\",[[0,[],0,\"Gender non-binary / non-conforming developers face a large pay discount of 10% relative to male developers.\"]]],[1,\"p\",[[0,[],0,\"Given very few observations in the dataset, the pay effect for transgender developers cannot be estimated precisely enough to conclude anything meaningful.\"]]],[10,6],[1,\"p\",[[0,[],0,\"Gay and lesbian software developers appear to make 2.5% more than straight / heterosexual developers, but this estimate is not statistically significant.\"]]],[1,\"p\",[[0,[],0,\"In fact, given the confidence intervals above, none of the categories of sexual orientation are statistically significantly different from heterosexual. \"]]],[3,\"ul\",[[[0,[],0,\"Again, this is in part due to limited dataâ€”only 2.4% of developers in the sample are gay or lesbian, for example\"]]]],[10,7],[1,\"p\",[[0,[],0,\"Good news for parentsâ€”developers with dependents (children, grandparents etc.) earn 3.7% more than those who donâ€™t, controlling for other factors.\"]]],[1,\"p\",[[0,[],0,\"There are a number of potential explanations for this\"]]],[3,\"ul\",[[[0,[],0,\"Workers with dependents likely want / need the extra income and hence seek out jobs that pay more\"]],[[0,[],0,\"I do not have evidence to conclude that employers are specifically choosing to pay those with dependents more than others, though this could also be the case\"]]]],[10,8],[1,\"p\",[[0,[],0,\"Former and current U.S. military service members earn 3% more than those without prior military service.\"]]],[1,\"p\",[[0,[],0,\"As with other traits, there are any number of potential drivers of the veteran pay premium, and it's inherently difficult to pinpoint the most likely explanation.\"]]],[1,\"h4\",[[0,[],0,\"Takeaways\"]]],[3,\"ul\",[[[0,[],0,\"Drawing justifiable conclusions around the impact of demographic characteristics on income is necessarily tricky given the highly imbalanced nature of the developer population\"]],[[0,[],0,\"Caution is advisable when positing causal connections, and these should ideally be accompanied by some theoretical mechanism\"]],[[0,[],0,\"That said, the results are interesting and should hopefully serve as a starting point for deeper and more rigorous analysis.\"]]]],[10,9],[1,\"h3\",[[0,[],0,\"Education\"]]],[10,10],[1,\"p\",[[0,[],0,\"Advanced, non-professional degrees drive higher earnings. A masters or doctoral degree (PhD etc.) drives statistically significant gains of 3% and 10%, respectively, relative to an equivalent developer with only a bachelorâ€™s.\"]]],[1,\"p\",[[0,[],0,\"Going to college but not completing is associated with a 3% cut in earnings, while graduating with an associate degree decreases earning by about 8% vs. a bachelorâ€™s. Again both are statistically significant.\"]]],[1,\"p\",[[0,[],0,\"The effect of professional degrees like JDs and MDs is not statistically significant due to wide confidence intervals.\"]]],[3,\"ul\",[[[0,[],0,\"Very few people with these degrees are working as software developers, so establishing a precise estimate is difficult.\"]]]],[1,\"p\",[[0,[],0,\"Not much can be said for developers that never reached the college levelâ€”due to lack of data, the confidence intervals are too wide to draw meaningful conclusions. However, these folks are almost certainly worse off than someone with an advanced degree.\"]]],[10,11],[1,\"p\",[[0,[],0,\"Interestingly, computer science is not the best-paid college major.\"]]],[3,\"ul\",[[[0,[],0,\"In fact, other engineering disciplines (civil, mechanical, electrical, etc.) (\"],[0,[1],1,\"5% increase\"],[0,[],0,\"), business degrees (accounting, finance, etc.) (\"],[0,[1],1,\"4% increase\"],[0,[],0,\"), and math / stats majors (\"],[0,[1],1,\"3.4% increase\"],[0,[],0,\") all earn more, all else equal.\"]]]],[1,\"p\",[[0,[],0,\"Outside of these areas, college major is largely irrelevant to developer pay. The meme of the \"],[0,[18],1,\"underpaid, over-educated\"],[0,[],0,\" sociology major doesnâ€™t apply.\"]]],[3,\"ul\",[[[0,[],0,\"This could be encouraging in that it shows you can be paid for good dev work regardless of your field of study\"]],[[0,[],0,\"With dev schools and bootcamps like \"],[0,[19],1,\"Lambda\"],[0,[],0,\" popping up all over, this is great news if you are considering a career change and worried you might be at a disadvantage.\"]],[[0,[],0,\"On the other hand, it does raise the questionâ€”why arenâ€™t developers who studied the most apparently relevant field paid more than all others?\"]],[[0,[],0,\"Does this say anything about undergraduate computer science teaching, which is often criticized for being \"],[0,[20],1,\"irrelevant and out of touch\"],[0,[],0,\" with professional software development work out in the wild?\"]]]],[1,\"p\",[[0,[],0,\"The exceptions are information systems / technology and web development / design degrees, which bear a pay discount of 2.4% and 10% respectively.\"]]],[3,\"ul\",[[[0,[],0,\"Why? My take is that these degrees are often associated with private, for-profit schools \"],[0,[21],1,\"not often known for their quality\"]]]],[10,12],[1,\"p\",[[0,[],0,\"Your parentâ€™s level of education matters as a software developer.\"]]],[1,\"p\",[[0,[],0,\"Developers with at least one parent holding a professional degree like a JD or MD will earn 5.3% more than a developer whose parents never earned more than a bachelorâ€™s degree. Masters and doctoral degrees among parents are associated with a 2.2% increase in pay for the children, though this relationship narrowly misses statistical significance for doctoral degrees.\"]]],[1,\"p\",[[0,[],0,\"Associate degrees, some college, and high school all have significantly negative impacts of 2.8-4%.\"]]],[1,\"p\",[[0,[],0,\"Primary school and no formal education were too rare in the dataset to generate precise effect estimates.\"]]],[1,\"p\",[[0,[],0,\"Itâ€™s interesting to consider how these effects manifest themselves throughout the professional life of a developer\"]]],[3,\"ul\",[[[0,[],0,\"We can all imagine ways in which parental education could have meaningful follow-on effects in the lives of children\"]],[[0,[],0,\"It is also possible that, with more controls, these effects would dissipate or lose significance\"]],[[0,[],0,\"For example, the effect may channel itself through income or other variables that correlate with (or are influenced by) education, rather than schooling itself\"]]]],[10,13],[1,\"p\",[[0,[],0,\"Participation in \"],[0,[22],1,\"hackathons\"],[0,[],0,\" is clearly associated with higher payâ€”more than 4.3% higher, as are full-time developer training programs (bootcamps), which provide a 3% bump.\"]]],[1,\"p\",[[0,[],0,\"Weâ€™ve witnessed an \"],[0,[23],1,\"explosion in the number of coding bootcamps\"],[0,[],0,\" over the past decade. The pay bump is equivalent in magnitude to a masterâ€™s degree, which is incredible given bootcamps take months to complete, not years, and are generally cheaper in tuition than an advanced degree.\"]]],[1,\"p\",[[0,[],0,\"Contributing to open source software, or OSS (certainly an educational experience, in a sense), has a positive but not statistically significant bump of 1.6%\"]]],[3,\"ul\",[[[0,[],0,\"Open-source penetration of the typical software stack has only increased over the yearsâ€”it would make sense if active contribution to OSS is rewarded with higher pay.\"]]]],[1,\"p\",[[0,[],0,\"Industry certifications get a big fat zero. No effect.\"]]],[1,\"p\",[[0,[],0,\"On the other hand, online programming courses, MOOCs, etc. are associated with a significant drop of slightly more than 2.4%. Given the \"],[0,[24],1,\"proliferation of online software development courses\"],[0,[],0,\" over the years, this is an inconvenient finding.\"]]],[3,\"ul\",[[[0,[],0,\"That all said, I do worry about potentially confounding or omitted variables that have not been controlled for\"]],[[0,[],0,\"I canâ€™t imagine a strong causal link between taking an online course and lower pay, but I can certainly imagine that the \\\"type of personâ€ who takes an online course might also be the type of person that generally earns less\"]]]],[1,\"p\",[[0,[],0,\"Likewise, the type of person to participate in a hackathon likely has other, unobserved traits that drive higher income\"]]],[3,\"ul\",[[[0,[],0,\"Certain companies, which may be higher paying on average, also host hackathons in their offices\"]]]],[1,\"p\",[[0,[],0,\"In other words, correlation may not be causation here, even after controlling for many variables.\"]]],[10,14],[1,\"p\",[[0,[],0,\"As an avid self-learner myself, I am disappointed to see that no form of self-learning seems to have a statistically discernible impact on earnings.\"]]],[3,\"ul\",[[[0,[],0,\"Books and e-books were close to achieving statistical significance, but even so, the point estimate is only 1%.\"]]]],[1,\"p\",[[0,[],0,\"Self-learning is a great way to, in targeted fashion, learn exactly what you need to know about a certain topic or area of knowledge. For many, it is more effective than traditional teaching methods.\"]]],[1,\"p\",[[0,[],0,\"However, it doesnâ€™t seem to impact pay in and of itself.\"]]],[1,\"h4\",[[0,[],0,\"Takeaways\"]]],[3,\"ul\",[[[0,[],0,\"Education matters, largely in the ways one would guess\"]],[[0,[],0,\"If youâ€™ve already graduated from college, advanced degrees, hackathons, bootcamps, and open source projects can be smart ways to increase your value as a developer in ways that show up in your paycheck\"]],[[0,[],0,\"If you havenâ€™t graduated yet, know that the exact major you pick matters less than showing interest or commitment to the craft, at least when it comes to pay\"]]]],[10,15],[1,\"h3\",[[0,[],0,\"Professional Characteristics\"]]],[10,16],[1,\"p\",[[0,[],0,\"Professional development experience matters much more than casual coding. The gains from more years of general coding experience tend to plateau after 15 years, while professional coding experience continues to pay dividends well into the 30 year range.\"]]],[1,\"p\",[[0,[],0,\"The benefit from experience with casual coding (relative to 0-2 years) maxes out at 10-15% and actually begins to decline after 26 years.\"]]],[3,\"ul\",[[[0,[],0,\"Again, this is holding other factors equal, including professional experience, so this may make sense\"]],[[0,[],0,\"Someone who learned to code 30 years ago and has little more to show for it than someone with only 10 years of coding experience might raise flags.\"]],[[0,[],0,\"We must be careful howeverâ€”taking the year one learned to code as given, years since learning to code correlates perfectly with age, suggesting that ageism may be leaking in here. I explore age specifically elsewhere in this post.\"]]]],[1,\"p\",[[0,[],0,\"The fastest gains from professional experience come in the first ten years.\"]]],[3,\"ul\",[[[0,[],0,\"A developer with 9-11 years of professional experience can expect to earn 30% more than a newbie, all else equal, which translates to about 2.5 percent year-over-year gains.\"]],[[0,[],0,\"Of course, â€œall elseâ€ is likely not equal for any given developer across a ten-year span, suggesting even greater potential annual raises for a given developer in the real world.\"]]]],[1,\"p\",[[0,[],0,\"After the first decade, the line is nearly straight, aside from a mid-career slump at the 25-year mark.\"]]],[3,\"ul\",[[[0,[],0,\"Do not be fooled, howeverâ€”constant absolute gains in fact represent declining growth\"]],[[0,[],0,\"In other words, each year of professional development experience provides a nearly-constant dollar raise but a declining percentage raise. I explore this phenomenon further in a upcoming post\"]]]],[1,\"p\",[[0,[],0,\"With that caveat, it is still encouraging to see that developer pay does not fully plateau or reverse course with additional professional experience over time.\"]]],[10,17],[1,\"p\",[[0,[],0,\"No surprise hereâ€”working part-time does not help your earnings.\"]]],[1,\"p\",[[0,[],0,\"More interestingly, developers working as freelancers or independent contractors make more than those employed full-time\"]]],[3,\"ul\",[[[0,[],0,\"This may be compensated for by what is almost surely more variable income\"]],[[0,[],0,\"In general, stable, full-time employment does come at a cost, not only in software development but in many other areas of the economy\"]]]],[1,\"p\",[[0,[],0,\"Reverse causation could also be at play hereâ€”someone who knows they could make more as a freelancer is exactly the kind of person who would become one.\"]]],[10,18],[1,\"p\",[[0,[],0,\"Itâ€™s no surprise that managers and executives earn more. This includes \"],[0,[25],1,\"product managers\"],[0,[],0,\", who might not write significant amounts of code themselves.\"]]],[3,\"ul\",[[[0,[],0,\"Engineering managers and C-suite execs make 10% more, while product managers make 5.8% more, all else equal.\"]]]],[1,\"p\",[[0,[],0,\"The only non-manager role that makes meaningfully more than its counterparts is DevOps:\"]]],[3,\"ul\",[[[0,[],0,\"DevOps specialists are about 2.2 percentage points higher on the pay scale than the non-DevOps average for similar developers.\"]]]],[1,\"p\",[[0,[],0,\"Conversely, there are a number of roles that make noticeably less despite similar levels of experience, education etc.\"]]],[3,\"ul\",[[[0,[],0,\"Database admins (DBAs), sysadmins, designers, QA / testing developers make 2.5-7.5% less than developers who donâ€™t fall under these categories\"]],[[0,[],0,\"With the exception of designers, these roles are commonly seen as the â€œback officeâ€ of IT, though one could easily find counter examples depending on the specific team or organization\"]],[[0,[],0,\"Perhaps needless to sayâ€”academics and students earn meaningfully less than those outside of academia\"]]]],[1,\"h4\",[[0,[],0,\"Takeaways\"]]],[3,\"ul\",[[[0,[],0,\"Professional experience matters and never stops mattering\"]],[[0,[],0,\"Casual development experience helps tooâ€”but only so much, measured both by the amount of experience and the earnings impact\"]],[[0,[],0,\"Among those working in industry, role matters positively for managers and DevOps professionals and negatively for system and database administrators, as well as designers\"]]]],[10,19],[1,\"h3\",[[0,[],0,\"Languages, Frameworks, Databases, Platforms, and Tools\"]]],[10,20],[1,\"p\",[[0,[],0,\"The main implication of these resultsâ€”languages largely donâ€™t matter to pay. The vast majority of languages do not provide a statistically significant pay bump or discount relative to jobs that donâ€™t require that language. The pay scale for programming languages is quite flat across the universe of languages.\"]]],[1,\"p\",[[0,[],0,\"Hack is a clear outlierâ€”working with Hack yields a 25% bump. However, donâ€™t drop everything to go learn Hack right now\"]]],[3,\"ul\",[[[0,[],0,\"Hack is not a widely used language\"]],[[0,[],0,\"It was developed by Facebook, and unlike other languages and frameworks that come out of the big tech giants, Hack has not had the same marketing push placed behind it. \"]],[[0,[],0,\"The effect we see here likely reflects developers who work at Facebook itselfâ€”thereâ€™s no sign of a robust hiring market for Hack talent.\"]]]],[1,\"p\",[[0,[],0,\"Outside of Hack, on the positive side we find Objective-C, C++, Go, VBA, and TypeScript with statistically significant income effects, ranging from 2.1 to 3.9 percent.\"]]],[1,\"p\",[[0,[],0,\"On the negative side we have JavaScript, VB.NET, CSS, and PHP\"]]],[3,\"ul\",[[[0,[],0,\"JS, CSS, and PHP likely reflect the lower pay of certain web development jobs\"]],[[0,[],0,\"These languages represent fundamental technologies of web development\"]],[[0,[],0,\"For that same reason however, they are considered table stakes\"]],[[0,[],0,\"Hence, using these technologies on the job doesnâ€™t provide much of a pay bump, though you may be quite employable\"]]]],[1,\"p\",[[0,[],0,\"Please note that the results above are \"],[0,[1],1,\"not\"],[0,[],0,\" saying â€œknowing language X increases / decreases pay.â€ Knowing a language is not likely to ever \"],[0,[0],1,\"harm\"],[0,[],0,\" oneâ€™s pay, but working a dev job that uses it might (relative to other development work).\"]]],[10,21],[1,\"p\",[[0,[],0,\"Reactâ€”what needs to be said?\"]]],[3,\"ul\",[[[0,[],0,\"The \"],[0,[26],1,\"cutting-edge JavaScript framework\"],[0,[],0,\" originated and maintained by Facebook is widely and wildly popular, especially among front-end developers looking for an easy-to-use but powerful way to craft compelling user interfaces.\"]],[[0,[],0,\"React is associated with a 4.1% pay increase and is the only framework with a statistically significant positive impact.\"]]]],[1,\"p\",[[0,[],0,\"Working with .NET Core and PyTorch negatively impacts income\"]]],[3,\"ul\",[[[0,[],0,\"I do not have a hypothesis about .NET Core, but I do know that \"],[0,[27],1,\"PyTorch was historically used much more among researchers\"],[0,[],0,\" than industry practitioners, likely driving lower pay\"]],[[0,[],0,\"Usage has since branched out as the framework has added production-grade capabilities and tooling.\"]]]],[10,22],[1,\"p\",[[0,[],0,\"One wordâ€”cloud. Almost all of the databases with positive income effects are hosted in the cloud, often exclusively as a managed service by one of the major public cloud service providers (Google, Amazon, Facebook).\"]]],[1,\"p\",[[0,[],0,\"Googleâ€™s BigQuery data warehouse tops the list, followed closely by Amazonâ€™s competing Redshift. Apache Hbase and Hive come next. Afterwards itâ€™s Amazonâ€™s DynamoDB and Microsoftâ€™s Azure Tables, Cosmos DB, and SQL. The list continues with Memcached, Redis, Elasticsearch, Google Cloud Storage, and Amazon RDS and Auroraâ€”all positive and statistically significant.\"]]],[1,\"p\",[[0,[],0,\"Older database technologies from legacy vendors dominate the negative end. This includes Oracleâ€™s once ubiquitous databases, MySQL, SQL Server, MariaDB, and IBMâ€™s Db2.\"]]],[1,\"p\",[[0,[],0,\"Itâ€™s fascinating to see the impact of the cloud revolution laid out in stark relief. There are meaningful income gains associated with working with next-gen cloud-enabled databases. This fact should be top of mind for developers looking to upgrade their skills and pay.\"]]],[10,23],[1,\"p\",[[0,[],0,\"Iâ€™ll say it againâ€”cloud. The various public clouds are the only platforms aside from Windows Phone with positive, statistically significant effects on developer earnings. Azure is associated with 4.1% higher pay, GCP 2.7%, AWS 1.7%.\"]]],[1,\"p\",[[0,[],0,\"And Windows Phone? Not going to try to explain that one.\"]]],[1,\"p\",[[0,[],0,\"Android, Arduino and Drupal had meaningful negative association with incomeâ€”2.4%, 4.6%, and 8.5% respectively.\"]]],[1,\"p\",[[0,[],0,\"Androidâ€™s ubiquitous operating system needs no introduction, though itâ€™s negative pay relationship might need an explanation. Unfortunately, I am stumped here.\"]]],[1,\"p\",[[0,[],0,\"Arduino is an \"],[0,[28],1,\"open-source prototyping platform\"],[0,[],0,\" with associated hardware microcontrollers that eases development of electronic devices. Though used for serious development work, \"],[0,[29],1,\"Arduino is also heavily used by engineering students\"],[0,[],0,\" as well, which likely drives the negative value.\"]]],[1,\"p\",[[0,[],0,\"Drupal is a PHP-based content management system whose \"],[0,[30],1,\"popularity peaked in 2011\"],[0,[],0,\" but has since been on a slow decline.\"]]],[10,24],[1,\"p\",[[0,[],0,\"You might not think that a developerâ€™s choice of IDE or text editors wouldnâ€™t matterâ€”and youâ€™d be (largely) correct! The associated effects here are generally quite small.\"]]],[1,\"p\",[[0,[],0,\"However, IntelliJ stands out from the pack\"]]],[3,\"ul\",[[[0,[],0,\"Billed by JetBrains, its creator, as the â€œJava IDE for professional developersâ€, IntelliJ users make 3.1% more than non-users\"]],[[0,[],0,\"Of course, this is not an entirely useful comparison for someone who doesnâ€™t use Java in their development work\"]]]],[1,\"p\",[[0,[],0,\"Notepad++ and Atom are associated with slightly lower earnings, on the order of 2%, which is statistically significant. Notably, both are popular but are generally viewed more as text editors than fully-fledged IDEs.\"]]],[1,\"p\",[[0,[],0,\"PhpStorm, Xcode, and Coda also had negative effects that were statistically significant.\"]]],[10,25],[1,\"p\",[[0,[],0,\"The incredibly popular Agile leads the pack among project management methodologies. Devs who use Agile in their development work earn 3.9% more than those who donâ€™t.\"]]],[1,\"p\",[[0,[],0,\"The less common extreme programming methodology is associated with 2.7% higher pay.\"]]],[1,\"p\",[[0,[],0,\"Lean comes in at 2.5%, while Scrum developers earn 1.5% more, all else equal.\"]]],[1,\"p\",[[0,[],0,\"Prince2 appears to be at outlier, but this is mostly due to limited dataâ€”only 0.1% of developers in the sample use the methodology.\"]]],[10,26],[1,\"p\",[[0,[],0,\"For the most part, the exact form of version control used does not matter.\"]]],[1,\"p\",[[0,[],0,\"The key takeaway hereâ€”any kind of version control is better than no version control, but please, please avoid copying and pasting files to a network share.\"]]],[1,\"h3\",[]],[10,27],[1,\"p\",[[0,[],0,\"The best practice appears to be the best paid\"]]],[3,\"ul\",[[[0,[],0,\"Checking in code multiple times per day\"]],[[0,[],0,\"Itâ€™s clearly important to check in code on some kind of cadenceâ€”at least monthly, ideally\"]],[[0,[],0,\"If you are checking in code less than once per month or not at all, your pay is likely being impacted as a result.\"]]]],[1,\"p\",[[0,[],0,\"Not to sound like a broken record, but the reverse causation caveat applies here as well. It is completely plausible that checking in code more often increases a developers pay. Itâ€™s also possible that companies that pay more are more likely to follow and mandate development best practices, such as frequent code check-ins.\"]]],[10,28],[1,\"p\",[[0,[],0,\"It seems too convenient that in a survey run by Stack Overflow that its own enterprise product would be associated with significantly higher developer pay, but I can only go where the data takes me. Developers using Stack Overflow Enterprise earn 9.4% more than those who donâ€™t.\"]]],[1,\"p\",[[0,[],0,\"This likely picks up some effect of simply working at a company that uses Stack Overflow Enterprise, which may be higher paying on average.\"]]],[1,\"p\",[[0,[],0,\"Other communication tools had smaller positive impacts like the incredibly popular Slack, Atlassianâ€™s Confluence, HipChat, and internal intranet sites (wikis, Google sites etc), which all have earnings effects in the 2-3% range.\"]]],[1,\"p\",[[0,[],0,\"Trello and Facebook are negative enough to be statistically significant.\"]]],[10,29],[1,\"p\",[[0,[],0,\"Surprisingly, developers who use two monitors earn 2.8% less than those who use only a single monitor, all else equal.\"]]],[1,\"p\",[[0,[],0,\"At this time, itâ€™s not clear why more monitors would negatively impact earnings. The potential for enhanced productivity may be swamped by the temptation to use the additional screen real estate for \"],[0,[31],1,\"non-work activities\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"No other monitor count had a statistically significant effect on income relative to one.\"]]],[1,\"h4\",[[0,[],0,\"Takeaways\"]]],[3,\"ul\",[[[0,[],0,\"The tools associated with higher developer pay are quite interesting and not necessarily what one might expect\"]],[[0,[],0,\"In some cases, the most popular tools also pay the most\"]],[[0,[],0,\"In other cases, more obscure tools appear to have an advantage\"]],[[0,[],0,\"Check in your code (at least every once in a while)!\"]],[[0,[],0,\"One clear trend is the impact the move to the cloud is having on developersâ€”the effects of the public cloud on developer pay are large and consistently statistically significant across the big 3 U.S. clouds\"]],[[0,[],0,\"Knowing how to use and leverage these next-generation computing environments and finding a job that employs those skills can drive meaningful pay improvements for the average developer\"]]]],[10,30],[1,\"h3\",[[0,[],0,\"Work Life, Health, and Wellness\"]]],[10,31],[1,\"p\",[[0,[],0,\"These results are admittedly difficult to interpret. There is no clear linear time trend for the impact of wake up time on earnings.\"]]],[1,\"p\",[[0,[],0,\"After 7am, later does appear to be somewhat betterâ€”up to a point. Strangely, developers between 11am and 12pm see 15.4% higher pay than those who are up before 5am.\"]]],[1,\"p\",[[0,[],0,\"The most important takeaway is thisâ€”\"],[0,[1],1,\"have a set schedule\"],[0,[],0,\". This will do more good than optimizing for a specific wake-up time. Not having a regular wake up time was associated with 7.7% lower pay for software developers.\"]]],[10,32],[1,\"p\",[[0,[],0,\"Exercise is strongly associated with earnings. While only exercising once or twice a week does not appear impactful, exercising 3 times or more per week is associated with 2-2.9% higher pay than a similar developer who does not exercise at all.\"]]],[1,\"p\",[[0,[],0,\"It is possible however that reverse causation could cause developers who earn more to work out moreâ€”perhaps because they have more time or can more easily afford a gym membership. Alternatively, higher paying companies often have gyms on-premises, making it easier to work out more.\"]]],[10,33],[1,\"p\",[[0,[],0,\"Donâ€™t skip meals. Any amount of meal skipping was associated with lower pay, though never statistically significant. Developers are not rewarded for this unhealthy work habit.\"]]],[10,34],[1,\"p\",[[0,[],0,\"Among ergonomic devices, \"],[0,[32],1,\"standing desks\"],[0,[],0,\" were associated with 3.2% higher pay, which is statistically significant.\"]]],[1,\"p\",[[0,[],0,\"Again, higher paying companies are potentially more like to provide employees with standing desks, so the direction of causality here is questionable.\"]]],[10,35],[1,\"p\",[[0,[],0,\"Time spent at the computer each day does not have a meaningful relationship with pay. Handcuffing yourself to your laptop is not going to earn you higher pay as a developer.\"]]],[10,36],[1,\"p\",[[0,[],0,\"Unlike time spent at the computer, time spent outside does have an impact on pay, with the ideal amount being 1-2 hours. Spending fewer than 30 minutes outside is associated with 2.4% lower pay than 30 minutes to an hour.\"]]],[1,\"p\",[[0,[],0,\"Spending more than 4 hours outside was associated with lower pay, but there were not enough developers who do this regularly to generate a precise estimate.\"]]],[1,\"h4\",[[0,[],0,\"Takeaways\"]]],[3,\"ul\",[[[0,[],0,\"The data suggest that common best practices are often the best way to go\"]],[[0,[],0,\"Spend at least a small amount of time outside each day\"]],[[0,[],0,\"Skipping meals will only grow your bank balance to the extent you save money on lunch\"]],[[0,[],0,\"Exercising a few times per week is better than never hitting the gym\"]]]],[10,37],[1,\"h2\",[[0,[],0,\"Conclusion\"]]],[1,\"p\",[[0,[],0,\"There are many important takeaways from the study and the charts above.\"]]],[1,\"p\",[[0,[],0,\"This analysis is a first attempt at exploring the various factors that affect developer pay. To that end, I hope that it is illuminating and informative.\"]]],[1,\"p\",[[0,[],0,\"However, as with many attempts to answer difficult questions, the analysis raises as many questions as it answers.\"]]],[1,\"p\",[[0,[],0,\"I am publishing the full code to reproduce this analysis because I believe open source, replicable research is the key to the robust advancement of knowledge\"]]],[3,\"ul\",[[[0,[],0,\"I would love for this analysis to serve as starting point for others who wish to elevate the state of knowledge on this important topic\"]],[[0,[],0,\"If you find an error or disagree with some aspect of the analysis, feel free to submit edits (pull requests) to my \"],[0,[33],1,\"GitLab\"],[0,[],0,\" or \"],[0,[34],1,\"GitHub\"],[0,[],0,\" repositories\"]]]],[1,\"p\",[[0,[],0,\"I care deeply about the technology industry. But solving its issues and compounding its strengths demands a rigorous understanding of its component elements. \"],[0,[35],1,\"Developers are a critical piece of the tech puzzle\"],[0,[],0,\", and they deserve our attention.\"]]],[1,\"h2\",[[0,[],0,\"Appendix\"]]],[1,\"h2\",[[0,[],0,\"Data\"]]],[1,\"p\",[[0,[],0,\"As in my last post, I leverage data from Stack Overflowâ€™s annual software developer survey, which asks about income, in addition to many other questions of interest. \"]]],[1,\"p\",[[0,[],0,\"Examples include\"]]],[3,\"ul\",[[[0,[],0,\"Which of the following best describes the highest level of formal education that youâ€™ve completed?\"]],[[0,[],0,\"Approximately how many people are employed by the company or organization you work for?\"]],[[0,[],0,\"Which of the following programming, scripting, and markup languages have you done extensive development work in over the past year?\"]]]],[1,\"p\",[[0,[],0,\"Iâ€™m interested in how answers to these questions affect income. While itâ€™s impossible to completely avoid issues of reverse causality or correlation rather than causation, by using regression augmented with machine learning techniques, described here, we can have greater confidence that our results accurately represent the true relationship income.\"]]],[1,\"p\",[[0,[],0,\"Essentially, weâ€™ll analyze how each possible answer affects income, holding all other answers constant.\"]]],[1,\"p\",[[0,[],0,\"I limit the dataset to only non-retired US respondents above the age of 18 with income between $10,000-250,000. Responses above $250K have a higher tendency to be troll (i.e. made up) responses, which Iâ€™d like to exclude, and few answers come in above this threshold regardless.\"]]],[1,\"p\",[[0,[],0,\"This leaves us with a dataset of approximately 11,000 developers.\"]]],[1,\"h3\",[[0,[],0,\"Methodology\"]]],[1,\"p\",[[0,[],0,\"I estimate the following equation on the data:\"]]],[1,\"p\",[[0,[],0,\"$$\\\\log(income) = \\\\beta_0 + \\\\beta_1T + \\\\beta_2X + \\\\epsilon$$\"]]],[1,\"p\",[[0,[],0,\"Where \\\\(T\\\\) is our trait of interest, \\\\(\\\\beta_1\\\\) is the effect of that trait on income relative to the base category, \\\\(X\\\\) is a set of controls (in our case, the respondent's answers to other questions in the survey), \\\\(\\\\beta_2\\\\) is the set of effects for each respective control, and \\\\(\\\\epsilon\\\\) is the irreducible error in our estimate.\"]]],[1,\"p\",[[0,[],0,\"Assuming weâ€™ve included a â€œcompleteâ€ and â€œcorrect\\\" set of controls, this should provide a reasonably accurate estimate of the relationship of the trait of interest, \\\\(T\\\\), with income. The log transformation of income means our results will be in roughly percentage terms, implying that trait \\\\(T\\\\) is associated with an increase in income of \\\\(\\\\beta_1*100\\\\%\\\\) relative to the â€œbase\\\" category, all else equal. The base category will vary by trait.\"]]],[1,\"p\",[[0,[],0,\"Selecting the right set of controls is non-trivial. One has any number of degrees of freedom to select a subset of controls among all those available, opening the doors to â€œp-hackingâ€ and other infamous behavior, which can lead to incorrect (biased) estimates of the parameters of interest.\"]]],[1,\"p\",[[0,[],0,\"To avoid this, I leverage a powerful machine learning technique, Double Selection (specifically Double Lasso Selection), to do principled covariate selection for each trait \\\\(T\\\\), rerunning the regression for every trait. As described in \"],[0,[36],1,\"Belloni, Chernozhukov, Hansen (2011)\"],[0,[],0,\", this should provide a more accurate estimate of the income effect of each trait than simply using all the covariates or attempting to manually select a subset. I wonâ€™t cover the method in detail here, but refer to the original paper for more information. \"],[0,[37],1,\"This post\"],[0,[],0,\" provides a relatively intuitive explanation, and is also where I originally learned of the technique.\"]]],[1,\"p\",[[0,[],0,\"Long story short, Double Selection makes us much more confident that the results represent the accurate effects.\"]]],[1,\"p\",[[0,[0],0,\"This post has been published on \"],[0,[38],1,\"www.productschool.com\"],[0,[],1,\" communities\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p><em><strong>Note: You can find this analysis updated for 2020 <a href=\"__GHOST_URL__/highest-paid-software-engineers-2020/\">here</a>.</strong></em></p><p>Dev fell in love with code at a young age.</p><p>He graduated from college with an engineering degree and then joined the Navy as a <a href=\"https://www.navy.com/careers/cyber-warfare-engineer\">cyber warfare engineer</a>. Pressured by his highly educated Persian parents, Dev returned to school after military service to complete a <a href=\"https://online.stanford.edu/programs/computer-science-ms-degree\">master's in computer science</a>. He has spent his entire career since in software development, mostly coding in <a href=\"https://en.wikipedia.org/wiki/C%2B%2B\">C++</a>.</p><p>He realized early on that workloads were moving to the cloud and spent years retooling and upgrading his skill set, familiarizing himself with each of the major cloud vendors. He championed his team's transition from an on-premise Oracle database to a next-gen database hosted in the public cloud.</p><p>Always on the cutting edge, Dev regularly attends employer-sponsored training sessions and hackathons.</p><p>Dev worked with all of the major programming methodologies over the years but eventually settled on <a href=\"https://www.agilealliance.org/agile101/\">Agile</a>, becoming a big fan.</p><p>Now a manager at a large, 15,000+ employee <a href=\"http://www.piedpiper.com/\">technology giant</a>, he takes time to work out 3-4 times per week at the free company gym. Even after completing an <a href=\"https://www.atlassian.com/agile/scrum/sprints\">agile sprint</a> he keeps moving - jogging home after work most days.</p><p>After promotion, Dev gave his second monitor to one of his younger direct reports. He wasn't spending as many hours furiously coding as he used to, so the extra real estate felt unnecessary.</p><p>A big proponent of healthy work habits, last year he procured a full set of standing desks for his entire team and required that all team members eat lunch away from their workstations. Rarely rushed himself, he never skips meals.</p><p>During the week, Dev wakes up just after 11am. Every. Single. Day.</p><p>Must be nice right?</p><p>However, at 50 years of age, Dev worries if his career has already peaked. He has no plans to retire any time soon, but whispers of <a href=\"http://blog.indeed.com/2017/10/19/tech-ageism-report/\">ageism in tech</a> and seeing his older colleagues being laid off have him wondering if he's next.</p><p>That said, he knows he could make up lost income working independently as a freelancer. He has a hunch he'd make even more running solo.</p><p>A proud, loving father, Dev hopes his daughter follows in his footsteps. He sees a bright, better future for her. As far as he's concerned, the world is her oyster.</p><h2 id=\"who-is-this-guy\">Who is this guy?</h2><p>If it's not clear already, Dev's not a real person.</p><p>But his personal and professional characteristics really do correlate with higher income.</p><p>Age. Gender. Race.</p><p>Education. Professional experience. Programming languages.</p><p>Methodology. Hackathons. Even how many monitors he uses.</p><p>The traits that correspond with higher pay are not always what we would expect - nor necessarily what we'd hope.</p><p>The economics of developer pay is an important topic for me. Developers are <strong>the</strong> key input in the production of software. You cannot understand tech unless you understand how developers get paidâ€”<strong>you just can't</strong>.</p><p>However, the publicly available analysis of this important issue is quite poor.</p><h2 id=\"the-problem-with-most-pay-analyses\">The problem with most pay analyses</h2><p><a href=\"__GHOST_URL__/the-growth-share-matrix-of-software-development/\">As covered in my last post</a>, Stack Overflow conducts an annual survey of software developers, asking about various aspects of their careers, like income, job title, etc.</p><p>One disappointing feature of most pay analyses is that they show the data without controlling for any other variables. Avoiding any math more complex than simple averages, <strong>the typical analyses of pay have no way to understand a multivariate world</strong>.</p><p><a href=\"https://insights.stackoverflow.com/survey/2018/\">Stack Overflowâ€™s own write-up</a> of the survey results does this at times, taking the simple average of income across all full-stack developers, for example, and comparing the same metric for DevOps specialists:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2019/01/stack_overflow_salary-1.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Statements like \"Engineering managers, DevOps specialists, and data scientists command the highest salariesâ€ are then made, which, though <em>technically true</em>, tend to mislead readers who are not well-versed in statistics into thinking that these are <em><a href=\"https://en.wikipedia.org/wiki/Ceteris_paribus\">ceteris paribus</a></em> (all things equal) comparisons (\"X makes more than Y, all else equal\"), <strong>which they are not</strong>.</p><p>To their credit, Stack Overflow at least takes the additional step of comparing these salaries against years of professional experience, but that is just one of many possible controls. In fact, the entire survey provides a rich set of potential controls to â€œhold equalâ€ and thereby generate more intuitively accurate statements about potential relationships (â€œX developers make more than Ys who are otherwise similarâ€, which is a qualitatively and likely quantitatively different statement than â€œXs make more than Ys\").</p><p>Unfortunately, most public discussion of pay does not control for <em>even a single variable</em>. This isnâ€™t lying with statistics so much as it is misleading with them.</p><p>Said simplyâ€”we donâ€™t only want to know â€œhow much more or less do 45-year-old developers make compared to 25-year-old developers.â€ More importantly:</p><blockquote>â€œHow much does a 45-year-old developer earn relative to a 25-year-old developer who is otherwise equivalent (in skills, experience, age, company size, country etc.)?â€</blockquote><p>Both are important questions, but to me, the latter is much more interesting and intuitive. It also happens to be much more difficult to answerâ€”hence it is rarely attempted.</p><p>This is an attempt do better. Not perfect, but much better.</p><h2 id=\"results\">Results</h2><p>I break down the results by survey question, with a chart displaying the controlled effect of each trait on income, in addition to <a href=\"https://www.khanacademy.org/math/ap-statistics/estimating-confidence-ap/introduction-confidence-intervals/v/confidence-intervals-and-margin-of-error\">95% confidence intervals</a>. Correspondingly, any references to statistical significance represent <a href=\"https://www.process.st/p-value/\">p-values</a> &lt; 0.05.</p><p>The results represent a subset of approximately 11,000 U.S-based developers from the Stack Overflow survey.</p><p>If youâ€™d like a nicely formatted report with the full set of results, enter your email below and youâ€™ll receive an email with a download link when ready.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive a report with the full results</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"youremail@example.com\" id=\"mce-EMAIL\" required>\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span>Send Report</span></button>\n</form>\n            </section><!--kg-card-end: html--><p>For more detail on the methodology, please see the appendix at the end.</p><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"/content/images/2019/01/annie-spratt-608001-unsplash-2.jpg\" class=\"kg-image\" alt loading=\"lazy\"></figure><h3 id=\"demographics\">Demographics</h3><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/age.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Initially, age increases earnings. That said, the annualized <a href=\"__GHOST_URL__/you-dont-understand-compound-growth/\">compound</a> gain is quite meagerâ€”about 0.2% through 45-54 years of ageâ€”with most of that happening before a developer turns 25.</p><p>More interesting is how the impact of age declines and turns negative (relative to a developer of 18-24 years of age) as a developer approaches 65:</p><ul><li>At this level of precision, <strong>I cannot distinguish the pay of a developer 55 or older from an otherwise similar one younger than 25</strong></li><li>I can say with reasonable certainty that <strong>a developer over the age of 65 makes less than one of 18-25 years of age</strong> who is otherwise similar.</li></ul><p>Ageism could be playing a role. Tech companies, especially startups, are perceived to have a <a href=\"https://www.techrepublic.com/article/tech-companies-admit-to-actively-targeting-younger-workers-for-jobs/\">preference for younger employees</a>. Evidence of ageism is often anecdotal, but this data is at least suggestive that there may be something real behind this concern.</p><p>Unfortunately, <strong>ageism is notoriously difficult to prove or disprove</strong>, exactly because it is exceedingly rare to find a 25-year-old who is, in every way other than age, the same as a 65-year-old.</p><ul><li>For starters, a 25-year-old developer cannot possibly have much more than 5 years of professional development experience, while a 65-year-old developer almost certainly does. And that is just one variable.</li></ul><p>This is certainly an issue worth exploring further.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/race.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Asian and middle eastern developers are paid much more than similar white developers, and the pay <em>premium</em> is likely larger than the pay <em>discount</em> faced by other minorities.</p><p>Black developers appear to earn 0.8% less than white developers with similar traits, though with a wide enough confidence interval to lose statistical significance.</p><ul><li>The lack of precision (plus or minus 5%) is frustrating but inevitable given the low proportion of black software developers in the population and the dataset</li><li><strong>Note: Only 1.5% of developers in my dataset are black</strong> (not significantly different than the overall developer population)</li></ul><p>Hispanic or latino/a developers earn 1.5% less than similar whites. Again, we see reasonably large confidence intervals due to lack of sufficient data.</p><p>That there is such a large pay premium for asian and middle eastern developers is an interesting factoid in itself and one that warrants further exploration</p><ul><li>The estimates range from 5% to 10%, and all are statistically significant.</li></ul><p>The size of these effects are especially impressive given the small proportion of the dataset these minority groups respectively represent:</p><ul><li><strong>East Asianâ€”2.8%</strong></li><li><strong>Middle Easternâ€”0.6%</strong></li><li><strong>South Asianâ€”3.6%</strong></li></ul><p>That they are statistically significant even with few data points suggests these effects are quite real.</p><p><a href=\"https://www.eeoc.gov/eeoc/publications/fs-epa.cfm\">Pay discrimination is a serious issue</a> that warrants rigorous analysis, much more than what Iâ€™ve done here.</p><ul><li>All in all, the results suggest that attempts to level the â€œpayingâ€ field should also focus on equalizing pay across various racial minority groups, not simply between minority groups and the majority</li></ul><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/gender-1.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>The pay gap for female software developers is similar in magnitude and low statistical significance to that of black developersâ€”roughly 1.3% plus or minus 2.4%.</p><p>Gender non-binary / non-conforming developers face a large pay discount of 10% relative to male developers.</p><p>Given very few observations in the dataset, the pay effect for transgender developers cannot be estimated precisely enough to conclude anything meaningful.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/sexual_orientation.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Gay and lesbian software developers appear to make 2.5% more than straight / heterosexual developers, but this estimate is not statistically significant.</p><p>In fact, given the confidence intervals above, none of the categories of sexual orientation are statistically significantly different from heterosexual. </p><ul><li>Again, this is in part due to limited dataâ€”only 2.4% of developers in the sample are gay or lesbian, for example</li></ul><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/dependents.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Good news for parentsâ€”developers with dependents (children, grandparents etc.) earn 3.7% more than those who donâ€™t, controlling for other factors.</p><p>There are a number of potential explanations for this</p><ul><li>Workers with dependents likely want / need the extra income and hence seek out jobs that pay more</li><li>I do not have evidence to conclude that employers are specifically choosing to pay those with dependents more than others, though this could also be the case</li></ul><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/military_us.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Former and current U.S. military service members earn 3% more than those without prior military service.</p><p>As with other traits, there are any number of potential drivers of the veteran pay premium, and it's inherently difficult to pinpoint the most likely explanation.</p><h4 id=\"takeaways\">Takeaways</h4><ul><li>Drawing justifiable conclusions around the impact of demographic characteristics on income is necessarily tricky given the highly imbalanced nature of the developer population</li><li>Caution is advisable when positing causal connections, and these should ideally be accompanied by some theoretical mechanism</li><li>That said, the results are interesting and should hopefully serve as a starting point for deeper and more rigorous analysis.</li></ul><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"/content/images/2019/01/vasily-koloda-620886-unsplash.jpg\" class=\"kg-image\" alt loading=\"lazy\"></figure><h3 id=\"education\">Education</h3><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/formal_education.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Advanced, non-professional degrees drive higher earnings. A masters or doctoral degree (PhD etc.) drives statistically significant gains of 3% and 10%, respectively, relative to an equivalent developer with only a bachelorâ€™s.</p><p>Going to college but not completing is associated with a 3% cut in earnings, while graduating with an associate degree decreases earning by about 8% vs. a bachelorâ€™s. Again both are statistically significant.</p><p>The effect of professional degrees like JDs and MDs is not statistically significant due to wide confidence intervals.</p><ul><li>Very few people with these degrees are working as software developers, so establishing a precise estimate is difficult.</li></ul><p>Not much can be said for developers that never reached the college levelâ€”due to lack of data, the confidence intervals are too wide to draw meaningful conclusions. However, these folks are almost certainly worse off than someone with an advanced degree.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/undergrad_major.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Interestingly, computer science is not the best-paid college major.</p><ul><li>In fact, other engineering disciplines (civil, mechanical, electrical, etc.) (<strong>5% increase</strong>), business degrees (accounting, finance, etc.) (<strong>4% increase</strong>), and math / stats majors (<strong>3.4% increase</strong>) all earn more, all else equal.</li></ul><p>Outside of these areas, college major is largely irrelevant to developer pay. The meme of the <a href=\"https://www.nytimes.com/2015/08/02/opinion/sunday/were-making-life-too-hard-for-millennials.html\">underpaid, over-educated</a> sociology major doesnâ€™t apply.</p><ul><li>This could be encouraging in that it shows you can be paid for good dev work regardless of your field of study</li><li>With dev schools and bootcamps like <a href=\"https://lambdaschool.com/\">Lambda</a> popping up all over, this is great news if you are considering a career change and worried you might be at a disadvantage.</li><li>On the other hand, it does raise the questionâ€”why arenâ€™t developers who studied the most apparently relevant field paid more than all others?</li><li>Does this say anything about undergraduate computer science teaching, which is often criticized for being <a href=\"https://www.cio.com/article/3293010/hiring-and-staffing/10-reasons-to-ignore-computer-science-degrees.html\">irrelevant and out of touch</a> with professional software development work out in the wild?</li></ul><p>The exceptions are information systems / technology and web development / design degrees, which bear a pay discount of 2.4% and 10% respectively.</p><ul><li>Why? My take is that these degrees are often associated with private, for-profit schools <a href=\"https://www.nytimes.com/2016/09/18/business/itt-educational-services-files-for-bankruptcy-after-aid-crackdown.html\">not often known for their quality</a></li></ul><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/education_parents.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Your parentâ€™s level of education matters as a software developer.</p><p>Developers with at least one parent holding a professional degree like a JD or MD will earn 5.3% more than a developer whose parents never earned more than a bachelorâ€™s degree. Masters and doctoral degrees among parents are associated with a 2.2% increase in pay for the children, though this relationship narrowly misses statistical significance for doctoral degrees.</p><p>Associate degrees, some college, and high school all have significantly negative impacts of 2.8-4%.</p><p>Primary school and no formal education were too rare in the dataset to generate precise effect estimates.</p><p>Itâ€™s interesting to consider how these effects manifest themselves throughout the professional life of a developer</p><ul><li>We can all imagine ways in which parental education could have meaningful follow-on effects in the lives of children</li><li>It is also possible that, with more controls, these effects would dissipate or lose significance</li><li>For example, the effect may channel itself through income or other variables that correlate with (or are influenced by) education, rather than schooling itself</li></ul><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/education_types.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Participation in <a href=\"https://hackathon.guide/\">hackathons</a> is clearly associated with higher payâ€”more than 4.3% higher, as are full-time developer training programs (bootcamps), which provide a 3% bump.</p><p>Weâ€™ve witnessed an <a href=\"https://www.coursereport.com/reports/2018-coding-bootcamp-market-size-research\">explosion in the number of coding bootcamps</a> over the past decade. The pay bump is equivalent in magnitude to a masterâ€™s degree, which is incredible given bootcamps take months to complete, not years, and are generally cheaper in tuition than an advanced degree.</p><p>Contributing to open source software, or OSS (certainly an educational experience, in a sense), has a positive but not statistically significant bump of 1.6%</p><ul><li>Open-source penetration of the typical software stack has only increased over the yearsâ€”it would make sense if active contribution to OSS is rewarded with higher pay.</li></ul><p>Industry certifications get a big fat zero. No effect.</p><p>On the other hand, online programming courses, MOOCs, etc. are associated with a significant drop of slightly more than 2.4%. Given the <a href=\"https://www.creativebloq.com/web-design/online-coding-courses-11513890\">proliferation of online software development courses</a> over the years, this is an inconvenient finding.</p><ul><li>That all said, I do worry about potentially confounding or omitted variables that have not been controlled for</li><li>I canâ€™t imagine a strong causal link between taking an online course and lower pay, but I can certainly imagine that the \"type of personâ€ who takes an online course might also be the type of person that generally earns less</li></ul><p>Likewise, the type of person to participate in a hackathon likely has other, unobserved traits that drive higher income</p><ul><li>Certain companies, which may be higher paying on average, also host hackathons in their offices</li></ul><p>In other words, correlation may not be causation here, even after controlling for many variables.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/self_taught_types.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>As an avid self-learner myself, I am disappointed to see that no form of self-learning seems to have a statistically discernible impact on earnings.</p><ul><li>Books and e-books were close to achieving statistical significance, but even so, the point estimate is only 1%.</li></ul><p>Self-learning is a great way to, in targeted fashion, learn exactly what you need to know about a certain topic or area of knowledge. For many, it is more effective than traditional teaching methods.</p><p>However, it doesnâ€™t seem to impact pay in and of itself.</p><h4 id=\"takeaways-1\">Takeaways</h4><ul><li>Education matters, largely in the ways one would guess</li><li>If youâ€™ve already graduated from college, advanced degrees, hackathons, bootcamps, and open source projects can be smart ways to increase your value as a developer in ways that show up in your paycheck</li><li>If you havenâ€™t graduated yet, know that the exact major you pick matters less than showing interest or commitment to the craft, at least when it comes to pay</li></ul><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"/content/images/2019/01/nesa-by-makers-701360-unsplash.jpg\" class=\"kg-image\" alt loading=\"lazy\"></figure><h3 id=\"professional-characteristics\">Professional Characteristics</h3><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/years_coding.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Professional development experience matters much more than casual coding. The gains from more years of general coding experience tend to plateau after 15 years, while professional coding experience continues to pay dividends well into the 30 year range.</p><p>The benefit from experience with casual coding (relative to 0-2 years) maxes out at 10-15% and actually begins to decline after 26 years.</p><ul><li>Again, this is holding other factors equal, including professional experience, so this may make sense</li><li>Someone who learned to code 30 years ago and has little more to show for it than someone with only 10 years of coding experience might raise flags.</li><li>We must be careful howeverâ€”taking the year one learned to code as given, years since learning to code correlates perfectly with age, suggesting that ageism may be leaking in here. I explore age specifically elsewhere in this post.</li></ul><p>The fastest gains from professional experience come in the first ten years.</p><ul><li>A developer with 9-11 years of professional experience can expect to earn 30% more than a newbie, all else equal, which translates to about 2.5 percent year-over-year gains.</li><li>Of course, â€œall elseâ€ is likely not equal for any given developer across a ten-year span, suggesting even greater potential annual raises for a given developer in the real world.</li></ul><p>After the first decade, the line is nearly straight, aside from a mid-career slump at the 25-year mark.</p><ul><li>Do not be fooled, howeverâ€”constant absolute gains in fact represent declining growth</li><li>In other words, each year of professional development experience provides a nearly-constant dollar raise but a declining percentage raise. I explore this phenomenon further in a upcoming post</li></ul><p>With that caveat, it is still encouraging to see that developer pay does not fully plateau or reverse course with additional professional experience over time.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/employment.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>No surprise hereâ€”working part-time does not help your earnings.</p><p>More interestingly, developers working as freelancers or independent contractors make more than those employed full-time</p><ul><li>This may be compensated for by what is almost surely more variable income</li><li>In general, stable, full-time employment does come at a cost, not only in software development but in many other areas of the economy</li></ul><p>Reverse causation could also be at play hereâ€”someone who knows they could make more as a freelancer is exactly the kind of person who would become one.</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"/content/images/2019/01/dev_type.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption><em>(Read: â€œDevOps specialists make 2% more than non-DevOps specialists, all else equalâ€)</em></figcaption></figure><p>Itâ€™s no surprise that managers and executives earn more. This includes <a href=\"https://qz.com/766658/the-highest-paid-workers-in-silicon-valley-are-not-software-engineers/\">product managers</a>, who might not write significant amounts of code themselves.</p><ul><li>Engineering managers and C-suite execs make 10% more, while product managers make 5.8% more, all else equal.</li></ul><p>The only non-manager role that makes meaningfully more than its counterparts is DevOps:</p><ul><li>DevOps specialists are about 2.2 percentage points higher on the pay scale than the non-DevOps average for similar developers.</li></ul><p>Conversely, there are a number of roles that make noticeably less despite similar levels of experience, education etc.</p><ul><li>Database admins (DBAs), sysadmins, designers, QA / testing developers make 2.5-7.5% less than developers who donâ€™t fall under these categories</li><li>With the exception of designers, these roles are commonly seen as the â€œback officeâ€ of IT, though one could easily find counter examples depending on the specific team or organization</li><li>Perhaps needless to sayâ€”academics and students earn meaningfully less than those outside of academia</li></ul><h4 id=\"takeaways-2\">Takeaways</h4><ul><li>Professional experience matters and never stops mattering</li><li>Casual development experience helps tooâ€”but only so much, measured both by the amount of experience and the earnings impact</li><li>Among those working in industry, role matters positively for managers and DevOps professionals and negatively for system and database administrators, as well as designers</li></ul><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"/content/images/2019/01/ilya-pavlov-87438-unsplash.jpg\" class=\"kg-image\" alt loading=\"lazy\"></figure><h3 id=\"languages-frameworks-databases-platforms-and-tools\">Languages, Frameworks, Databases, Platforms, and Tools</h3><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"/content/images/2019/01/languages-1.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption><em>(Read: â€œDevelopers who have done extensive development work involving Golang earn more than those who havenâ€™tâ€)</em></figcaption></figure><p>The main implication of these resultsâ€”languages largely donâ€™t matter to pay. The vast majority of languages do not provide a statistically significant pay bump or discount relative to jobs that donâ€™t require that language. The pay scale for programming languages is quite flat across the universe of languages.</p><p>Hack is a clear outlierâ€”working with Hack yields a 25% bump. However, donâ€™t drop everything to go learn Hack right now</p><ul><li>Hack is not a widely used language</li><li>It was developed by Facebook, and unlike other languages and frameworks that come out of the big tech giants, Hack has not had the same marketing push placed behind it. </li><li>The effect we see here likely reflects developers who work at Facebook itselfâ€”thereâ€™s no sign of a robust hiring market for Hack talent.</li></ul><p>Outside of Hack, on the positive side we find Objective-C, C++, Go, VBA, and TypeScript with statistically significant income effects, ranging from 2.1 to 3.9 percent.</p><p>On the negative side we have JavaScript, VB.NET, CSS, and PHP</p><ul><li>JS, CSS, and PHP likely reflect the lower pay of certain web development jobs</li><li>These languages represent fundamental technologies of web development</li><li>For that same reason however, they are considered table stakes</li><li>Hence, using these technologies on the job doesnâ€™t provide much of a pay bump, though you may be quite employable</li></ul><p>Please note that the results above are <strong>not</strong> saying â€œknowing language X increases / decreases pay.â€ Knowing a language is not likely to ever <em>harm</em> oneâ€™s pay, but working a dev job that uses it might (relative to other development work).</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/frameworks.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Reactâ€”what needs to be said?</p><ul><li>The <a href=\"https://reactjs.org/\">cutting-edge JavaScript framework</a> originated and maintained by Facebook is widely and wildly popular, especially among front-end developers looking for an easy-to-use but powerful way to craft compelling user interfaces.</li><li>React is associated with a 4.1% pay increase and is the only framework with a statistically significant positive impact.</li></ul><p>Working with .NET Core and PyTorch negatively impacts income</p><ul><li>I do not have a hypothesis about .NET Core, but I do know that <a href=\"https://code.fb.com/ai-research/announcing-pytorch-1-0-for-both-research-and-production/\">PyTorch was historically used much more among researchers</a> than industry practitioners, likely driving lower pay</li><li>Usage has since branched out as the framework has added production-grade capabilities and tooling.</li></ul><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/databases.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>One wordâ€”cloud. Almost all of the databases with positive income effects are hosted in the cloud, often exclusively as a managed service by one of the major public cloud service providers (Google, Amazon, Facebook).</p><p>Googleâ€™s BigQuery data warehouse tops the list, followed closely by Amazonâ€™s competing Redshift. Apache Hbase and Hive come next. Afterwards itâ€™s Amazonâ€™s DynamoDB and Microsoftâ€™s Azure Tables, Cosmos DB, and SQL. The list continues with Memcached, Redis, Elasticsearch, Google Cloud Storage, and Amazon RDS and Auroraâ€”all positive and statistically significant.</p><p>Older database technologies from legacy vendors dominate the negative end. This includes Oracleâ€™s once ubiquitous databases, MySQL, SQL Server, MariaDB, and IBMâ€™s Db2.</p><p>Itâ€™s fascinating to see the impact of the cloud revolution laid out in stark relief. There are meaningful income gains associated with working with next-gen cloud-enabled databases. This fact should be top of mind for developers looking to upgrade their skills and pay.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/platforms.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Iâ€™ll say it againâ€”cloud. The various public clouds are the only platforms aside from Windows Phone with positive, statistically significant effects on developer earnings. Azure is associated with 4.1% higher pay, GCP 2.7%, AWS 1.7%.</p><p>And Windows Phone? Not going to try to explain that one.</p><p>Android, Arduino and Drupal had meaningful negative association with incomeâ€”2.4%, 4.6%, and 8.5% respectively.</p><p>Androidâ€™s ubiquitous operating system needs no introduction, though itâ€™s negative pay relationship might need an explanation. Unfortunately, I am stumped here.</p><p>Arduino is an <a href=\"https://www.arduino.cc/\">open-source prototyping platform</a> with associated hardware microcontrollers that eases development of electronic devices. Though used for serious development work, <a href=\"https://www.arduino.cc/en/main/education\">Arduino is also heavily used by engineering students</a> as well, which likely drives the negative value.</p><p>Drupal is a PHP-based content management system whose <a href=\"https://trends.google.com/trends/explore?date=all&amp;geo=US&amp;q=drupal\">popularity peaked in 2011</a> but has since been on a slow decline.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/ide.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>You might not think that a developerâ€™s choice of IDE or text editors wouldnâ€™t matterâ€”and youâ€™d be (largely) correct! The associated effects here are generally quite small.</p><p>However, IntelliJ stands out from the pack</p><ul><li>Billed by JetBrains, its creator, as the â€œJava IDE for professional developersâ€, IntelliJ users make 3.1% more than non-users</li><li>Of course, this is not an entirely useful comparison for someone who doesnâ€™t use Java in their development work</li></ul><p>Notepad++ and Atom are associated with slightly lower earnings, on the order of 2%, which is statistically significant. Notably, both are popular but are generally viewed more as text editors than fully-fledged IDEs.</p><p>PhpStorm, Xcode, and Coda also had negative effects that were statistically significant.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/methodology.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>The incredibly popular Agile leads the pack among project management methodologies. Devs who use Agile in their development work earn 3.9% more than those who donâ€™t.</p><p>The less common extreme programming methodology is associated with 2.7% higher pay.</p><p>Lean comes in at 2.5%, while Scrum developers earn 1.5% more, all else equal.</p><p>Prince2 appears to be at outlier, but this is mostly due to limited dataâ€”only 0.1% of developers in the sample use the methodology.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/version_control.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>For the most part, the exact form of version control used does not matter.</p><p>The key takeaway hereâ€”any kind of version control is better than no version control, but please, please avoid copying and pasting files to a network share.</p><h3></h3><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/check_in_code.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>The best practice appears to be the best paid</p><ul><li>Checking in code multiple times per day</li><li>Itâ€™s clearly important to check in code on some kind of cadenceâ€”at least monthly, ideally</li><li>If you are checking in code less than once per month or not at all, your pay is likely being impacted as a result.</li></ul><p>Not to sound like a broken record, but the reverse causation caveat applies here as well. It is completely plausible that checking in code more often increases a developers pay. Itâ€™s also possible that companies that pay more are more likely to follow and mandate development best practices, such as frequent code check-ins.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/communication_tools.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>It seems too convenient that in a survey run by Stack Overflow that its own enterprise product would be associated with significantly higher developer pay, but I can only go where the data takes me. Developers using Stack Overflow Enterprise earn 9.4% more than those who donâ€™t.</p><p>This likely picks up some effect of simply working at a company that uses Stack Overflow Enterprise, which may be higher paying on average.</p><p>Other communication tools had smaller positive impacts like the incredibly popular Slack, Atlassianâ€™s Confluence, HipChat, and internal intranet sites (wikis, Google sites etc), which all have earnings effects in the 2-3% range.</p><p>Trello and Facebook are negative enough to be statistically significant.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/number_monitors.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Surprisingly, developers who use two monitors earn 2.8% less than those who use only a single monitor, all else equal.</p><p>At this time, itâ€™s not clear why more monitors would negatively impact earnings. The potential for enhanced productivity may be swamped by the temptation to use the additional screen real estate for <a href=\"https://www.reddit.com/\">non-work activities</a>.</p><p>No other monitor count had a statistically significant effect on income relative to one.</p><h4 id=\"takeaways-3\">Takeaways</h4><ul><li>The tools associated with higher developer pay are quite interesting and not necessarily what one might expect</li><li>In some cases, the most popular tools also pay the most</li><li>In other cases, more obscure tools appear to have an advantage</li><li>Check in your code (at least every once in a while)!</li><li>One clear trend is the impact the move to the cloud is having on developersâ€”the effects of the public cloud on developer pay are large and consistently statistically significant across the big 3 U.S. clouds</li><li>Knowing how to use and leverage these next-generation computing environments and finding a job that employs those skills can drive meaningful pay improvements for the average developer</li></ul><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"/content/images/2019/01/marion-michele-191320-unsplash.jpg\" class=\"kg-image\" alt loading=\"lazy\"></figure><h3 id=\"work-life-health-and-wellness\">Work Life, Health, and Wellness</h3><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/wake_time.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>These results are admittedly difficult to interpret. There is no clear linear time trend for the impact of wake up time on earnings.</p><p>After 7am, later does appear to be somewhat betterâ€”up to a point. Strangely, developers between 11am and 12pm see 15.4% higher pay than those who are up before 5am.</p><p>The most important takeaway is thisâ€”<strong>have a set schedule</strong>. This will do more good than optimizing for a specific wake-up time. Not having a regular wake up time was associated with 7.7% lower pay for software developers.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/exercise.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Exercise is strongly associated with earnings. While only exercising once or twice a week does not appear impactful, exercising 3 times or more per week is associated with 2-2.9% higher pay than a similar developer who does not exercise at all.</p><p>It is possible however that reverse causation could cause developers who earn more to work out moreâ€”perhaps because they have more time or can more easily afford a gym membership. Alternatively, higher paying companies often have gyms on-premises, making it easier to work out more.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/skip_meals.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Donâ€™t skip meals. Any amount of meal skipping was associated with lower pay, though never statistically significant. Developers are not rewarded for this unhealthy work habit.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/ergonomic_devices.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Among ergonomic devices, <a href=\"https://thewirecutter.com/reviews/best-standing-desk/\">standing desks</a> were associated with 3.2% higher pay, which is statistically significant.</p><p>Again, higher paying companies are potentially more like to provide employees with standing desks, so the direction of causality here is questionable.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/hours_computer.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Time spent at the computer each day does not have a meaningful relationship with pay. Handcuffing yourself to your laptop is not going to earn you higher pay as a developer.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2019/01/hours_outside.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Unlike time spent at the computer, time spent outside does have an impact on pay, with the ideal amount being 1-2 hours. Spending fewer than 30 minutes outside is associated with 2.4% lower pay than 30 minutes to an hour.</p><p>Spending more than 4 hours outside was associated with lower pay, but there were not enough developers who do this regularly to generate a precise estimate.</p><h4 id=\"takeaways-4\">Takeaways</h4><ul><li>The data suggest that common best practices are often the best way to go</li><li>Spend at least a small amount of time outside each day</li><li>Skipping meals will only grow your bank balance to the extent you save money on lunch</li><li>Exercising a few times per week is better than never hitting the gym</li></ul><figure class=\"kg-card kg-image-card kg-width-full\"><img src=\"/content/images/2019/01/hans-peter-gauster-252751-unsplash.jpg\" class=\"kg-image\" alt loading=\"lazy\"></figure><h2 id=\"conclusion\">Conclusion</h2><p>There are many important takeaways from the study and the charts above.</p><p>This analysis is a first attempt at exploring the various factors that affect developer pay. To that end, I hope that it is illuminating and informative.</p><p>However, as with many attempts to answer difficult questions, the analysis raises as many questions as it answers.</p><p>I am publishing the full code to reproduce this analysis because I believe open source, replicable research is the key to the robust advancement of knowledge</p><ul><li>I would love for this analysis to serve as starting point for others who wish to elevate the state of knowledge on this important topic</li><li>If you find an error or disagree with some aspect of the analysis, feel free to submit edits (pull requests) to my <a href=\"https://gitlab.com/whoisnnamdi/highest-paid-software-developer\">GitLab</a> or <a href=\"https://github.com/whoisnnamdi/highest-paid-software-developer\">GitHub</a> repositories</li></ul><p>I care deeply about the technology industry. But solving its issues and compounding its strengths demands a rigorous understanding of its component elements. <a href=\"https://www.cnbc.com/2018/09/06/companies-worry-more-about-access-to-software-developers-than-capital.html\">Developers are a critical piece of the tech puzzle</a>, and they deserve our attention.</p><h2 id=\"appendix\">Appendix</h2><h2 id=\"data\">Data</h2><p>As in my last post, I leverage data from Stack Overflowâ€™s annual software developer survey, which asks about income, in addition to many other questions of interest. </p><p>Examples include</p><ul><li>Which of the following best describes the highest level of formal education that youâ€™ve completed?</li><li>Approximately how many people are employed by the company or organization you work for?</li><li>Which of the following programming, scripting, and markup languages have you done extensive development work in over the past year?</li></ul><p>Iâ€™m interested in how answers to these questions affect income. While itâ€™s impossible to completely avoid issues of reverse causality or correlation rather than causation, by using regression augmented with machine learning techniques, described here, we can have greater confidence that our results accurately represent the true relationship income.</p><p>Essentially, weâ€™ll analyze how each possible answer affects income, holding all other answers constant.</p><p>I limit the dataset to only non-retired US respondents above the age of 18 with income between $10,000-250,000. Responses above $250K have a higher tendency to be troll (i.e. made up) responses, which Iâ€™d like to exclude, and few answers come in above this threshold regardless.</p><p>This leaves us with a dataset of approximately 11,000 developers.</p><h3 id=\"methodology\">Methodology</h3><p>I estimate the following equation on the data:</p><p>$$\\log(income) = \\beta_0 + \\beta_1T + \\beta_2X + \\epsilon$$</p><p>Where \\(T\\) is our trait of interest, \\(\\beta_1\\) is the effect of that trait on income relative to the base category, \\(X\\) is a set of controls (in our case, the respondent's answers to other questions in the survey), \\(\\beta_2\\) is the set of effects for each respective control, and \\(\\epsilon\\) is the irreducible error in our estimate.</p><p>Assuming weâ€™ve included a â€œcompleteâ€ and â€œcorrect\" set of controls, this should provide a reasonably accurate estimate of the relationship of the trait of interest, \\(T\\), with income. The log transformation of income means our results will be in roughly percentage terms, implying that trait \\(T\\) is associated with an increase in income of \\(\\beta_1*100\\%\\) relative to the â€œbase\" category, all else equal. The base category will vary by trait.</p><p>Selecting the right set of controls is non-trivial. One has any number of degrees of freedom to select a subset of controls among all those available, opening the doors to â€œp-hackingâ€ and other infamous behavior, which can lead to incorrect (biased) estimates of the parameters of interest.</p><p>To avoid this, I leverage a powerful machine learning technique, Double Selection (specifically Double Lasso Selection), to do principled covariate selection for each trait \\(T\\), rerunning the regression for every trait. As described in <a href=\"https://arxiv.org/abs/1201.0224\">Belloni, Chernozhukov, Hansen (2011)</a>, this should provide a more accurate estimate of the income effect of each trait than simply using all the covariates or attempting to manually select a subset. I wonâ€™t cover the method in detail here, but refer to the original paper for more information. <a href=\"https://medium.com/teconomics-blog/using-ml-to-resolve-experiments-faster-bd8053ff602e\">This post</a> provides a relatively intuitive explanation, and is also where I originally learned of the technique.</p><p>Long story short, Double Selection makes us much more confident that the results represent the accurate effects.</p><p><em>This post has been published on <a href=\"http://www.productschool.com\">www.productschool.com</a> communities</em></p>","comment_id":"5c3705e19e310a4f2c5532b6","plaintext":"Note: You can find this analysis updated for 2020 here\n[__GHOST_URL__/highest-paid-software-engineers-2020/].\n\nDev fell in love with code at a young age.\n\nHe graduated from college with an engineering degree and then joined the Navy as\na cyber warfare engineer [https://www.navy.com/careers/cyber-warfare-engineer].\nPressured by his highly educated Persian parents, Dev returned to school after\nmilitary service to complete a master's in computer science\n[https://online.stanford.edu/programs/computer-science-ms-degree]. He has spent\nhis entire career since in software development, mostly coding in C++\n[https://en.wikipedia.org/wiki/C%2B%2B].\n\nHe realized early on that workloads were moving to the cloud and spent years\nretooling and upgrading his skill set, familiarizing himself with each of the\nmajor cloud vendors. He championed his team's transition from an on-premise\nOracle database to a next-gen database hosted in the public cloud.\n\nAlways on the cutting edge, Dev regularly attends employer-sponsored training\nsessions and hackathons.\n\nDev worked with all of the major programming methodologies over the years but\neventually settled on Agile [https://www.agilealliance.org/agile101/], becoming\na big fan.\n\nNow a manager at a large, 15,000+ employee technology giant\n[http://www.piedpiper.com/], he takes time to work out 3-4 times per week at the\nfree company gym. Even after completing an agile sprint\n[https://www.atlassian.com/agile/scrum/sprints] he keeps moving - jogging home\nafter work most days.\n\nAfter promotion, Dev gave his second monitor to one of his younger direct\nreports. He wasn't spending as many hours furiously coding as he used to, so the\nextra real estate felt unnecessary.\n\nA big proponent of healthy work habits, last year he procured a full set of\nstanding desks for his entire team and required that all team members eat lunch\naway from their workstations. Rarely rushed himself, he never skips meals.\n\nDuring the week, Dev wakes up just after 11am. Every. Single. Day.\n\nMust be nice right?\n\nHowever, at 50 years of age, Dev worries if his career has already peaked. He\nhas no plans to retire any time soon, but whispers of ageism in tech\n[http://blog.indeed.com/2017/10/19/tech-ageism-report/] and seeing his older\ncolleagues being laid off have him wondering if he's next.\n\nThat said, he knows he could make up lost income working independently as a\nfreelancer. He has a hunch he'd make even more running solo.\n\nA proud, loving father, Dev hopes his daughter follows in his footsteps. He sees\na bright, better future for her. As far as he's concerned, the world is her\noyster.\n\nWho is this guy?\nIf it's not clear already, Dev's not a real person.\n\nBut his personal and professional characteristics really do correlate with\nhigher income.\n\nAge. Gender. Race.\n\nEducation. Professional experience. Programming languages.\n\nMethodology. Hackathons. Even how many monitors he uses.\n\nThe traits that correspond with higher pay are not always what we would expect -\nnor necessarily what we'd hope.\n\nThe economics of developer pay is an important topic for me. Developers are the \nkey input in the production of software. You cannot understand tech unless you\nunderstand how developers get paidâ€”you just can't.\n\nHowever, the publicly available analysis of this important issue is quite poor.\n\nThe problem with most pay analyses\nAs covered in my last post\n[__GHOST_URL__/the-growth-share-matrix-of-software-development/], Stack Overflow\nconducts an annual survey of software developers, asking about various aspects\nof their careers, like income, job title, etc.\n\nOne disappointing feature of most pay analyses is that they show the data\nwithout controlling for any other variables. Avoiding any math more complex than\nsimple averages, the typical analyses of pay have no way to understand a\nmultivariate world.\n\nStack Overflowâ€™s own write-up [https://insights.stackoverflow.com/survey/2018/] \nof the survey results does this at times, taking the simple average of income\nacross all full-stack developers, for example, and comparing the same metric for\nDevOps specialists:\n\nStatements like \"Engineering managers, DevOps specialists, and data scientists\ncommand the highest salariesâ€ are then made, which, though technically true,\ntend to mislead readers who are not well-versed in statistics into thinking that\nthese are ceteris paribus [https://en.wikipedia.org/wiki/Ceteris_paribus] (all\nthings equal) comparisons (\"X makes more than Y, all else equal\"), which they\nare not.\n\nTo their credit, Stack Overflow at least takes the additional step of comparing\nthese salaries against years of professional experience, but that is just one of\nmany possible controls. In fact, the entire survey provides a rich set of\npotential controls to â€œhold equalâ€ and thereby generate more intuitively\naccurate statements about potential relationships (â€œX developers make more than\nYs who are otherwise similarâ€, which is a qualitatively and likely\nquantitatively different statement than â€œXs make more than Ys\").\n\nUnfortunately, most public discussion of pay does not control for even a single\nvariable. This isnâ€™t lying with statistics so much as it is misleading with\nthem.\n\nSaid simplyâ€”we donâ€™t only want to know â€œhow much more or less do 45-year-old\ndevelopers make compared to 25-year-old developers.â€ More importantly:\n\n> â€œHow much does a 45-year-old developer earn relative to a 25-year-old developer\nwho is otherwise equivalent (in skills, experience, age, company size, country\netc.)?â€\nBoth are important questions, but to me, the latter is much more interesting and\nintuitive. It also happens to be much more difficult to answerâ€”hence it is\nrarely attempted.\n\nThis is an attempt do better. Not perfect, but much better.\n\nResults\nI break down the results by survey question, with a chart displaying the\ncontrolled effect of each trait on income, in addition to 95% confidence\nintervals\n[https://www.khanacademy.org/math/ap-statistics/estimating-confidence-ap/introduction-confidence-intervals/v/confidence-intervals-and-margin-of-error]\n. Correspondingly, any references to statistical significance represent p-values\n[https://www.process.st/p-value/] < 0.05.\n\nThe results represent a subset of approximately 11,000 U.S-based developers from\nthe Stack Overflow survey.\n\nIf youâ€™d like a nicely formatted report with the full set of results, enter your\nemail below and youâ€™ll receive an email with a download link when ready.\n\nReceive a report with the full results\n\n\nSend Report For more detail on the methodology, please see the appendix at the\nend.\n\nDemographics\nInitially, age increases earnings. That said, the annualized compound\n[__GHOST_URL__/you-dont-understand-compound-growth/] gain is quite meagerâ€”about\n0.2% through 45-54 years of ageâ€”with most of that happening before a developer\nturns 25.\n\nMore interesting is how the impact of age declines and turns negative (relative\nto a developer of 18-24 years of age) as a developer approaches 65:\n\n * At this level of precision, I cannot distinguish the pay of a developer 55 or\n   older from an otherwise similar one younger than 25\n * I can say with reasonable certainty that a developer over the age of 65 makes\n   less than one of 18-25 years of age who is otherwise similar.\n\nAgeism could be playing a role. Tech companies, especially startups, are\nperceived to have a preference for younger employees\n[https://www.techrepublic.com/article/tech-companies-admit-to-actively-targeting-younger-workers-for-jobs/]\n. Evidence of ageism is often anecdotal, but this data is at least suggestive\nthat there may be something real behind this concern.\n\nUnfortunately, ageism is notoriously difficult to prove or disprove, exactly\nbecause it is exceedingly rare to find a 25-year-old who is, in every way other\nthan age, the same as a 65-year-old.\n\n * For starters, a 25-year-old developer cannot possibly have much more than 5\n   years of professional development experience, while a 65-year-old developer\n   almost certainly does. And that is just one variable.\n\nThis is certainly an issue worth exploring further.\n\nAsian and middle eastern developers are paid much more than similar white\ndevelopers, and the pay premium is likely larger than the pay discount faced by\nother minorities.\n\nBlack developers appear to earn 0.8% less than white developers with similar\ntraits, though with a wide enough confidence interval to lose statistical\nsignificance.\n\n * The lack of precision (plus or minus 5%) is frustrating but inevitable given\n   the low proportion of black software developers in the population and the\n   dataset\n * Note: Only 1.5% of developers in my dataset are black (not significantly\n   different than the overall developer population)\n\nHispanic or latino/a developers earn 1.5% less than similar whites. Again, we\nsee reasonably large confidence intervals due to lack of sufficient data.\n\nThat there is such a large pay premium for asian and middle eastern developers\nis an interesting factoid in itself and one that warrants further exploration\n\n * The estimates range from 5% to 10%, and all are statistically significant.\n\nThe size of these effects are especially impressive given the small proportion\nof the dataset these minority groups respectively represent:\n\n * East Asianâ€”2.8%\n * Middle Easternâ€”0.6%\n * South Asianâ€”3.6%\n\nThat they are statistically significant even with few data points suggests these\neffects are quite real.\n\nPay discrimination is a serious issue\n[https://www.eeoc.gov/eeoc/publications/fs-epa.cfm] that warrants rigorous\nanalysis, much more than what Iâ€™ve done here.\n\n * All in all, the results suggest that attempts to level the â€œpayingâ€ field\n   should also focus on equalizing pay across various racial minority groups,\n   not simply between minority groups and the majority\n\nThe pay gap for female software developers is similar in magnitude and low\nstatistical significance to that of black developersâ€”roughly 1.3% plus or minus\n2.4%.\n\nGender non-binary / non-conforming developers face a large pay discount of 10%\nrelative to male developers.\n\nGiven very few observations in the dataset, the pay effect for transgender\ndevelopers cannot be estimated precisely enough to conclude anything meaningful.\n\nGay and lesbian software developers appear to make 2.5% more than straight /\nheterosexual developers, but this estimate is not statistically significant.\n\nIn fact, given the confidence intervals above, none of the categories of sexual\norientation are statistically significantly different from heterosexual. \n\n * Again, this is in part due to limited dataâ€”only 2.4% of developers in the\n   sample are gay or lesbian, for example\n\nGood news for parentsâ€”developers with dependents (children, grandparents etc.)\nearn 3.7% more than those who donâ€™t, controlling for other factors.\n\nThere are a number of potential explanations for this\n\n * Workers with dependents likely want / need the extra income and hence seek\n   out jobs that pay more\n * I do not have evidence to conclude that employers are specifically choosing\n   to pay those with dependents more than others, though this could also be the\n   case\n\nFormer and current U.S. military service members earn 3% more than those without\nprior military service.\n\nAs with other traits, there are any number of potential drivers of the veteran\npay premium, and it's inherently difficult to pinpoint the most likely\nexplanation.\n\nTakeaways\n * Drawing justifiable conclusions around the impact of demographic\n   characteristics on income is necessarily tricky given the highly imbalanced\n   nature of the developer population\n * Caution is advisable when positing causal connections, and these should\n   ideally be accompanied by some theoretical mechanism\n * That said, the results are interesting and should hopefully serve as a\n   starting point for deeper and more rigorous analysis.\n\nEducation\nAdvanced, non-professional degrees drive higher earnings. A masters or doctoral\ndegree (PhD etc.) drives statistically significant gains of 3% and 10%,\nrespectively, relative to an equivalent developer with only a bachelorâ€™s.\n\nGoing to college but not completing is associated with a 3% cut in earnings,\nwhile graduating with an associate degree decreases earning by about 8% vs. a\nbachelorâ€™s. Again both are statistically significant.\n\nThe effect of professional degrees like JDs and MDs is not statistically\nsignificant due to wide confidence intervals.\n\n * Very few people with these degrees are working as software developers, so\n   establishing a precise estimate is difficult.\n\nNot much can be said for developers that never reached the college levelâ€”due to\nlack of data, the confidence intervals are too wide to draw meaningful\nconclusions. However, these folks are almost certainly worse off than someone\nwith an advanced degree.\n\nInterestingly, computer science is not the best-paid college major.\n\n * In fact, other engineering disciplines (civil, mechanical, electrical, etc.)\n   (5% increase), business degrees (accounting, finance, etc.) (4% increase),\n   and math / stats majors (3.4% increase) all earn more, all else equal.\n\nOutside of these areas, college major is largely irrelevant to developer pay.\nThe meme of the underpaid, over-educated\n[https://www.nytimes.com/2015/08/02/opinion/sunday/were-making-life-too-hard-for-millennials.html] \nsociology major doesnâ€™t apply.\n\n * This could be encouraging in that it shows you can be paid for good dev work\n   regardless of your field of study\n * With dev schools and bootcamps like Lambda [https://lambdaschool.com/] \n   popping up all over, this is great news if you are considering a career\n   change and worried you might be at a disadvantage.\n * On the other hand, it does raise the questionâ€”why arenâ€™t developers who\n   studied the most apparently relevant field paid more than all others?\n * Does this say anything about undergraduate computer science teaching, which\n   is often criticized for being irrelevant and out of touch\n   [https://www.cio.com/article/3293010/hiring-and-staffing/10-reasons-to-ignore-computer-science-degrees.html] \n   with professional software development work out in the wild?\n\nThe exceptions are information systems / technology and web development / design\ndegrees, which bear a pay discount of 2.4% and 10% respectively.\n\n * Why? My take is that these degrees are often associated with private,\n   for-profit schools not often known for their quality\n   [https://www.nytimes.com/2016/09/18/business/itt-educational-services-files-for-bankruptcy-after-aid-crackdown.html]\n\nYour parentâ€™s level of education matters as a software developer.\n\nDevelopers with at least one parent holding a professional degree like a JD or\nMD will earn 5.3% more than a developer whose parents never earned more than a\nbachelorâ€™s degree. Masters and doctoral degrees among parents are associated\nwith a 2.2% increase in pay for the children, though this relationship narrowly\nmisses statistical significance for doctoral degrees.\n\nAssociate degrees, some college, and high school all have significantly negative\nimpacts of 2.8-4%.\n\nPrimary school and no formal education were too rare in the dataset to generate\nprecise effect estimates.\n\nItâ€™s interesting to consider how these effects manifest themselves throughout\nthe professional life of a developer\n\n * We can all imagine ways in which parental education could have meaningful\n   follow-on effects in the lives of children\n * It is also possible that, with more controls, these effects would dissipate\n   or lose significance\n * For example, the effect may channel itself through income or other variables\n   that correlate with (or are influenced by) education, rather than schooling\n   itself\n\nParticipation in hackathons [https://hackathon.guide/] is clearly associated\nwith higher payâ€”more than 4.3% higher, as are full-time developer training\nprograms (bootcamps), which provide a 3% bump.\n\nWeâ€™ve witnessed an explosion in the number of coding bootcamps\n[https://www.coursereport.com/reports/2018-coding-bootcamp-market-size-research] \nover the past decade. The pay bump is equivalent in magnitude to a masterâ€™s\ndegree, which is incredible given bootcamps take months to complete, not years,\nand are generally cheaper in tuition than an advanced degree.\n\nContributing to open source software, or OSS (certainly an educational\nexperience, in a sense), has a positive but not statistically significant bump\nof 1.6%\n\n * Open-source penetration of the typical software stack has only increased over\n   the yearsâ€”it would make sense if active contribution to OSS is rewarded with\n   higher pay.\n\nIndustry certifications get a big fat zero. No effect.\n\nOn the other hand, online programming courses, MOOCs, etc. are associated with a\nsignificant drop of slightly more than 2.4%. Given the proliferation of online\nsoftware development courses\n[https://www.creativebloq.com/web-design/online-coding-courses-11513890] over\nthe years, this is an inconvenient finding.\n\n * That all said, I do worry about potentially confounding or omitted variables\n   that have not been controlled for\n * I canâ€™t imagine a strong causal link between taking an online course and\n   lower pay, but I can certainly imagine that the \"type of personâ€ who takes an\n   online course might also be the type of person that generally earns less\n\nLikewise, the type of person to participate in a hackathon likely has other,\nunobserved traits that drive higher income\n\n * Certain companies, which may be higher paying on average, also host\n   hackathons in their offices\n\nIn other words, correlation may not be causation here, even after controlling\nfor many variables.\n\nAs an avid self-learner myself, I am disappointed to see that no form of\nself-learning seems to have a statistically discernible impact on earnings.\n\n * Books and e-books were close to achieving statistical significance, but even\n   so, the point estimate is only 1%.\n\nSelf-learning is a great way to, in targeted fashion, learn exactly what you\nneed to know about a certain topic or area of knowledge. For many, it is more\neffective than traditional teaching methods.\n\nHowever, it doesnâ€™t seem to impact pay in and of itself.\n\nTakeaways\n * Education matters, largely in the ways one would guess\n * If youâ€™ve already graduated from college, advanced degrees, hackathons,\n   bootcamps, and open source projects can be smart ways to increase your value\n   as a developer in ways that show up in your paycheck\n * If you havenâ€™t graduated yet, know that the exact major you pick matters less\n   than showing interest or commitment to the craft, at least when it comes to\n   pay\n\nProfessional Characteristics\nProfessional development experience matters much more than casual coding. The\ngains from more years of general coding experience tend to plateau after 15\nyears, while professional coding experience continues to pay dividends well into\nthe 30 year range.\n\nThe benefit from experience with casual coding (relative to 0-2 years) maxes out\nat 10-15% and actually begins to decline after 26 years.\n\n * Again, this is holding other factors equal, including professional\n   experience, so this may make sense\n * Someone who learned to code 30 years ago and has little more to show for it\n   than someone with only 10 years of coding experience might raise flags.\n * We must be careful howeverâ€”taking the year one learned to code as given,\n   years since learning to code correlates perfectly with age, suggesting that\n   ageism may be leaking in here. I explore age specifically elsewhere in this\n   post.\n\nThe fastest gains from professional experience come in the first ten years.\n\n * A developer with 9-11 years of professional experience can expect to earn 30%\n   more than a newbie, all else equal, which translates to about 2.5 percent\n   year-over-year gains.\n * Of course, â€œall elseâ€ is likely not equal for any given developer across a\n   ten-year span, suggesting even greater potential annual raises for a given\n   developer in the real world.\n\nAfter the first decade, the line is nearly straight, aside from a mid-career\nslump at the 25-year mark.\n\n * Do not be fooled, howeverâ€”constant absolute gains in fact represent declining\n   growth\n * In other words, each year of professional development experience provides a\n   nearly-constant dollar raise but a declining percentage raise. I explore this\n   phenomenon further in a upcoming post\n\nWith that caveat, it is still encouraging to see that developer pay does not\nfully plateau or reverse course with additional professional experience over\ntime.\n\nNo surprise hereâ€”working part-time does not help your earnings.\n\nMore interestingly, developers working as freelancers or independent contractors\nmake more than those employed full-time\n\n * This may be compensated for by what is almost surely more variable income\n * In general, stable, full-time employment does come at a cost, not only in\n   software development but in many other areas of the economy\n\nReverse causation could also be at play hereâ€”someone who knows they could make\nmore as a freelancer is exactly the kind of person who would become one.\n\n(Read: â€œDevOps specialists make 2% more than non-DevOps specialists, all else\nequalâ€)Itâ€™s no surprise that managers and executives earn more. This includes product\nmanagers\n[https://qz.com/766658/the-highest-paid-workers-in-silicon-valley-are-not-software-engineers/]\n, who might not write significant amounts of code themselves.\n\n * Engineering managers and C-suite execs make 10% more, while product managers\n   make 5.8% more, all else equal.\n\nThe only non-manager role that makes meaningfully more than its counterparts is\nDevOps:\n\n * DevOps specialists are about 2.2 percentage points higher on the pay scale\n   than the non-DevOps average for similar developers.\n\nConversely, there are a number of roles that make noticeably less despite\nsimilar levels of experience, education etc.\n\n * Database admins (DBAs), sysadmins, designers, QA / testing developers make\n   2.5-7.5% less than developers who donâ€™t fall under these categories\n * With the exception of designers, these roles are commonly seen as the â€œback\n   officeâ€ of IT, though one could easily find counter examples depending on the\n   specific team or organization\n * Perhaps needless to sayâ€”academics and students earn meaningfully less than\n   those outside of academia\n\nTakeaways\n * Professional experience matters and never stops mattering\n * Casual development experience helps tooâ€”but only so much, measured both by\n   the amount of experience and the earnings impact\n * Among those working in industry, role matters positively for managers and\n   DevOps professionals and negatively for system and database administrators,\n   as well as designers\n\nLanguages, Frameworks, Databases, Platforms, and Tools\n(Read: â€œDevelopers who have done extensive development work involving Golang\nearn more than those who havenâ€™tâ€)The main implication of these\nresultsâ€”languages largely donâ€™t matter to pay. The vast majority of languages do\nnot provide a statistically significant pay bump or discount relative to jobs\nthat donâ€™t require that language. The pay scale for programming languages is\nquite flat across the universe of languages.\n\nHack is a clear outlierâ€”working with Hack yields a 25% bump. However, donâ€™t drop\neverything to go learn Hack right now\n\n * Hack is not a widely used language\n * It was developed by Facebook, and unlike other languages and frameworks that\n   come out of the big tech giants, Hack has not had the same marketing push\n   placed behind it. \n * The effect we see here likely reflects developers who work at Facebook\n   itselfâ€”thereâ€™s no sign of a robust hiring market for Hack talent.\n\nOutside of Hack, on the positive side we find Objective-C, C++, Go, VBA, and\nTypeScript with statistically significant income effects, ranging from 2.1 to\n3.9 percent.\n\nOn the negative side we have JavaScript, VB.NET, CSS, and PHP\n\n * JS, CSS, and PHP likely reflect the lower pay of certain web development jobs\n * These languages represent fundamental technologies of web development\n * For that same reason however, they are considered table stakes\n * Hence, using these technologies on the job doesnâ€™t provide much of a pay\n   bump, though you may be quite employable\n\nPlease note that the results above are not saying â€œknowing language X increases\n/ decreases pay.â€ Knowing a language is not likely to ever harm oneâ€™s pay, but\nworking a dev job that uses it might (relative to other development work).\n\nReactâ€”what needs to be said?\n\n * The cutting-edge JavaScript framework [https://reactjs.org/] originated and\n   maintained by Facebook is widely and wildly popular, especially among\n   front-end developers looking for an easy-to-use but powerful way to craft\n   compelling user interfaces.\n * React is associated with a 4.1% pay increase and is the only framework with a\n   statistically significant positive impact.\n\nWorking with .NET Core and PyTorch negatively impacts income\n\n * I do not have a hypothesis about .NET Core, but I do know that PyTorch was\n   historically used much more among researchers\n   [https://code.fb.com/ai-research/announcing-pytorch-1-0-for-both-research-and-production/] \n   than industry practitioners, likely driving lower pay\n * Usage has since branched out as the framework has added production-grade\n   capabilities and tooling.\n\nOne wordâ€”cloud. Almost all of the databases with positive income effects are\nhosted in the cloud, often exclusively as a managed service by one of the major\npublic cloud service providers (Google, Amazon, Facebook).\n\nGoogleâ€™s BigQuery data warehouse tops the list, followed closely by Amazonâ€™s\ncompeting Redshift. Apache Hbase and Hive come next. Afterwards itâ€™s Amazonâ€™s\nDynamoDB and Microsoftâ€™s Azure Tables, Cosmos DB, and SQL. The list continues\nwith Memcached, Redis, Elasticsearch, Google Cloud Storage, and Amazon RDS and\nAuroraâ€”all positive and statistically significant.\n\nOlder database technologies from legacy vendors dominate the negative end. This\nincludes Oracleâ€™s once ubiquitous databases, MySQL, SQL Server, MariaDB, and\nIBMâ€™s Db2.\n\nItâ€™s fascinating to see the impact of the cloud revolution laid out in stark\nrelief. There are meaningful income gains associated with working with next-gen\ncloud-enabled databases. This fact should be top of mind for developers looking\nto upgrade their skills and pay.\n\nIâ€™ll say it againâ€”cloud. The various public clouds are the only platforms aside\nfrom Windows Phone with positive, statistically significant effects on developer\nearnings. Azure is associated with 4.1% higher pay, GCP 2.7%, AWS 1.7%.\n\nAnd Windows Phone? Not going to try to explain that one.\n\nAndroid, Arduino and Drupal had meaningful negative association with\nincomeâ€”2.4%, 4.6%, and 8.5% respectively.\n\nAndroidâ€™s ubiquitous operating system needs no introduction, though itâ€™s\nnegative pay relationship might need an explanation. Unfortunately, I am stumped\nhere.\n\nArduino is an open-source prototyping platform [https://www.arduino.cc/] with\nassociated hardware microcontrollers that eases development of electronic\ndevices. Though used for serious development work, Arduino is also heavily used\nby engineering students [https://www.arduino.cc/en/main/education] as well,\nwhich likely drives the negative value.\n\nDrupal is a PHP-based content management system whose popularity peaked in 2011\n[https://trends.google.com/trends/explore?date=all&geo=US&q=drupal] but has\nsince been on a slow decline.\n\nYou might not think that a developerâ€™s choice of IDE or text editors wouldnâ€™t\nmatterâ€”and youâ€™d be (largely) correct! The associated effects here are generally\nquite small.\n\nHowever, IntelliJ stands out from the pack\n\n * Billed by JetBrains, its creator, as the â€œJava IDE for professional\n   developersâ€, IntelliJ users make 3.1% more than non-users\n * Of course, this is not an entirely useful comparison for someone who doesnâ€™t\n   use Java in their development work\n\nNotepad++ and Atom are associated with slightly lower earnings, on the order of\n2%, which is statistically significant. Notably, both are popular but are\ngenerally viewed more as text editors than fully-fledged IDEs.\n\nPhpStorm, Xcode, and Coda also had negative effects that were statistically\nsignificant.\n\nThe incredibly popular Agile leads the pack among project management\nmethodologies. Devs who use Agile in their development work earn 3.9% more than\nthose who donâ€™t.\n\nThe less common extreme programming methodology is associated with 2.7% higher\npay.\n\nLean comes in at 2.5%, while Scrum developers earn 1.5% more, all else equal.\n\nPrince2 appears to be at outlier, but this is mostly due to limited dataâ€”only\n0.1% of developers in the sample use the methodology.\n\nFor the most part, the exact form of version control used does not matter.\n\nThe key takeaway hereâ€”any kind of version control is better than no version\ncontrol, but please, please avoid copying and pasting files to a network share.\n\n\nThe best practice appears to be the best paid\n\n * Checking in code multiple times per day\n * Itâ€™s clearly important to check in code on some kind of cadenceâ€”at least\n   monthly, ideally\n * If you are checking in code less than once per month or not at all, your pay\n   is likely being impacted as a result.\n\nNot to sound like a broken record, but the reverse causation caveat applies here\nas well. It is completely plausible that checking in code more often increases a\ndevelopers pay. Itâ€™s also possible that companies that pay more are more likely\nto follow and mandate development best practices, such as frequent code\ncheck-ins.\n\nIt seems too convenient that in a survey run by Stack Overflow that its own\nenterprise product would be associated with significantly higher developer pay,\nbut I can only go where the data takes me. Developers using Stack Overflow\nEnterprise earn 9.4% more than those who donâ€™t.\n\nThis likely picks up some effect of simply working at a company that uses Stack\nOverflow Enterprise, which may be higher paying on average.\n\nOther communication tools had smaller positive impacts like the incredibly\npopular Slack, Atlassianâ€™s Confluence, HipChat, and internal intranet sites\n(wikis, Google sites etc), which all have earnings effects in the 2-3% range.\n\nTrello and Facebook are negative enough to be statistically significant.\n\nSurprisingly, developers who use two monitors earn 2.8% less than those who use\nonly a single monitor, all else equal.\n\nAt this time, itâ€™s not clear why more monitors would negatively impact earnings.\nThe potential for enhanced productivity may be swamped by the temptation to use\nthe additional screen real estate for non-work activities\n[https://www.reddit.com/].\n\nNo other monitor count had a statistically significant effect on income relative\nto one.\n\nTakeaways\n * The tools associated with higher developer pay are quite interesting and not\n   necessarily what one might expect\n * In some cases, the most popular tools also pay the most\n * In other cases, more obscure tools appear to have an advantage\n * Check in your code (at least every once in a while)!\n * One clear trend is the impact the move to the cloud is having on\n   developersâ€”the effects of the public cloud on developer pay are large and\n   consistently statistically significant across the big 3 U.S. clouds\n * Knowing how to use and leverage these next-generation computing environments\n   and finding a job that employs those skills can drive meaningful pay\n   improvements for the average developer\n\nWork Life, Health, and Wellness\nThese results are admittedly difficult to interpret. There is no clear linear\ntime trend for the impact of wake up time on earnings.\n\nAfter 7am, later does appear to be somewhat betterâ€”up to a point. Strangely,\ndevelopers between 11am and 12pm see 15.4% higher pay than those who are up\nbefore 5am.\n\nThe most important takeaway is thisâ€”have a set schedule. This will do more good\nthan optimizing for a specific wake-up time. Not having a regular wake up time\nwas associated with 7.7% lower pay for software developers.\n\nExercise is strongly associated with earnings. While only exercising once or\ntwice a week does not appear impactful, exercising 3 times or more per week is\nassociated with 2-2.9% higher pay than a similar developer who does not exercise\nat all.\n\nIt is possible however that reverse causation could cause developers who earn\nmore to work out moreâ€”perhaps because they have more time or can more easily\nafford a gym membership. Alternatively, higher paying companies often have gyms\non-premises, making it easier to work out more.\n\nDonâ€™t skip meals. Any amount of meal skipping was associated with lower pay,\nthough never statistically significant. Developers are not rewarded for this\nunhealthy work habit.\n\nAmong ergonomic devices, standing desks\n[https://thewirecutter.com/reviews/best-standing-desk/] were associated with\n3.2% higher pay, which is statistically significant.\n\nAgain, higher paying companies are potentially more like to provide employees\nwith standing desks, so the direction of causality here is questionable.\n\nTime spent at the computer each day does not have a meaningful relationship with\npay. Handcuffing yourself to your laptop is not going to earn you higher pay as\na developer.\n\nUnlike time spent at the computer, time spent outside does have an impact on\npay, with the ideal amount being 1-2 hours. Spending fewer than 30 minutes\noutside is associated with 2.4% lower pay than 30 minutes to an hour.\n\nSpending more than 4 hours outside was associated with lower pay, but there were\nnot enough developers who do this regularly to generate a precise estimate.\n\nTakeaways\n * The data suggest that common best practices are often the best way to go\n * Spend at least a small amount of time outside each day\n * Skipping meals will only grow your bank balance to the extent you save money\n   on lunch\n * Exercising a few times per week is better than never hitting the gym\n\nConclusion\nThere are many important takeaways from the study and the charts above.\n\nThis analysis is a first attempt at exploring the various factors that affect\ndeveloper pay. To that end, I hope that it is illuminating and informative.\n\nHowever, as with many attempts to answer difficult questions, the analysis\nraises as many questions as it answers.\n\nI am publishing the full code to reproduce this analysis because I believe open\nsource, replicable research is the key to the robust advancement of knowledge\n\n * I would love for this analysis to serve as starting point for others who wish\n   to elevate the state of knowledge on this important topic\n * If you find an error or disagree with some aspect of the analysis, feel free\n   to submit edits (pull requests) to my GitLab\n   [https://gitlab.com/whoisnnamdi/highest-paid-software-developer] or GitHub\n   [https://github.com/whoisnnamdi/highest-paid-software-developer] repositories\n\nI care deeply about the technology industry. But solving its issues and\ncompounding its strengths demands a rigorous understanding of its component\nelements. Developers are a critical piece of the tech puzzle\n[https://www.cnbc.com/2018/09/06/companies-worry-more-about-access-to-software-developers-than-capital.html]\n, and they deserve our attention.\n\nAppendix\nData\nAs in my last post, I leverage data from Stack Overflowâ€™s annual software\ndeveloper survey, which asks about income, in addition to many other questions\nof interest. \n\nExamples include\n\n * Which of the following best describes the highest level of formal education\n   that youâ€™ve completed?\n * Approximately how many people are employed by the company or organization you\n   work for?\n * Which of the following programming, scripting, and markup languages have you\n   done extensive development work in over the past year?\n\nIâ€™m interested in how answers to these questions affect income. While itâ€™s\nimpossible to completely avoid issues of reverse causality or correlation rather\nthan causation, by using regression augmented with machine learning techniques,\ndescribed here, we can have greater confidence that our results accurately\nrepresent the true relationship income.\n\nEssentially, weâ€™ll analyze how each possible answer affects income, holding all\nother answers constant.\n\nI limit the dataset to only non-retired US respondents above the age of 18 with\nincome between $10,000-250,000. Responses above $250K have a higher tendency to\nbe troll (i.e. made up) responses, which Iâ€™d like to exclude, and few answers\ncome in above this threshold regardless.\n\nThis leaves us with a dataset of approximately 11,000 developers.\n\nMethodology\nI estimate the following equation on the data:\n\n$$\\log(income) = \\beta_0 + \\beta_1T + \\beta_2X + \\epsilon$$\n\nWhere \\(T\\) is our trait of interest, \\(\\beta_1\\) is the effect of that trait on\nincome relative to the base category, \\(X\\) is a set of controls (in our case,\nthe respondent's answers to other questions in the survey), \\(\\beta_2\\) is the\nset of effects for each respective control, and \\(\\epsilon\\) is the irreducible\nerror in our estimate.\n\nAssuming weâ€™ve included a â€œcompleteâ€ and â€œcorrect\" set of controls, this should\nprovide a reasonably accurate estimate of the relationship of the trait of\ninterest, \\(T\\), with income. The log transformation of income means our results\nwill be in roughly percentage terms, implying that trait \\(T\\) is associated\nwith an increase in income of \\(\\beta_1*100\\%\\) relative to the â€œbase\" category,\nall else equal. The base category will vary by trait.\n\nSelecting the right set of controls is non-trivial. One has any number of\ndegrees of freedom to select a subset of controls among all those available,\nopening the doors to â€œp-hackingâ€ and other infamous behavior, which can lead to\nincorrect (biased) estimates of the parameters of interest.\n\nTo avoid this, I leverage a powerful machine learning technique, Double\nSelection (specifically Double Lasso Selection), to do principled covariate\nselection for each trait \\(T\\), rerunning the regression for every trait. As\ndescribed in Belloni, Chernozhukov, Hansen (2011)\n[https://arxiv.org/abs/1201.0224], this should provide a more accurate estimate\nof the income effect of each trait than simply using all the covariates or\nattempting to manually select a subset. I wonâ€™t cover the method in detail here,\nbut refer to the original paper for more information. This post\n[https://medium.com/teconomics-blog/using-ml-to-resolve-experiments-faster-bd8053ff602e] \nprovides a relatively intuitive explanation, and is also where I originally\nlearned of the technique.\n\nLong story short, Double Selection makes us much more confident that the results\nrepresent the accurate effects.\n\nThis post has been published on www.productschool.com\n[http://www.productschool.com] communities","feature_image":"__GHOST_URL__/content/images/2019/01/luke-porter-107784-unsplash.jpg","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2019-01-10T08:44:17.000Z","updated_at":"2020-03-01T22:15:24.000Z","published_at":"2019-01-15T11:48:50.000Z","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5c566a9d391457241b37a2de","uuid":"ae37b194-50dd-43ce-b724-f796d4fd767a","title":"Entrepreneur's Ruin, or How Not to Go Bust","slug":"entrepreneurs-ruin","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"/content/images/2020/04/matrix-3.png\"}],[\"image\",{\"src\":\"/content/images/2020/04/prob-up-3.png\"}],[\"image\",{\"src\":\"/content/images/2019/02/ruin-probability-2.png\"}],[\"image\",{\"src\":\"/content/images/2019/02/ruin-survival-2.png\"}]],\"markups\":[[\"em\"],[\"strong\"],[\"a\",[\"href\",\"https://www.fdic.gov/deposit/\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Pyrrhic_victory\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Gambler%27s_ruin\"]],[\"a\",[\"href\",\"https://psychcentral.com/blog/what-does-it-really-mean-to-be-needy/\"]],[\"a\",[\"href\",\"https://amzn.to/2D52mHo\"]],[\"a\",[\"href\",\"__GHOST_URL__/you-dont-understand-compound-growth/\"]],[\"a\",[\"href\",\"https://www.merriam-webster.com/dictionary/humblebrag\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Oxygen_bar\"]],[\"a\",[\"href\",\"https://www.lacroixwater.com/\"]]],\"sections\":[[1,\"h1\",[[0,[],0,\"Managing risk is hard work.\"]]],[1,\"p\",[]],[1,\"p\",[[0,[],0,\"In evaluating potential opportunities, leaders must consider both \"],[0,[0],1,\"probability\"],[0,[],0,\" (the odds of success) and \"],[0,[0],1,\"criticality \"],[0,[],0,\"(the importance of success).\"]]],[1,\"p\",[[0,[],0,\"We can arrange these opportunities on a matrix, with â€œnecessity for survivalâ€ on the x-axis and â€œprobability of successâ€ on the y-axis:\"]]],[10,0],[1,\"p\",[[0,[],0,\"In industry, we often talk about â€œcritical processesâ€â€”the things that must go right, otherwise chaos ensues (we go bust, our customers abandon us, we lose our best employees en masse, etc).\"]]],[1,\"p\",[[0,[],0,\"Business leaders often fall for the seductive fallacy that â€œif we only maximize the probability of successâ€ of these critical processes, all will be right in the world:\"]]],[10,1],[1,\"p\",[[0,[1],1,\"This is wrong.\"]]],[1,\"p\",[[0,[],0,\"Why?\"]]],[1,\"p\",[[0,[],0,\"Because over long periods, \"],[0,[1],1,\"the only certainty in life is uncertainty.\"]]],[1,\"p\",[[0,[],0,\"Even if we achieve a 99% probability of success in a particular critical activityâ€”with timeâ€”the 1% outcome will be realized, and we will go bust.\"]]],[1,\"p\",[[0,[],0,\"Take banking for example. Prior to the advent of \"],[0,[2],1,\"deposit insurance\"],[0,[],0,\", retail banks went bust with regularity. Any given bank was stable and solvent 99% of the time. However, 1% of the time, some internal or external forcing function would sweep numerous banks into the trash heap overnight.\"]]],[1,\"p\",[[0,[],0,\"It didnâ€™t matter that things â€œworked outâ€ most of the time. Deposits are a capital constraint for the bank. A single run on the bank was enough to bankrupt the firm.\"]]],[1,\"p\",[[0,[],0,\"99.9% of days, the banker wakes up at 6am, looks out the window at the bright, rising sun, and goes on with their day.\"]]],[1,\"p\",[[0,[],0,\"But inevitably, one evening the banker is rudely roused in the dead of night by the rancorous roar of a mob demanding their money back.\"]]],[1,\"h2\",[[0,[],0,\"Winning the battle but losing the war\"]]],[1,\"p\",[[0,[],0,\"The fundamental error is in seeing the world as:\"]]],[3,\"ul\",[[[0,[0],1,\"static\"],[0,[],0,\" (a single game, never to be repeated -> probability of success dominates -> win the battle, even if \"],[0,[3],1,\"pyrrhic\"],[0,[],0,\") rather than\"]],[[0,[1],1,\"dynamic\"],[0,[],0,\" (repeated games, you need to still be alive in order to play -> survival dominates -> survive the battle, win the war)\"]]]],[1,\"p\",[[0,[],0,\"This is why itâ€™s foolish to focus solely on maximizing the probability of success of any given â€œcriticalâ€ initiative.\"]]],[1,\"p\",[[0,[],0,\"At best, maximizing the probability of success clips your potential upside. If you already know something will work, you can never be positively surprised:\"]]],[10,2],[1,\"p\",[[0,[],0,\"Instead, \"],[0,[0],1,\"reduce\"],[0,[],0,\" the number of activities that your business is fragile to or dependent on. We need to \"],[0,[0],1,\"cut down\"],[0,[],0,\" the number of critical processesâ€”not maximize the odds of their successful completion.\"]]],[1,\"p\",[[0,[0],1,\"Survival\"],[0,[],0,\" is the only critical process.\"]]],[1,\"p\",[[0,[],0,\"Only by reducing the surface area and impact of potential failure, rather than the odds of failure, do we ensure survival.\"]]],[1,\"p\",[[0,[],0,\"How?\"]]],[1,\"p\",[[0,[1],1,\"Aggressive elimination of single points of failure or vulnerability.\"]]],[1,\"h2\",[[0,[],0,\"Donâ€™t hate the game, hate the constraint\"]]],[1,\"p\",[[0,[],0,\"Commentators describe Silicon Valley and entrepreneurship as a â€œlotteryâ€ or â€œcasinoâ€ with stacked odds disfavoring any individual entrepreneur or startup.\"]]],[1,\"p\",[[0,[],0,\"The issue is not the game itself, however. The problem is ruinâ€”specifically, \"],[0,[4],1,\"gamblerâ€™s ruin\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"A gambler facing a series of risky bets under a capital constraint will eventually go broke, with certainty. With enough time, the gambler will hit a bad streak, cratering to zero. This can be true even if each bet has a positive expected value.\"]]],[1,\"p\",[[0,[],0,\"Like the banks referenced above, the gambler â€œneedsâ€ capital. If the bank account ever hits zero, itâ€™s game over.\"]]],[1,\"p\",[[0,[],0,\"The same is true in business, especially early-stage entrepreneurship.\"]]],[1,\"p\",[[0,[],0,\"The reason so many startups go bust is not, as is commonly believed, because they have â€œlow odds of successâ€.\"]]],[1,\"p\",[[0,[],0,\"The reason so many startups fail is because they have too many \"],[0,[0],1,\"needs\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"In other words, startups are \"],[0,[1,5],2,\"too needy\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Many startups today need most or all the following to succeed:\"]]],[3,\"ul\",[[[0,[],0,\"Product-market fit \"]],[[0,[],0,\"Great founding team \"]],[[0,[],0,\"A+ players \"]],[[0,[],0,\"Positive unit economics \"]],[[0,[],0,\"No economic recession \"]],[[0,[],0,\"Large and growing addressable market \"]],[[0,[],0,\"Low competition\"]],[[0,[],0,\"Venture capital\"]],[[0,[],0,\"Big, marquee, â€œanchorâ€ customers \"]],[[0,[],0,\"â€¦ \"]]]],[1,\"p\",[[0,[],0,\"The list goes on.\"]]],[1,\"p\",[[0,[],0,\"See why startups are so fragile, why most are doomed to fail?\"]]],[1,\"p\",[[0,[],0,\"Companies are constrained by their needs. If your company, startup or otherwise, needs every single one, or even most, of the above items to go well, \"],[0,[0],1,\"it will not be long for this world\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Eventually, you \"],[0,[0],1,\"will\"],[0,[],0,\" fail in some way, and unless you are robust (or even better, \"],[0,[6],1,\"antifragile\"],[0,[],0,\") to these risks, you will go bust \"],[0,[1],1,\"with certainty\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"I repeat: \"],[0,[1],1,\"robust, or go bust\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Hence, \"],[0,[1],1,\"â€œEntrepreneur's Ruinâ€\"],[0,[],0,\" is the natural bias among business leaders to:\"]]],[3,\"ul\",[[[0,[1],1,\"overweight maximization of probability and predictability\"],[0,[],0,\" and\"]],[[0,[1],1,\"underweight rigorous elimination of single points of failure\"]]]],[1,\"p\",[[0,[],0,\"It's the tendency to see business as:\"]]],[3,\"ul\",[[[0,[1],0,\"â€œ\"],[0,[0],1,\"one and done\"],[0,[],1,\"â€\"],[0,[],0,\" rather than \"]],[[0,[1],0,\"â€œ\"],[0,[0],1,\"one times one times one...\"],[0,[],1,\"â€\"],[0,[],0,\" \"],[0,[7],1,\"compounding\"],[0,[],0,\" ad infinitum\"]]]],[1,\"p\",[[0,[],0,\"In this multiplicative world, a single zero wipes you out. Prior success is irrelevant. A priori probability or â€œconfidenceâ€ of success is also irrelevant.\"]]],[1,\"p\",[[0,[],0,\"Like the banker, all that matters is sticking around long enough to see another sunrise.\"]]],[1,\"h2\",[[0,[],0,\"Needs vs. nice-to-haves\"]]],[1,\"p\",[[0,[],0,\"The companies that survive and thrive over the long-term are the ones that keep this â€œneeds list\\\" as short as possible.\"]]],[1,\"p\",[[0,[],0,\"The â€œbestâ€ companies do not have the best team, the largest market, the highest profitability etc.\"]]],[1,\"p\",[[0,[],0,\"Ironically, the best companies are the ones that get by:\"]]],[3,\"ul\",[[[0,[],0,\" \"],[0,[1],1,\"EVEN THOUGH\"],[0,[],0,\" they donâ€™t have the best teamâ€¦ \"]],[[0,[],0,\" \"],[0,[1],1,\"IN SPITE OF\"],[0,[],0,\" a difficult economic environmentâ€¦ \"]],[[0,[1],1,\" WITHOUT\"],[0,[],0,\" access to free-flowing venture capitalâ€¦ \"]]]],[1,\"p\",[[0,[],0,\"And so on.\"]]],[1,\"p\",[[0,[],0,\"By turning â€œneedsâ€ into â€œnice-to-havesâ€, exceptional companies cap their downside while retaining exposure to positive surprises, i.e. upside.\"]]],[1,\"p\",[[0,[],0,\"Interviewers love to ask executives about their â€œkeys to successâ€. In response, CEOs proclaim â€œXYZ is \"],[0,[0],1,\"critical\"],[0,[],0,\" to our successâ€ (insert â€œcultureâ€, â€œpeopleâ€, â€œoperational excellenceâ€, etc).\"]]],[1,\"p\",[[0,[],0,\"No. \"],[0,[1],1,\"â€œAs little as possibleâ€\"],[0,[],0,\" should be critical to your success.\"]]],[1,\"p\",[[0,[],0,\"If you are asked â€œwhat are the keys to your successâ€, the best answer isâ€”paradoxicallyâ€”\"],[0,[1],1,\"â€œnothingâ€\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"When business leaders, via subtle \"],[0,[8],1,\"humble brag\"],[0,[],0,\", share their â€œcritical strengthsâ€, they arenâ€™t revealing the keys to their success. \"],[0,[1],1,\"They are writing their own obituary\"],[0,[],0,\":\"]]],[1,\"blockquote\",[[0,[],0,\"â€œ\"],[0,[1],1,\"Bankruptly\"],[0,[],0,\" was a darling Silicon Valley startup admired by all. For most of its tragically short life, Bankruptly had amazing growth, a huge market, and ample capital. But only months after raising a massive round of financing Bankruptly began running into issues. Soon afterward, Bankruptly suddenlyâ€¦â€\"]]],[1,\"p\",[[0,[],0,\"You can finish the story.\"]]],[1,\"h2\",[[0,[],0,\"Don't be needy\"]]],[1,\"p\",[[0,[],0,\"One of the primary functions of modern civilization is to guarantee human needs (air, food, water, shelter, community) and in turn create an unlimited number of nice-to-haves (\"],[0,[9],1,\"oxygen bars\"],[0,[],0,\", avocado toast, \"],[0,[10],1,\"LaCroix\"],[0,[],0,\", seasonal homes in Tahoe and the Hamptons, secret societiesâ€”you get the point).\"]]],[1,\"p\",[[0,[],0,\"With such a multitude of \"],[0,[1],1,\"options\"],[0,[],0,\", life goes from nasty, brutish, and short to bougie, fabulous, and, frankly, \"],[0,[0],1,\"too long\"],[0,[],0,\" between seasons of Game of Thrones. Wouldnâ€™t it be great to shorten that bit?\"]]],[1,\"p\",[[0,[],0,\"Analogously, great business leaders cut down the list of things that â€œmust go rightâ€ and expand the list of things that feel great if they happen but are not particularly painful if they donâ€™t.\"]]],[1,\"p\",[[0,[],0,\"In other words, \"],[0,[1],1,\"they cap downside while maintaining positive optionality\"],[0,[],0,\":\"]]],[10,3],[1,\"p\",[[0,[],0,\"In doing so, they increase the effective â€œmoney in the bankâ€ or â€œreserve capitalâ€ of the company (the â€œgamblerâ€), extending its lifespan and paving a longer runway for the kinds of experimentation and random positive luck (â€œjackpotsâ€) that so often drive business success.\"]]],[1,\"p\",[[0,[],0,\"So do what you want in your personal life, but in managing a business, don't be needy. It'll ruin you!\"]]]],\"ghostVersion\":\"3.0\"}","html":"<h1 id=\"managing-risk-is-hard-work-\">Managing risk is hard work.</h1><p></p><p>In evaluating potential opportunities, leaders must consider both <em>probability</em> (the odds of success) and <em>criticality </em>(the importance of success).</p><p>We can arrange these opportunities on a matrix, with â€œnecessity for survivalâ€ on the x-axis and â€œprobability of successâ€ on the y-axis:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/04/matrix-3.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>In industry, we often talk about â€œcritical processesâ€â€”the things that must go right, otherwise chaos ensues (we go bust, our customers abandon us, we lose our best employees en masse, etc).</p><p>Business leaders often fall for the seductive fallacy that â€œif we only maximize the probability of successâ€ of these critical processes, all will be right in the world:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/04/prob-up-3.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p><strong>This is wrong.</strong></p><p>Why?</p><p>Because over long periods, <strong>the only certainty in life is uncertainty.</strong></p><p>Even if we achieve a 99% probability of success in a particular critical activityâ€”with timeâ€”the 1% outcome will be realized, and we will go bust.</p><p>Take banking for example. Prior to the advent of <a href=\"https://www.fdic.gov/deposit/\">deposit insurance</a>, retail banks went bust with regularity. Any given bank was stable and solvent 99% of the time. However, 1% of the time, some internal or external forcing function would sweep numerous banks into the trash heap overnight.</p><p>It didnâ€™t matter that things â€œworked outâ€ most of the time. Deposits are a capital constraint for the bank. A single run on the bank was enough to bankrupt the firm.</p><p>99.9% of days, the banker wakes up at 6am, looks out the window at the bright, rising sun, and goes on with their day.</p><p>But inevitably, one evening the banker is rudely roused in the dead of night by the rancorous roar of a mob demanding their money back.</p><h2 id=\"winning-the-battle-but-losing-the-war\">Winning the battle but losing the war</h2><p>The fundamental error is in seeing the world as:</p><ul><li><em>static</em> (a single game, never to be repeated -&gt; probability of success dominates -&gt; win the battle, even if <a href=\"https://en.wikipedia.org/wiki/Pyrrhic_victory\">pyrrhic</a>) rather than</li><li><strong>dynamic</strong> (repeated games, you need to still be alive in order to play -&gt; survival dominates -&gt; survive the battle, win the war)</li></ul><p>This is why itâ€™s foolish to focus solely on maximizing the probability of success of any given â€œcriticalâ€ initiative.</p><p>At best, maximizing the probability of success clips your potential upside. If you already know something will work, you can never be positively surprised:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2019/02/ruin-probability-2.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Instead, <em>reduce</em> the number of activities that your business is fragile to or dependent on. We need to <em>cut down</em> the number of critical processesâ€”not maximize the odds of their successful completion.</p><p><em>Survival</em> is the only critical process.</p><p>Only by reducing the surface area and impact of potential failure, rather than the odds of failure, do we ensure survival.</p><p>How?</p><p><strong>Aggressive elimination of single points of failure or vulnerability.</strong></p><h2 id=\"don-t-hate-the-game-hate-the-constraint\">Donâ€™t hate the game, hate the constraint</h2><p>Commentators describe Silicon Valley and entrepreneurship as a â€œlotteryâ€ or â€œcasinoâ€ with stacked odds disfavoring any individual entrepreneur or startup.</p><p>The issue is not the game itself, however. The problem is ruinâ€”specifically, <a href=\"https://en.wikipedia.org/wiki/Gambler%27s_ruin\">gamblerâ€™s ruin</a>.</p><p>A gambler facing a series of risky bets under a capital constraint will eventually go broke, with certainty. With enough time, the gambler will hit a bad streak, cratering to zero. This can be true even if each bet has a positive expected value.</p><p>Like the banks referenced above, the gambler â€œneedsâ€ capital. If the bank account ever hits zero, itâ€™s game over.</p><p>The same is true in business, especially early-stage entrepreneurship.</p><p>The reason so many startups go bust is not, as is commonly believed, because they have â€œlow odds of successâ€.</p><p>The reason so many startups fail is because they have too many <em>needs</em>.</p><p>In other words, startups are <strong><a href=\"https://psychcentral.com/blog/what-does-it-really-mean-to-be-needy/\">too needy</a></strong>.</p><p>Many startups today need most or all the following to succeed:</p><ul><li>Product-market fit </li><li>Great founding team </li><li>A+ players </li><li>Positive unit economics </li><li>No economic recession </li><li>Large and growing addressable market </li><li>Low competition</li><li>Venture capital</li><li>Big, marquee, â€œanchorâ€ customers </li><li>â€¦ </li></ul><p>The list goes on.</p><p>See why startups are so fragile, why most are doomed to fail?</p><p>Companies are constrained by their needs. If your company, startup or otherwise, needs every single one, or even most, of the above items to go well, <em>it will not be long for this world</em>.</p><p>Eventually, you <em>will</em> fail in some way, and unless you are robust (or even better, <a href=\"https://amzn.to/2D52mHo\">antifragile</a>) to these risks, you will go bust <strong>with certainty</strong>.</p><p>I repeat: <strong>robust, or go bust</strong>.</p><p>Hence, <strong>â€œEntrepreneur's Ruinâ€</strong> is the natural bias among business leaders to:</p><ul><li><strong>overweight maximization of probability and predictability</strong> and</li><li><strong>underweight rigorous elimination of single points of failure</strong></li></ul><p>It's the tendency to see business as:</p><ul><li><strong>â€œ<em>one and done</em>â€</strong> rather than </li><li><strong>â€œ<em>one times one times one...</em>â€</strong> <a href=\"__GHOST_URL__/you-dont-understand-compound-growth/\">compounding</a> ad infinitum</li></ul><p>In this multiplicative world, a single zero wipes you out. Prior success is irrelevant. A priori probability or â€œconfidenceâ€ of success is also irrelevant.</p><p>Like the banker, all that matters is sticking around long enough to see another sunrise.</p><h2 id=\"needs-vs-nice-to-haves\">Needs vs. nice-to-haves</h2><p>The companies that survive and thrive over the long-term are the ones that keep this â€œneeds list\" as short as possible.</p><p>The â€œbestâ€ companies do not have the best team, the largest market, the highest profitability etc.</p><p>Ironically, the best companies are the ones that get by:</p><ul><li> <strong>EVEN THOUGH</strong> they donâ€™t have the best teamâ€¦ </li><li> <strong>IN SPITE OF</strong> a difficult economic environmentâ€¦ </li><li><strong> WITHOUT</strong> access to free-flowing venture capitalâ€¦ </li></ul><p>And so on.</p><p>By turning â€œneedsâ€ into â€œnice-to-havesâ€, exceptional companies cap their downside while retaining exposure to positive surprises, i.e. upside.</p><p>Interviewers love to ask executives about their â€œkeys to successâ€. In response, CEOs proclaim â€œXYZ is <em>critical</em> to our successâ€ (insert â€œcultureâ€, â€œpeopleâ€, â€œoperational excellenceâ€, etc).</p><p>No. <strong>â€œAs little as possibleâ€</strong> should be critical to your success.</p><p>If you are asked â€œwhat are the keys to your successâ€, the best answer isâ€”paradoxicallyâ€”<strong>â€œnothingâ€</strong>.</p><p>When business leaders, via subtle <a href=\"https://www.merriam-webster.com/dictionary/humblebrag\">humble brag</a>, share their â€œcritical strengthsâ€, they arenâ€™t revealing the keys to their success. <strong>They are writing their own obituary</strong>:</p><blockquote>â€œ<strong>Bankruptly</strong> was a darling Silicon Valley startup admired by all. For most of its tragically short life, Bankruptly had amazing growth, a huge market, and ample capital. But only months after raising a massive round of financing Bankruptly began running into issues. Soon afterward, Bankruptly suddenlyâ€¦â€</blockquote><p>You can finish the story.</p><h2 id=\"don-t-be-needy\">Don't be needy</h2><p>One of the primary functions of modern civilization is to guarantee human needs (air, food, water, shelter, community) and in turn create an unlimited number of nice-to-haves (<a href=\"https://en.wikipedia.org/wiki/Oxygen_bar\">oxygen bars</a>, avocado toast, <a href=\"https://www.lacroixwater.com/\">LaCroix</a>, seasonal homes in Tahoe and the Hamptons, secret societiesâ€”you get the point).</p><p>With such a multitude of <strong>options</strong>, life goes from nasty, brutish, and short to bougie, fabulous, and, frankly, <em>too long</em> between seasons of Game of Thrones. Wouldnâ€™t it be great to shorten that bit?</p><p>Analogously, great business leaders cut down the list of things that â€œmust go rightâ€ and expand the list of things that feel great if they happen but are not particularly painful if they donâ€™t.</p><p>In other words, <strong>they cap downside while maintaining positive optionality</strong>:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2019/02/ruin-survival-2.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>In doing so, they increase the effective â€œmoney in the bankâ€ or â€œreserve capitalâ€ of the company (the â€œgamblerâ€), extending its lifespan and paving a longer runway for the kinds of experimentation and random positive luck (â€œjackpotsâ€) that so often drive business success.</p><p>So do what you want in your personal life, but in managing a business, don't be needy. It'll ruin you!</p>","comment_id":"5c566a9d391457241b37a2de","plaintext":"Managing risk is hard work.\n\n\nIn evaluating potential opportunities, leaders must consider both probability \n(the odds of success) and criticality (the importance of success).\n\nWe can arrange these opportunities on a matrix, with â€œnecessity for survivalâ€ on\nthe x-axis and â€œprobability of successâ€ on the y-axis:\n\nIn industry, we often talk about â€œcritical processesâ€â€”the things that must go\nright, otherwise chaos ensues (we go bust, our customers abandon us, we lose our\nbest employees en masse, etc).\n\nBusiness leaders often fall for the seductive fallacy that â€œif we only maximize\nthe probability of successâ€ of these critical processes, all will be right in\nthe world:\n\nThis is wrong.\n\nWhy?\n\nBecause over long periods, the only certainty in life is uncertainty.\n\nEven if we achieve a 99% probability of success in a particular critical\nactivityâ€”with timeâ€”the 1% outcome will be realized, and we will go bust.\n\nTake banking for example. Prior to the advent of deposit insurance\n[https://www.fdic.gov/deposit/], retail banks went bust with regularity. Any\ngiven bank was stable and solvent 99% of the time. However, 1% of the time, some\ninternal or external forcing function would sweep numerous banks into the trash\nheap overnight.\n\nIt didnâ€™t matter that things â€œworked outâ€ most of the time. Deposits are a\ncapital constraint for the bank. A single run on the bank was enough to bankrupt\nthe firm.\n\n99.9% of days, the banker wakes up at 6am, looks out the window at the bright,\nrising sun, and goes on with their day.\n\nBut inevitably, one evening the banker is rudely roused in the dead of night by\nthe rancorous roar of a mob demanding their money back.\n\nWinning the battle but losing the war\nThe fundamental error is in seeing the world as:\n\n * static (a single game, never to be repeated -> probability of success\n   dominates -> win the battle, even if pyrrhic\n   [https://en.wikipedia.org/wiki/Pyrrhic_victory]) rather than\n * dynamic (repeated games, you need to still be alive in order to play ->\n   survival dominates -> survive the battle, win the war)\n\nThis is why itâ€™s foolish to focus solely on maximizing the probability of\nsuccess of any given â€œcriticalâ€ initiative.\n\nAt best, maximizing the probability of success clips your potential upside. If\nyou already know something will work, you can never be positively surprised:\n\nInstead, reduce the number of activities that your business is fragile to or\ndependent on. We need to cut down the number of critical processesâ€”not maximize\nthe odds of their successful completion.\n\nSurvival is the only critical process.\n\nOnly by reducing the surface area and impact of potential failure, rather than\nthe odds of failure, do we ensure survival.\n\nHow?\n\nAggressive elimination of single points of failure or vulnerability.\n\nDonâ€™t hate the game, hate the constraint\nCommentators describe Silicon Valley and entrepreneurship as a â€œlotteryâ€ or\nâ€œcasinoâ€ with stacked odds disfavoring any individual entrepreneur or startup.\n\nThe issue is not the game itself, however. The problem is ruinâ€”specifically, \ngamblerâ€™s ruin [https://en.wikipedia.org/wiki/Gambler%27s_ruin].\n\nA gambler facing a series of risky bets under a capital constraint will\neventually go broke, with certainty. With enough time, the gambler will hit a\nbad streak, cratering to zero. This can be true even if each bet has a positive\nexpected value.\n\nLike the banks referenced above, the gambler â€œneedsâ€ capital. If the bank\naccount ever hits zero, itâ€™s game over.\n\nThe same is true in business, especially early-stage entrepreneurship.\n\nThe reason so many startups go bust is not, as is commonly believed, because\nthey have â€œlow odds of successâ€.\n\nThe reason so many startups fail is because they have too many needs.\n\nIn other words, startups are too needy\n[https://psychcentral.com/blog/what-does-it-really-mean-to-be-needy/].\n\nMany startups today need most or all the following to succeed:\n\n * Product-market fit \n * Great founding team \n * A+ players \n * Positive unit economics \n * No economic recession \n * Large and growing addressable market \n * Low competition\n * Venture capital\n * Big, marquee, â€œanchorâ€ customers \n * â€¦ \n\nThe list goes on.\n\nSee why startups are so fragile, why most are doomed to fail?\n\nCompanies are constrained by their needs. If your company, startup or otherwise,\nneeds every single one, or even most, of the above items to go well, it will not\nbe long for this world.\n\nEventually, you will fail in some way, and unless you are robust (or even\nbetter, antifragile [https://amzn.to/2D52mHo]) to these risks, you will go bust \nwith certainty.\n\nI repeat: robust, or go bust.\n\nHence, â€œEntrepreneur's Ruinâ€ is the natural bias among business leaders to:\n\n * overweight maximization of probability and predictability and\n * underweight rigorous elimination of single points of failure\n\nIt's the tendency to see business as:\n\n * â€œone and doneâ€ rather than \n * â€œone times one times one...â€ compounding\n   [__GHOST_URL__/you-dont-understand-compound-growth/] ad infinitum\n\nIn this multiplicative world, a single zero wipes you out. Prior success is\nirrelevant. A priori probability or â€œconfidenceâ€ of success is also irrelevant.\n\nLike the banker, all that matters is sticking around long enough to see another\nsunrise.\n\nNeeds vs. nice-to-haves\nThe companies that survive and thrive over the long-term are the ones that keep\nthis â€œneeds list\" as short as possible.\n\nThe â€œbestâ€ companies do not have the best team, the largest market, the highest\nprofitability etc.\n\nIronically, the best companies are the ones that get by:\n\n *  EVEN THOUGH they donâ€™t have the best teamâ€¦ \n *  IN SPITE OF a difficult economic environmentâ€¦ \n *  WITHOUT access to free-flowing venture capitalâ€¦ \n\nAnd so on.\n\nBy turning â€œneedsâ€ into â€œnice-to-havesâ€, exceptional companies cap their\ndownside while retaining exposure to positive surprises, i.e. upside.\n\nInterviewers love to ask executives about their â€œkeys to successâ€. In response,\nCEOs proclaim â€œXYZ is critical to our successâ€ (insert â€œcultureâ€, â€œpeopleâ€,\nâ€œoperational excellenceâ€, etc).\n\nNo. â€œAs little as possibleâ€ should be critical to your success.\n\nIf you are asked â€œwhat are the keys to your successâ€, the best answer\nisâ€”paradoxicallyâ€”â€œnothingâ€.\n\nWhen business leaders, via subtle humble brag\n[https://www.merriam-webster.com/dictionary/humblebrag], share their â€œcritical\nstrengthsâ€, they arenâ€™t revealing the keys to their success. They are writing\ntheir own obituary:\n\n> â€œBankruptly was a darling Silicon Valley startup admired by all. For most of its\ntragically short life, Bankruptly had amazing growth, a huge market, and ample\ncapital. But only months after raising a massive round of financing Bankruptly\nbegan running into issues. Soon afterward, Bankruptly suddenlyâ€¦â€\nYou can finish the story.\n\nDon't be needy\nOne of the primary functions of modern civilization is to guarantee human needs\n(air, food, water, shelter, community) and in turn create an unlimited number of\nnice-to-haves (oxygen bars [https://en.wikipedia.org/wiki/Oxygen_bar], avocado\ntoast, LaCroix [https://www.lacroixwater.com/], seasonal homes in Tahoe and the\nHamptons, secret societiesâ€”you get the point).\n\nWith such a multitude of options, life goes from nasty, brutish, and short to\nbougie, fabulous, and, frankly, too long between seasons of Game of Thrones.\nWouldnâ€™t it be great to shorten that bit?\n\nAnalogously, great business leaders cut down the list of things that â€œmust go\nrightâ€ and expand the list of things that feel great if they happen but are not\nparticularly painful if they donâ€™t.\n\nIn other words, they cap downside while maintaining positive optionality:\n\nIn doing so, they increase the effective â€œmoney in the bankâ€ or â€œreserve\ncapitalâ€ of the company (the â€œgamblerâ€), extending its lifespan and paving a\nlonger runway for the kinds of experimentation and random positive luck\n(â€œjackpotsâ€) that so often drive business success.\n\nSo do what you want in your personal life, but in managing a business, don't be\nneedy. It'll ruin you!","feature_image":"__GHOST_URL__/content/images/2019/02/jonathan-petersson-614702-unsplash.jpg","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2019-02-03T04:14:21.000Z","updated_at":"2020-04-06T20:26:30.000Z","published_at":"2019-02-28T00:09:39.000Z","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5cefa8c0f9f4410ef2e73d86","uuid":"1490b764-b0f4-4c3c-903d-4bf51b96b114","title":"How to Conquer Cohort Analysis With a Powerful Clinical Research Tool","slug":"how-to-conquer-cohort-analysis","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"**Understanding cohort performance is critical for modern, high-velocity businesses, especially those with subscription or recurring revenue models.**\\n\\nIn SaaS or consumer subscription settings, small changes in churn can [radically impact revenue growth](https://www.forentrepreneurs.com/why-churn-is-critical-in-saas/?fbclid=IwAR3RmfnV8ek0lDyyWwEXdkHNJhJxXymIN-hJeuo32c3cYekTnQOgLvAryi4).\\n\\nProduct managers, growth hackers, marketers, data scientists, and investors all need to understand how business decisions impact user retention.\\n\\nWith so many recurring revenue businesses going public, Silicon Valley *should* get the picture by now.\\n\\nBelieve it or not, however, **medical researchers measure customer retention better than you do.**\\n\\nWhat?\\n\\nSounds bold, but itâ€™s not. Over decades, clinical researchers have refined precise and rigorous ways of measuring retentionâ€”except instead of _customer_ retention, they measure _patient survival_.\\n\\nThe gravity of life and death means researchers take great care in measuring treatment efficacy.\\n\\nTo do this, clinical researchers use a statistical method called the [**Kaplan-Meier estimator**](https://en.wikipedia.org/wiki/Kaplan%E2%80%93Meier_estimator). The formula elegantly solves a frequent issue that pops up in cohort retention analysis: **making valid comparisons within and across groups of cohorts of different lifespans**:\\n\\n<!--<script type=\\\"text/x-mathjax-config\\\">MathJax.Hub.Config({tex2jax: {inlineMath:[['$','$']]}});</script>\\n<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=default' async></script>-->\\n\\n$$ \\\\widehat S(t) = \\\\prod\\\\limits_{i:\\\\ t_i\\\\le t} \\\\left(1 - \\\\frac{d_i}{n_i}\\\\right) $$\\n\\nDespite the fancy formula, survival analysis using Kaplan-Meier (KM) is actually quite simple and delivers much better results than other methods:\\n\\n![4](/content/images/2019/05/4.png)\\n\\nIn this post I'll explain these results, breakdown the KM estimator in simple terms, and convince you to use it for retention analysis.\\n\\nThe bottom-line: **if you are an operator or investor who wants to properly measure customer cohort retention, Kaplan-Meier is the way to do it.**\\n\\n<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive my next post in your inbox</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"youremail@example.com\\\" id=\\\"mce-EMAIL\\\" required>\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span>Subscribe</span></button>\\n</form>\\n</section>\\n\\n## Two inevitabilities: Death and Churn\\nThe core problem the KM estimator helps us deal with is **missing data**.\\n\\n**Cohort data is inherently flawed in that more recent cohorts have fewer data points to compare against older cohorts**. For example, a five-month-old cohort can only be compared with the first five months of a ten-month-old cohort. The retention rates of a cohort of customers acquired seven months ago can only reasonably be compared to the first seven month retention of older cohorts.\\n\\nImagine you had the full retention history of the previous 12 monthly cohorts and you wanted to predict the 12-month retention curve of a newly acquired customer. Itâ€™s not at all obvious how to do this.\\n\\nTo understand this better, letâ€™s visualize a simpler example with only five cohorts:\\n\\n![1](/content/images/2019/05/1.png)\\n\\nYou might first try to calculate average retention across cohorts. This is problematic for two reasons:\\n* The simple average will not be representative if our cohorts differ in size\\n* For any given month we can only average over cohorts that have been alive at least that long, so we effectively average over fewer and fewer cohorts over time\\n\\nWe can see the second issue below. With both the simple and weighted average, we get strange results when performance oscillates across cohorts:\\n\\n![2-1](/content/images/2019/05/2-1.png)\\n\\nAssuming we donâ€™t re-add returning users who previously churned into their original cohort, retention cannot possibly tick up after decliningâ€”itâ€™s a one way street. This is an artifact of our flawed method, as 5-month retention cannot exceed 4-month retention by definition.\\n\\nA third, related problem arises when comparing groups of cohorts to other groups, for example, comparing 2016â€™s group of monthly cohorts to 2017â€™s. As weâ€™ve just shown, using averages to estimate retention curves for each group doesnâ€™t work, which means we also cannot compare one group to another.\\n\\n## Questions? Ask your doctor\\n![ani-kolleshi-684082-unsplash](/content/images/2019/05/ani-kolleshi-684082-unsplash.jpg)\\n\\nBelieve it or not, clinical researchers deal with this same issue all the time.\\n\\nCustomer cohorts are analogous to groups of patients starting treatment at different times. Here the â€œtreatmentâ€ is the time of customer acquisition and â€œdeathâ€ is simply churn.\\n\\nOr, imagine if the â€œ2016 cohortsâ€ and â€œ2017 cohortsâ€, rather than being year-grouped cohorts, were groups receiving different treatments in a clinical trial. We want to quantify differences in patient survival rates (customer retention) between the two groups.\\n\\nPharmaceutical companies and other research outfits regularly contend  with this. Patients start treatment at different times. Patients drop out of studies, by dying, but also by moving locations or deciding to stop taking the medication.\\n\\nThis creates a host of missing data issues at the beginning, middle, and end of any patientâ€™s clinical test record, complicating analysis of effectiveness and safety.\\n\\nTo solve this problem, in 1958, a mathematician, [Edward Kaplan](https://en.wikipedia.org/wiki/Edward_L._Kaplan), and statistician, [Paul Meier](https://www.chicagotribune.com/news/ct-xpm-2011-08-18-ct-met-meier-obit-20110818-story.html), jointly created the [Kaplan-Meier estimator](https://www.tandfonline.com/doi/abs/10.1080/01621459.1958.10501452). Also called the _product-limit estimator_, the method effectively deals with the missing data issue, providing a more precise estimate of the probability of survival up to any point.\\n\\n[The core idea behind Kaplan-Meier](http://biostat.mc.vanderbilt.edu/wiki/pub/Main/ClinStat/km.lam.pdf):\\n> The estimated probability of surviving up to any point is the cumulative probability of surviving each preceding time interval, calculated as the product of the preceding survival probabilities\\n\\nThat strange formula above is simply multiplying a bunch of probabilities against one another to find the cumulative probability of survival at a certain point.\\n\\nWhere do these probabilities come from? **Directly from the data**.\\n\\nKM says our best estimate of the probability of survival from one month to the next is exactly the weighted average retention rate for that month in our dataset (also called the [_maximum likelihood estimator_](https://towardsdatascience.com/a-gentle-introduction-to-maximum-likelihood-estimation-9fbff27ea12f) in statistics parlance). So if in a group of cohorts we have 1000 customers from month one, of which 600 survive until month two, our best guess of the â€œtrueâ€ probability of survival from month 1 to 2 is 60%.\\n\\nWe do the same for the next month. Divide the number of customers that survived through month 3 by the number of customers who survived through month 2 to get the estimated probability of survival from month 2 to 3. If we donâ€™t have month 3 data for a cohort because itâ€™s only two months old, we exclude those customers from our calculations for month 3 survival.\\n\\nRepeat for as many cohorts / months as you have, excluding in each calculation any cohorts missing data for the current period. Then, to calculate the probability of survival through any given month, multiply the individual monthly ([conditional](https://www.khanacademy.org/math/statistics-probability/probability-library/conditional-probability-independence/v/calculating-conditional-probability)) probabilities up through that month.\\n\\nThough a morbid thought,  measuring patient survival is functionally equivalent to measuring customer retention, so we can easily transfer KM to customer cohort analysis!\\n\\n## Putting Kaplan-Meier to the test\\nLetâ€™s make this clearer by applying the Kaplan-Meier estimator to our previous example.\\n\\n![3-1](/content/images/2019/05/3-1.png)\\n\\nThe probability of surviving month 1 is **69%** (total customers alive in month 1 divided by total in month 0). The probability of surviving month 2, given a customer survived month 1, is **72%** (total customers alive in month 2 divided by total in month 1, excluding the last cohort which is missing month 2 data). So the cumulative probability of surviving at least two months is 69% x 72% = **50%**. Rinse, wash, and repeat for each subsequent month.\\n\\nSide-by-side comparison reveals the superiority of KM:\\n\\n![4](/content/images/2019/05/4.png)\\n\\nWhatâ€™s great about KM is it leverages all the data we have, even the younger cohorts for whom we have fewer observations. For example, while the average of all the available cohorts at month 3 only uses the data for cohorts 1-3, due to its cumulative nature, the KM estimator effectively incorporates the improved early retention of the newer cohorts. This yields a 3-month retention estimate of 38%, which is higher than any of the cohorts we can actually measure at month 3.\\n\\n**This is exactly what we want**â€”cohorts 4 and 5 are both larger and better retaining than 1-3. Hence, it is likely that the 3-month retention rate for a random customer picked among these cohorts will exceed the historical average, as the customer will likely be in cohorts 4 or 5.\\n\\nUsing all the data is also nice because it makes our estimates of the tail probabilities much more precise than if we could only rely on the data of customers who we retained that long.\\n\\nKaplan-Meier curves also fixes the wonky behavior in the right tail of the retention curve by respecting a [fundamental law of probability](https://www.investopedia.com/terms/c/compound-probability.asp): cumulative probabilities can only decline as you multiply more numbers.\\n\\n## Recommended by 95% of doctors\\nThis analysis could easily be extended. Letâ€™s go back to the 2016 vs 2017 exampleâ€”we could run the Kaplan-Meier calculation on each respective group of cohorts and then compare the resulting survival curves, highlighting differences in expected retention between the two groups.\\n\\nWhile I wonâ€™t cover it here, you can also calculate [p-values, confidence intervals, and statistical significance tests](https://math.unm.edu/~james/w4.pdf) for Kaplan-Meier curves. This lets you to make rigorous statements like â€œthe improvement of cohort retention in 2018 relative to 2017 was statistically significant (at the 5% level)â€â€”cool stuff:\\n\\n![5](/content/images/2019/05/5.png)\\n\\n**Kaplan-Meier is a powerful tool for anyone who spends time analyzing customer cohort data.** KM has been battle-tested in rigorous clinical trialsâ€”if anything itâ€™s surprising it hasnâ€™t caught on more among technology operators and investors.\\n\\nIf youâ€™re a product manager, growth hacker, marketer, data scientist, investor, or anyone else who understands the deep importance of customer retention analysis, the Kaplan-Meier estimator should be a valuable weapon in your analytics arsenal.\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}","html":"<!--kg-card-begin: markdown--><p><strong>Understanding cohort performance is critical for modern, high-velocity businesses, especially those with subscription or recurring revenue models.</strong></p>\n<p>In SaaS or consumer subscription settings, small changes in churn can <a href=\"https://www.forentrepreneurs.com/why-churn-is-critical-in-saas/?fbclid=IwAR3RmfnV8ek0lDyyWwEXdkHNJhJxXymIN-hJeuo32c3cYekTnQOgLvAryi4\">radically impact revenue growth</a>.</p>\n<p>Product managers, growth hackers, marketers, data scientists, and investors all need to understand how business decisions impact user retention.</p>\n<p>With so many recurring revenue businesses going public, Silicon Valley <em>should</em> get the picture by now.</p>\n<p>Believe it or not, however, <strong>medical researchers measure customer retention better than you do.</strong></p>\n<p>What?</p>\n<p>Sounds bold, but itâ€™s not. Over decades, clinical researchers have refined precise and rigorous ways of measuring retentionâ€”except instead of <em>customer</em> retention, they measure <em>patient survival</em>.</p>\n<p>The gravity of life and death means researchers take great care in measuring treatment efficacy.</p>\n<p>To do this, clinical researchers use a statistical method called the <a href=\"https://en.wikipedia.org/wiki/Kaplan%E2%80%93Meier_estimator\"><strong>Kaplan-Meier estimator</strong></a>. The formula elegantly solves a frequent issue that pops up in cohort retention analysis: <strong>making valid comparisons within and across groups of cohorts of different lifespans</strong>:</p>\n<!--<script type=\"text/x-mathjax-config\">MathJax.Hub.Config({tex2jax: {inlineMath:[['$','$']]}});</script>\n<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=default' async></script>-->\n<p>$$ \\widehat S(t) = \\prod\\limits_{i:\\ t_i\\le t} \\left(1 - \\frac{d_i}{n_i}\\right) $$</p>\n<p>Despite the fancy formula, survival analysis using Kaplan-Meier (KM) is actually quite simple and delivers much better results than other methods:</p>\n<p><img src=\"/content/images/2019/05/4.png\" alt=\"4\" loading=\"lazy\"></p>\n<p>In this post I'll explain these results, breakdown the KM estimator in simple terms, and convince you to use it for retention analysis.</p>\n<p>The bottom-line: <strong>if you are an operator or investor who wants to properly measure customer cohort retention, Kaplan-Meier is the way to do it.</strong></p>\n<section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive my next post in your inbox</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"youremail@example.com\" id=\"mce-EMAIL\" required>\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span>Subscribe</span></button>\n</form>\n</section>\n<h2 id=\"twoinevitabilitiesdeathandchurn\">Two inevitabilities: Death and Churn</h2>\n<p>The core problem the KM estimator helps us deal with is <strong>missing data</strong>.</p>\n<p><strong>Cohort data is inherently flawed in that more recent cohorts have fewer data points to compare against older cohorts</strong>. For example, a five-month-old cohort can only be compared with the first five months of a ten-month-old cohort. The retention rates of a cohort of customers acquired seven months ago can only reasonably be compared to the first seven month retention of older cohorts.</p>\n<p>Imagine you had the full retention history of the previous 12 monthly cohorts and you wanted to predict the 12-month retention curve of a newly acquired customer. Itâ€™s not at all obvious how to do this.</p>\n<p>To understand this better, letâ€™s visualize a simpler example with only five cohorts:</p>\n<p><img src=\"/content/images/2019/05/1.png\" alt=\"1\" loading=\"lazy\"></p>\n<p>You might first try to calculate average retention across cohorts. This is problematic for two reasons:</p>\n<ul>\n<li>The simple average will not be representative if our cohorts differ in size</li>\n<li>For any given month we can only average over cohorts that have been alive at least that long, so we effectively average over fewer and fewer cohorts over time</li>\n</ul>\n<p>We can see the second issue below. With both the simple and weighted average, we get strange results when performance oscillates across cohorts:</p>\n<p><img src=\"/content/images/2019/05/2-1.png\" alt=\"2-1\" loading=\"lazy\"></p>\n<p>Assuming we donâ€™t re-add returning users who previously churned into their original cohort, retention cannot possibly tick up after decliningâ€”itâ€™s a one way street. This is an artifact of our flawed method, as 5-month retention cannot exceed 4-month retention by definition.</p>\n<p>A third, related problem arises when comparing groups of cohorts to other groups, for example, comparing 2016â€™s group of monthly cohorts to 2017â€™s. As weâ€™ve just shown, using averages to estimate retention curves for each group doesnâ€™t work, which means we also cannot compare one group to another.</p>\n<h2 id=\"questionsaskyourdoctor\">Questions? Ask your doctor</h2>\n<p><img src=\"/content/images/2019/05/ani-kolleshi-684082-unsplash.jpg\" alt=\"ani-kolleshi-684082-unsplash\" loading=\"lazy\"></p>\n<p>Believe it or not, clinical researchers deal with this same issue all the time.</p>\n<p>Customer cohorts are analogous to groups of patients starting treatment at different times. Here the â€œtreatmentâ€ is the time of customer acquisition and â€œdeathâ€ is simply churn.</p>\n<p>Or, imagine if the â€œ2016 cohortsâ€ and â€œ2017 cohortsâ€, rather than being year-grouped cohorts, were groups receiving different treatments in a clinical trial. We want to quantify differences in patient survival rates (customer retention) between the two groups.</p>\n<p>Pharmaceutical companies and other research outfits regularly contend  with this. Patients start treatment at different times. Patients drop out of studies, by dying, but also by moving locations or deciding to stop taking the medication.</p>\n<p>This creates a host of missing data issues at the beginning, middle, and end of any patientâ€™s clinical test record, complicating analysis of effectiveness and safety.</p>\n<p>To solve this problem, in 1958, a mathematician, <a href=\"https://en.wikipedia.org/wiki/Edward_L._Kaplan\">Edward Kaplan</a>, and statistician, <a href=\"https://www.chicagotribune.com/news/ct-xpm-2011-08-18-ct-met-meier-obit-20110818-story.html\">Paul Meier</a>, jointly created the <a href=\"https://www.tandfonline.com/doi/abs/10.1080/01621459.1958.10501452\">Kaplan-Meier estimator</a>. Also called the <em>product-limit estimator</em>, the method effectively deals with the missing data issue, providing a more precise estimate of the probability of survival up to any point.</p>\n<p><a href=\"http://biostat.mc.vanderbilt.edu/wiki/pub/Main/ClinStat/km.lam.pdf\">The core idea behind Kaplan-Meier</a>:</p>\n<blockquote>\n<p>The estimated probability of surviving up to any point is the cumulative probability of surviving each preceding time interval, calculated as the product of the preceding survival probabilities</p>\n</blockquote>\n<p>That strange formula above is simply multiplying a bunch of probabilities against one another to find the cumulative probability of survival at a certain point.</p>\n<p>Where do these probabilities come from? <strong>Directly from the data</strong>.</p>\n<p>KM says our best estimate of the probability of survival from one month to the next is exactly the weighted average retention rate for that month in our dataset (also called the <a href=\"https://towardsdatascience.com/a-gentle-introduction-to-maximum-likelihood-estimation-9fbff27ea12f\"><em>maximum likelihood estimator</em></a> in statistics parlance). So if in a group of cohorts we have 1000 customers from month one, of which 600 survive until month two, our best guess of the â€œtrueâ€ probability of survival from month 1 to 2 is 60%.</p>\n<p>We do the same for the next month. Divide the number of customers that survived through month 3 by the number of customers who survived through month 2 to get the estimated probability of survival from month 2 to 3. If we donâ€™t have month 3 data for a cohort because itâ€™s only two months old, we exclude those customers from our calculations for month 3 survival.</p>\n<p>Repeat for as many cohorts / months as you have, excluding in each calculation any cohorts missing data for the current period. Then, to calculate the probability of survival through any given month, multiply the individual monthly (<a href=\"https://www.khanacademy.org/math/statistics-probability/probability-library/conditional-probability-independence/v/calculating-conditional-probability\">conditional</a>) probabilities up through that month.</p>\n<p>Though a morbid thought,  measuring patient survival is functionally equivalent to measuring customer retention, so we can easily transfer KM to customer cohort analysis!</p>\n<h2 id=\"puttingkaplanmeiertothetest\">Putting Kaplan-Meier to the test</h2>\n<p>Letâ€™s make this clearer by applying the Kaplan-Meier estimator to our previous example.</p>\n<p><img src=\"/content/images/2019/05/3-1.png\" alt=\"3-1\" loading=\"lazy\"></p>\n<p>The probability of surviving month 1 is <strong>69%</strong> (total customers alive in month 1 divided by total in month 0). The probability of surviving month 2, given a customer survived month 1, is <strong>72%</strong> (total customers alive in month 2 divided by total in month 1, excluding the last cohort which is missing month 2 data). So the cumulative probability of surviving at least two months is 69% x 72% = <strong>50%</strong>. Rinse, wash, and repeat for each subsequent month.</p>\n<p>Side-by-side comparison reveals the superiority of KM:</p>\n<p><img src=\"/content/images/2019/05/4.png\" alt=\"4\" loading=\"lazy\"></p>\n<p>Whatâ€™s great about KM is it leverages all the data we have, even the younger cohorts for whom we have fewer observations. For example, while the average of all the available cohorts at month 3 only uses the data for cohorts 1-3, due to its cumulative nature, the KM estimator effectively incorporates the improved early retention of the newer cohorts. This yields a 3-month retention estimate of 38%, which is higher than any of the cohorts we can actually measure at month 3.</p>\n<p><strong>This is exactly what we want</strong>â€”cohorts 4 and 5 are both larger and better retaining than 1-3. Hence, it is likely that the 3-month retention rate for a random customer picked among these cohorts will exceed the historical average, as the customer will likely be in cohorts 4 or 5.</p>\n<p>Using all the data is also nice because it makes our estimates of the tail probabilities much more precise than if we could only rely on the data of customers who we retained that long.</p>\n<p>Kaplan-Meier curves also fixes the wonky behavior in the right tail of the retention curve by respecting a <a href=\"https://www.investopedia.com/terms/c/compound-probability.asp\">fundamental law of probability</a>: cumulative probabilities can only decline as you multiply more numbers.</p>\n<h2 id=\"recommendedby95ofdoctors\">Recommended by 95% of doctors</h2>\n<p>This analysis could easily be extended. Letâ€™s go back to the 2016 vs 2017 exampleâ€”we could run the Kaplan-Meier calculation on each respective group of cohorts and then compare the resulting survival curves, highlighting differences in expected retention between the two groups.</p>\n<p>While I wonâ€™t cover it here, you can also calculate <a href=\"https://math.unm.edu/~james/w4.pdf\">p-values, confidence intervals, and statistical significance tests</a> for Kaplan-Meier curves. This lets you to make rigorous statements like â€œthe improvement of cohort retention in 2018 relative to 2017 was statistically significant (at the 5% level)â€â€”cool stuff:</p>\n<p><img src=\"/content/images/2019/05/5.png\" alt=\"5\" loading=\"lazy\"></p>\n<p><strong>Kaplan-Meier is a powerful tool for anyone who spends time analyzing customer cohort data.</strong> KM has been battle-tested in rigorous clinical trialsâ€”if anything itâ€™s surprising it hasnâ€™t caught on more among technology operators and investors.</p>\n<p>If youâ€™re a product manager, growth hacker, marketer, data scientist, investor, or anyone else who understands the deep importance of customer retention analysis, the Kaplan-Meier estimator should be a valuable weapon in your analytics arsenal.</p>\n<!--kg-card-end: markdown-->","comment_id":"5cefa8c0f9f4410ef2e73d86","plaintext":"Understanding cohort performance is critical for modern, high-velocity\nbusinesses, especially those with subscription or recurring revenue models.\n\nIn SaaS or consumer subscription settings, small changes in churn can radically\nimpact revenue growth\n[https://www.forentrepreneurs.com/why-churn-is-critical-in-saas/?fbclid=IwAR3RmfnV8ek0lDyyWwEXdkHNJhJxXymIN-hJeuo32c3cYekTnQOgLvAryi4]\n.\n\nProduct managers, growth hackers, marketers, data scientists, and investors all\nneed to understand how business decisions impact user retention.\n\nWith so many recurring revenue businesses going public, Silicon Valley should \nget the picture by now.\n\nBelieve it or not, however, medical researchers measure customer retention\nbetter than you do.\n\nWhat?\n\nSounds bold, but itâ€™s not. Over decades, clinical researchers have refined\nprecise and rigorous ways of measuring retentionâ€”except instead of customer \nretention, they measure patient survival.\n\nThe gravity of life and death means researchers take great care in measuring\ntreatment efficacy.\n\nTo do this, clinical researchers use a statistical method called the \nKaplan-Meier estimator\n[https://en.wikipedia.org/wiki/Kaplan%E2%80%93Meier_estimator]. The formula\nelegantly solves a frequent issue that pops up in cohort retention analysis: \nmaking valid comparisons within and across groups of cohorts of different\nlifespans:\n\n$$ \\widehat S(t) = \\prod\\limits_{i:\\ t_i\\le t} \\left(1 - \\frac{d_i}{n_i}\\right)\n$$\n\nDespite the fancy formula, survival analysis using Kaplan-Meier (KM) is actually\nquite simple and delivers much better results than other methods:\n\n\n\nIn this post I'll explain these results, breakdown the KM estimator in simple\nterms, and convince you to use it for retention analysis.\n\nThe bottom-line: if you are an operator or investor who wants to properly\nmeasure customer cohort retention, Kaplan-Meier is the way to do it.\n\nReceive my next post in your inbox\n\n\nSubscribeTwo inevitabilities: Death and Churn\nThe core problem the KM estimator helps us deal with is missing data.\n\nCohort data is inherently flawed in that more recent cohorts have fewer data\npoints to compare against older cohorts. For example, a five-month-old cohort\ncan only be compared with the first five months of a ten-month-old cohort. The\nretention rates of a cohort of customers acquired seven months ago can only\nreasonably be compared to the first seven month retention of older cohorts.\n\nImagine you had the full retention history of the previous 12 monthly cohorts\nand you wanted to predict the 12-month retention curve of a newly acquired\ncustomer. Itâ€™s not at all obvious how to do this.\n\nTo understand this better, letâ€™s visualize a simpler example with only five\ncohorts:\n\n\n\nYou might first try to calculate average retention across cohorts. This is\nproblematic for two reasons:\n\n * The simple average will not be representative if our cohorts differ in size\n * For any given month we can only average over cohorts that have been alive at\n   least that long, so we effectively average over fewer and fewer cohorts over\n   time\n\nWe can see the second issue below. With both the simple and weighted average, we\nget strange results when performance oscillates across cohorts:\n\n\n\nAssuming we donâ€™t re-add returning users who previously churned into their\noriginal cohort, retention cannot possibly tick up after decliningâ€”itâ€™s a one\nway street. This is an artifact of our flawed method, as 5-month retention\ncannot exceed 4-month retention by definition.\n\nA third, related problem arises when comparing groups of cohorts to other\ngroups, for example, comparing 2016â€™s group of monthly cohorts to 2017â€™s. As\nweâ€™ve just shown, using averages to estimate retention curves for each group\ndoesnâ€™t work, which means we also cannot compare one group to another.\n\nQuestions? Ask your doctor\n\n\nBelieve it or not, clinical researchers deal with this same issue all the time.\n\nCustomer cohorts are analogous to groups of patients starting treatment at\ndifferent times. Here the â€œtreatmentâ€ is the time of customer acquisition and\nâ€œdeathâ€ is simply churn.\n\nOr, imagine if the â€œ2016 cohortsâ€ and â€œ2017 cohortsâ€, rather than being\nyear-grouped cohorts, were groups receiving different treatments in a clinical\ntrial. We want to quantify differences in patient survival rates (customer\nretention) between the two groups.\n\nPharmaceutical companies and other research outfits regularly contend with this.\nPatients start treatment at different times. Patients drop out of studies, by\ndying, but also by moving locations or deciding to stop taking the medication.\n\nThis creates a host of missing data issues at the beginning, middle, and end of\nany patientâ€™s clinical test record, complicating analysis of effectiveness and\nsafety.\n\nTo solve this problem, in 1958, a mathematician, Edward Kaplan\n[https://en.wikipedia.org/wiki/Edward_L._Kaplan], and statistician, Paul Meier\n[https://www.chicagotribune.com/news/ct-xpm-2011-08-18-ct-met-meier-obit-20110818-story.html]\n, jointly created the Kaplan-Meier estimator\n[https://www.tandfonline.com/doi/abs/10.1080/01621459.1958.10501452]. Also\ncalled the product-limit estimator, the method effectively deals with the\nmissing data issue, providing a more precise estimate of the probability of\nsurvival up to any point.\n\nThe core idea behind Kaplan-Meier\n[http://biostat.mc.vanderbilt.edu/wiki/pub/Main/ClinStat/km.lam.pdf]:\n\n> The estimated probability of surviving up to any point is the cumulative\nprobability of surviving each preceding time interval, calculated as the product\nof the preceding survival probabilities\n\n\nThat strange formula above is simply multiplying a bunch of probabilities\nagainst one another to find the cumulative probability of survival at a certain\npoint.\n\nWhere do these probabilities come from? Directly from the data.\n\nKM says our best estimate of the probability of survival from one month to the\nnext is exactly the weighted average retention rate for that month in our\ndataset (also called the maximum likelihood estimator\n[https://towardsdatascience.com/a-gentle-introduction-to-maximum-likelihood-estimation-9fbff27ea12f] \nin statistics parlance). So if in a group of cohorts we have 1000 customers from\nmonth one, of which 600 survive until month two, our best guess of the â€œtrueâ€\nprobability of survival from month 1 to 2 is 60%.\n\nWe do the same for the next month. Divide the number of customers that survived\nthrough month 3 by the number of customers who survived through month 2 to get\nthe estimated probability of survival from month 2 to 3. If we donâ€™t have month\n3 data for a cohort because itâ€™s only two months old, we exclude those customers\nfrom our calculations for month 3 survival.\n\nRepeat for as many cohorts / months as you have, excluding in each calculation\nany cohorts missing data for the current period. Then, to calculate the\nprobability of survival through any given month, multiply the individual monthly\n(conditional\n[https://www.khanacademy.org/math/statistics-probability/probability-library/conditional-probability-independence/v/calculating-conditional-probability]\n) probabilities up through that month.\n\nThough a morbid thought, measuring patient survival is functionally equivalent\nto measuring customer retention, so we can easily transfer KM to customer cohort\nanalysis!\n\nPutting Kaplan-Meier to the test\nLetâ€™s make this clearer by applying the Kaplan-Meier estimator to our previous\nexample.\n\n\n\nThe probability of surviving month 1 is 69% (total customers alive in month 1\ndivided by total in month 0). The probability of surviving month 2, given a\ncustomer survived month 1, is 72% (total customers alive in month 2 divided by\ntotal in month 1, excluding the last cohort which is missing month 2 data). So\nthe cumulative probability of surviving at least two months is 69% x 72% = 50%.\nRinse, wash, and repeat for each subsequent month.\n\nSide-by-side comparison reveals the superiority of KM:\n\n\n\nWhatâ€™s great about KM is it leverages all the data we have, even the younger\ncohorts for whom we have fewer observations. For example, while the average of\nall the available cohorts at month 3 only uses the data for cohorts 1-3, due to\nits cumulative nature, the KM estimator effectively incorporates the improved\nearly retention of the newer cohorts. This yields a 3-month retention estimate\nof 38%, which is higher than any of the cohorts we can actually measure at month\n3.\n\nThis is exactly what we wantâ€”cohorts 4 and 5 are both larger and better\nretaining than 1-3. Hence, it is likely that the 3-month retention rate for a\nrandom customer picked among these cohorts will exceed the historical average,\nas the customer will likely be in cohorts 4 or 5.\n\nUsing all the data is also nice because it makes our estimates of the tail\nprobabilities much more precise than if we could only rely on the data of\ncustomers who we retained that long.\n\nKaplan-Meier curves also fixes the wonky behavior in the right tail of the\nretention curve by respecting a fundamental law of probability\n[https://www.investopedia.com/terms/c/compound-probability.asp]: cumulative\nprobabilities can only decline as you multiply more numbers.\n\nRecommended by 95% of doctors\nThis analysis could easily be extended. Letâ€™s go back to the 2016 vs 2017\nexampleâ€”we could run the Kaplan-Meier calculation on each respective group of\ncohorts and then compare the resulting survival curves, highlighting differences\nin expected retention between the two groups.\n\nWhile I wonâ€™t cover it here, you can also calculate p-values, confidence\nintervals, and statistical significance tests\n[https://math.unm.edu/~james/w4.pdf] for Kaplan-Meier curves. This lets you to\nmake rigorous statements like â€œthe improvement of cohort retention in 2018\nrelative to 2017 was statistically significant (at the 5% level)â€â€”cool stuff:\n\n\n\nKaplan-Meier is a powerful tool for anyone who spends time analyzing customer\ncohort data. KM has been battle-tested in rigorous clinical trialsâ€”if anything\nitâ€™s surprising it hasnâ€™t caught on more among technology operators and\ninvestors.\n\nIf youâ€™re a product manager, growth hacker, marketer, data scientist, investor,\nor anyone else who understands the deep importance of customer retention\nanalysis, the Kaplan-Meier estimator should be a valuable weapon in your\nanalytics arsenal.","feature_image":"__GHOST_URL__/content/images/2019/05/lucas-vasques-453684-unsplash.jpg","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2019-05-30T09:56:16.000Z","updated_at":"2019-06-04T04:30:45.000Z","published_at":"2019-06-03T12:00:00.000Z","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5d34c61cf9f4410ef2e73e4b","uuid":"60f0b108-6816-4124-9f49-4dc233bfe72c","title":"Waitlists are a Vanity Metric","slug":"waitlists-are-a-vanity-metric","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Waitlists, registered users, and other cumulative measures are vanity metrics.\\n\\nBy vanity â€“ I mean they better measure the size of your *pride* than the size of your *business*.\\n\\nFirst-year MBA operations courses emphasize that long lines should be avoided and certainly not optimized for.\\n\\nUnless you are in fact a vanity or â€œprestigeâ€ product, bragging about these metrics destroys your credibility in the eyes of potential investors.\\n\\nMost importantly, in paying them too much attention, you fool, distract, and mislead your most gullible stakeholder â€“ yourself.\\n\\n> The first principle is that you must not fool yourself â€“ and you are the easiest person to fool â€“ Richard Feynman\\n\\nBe kind to your potential customers, your investors, and yourself â€“ **ignore these misleading numbers**.\\n\\nCumulative metrics are problematic for many reasons. The main two are:\\n\\n- They almost never decrease â€“ *by design*\\n- They have *zero* intrinsic correlation to customer value\\n\\n<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive my next thought in your inbox</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"I email every few months\\\" id=\\\"mce-EMAIL\\\" required>\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span>Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## If it canâ€™t decline, itâ€™s not worth your time\\n> To have weight, a metric should be capable of moving in either direction â€“ up or down.\\n\\nAn easily gamed number that can only move in one direction is problematic. Most cumulative metrics have this feature.\\n\\nA measure that moves up or down with the health of the business is a valuable signal â€“ both in terms of its *level* and its *change* (or rather rate of change).\\n\\nThat its level is X, instead of Y or Z, tells us something. That it grew by X% last month also tells us something. That \\\"something\\\" is much more informative when X can move up or down and X% can be positive or negative.\\n\\nClassic examples include monthly revenue, paying users, monthly expenses per employee, or annual profits.\\n\\nOn the other hand, total registered users â€“ people whoâ€™ve created an account for a website or app but donâ€™t necessarily pay for it â€“ never declines unless users un-register themselves. This rarely happens.\\n\\nIn practice, the registered user count grows and grows, with no regard to whether the business is improving. Hence, both its level and its change provide little information.\\n\\nWaitlists are functionally similar. They exist to signal attractiveness to third parties but are completely manipulable.\\n\\nThe size of a waitlist never declines unless you want it to. The outflow is entirely in your control. \\n\\nIf you never want your waitlist to shorten, *stop accepting new users off the waitlist*. Mission complete.\\n\\nAs such, waitlists are mostly a rebrand of \\\"cumulative registered users\\\".\\n\\nHaving a long waitlist *sounds* cool, but a waitlist alone is little more than a list of opt-in email addresses saved in a CSV file on your desktop or, better yet, â€œin the cloudâ€ somewhere.\\n\\n\\n## A true business imposes costs on its customers and delivers value in return\\n> The cost customers willfully bear to interact with your business implies value delivered. Those costs historically came in the form of dollars but increasingly take the form of attention or time.\\n\\nIf a customer isnâ€™t giving you their money, attention, or time, **theyâ€™re not a customer.**\\n\\nYou can call them registered users, opt-ins, friendly acquaintances â€“ it doesnâ€™t really matter.\\n\\nBut theyâ€™re not customers.\\n\\nAdding oneself to a digital waitlist imposes almost no cost. If anything, itâ€™s a free option â€“ maybe Iâ€™ll sign up once the service is available, maybe I wonâ€™t.\\n\\nWhen a human being accepts a free option, we call that person â€œrationalâ€. We donâ€™t call them a â€œcustomerâ€.\\n\\nLike selling dollars for 75 cents, there is no signal in handing out free options.\\n\\nFlaunting the length of your waitlist is like bragging about raising $10M from investors with no plans to do anything with the money. This is why bankers subtract **cash** from **equity value** when calculating **enterprise value** â€“ quite literally, how much your business is worth.\\n\\nIn the preceding example, your *equity value* might be $10M, but your *enterprise value* would be a flat $0. Youâ€™ve delivered zero additional value to your investors.\\n\\nAdding 10,000 people to your waitlist but not doing anything with those users is similarly worthless.\\n\\n\\n## How to make your waitlist valuable\\n\\nI know what youâ€™re thinking â€“ â€œbut what if Iâ€™mâ€¦\\\"\\n\\n- Fundraising and want to give investors every possible reason to write a check\\n- A fledgling startup without many options for measuring progress\\n- Bored and just like staring at numbers (guilty as charged)\\n\\nNot all is lost â€“ paired with other metrics waitlists can in fact be a signal of business value.\\n\\n\\n- **Example:** the proportion of people taken off the waitlist who subscribe or purchase the product\\n\\nThis provides some directional sense of future value â€“ if we let X people off the waitlist weâ€™ll gain Y customers. That Y/X ratio is a **conversion rate**.\\n\\nWho knows if that conversion rate will hold across the entire waitlist â€“ it probably wonâ€™t â€“ but at least we know the waitlist has some value and isnâ€™t pure vanity.\\n\\n\\n- **Another example:** charge people for reserving a spot in line like Tesla did for the Model 3\\n\\nThat hundreds of thousands of people were willing to put down a deposit before ever touching, let alone driving, the car was a huge signal.\\n\\nThat spot in line was valuable to customers, and they manifested that value by forking over thousands of dollars years in advance of the launch. Investors, too, saw value, rewarding Tesla with a higher valuation.\\n\\nNotice a pattern? To make waitlists useful, **link them to customer value**.\\n\\n\\n## Donâ€™t wait\\n\\nThat slide in your pitch deck where you mention how large your waitlist is? Unless you can tie it to customer value, **delete it**.\\n\\nHeard about some hot startup with a waitlist 10X as long as yours? **Ignore it**.\\n\\nBy distancing yourself from the raucous noise of waitlists and other cumulative measures â€“ you refocus your attention on the true signal of entrepreneurial success â€“ **delivering value to customers**.\\n\\nShip them a product. Provide them a service.\\n\\nBut please, donâ€™t just hand them a ticket with a number on it and call it a day â€“ or a business.\"}],[\"markdown\",{\"markdown\":\"*This post has been published on [www.productschool.com](https://www.productschool.com) communities.*\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}","html":"<!--kg-card-begin: markdown--><p>Waitlists, registered users, and other cumulative measures are vanity metrics.</p>\n<p>By vanity â€“ I mean they better measure the size of your <em>pride</em> than the size of your <em>business</em>.</p>\n<p>First-year MBA operations courses emphasize that long lines should be avoided and certainly not optimized for.</p>\n<p>Unless you are in fact a vanity or â€œprestigeâ€ product, bragging about these metrics destroys your credibility in the eyes of potential investors.</p>\n<p>Most importantly, in paying them too much attention, you fool, distract, and mislead your most gullible stakeholder â€“ yourself.</p>\n<blockquote>\n<p>The first principle is that you must not fool yourself â€“ and you are the easiest person to fool â€“ Richard Feynman</p>\n</blockquote>\n<p>Be kind to your potential customers, your investors, and yourself â€“ <strong>ignore these misleading numbers</strong>.</p>\n<p>Cumulative metrics are problematic for many reasons. The main two are:</p>\n<ul>\n<li>They almost never decrease â€“ <em>by design</em></li>\n<li>They have <em>zero</em> intrinsic correlation to customer value</li>\n</ul>\n<section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive my next thought in your inbox</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"I email every few months\" id=\"mce-EMAIL\" required>\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span>Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"ifitcantdeclineitsnotworthyourtime\">If it canâ€™t decline, itâ€™s not worth your time</h2>\n<blockquote>\n<p>To have weight, a metric should be capable of moving in either direction â€“ up or down.</p>\n</blockquote>\n<p>An easily gamed number that can only move in one direction is problematic. Most cumulative metrics have this feature.</p>\n<p>A measure that moves up or down with the health of the business is a valuable signal â€“ both in terms of its <em>level</em> and its <em>change</em> (or rather rate of change).</p>\n<p>That its level is X, instead of Y or Z, tells us something. That it grew by X% last month also tells us something. That &quot;something&quot; is much more informative when X can move up or down and X% can be positive or negative.</p>\n<p>Classic examples include monthly revenue, paying users, monthly expenses per employee, or annual profits.</p>\n<p>On the other hand, total registered users â€“ people whoâ€™ve created an account for a website or app but donâ€™t necessarily pay for it â€“ never declines unless users un-register themselves. This rarely happens.</p>\n<p>In practice, the registered user count grows and grows, with no regard to whether the business is improving. Hence, both its level and its change provide little information.</p>\n<p>Waitlists are functionally similar. They exist to signal attractiveness to third parties but are completely manipulable.</p>\n<p>The size of a waitlist never declines unless you want it to. The outflow is entirely in your control.</p>\n<p>If you never want your waitlist to shorten, <em>stop accepting new users off the waitlist</em>. Mission complete.</p>\n<p>As such, waitlists are mostly a rebrand of &quot;cumulative registered users&quot;.</p>\n<p>Having a long waitlist <em>sounds</em> cool, but a waitlist alone is little more than a list of opt-in email addresses saved in a CSV file on your desktop or, better yet, â€œin the cloudâ€ somewhere.</p>\n<h2 id=\"atruebusinessimposescostsonitscustomersanddeliversvalueinreturn\">A true business imposes costs on its customers and delivers value in return</h2>\n<blockquote>\n<p>The cost customers willfully bear to interact with your business implies value delivered. Those costs historically came in the form of dollars but increasingly take the form of attention or time.</p>\n</blockquote>\n<p>If a customer isnâ€™t giving you their money, attention, or time, <strong>theyâ€™re not a customer.</strong></p>\n<p>You can call them registered users, opt-ins, friendly acquaintances â€“ it doesnâ€™t really matter.</p>\n<p>But theyâ€™re not customers.</p>\n<p>Adding oneself to a digital waitlist imposes almost no cost. If anything, itâ€™s a free option â€“ maybe Iâ€™ll sign up once the service is available, maybe I wonâ€™t.</p>\n<p>When a human being accepts a free option, we call that person â€œrationalâ€. We donâ€™t call them a â€œcustomerâ€.</p>\n<p>Like selling dollars for 75 cents, there is no signal in handing out free options.</p>\n<p>Flaunting the length of your waitlist is like bragging about raising $10M from investors with no plans to do anything with the money. This is why bankers subtract <strong>cash</strong> from <strong>equity value</strong> when calculating <strong>enterprise value</strong> â€“ quite literally, how much your business is worth.</p>\n<p>In the preceding example, your <em>equity value</em> might be $10M, but your <em>enterprise value</em> would be a flat $0. Youâ€™ve delivered zero additional value to your investors.</p>\n<p>Adding 10,000 people to your waitlist but not doing anything with those users is similarly worthless.</p>\n<h2 id=\"howtomakeyourwaitlistvaluable\">How to make your waitlist valuable</h2>\n<p>I know what youâ€™re thinking â€“ â€œbut what if Iâ€™mâ€¦&quot;</p>\n<ul>\n<li>Fundraising and want to give investors every possible reason to write a check</li>\n<li>A fledgling startup without many options for measuring progress</li>\n<li>Bored and just like staring at numbers (guilty as charged)</li>\n</ul>\n<p>Not all is lost â€“ paired with other metrics waitlists can in fact be a signal of business value.</p>\n<ul>\n<li><strong>Example:</strong> the proportion of people taken off the waitlist who subscribe or purchase the product</li>\n</ul>\n<p>This provides some directional sense of future value â€“ if we let X people off the waitlist weâ€™ll gain Y customers. That Y/X ratio is a <strong>conversion rate</strong>.</p>\n<p>Who knows if that conversion rate will hold across the entire waitlist â€“ it probably wonâ€™t â€“ but at least we know the waitlist has some value and isnâ€™t pure vanity.</p>\n<ul>\n<li><strong>Another example:</strong> charge people for reserving a spot in line like Tesla did for the Model 3</li>\n</ul>\n<p>That hundreds of thousands of people were willing to put down a deposit before ever touching, let alone driving, the car was a huge signal.</p>\n<p>That spot in line was valuable to customers, and they manifested that value by forking over thousands of dollars years in advance of the launch. Investors, too, saw value, rewarding Tesla with a higher valuation.</p>\n<p>Notice a pattern? To make waitlists useful, <strong>link them to customer value</strong>.</p>\n<h2 id=\"dontwait\">Donâ€™t wait</h2>\n<p>That slide in your pitch deck where you mention how large your waitlist is? Unless you can tie it to customer value, <strong>delete it</strong>.</p>\n<p>Heard about some hot startup with a waitlist 10X as long as yours? <strong>Ignore it</strong>.</p>\n<p>By distancing yourself from the raucous noise of waitlists and other cumulative measures â€“ you refocus your attention on the true signal of entrepreneurial success â€“ <strong>delivering value to customers</strong>.</p>\n<p>Ship them a product. Provide them a service.</p>\n<p>But please, donâ€™t just hand them a ticket with a number on it and call it a day â€“ or a business.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p><em>This post has been published on <a href=\"https://www.productschool.com\">www.productschool.com</a> communities.</em></p>\n<!--kg-card-end: markdown-->","comment_id":"5d34c61cf9f4410ef2e73e4b","plaintext":"Waitlists, registered users, and other cumulative measures are vanity metrics.\n\nBy vanity â€“ I mean they better measure the size of your pride than the size of\nyour business.\n\nFirst-year MBA operations courses emphasize that long lines should be avoided\nand certainly not optimized for.\n\nUnless you are in fact a vanity or â€œprestigeâ€ product, bragging about these\nmetrics destroys your credibility in the eyes of potential investors.\n\nMost importantly, in paying them too much attention, you fool, distract, and\nmislead your most gullible stakeholder â€“ yourself.\n\n> The first principle is that you must not fool yourself â€“ and you are the easiest\nperson to fool â€“ Richard Feynman\n\n\nBe kind to your potential customers, your investors, and yourself â€“ ignore these\nmisleading numbers.\n\nCumulative metrics are problematic for many reasons. The main two are:\n\n * They almost never decrease â€“ by design\n * They have zero intrinsic correlation to customer value\n\nReceive my next thought in your inbox\n\n\nGo âš¡If it canâ€™t decline, itâ€™s not worth your time\n> To have weight, a metric should be capable of moving in either direction â€“ up or\ndown.\n\n\nAn easily gamed number that can only move in one direction is problematic. Most\ncumulative metrics have this feature.\n\nA measure that moves up or down with the health of the business is a valuable\nsignal â€“ both in terms of its level and its change (or rather rate of change).\n\nThat its level is X, instead of Y or Z, tells us something. That it grew by X%\nlast month also tells us something. That \"something\" is much more informative\nwhen X can move up or down and X% can be positive or negative.\n\nClassic examples include monthly revenue, paying users, monthly expenses per\nemployee, or annual profits.\n\nOn the other hand, total registered users â€“ people whoâ€™ve created an account for\na website or app but donâ€™t necessarily pay for it â€“ never declines unless users\nun-register themselves. This rarely happens.\n\nIn practice, the registered user count grows and grows, with no regard to\nwhether the business is improving. Hence, both its level and its change provide\nlittle information.\n\nWaitlists are functionally similar. They exist to signal attractiveness to third\nparties but are completely manipulable.\n\nThe size of a waitlist never declines unless you want it to. The outflow is\nentirely in your control.\n\nIf you never want your waitlist to shorten, stop accepting new users off the\nwaitlist. Mission complete.\n\nAs such, waitlists are mostly a rebrand of \"cumulative registered users\".\n\nHaving a long waitlist sounds cool, but a waitlist alone is little more than a\nlist of opt-in email addresses saved in a CSV file on your desktop or, better\nyet, â€œin the cloudâ€ somewhere.\n\nA true business imposes costs on its customers and delivers value in return\n> The cost customers willfully bear to interact with your business implies value\ndelivered. Those costs historically came in the form of dollars but increasingly\ntake the form of attention or time.\n\n\nIf a customer isnâ€™t giving you their money, attention, or time, theyâ€™re not a\ncustomer.\n\nYou can call them registered users, opt-ins, friendly acquaintances â€“ it doesnâ€™t\nreally matter.\n\nBut theyâ€™re not customers.\n\nAdding oneself to a digital waitlist imposes almost no cost. If anything, itâ€™s a\nfree option â€“ maybe Iâ€™ll sign up once the service is available, maybe I wonâ€™t.\n\nWhen a human being accepts a free option, we call that person â€œrationalâ€. We\ndonâ€™t call them a â€œcustomerâ€.\n\nLike selling dollars for 75 cents, there is no signal in handing out free\noptions.\n\nFlaunting the length of your waitlist is like bragging about raising $10M from\ninvestors with no plans to do anything with the money. This is why bankers\nsubtract cash from equity value when calculating enterprise value â€“ quite\nliterally, how much your business is worth.\n\nIn the preceding example, your equity value might be $10M, but your enterprise\nvalue would be a flat $0. Youâ€™ve delivered zero additional value to your\ninvestors.\n\nAdding 10,000 people to your waitlist but not doing anything with those users is\nsimilarly worthless.\n\nHow to make your waitlist valuable\nI know what youâ€™re thinking â€“ â€œbut what if Iâ€™mâ€¦\"\n\n * Fundraising and want to give investors every possible reason to write a check\n * A fledgling startup without many options for measuring progress\n * Bored and just like staring at numbers (guilty as charged)\n\nNot all is lost â€“ paired with other metrics waitlists can in fact be a signal of\nbusiness value.\n\n * Example: the proportion of people taken off the waitlist who subscribe or\n   purchase the product\n\nThis provides some directional sense of future value â€“ if we let X people off\nthe waitlist weâ€™ll gain Y customers. That Y/X ratio is a conversion rate.\n\nWho knows if that conversion rate will hold across the entire waitlist â€“ it\nprobably wonâ€™t â€“ but at least we know the waitlist has some value and isnâ€™t pure\nvanity.\n\n * Another example: charge people for reserving a spot in line like Tesla did\n   for the Model 3\n\nThat hundreds of thousands of people were willing to put down a deposit before\never touching, let alone driving, the car was a huge signal.\n\nThat spot in line was valuable to customers, and they manifested that value by\nforking over thousands of dollars years in advance of the launch. Investors,\ntoo, saw value, rewarding Tesla with a higher valuation.\n\nNotice a pattern? To make waitlists useful, link them to customer value.\n\nDonâ€™t wait\nThat slide in your pitch deck where you mention how large your waitlist is?\nUnless you can tie it to customer value, delete it.\n\nHeard about some hot startup with a waitlist 10X as long as yours? Ignore it.\n\nBy distancing yourself from the raucous noise of waitlists and other cumulative\nmeasures â€“ you refocus your attention on the true signal of entrepreneurial\nsuccess â€“ delivering value to customers.\n\nShip them a product. Provide them a service.\n\nBut please, donâ€™t just hand them a ticket with a number on it and call it a day\nâ€“ or a business.\n\nThis post has been published on www.productschool.com\n[https://www.productschool.com] communities.","feature_image":"__GHOST_URL__/content/images/2019/07/vanity-4.jpg","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2019-07-21T20:07:56.000Z","updated_at":"2019-12-03T13:49:17.000Z","published_at":"2019-07-28T19:33:48.000Z","custom_excerpt":"Waitlists, registered users, and other cumulative measures better measure the size of your pride than the size of your business","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5db52ef411e40f15bb24f9a0","uuid":"83e28215-2432-41ce-b774-23464169a570","title":"High Retention = High Volatility","slug":"high-retention-high-volatility","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"https://images.unsplash.com/photo-1535320903710-d993d3d77d29?ixlib=rb-1.2.1&q=80&fm=jpg&crop=entropy&cs=tinysrgb&w=2000&fit=max&ixid=eyJhcHBfaWQiOjExNzczfQ\",\"caption\":\"\",\"alt\":\"\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: High Retention = High Volatility\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2019/10/DraggedImage-1.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2019/10/DraggedImage-2.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2019/10/DraggedImage-3.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2019/10/image.png\",\"caption\":\"Source: <a href=\\\"https://www.linkedin.com/in/jonbma/\\\">Jon Ma</a> @ <a href=\\\"https://www.publiccomps.com/\\\">Public Comps</a>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2019/10/DraggedImage-4.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2019/10/DraggedImage-5.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2019/11/image-1.png\"}],[\"hr\",{}],[\"embed\",{\"url\":\"https://twitter.com/whoisnnamdi/status/1191487947528269827\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">With great retention... comes great volatility ðŸ’£<br><br>Volatility increases as SaaS revenue retention improves ðŸ“ˆ<br><br>Retention is therefore a double-edge sword âš”ï¸<br><br>How and why companies with strong revenue retention see the greatest volatility ðŸ“‰:<a href=\\\"https://t.co/RIPIjngWPs\\\">https://t.co/RIPIjngWPs</a></p>&mdash; Nnamdi Iregbulem (@whoisnnamdi) <a href=\\\"https://twitter.com/whoisnnamdi/status/1191487947528269827?ref_src=twsrc%5Etfw\\\">November 4, 2019</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: High Retention = High Volatility\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[[\"em\"],[\"strong\"],[\"a\",[\"href\",\"https://www.investopedia.com/terms/p/presentvalue.asp\"]],[\"a\",[\"href\",\"https://www.thebalance.com/why-do-bond-prices-and-yields-move-in-opposite-directions-417082\"]],[\"a\",[\"href\",\"https://hbr.org/2015/04/a-refresher-on-cost-of-capital\"]],[\"a\",[\"href\",\"https://www.blackrock.com/us/individual/education/understanding-duration\"]],[\"a\",[\"href\",\"__GHOST_URL__/you-dont-understand-compound-growth/\"]],[\"a\",[\"href\",\"https://theconversation.com/fallout-from-weworks-failed-ipo-shows-the-folly-of-excessive-valuations-125014\"]],[\"a\",[\"href\",\"https://www.wsj.com/articles/fed-cuts-rates-by-quarter-point-11572458556\"]]],\"sections\":[[1,\"blockquote\",[[0,[],0,\"\\\"With great retention comes great volatility\\\" â€“ Uncle Ben in Spiderman\"]]],[1,\"p\",[[0,[],0,\"OK â€“ that's not \"],[0,[0],1,\"exactly\"],[0,[],0,\" what Uncle Ben said, but it makes an important point: \"],[0,[1],1,\"retention is a double-edged sword.\"]]],[1,\"p\",[[0,[],0,\"Higher retention means customers stick around and pay you longer. Customers paying you more over time is even better.\"]]],[1,\"p\",[[0,[],0,\"Improving retention increases the value of your business, all else equal.\"]]],[1,\"p\",[[0,[],0,\"However, \"],[0,[1],1,\"higher retention also drives higher valuation volatility.\"]]],[1,\"p\",[[0,[],0,\"The reason is clear to anyone whoâ€™s ever traded bonds.\"]]],[1,\"h2\",[[0,[],0,\"Cohort Math = Bond Math\"]]],[10,0],[1,\"p\",[[0,[],0,\"A cohort of customers can be likened to financial security â€“ a bond paying you some amount periodically, perhaps indefinitely.\"]]],[1,\"p\",[[0,[],0,\"This â€œinterest rateâ€ fluctuates â€“ it changes over time. Some customers cancel, churning out, and others maintain or even increase the size of their subscription, paying more over time. Positive churn implies these payments decline over time, while negative churn implies the opposite.\"]]],[1,\"p\",[[0,[],0,\"A bond has some value associated with it, which is roughly equal to the \"],[0,[2],1,\"present discounted value\"],[0,[],0,\" of all the future payments from the bond.\"]]],[1,\"p\",[[0,[],0,\"This value \"],[0,[3],1,\"varies inversely\"],[0,[],0,\" with the effective interest rate or yield of the bond. Similarly the value of a stream of cash flows varies inversely with the discount rate applied, or in the case of a company, its \"],[0,[4],1,\"cost of capital\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"This sensitivity to interest rates increases with the tenure of the bond. In others words, the value of a 30-year bond is more sensitive to interest rates than that of a 10-year bond.\"]]],[1,\"p\",[[0,[],0,\"In finance, this concept is called \"],[0,[5,1],2,\"duration\"],[0,[],0,\". Duration measures the sensitivity of the value of a bond to a change in interest rates, which is tied to the lifetime of the bond. Bonds with longer tenure or back-loaded cash flows are more sensitive to changes in interest rates.\"]]],[1,\"p\",[[0,[],0,\"Due to the \"],[0,[6],1,\"multiplicative nature\"],[0,[],0,\" of discounting, the present value of far-away payments is more sensitive to a change in interest rates than the value of soon-to-come payments.\"]]],[1,\"p\",[[0,[],0,\"This is exactly the situation companies with high retention face.\"]]],[10,1],[1,\"h2\",[[0,[],0,\"Cohort Lifetime = Bond Duration\"]]],[1,\"p\",[[0,[1],1,\"With higher retention, more and more of the value of an acquired customer comes from its later years of life.\"],[0,[],0,\" \"]]],[1,\"p\",[[0,[],0,\"Again, the present value of these later years is more sensitive to changes in the discount rate applied to the cash flows, due to the \"],[0,[6],1,\"compounding of discounting\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Since all companies are on some level simply a collection of various customer cohorts with variable and fixed costs layered on, the summed value of the individual cohorts determines the overall company's valuation.\"]]],[1,\"p\",[[0,[],0,\"Hence, the better your retention, the more sensitive and volatile your valuation is to changes in your discount rate or cost of capital. This contrasts with a high-churn company where customers last only a few months or years.\"]]],[1,\"p\",[[0,[1],1,\"Letâ€™s break out the spreadsheet and prove this to ourselves:\"]]],[3,\"ul\",[[[0,[],0,\"Imagine we acquire a cohort of customers who pay an annual amount growing or contracting at some constant yearly rate, which represents our revenue retention\"]],[[0,[],0,\"Letâ€™s assume this expansion or contraction continues for 10 years, after which the revenue collected flattens out\"]],[[0,[],0,\"Lastly, we assume some discount rate or cost of capital, which we will use to discount the value of those payments back to the present\"]]]],[10,2],[1,\"p\",[[0,[],0,\"Now we ask the question: assuming a base discount rate of 10%, how would an increase to 15% or 20% impact the present value of the cohortâ€™s revenue stream?\"]]],[1,\"p\",[[0,[],0,\"The answer is quite dramatic:\"]]],[10,3],[1,\"p\",[[0,[1],1,\"For a company with strong net retention of 130% (-30% revenue churn), an increase in discount rate from 10 to 15% cuts the companyâ€™s valuation in half.\"]]],[1,\"p\",[[0,[],0,\"Notice how a company with 30% annual revenue churn only sees a 10% impact from a similar change in discount rate. This reflects the non-linear impact of the discount rate with respect to retention described earlier:\"]]],[10,4],[1,\"h2\",[[0,[],0,\"Theory â†’ Reality\"]]],[1,\"p\",[[0,[],0,\"Many SaaS companies have gone public this year with strong net retention metrics of 100%+.\"]]],[1,\"p\",[[0,[],0,\"In recent months, however, these same companies have seen their valuations tank, often without any meaningful changes in operational performance.\"]]],[10,5],[1,\"p\",[[0,[],0,\"While some point to this as an example of the â€œ\"],[0,[7],1,\"WeWork Effect\"],[0,[],0,\"â€, these business are so fundamentally different in both business models and business performance that WeWorkâ€™s troubles cannot possibly explain these haircuts.\"]]],[1,\"p\",[[0,[],0,\"Letâ€™s go a level deeper. If lower churn leads to higher volatility we should be able to see it in the data.\"]]],[1,\"p\",[[0,[],0,\"I assembled the following set of SaaS stocks, finding their latest revenue growth and net retention data, along with the price decline they saw from 9/21 to 10/21.\"]]],[10,6],[1,\"p\",[[0,[],0,\"If the theory is true, we should see companies with higher net revenue retention declined further in the recent valuation pullback.\"]]],[1,\"p\",[[0,[],0,\"Thatâ€™s exactly what we see:\"]]],[10,7],[1,\"p\",[[0,[1],1,\"Higher revenue retention, bigger valuation cut.\"],[0,[],0,\" On average, 10% higher retention lead to an additional 3.4% decline in price. The relationship is statistically significant at p < 0.05 (in case you were wondering), and the \\\"low\\\" R-squared of 0.36 simply means you can't explain all of the variation in or predict the level of price change using only this single variable, despite the strong relationship. Given public stock movements are notoriously difficult to predict, this is not surprising.\"]]],[1,\"p\",[[0,[],0,\"And for good measure, if we decompose overall growth and examine the component reflecting only the addition of new customers (1 + overall growth - net retention), we see little correlation with the recent movement in SaaS stocks:\"]]],[10,8],[1,\"h2\",[[0,[],0,\"Itâ€™s all about retention\"]]],[1,\"p\",[[0,[],0,\"Both in theory and in practice, \"],[0,[1],1,\"better retention drives higher volatility.\"]]],[1,\"p\",[[0,[],0,\"Why does this matter?\"]]],[1,\"p\",[[0,[],0,\"The Federal Reserve recently \"],[0,[8],1,\"cut interest rates\"],[0,[],0,\" for the third time this year.\"]]],[1,\"p\",[[0,[1],1,\"The era of low interest rates won't last.\"],[0,[],0,\" If interest rates or the cost of capital spike, SaaS valuations will necessarily decline.\"]]],[1,\"p\",[[0,[],0,\"Keep this is mind when evaluating high-flying SaaS investments or the value of your company's equity: \"],[0,[1],1,\"those with the best retention metrics will see the biggest drops.\"]]],[10,9],[1,\"p\",[[0,[],0,\"If you want to comment, like or share this post you can use this tweet:\"]]],[10,10],[10,11],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}","html":"<blockquote>\"With great retention comes great volatility\" â€“ Uncle Ben in Spiderman</blockquote><p>OK â€“ that's not <em>exactly</em> what Uncle Ben said, but it makes an important point: <strong>retention is a double-edged sword.</strong></p><p>Higher retention means customers stick around and pay you longer. Customers paying you more over time is even better.</p><p>Improving retention increases the value of your business, all else equal.</p><p>However, <strong>higher retention also drives higher valuation volatility.</strong></p><p>The reason is clear to anyone whoâ€™s ever traded bonds.</p><h2 id=\"cohort-math-bond-math\">Cohort Math = Bond Math</h2><figure class=\"kg-card kg-image-card\"><img src=\"https://images.unsplash.com/photo-1535320903710-d993d3d77d29?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>A cohort of customers can be likened to financial security â€“ a bond paying you some amount periodically, perhaps indefinitely.</p><p>This â€œinterest rateâ€ fluctuates â€“ it changes over time. Some customers cancel, churning out, and others maintain or even increase the size of their subscription, paying more over time. Positive churn implies these payments decline over time, while negative churn implies the opposite.</p><p>A bond has some value associated with it, which is roughly equal to the <a href=\"https://www.investopedia.com/terms/p/presentvalue.asp\">present discounted value</a> of all the future payments from the bond.</p><p>This value <a href=\"https://www.thebalance.com/why-do-bond-prices-and-yields-move-in-opposite-directions-417082\">varies inversely</a> with the effective interest rate or yield of the bond. Similarly the value of a stream of cash flows varies inversely with the discount rate applied, or in the case of a company, its <a href=\"https://hbr.org/2015/04/a-refresher-on-cost-of-capital\">cost of capital</a>.</p><p>This sensitivity to interest rates increases with the tenure of the bond. In others words, the value of a 30-year bond is more sensitive to interest rates than that of a 10-year bond.</p><p>In finance, this concept is called <a href=\"https://www.blackrock.com/us/individual/education/understanding-duration\"><strong>duration</strong></a>. Duration measures the sensitivity of the value of a bond to a change in interest rates, which is tied to the lifetime of the bond. Bonds with longer tenure or back-loaded cash flows are more sensitive to changes in interest rates.</p><p>Due to the <a href=\"__GHOST_URL__/you-dont-understand-compound-growth/\">multiplicative nature</a> of discounting, the present value of far-away payments is more sensitive to a change in interest rates than the value of soon-to-come payments.</p><p>This is exactly the situation companies with high retention face.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: High Retention = High Volatility\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: html--><h2 id=\"cohort-lifetime-bond-duration\">Cohort Lifetime = Bond Duration</h2><p><strong>With higher retention, more and more of the value of an acquired customer comes from its later years of life.</strong> </p><p>Again, the present value of these later years is more sensitive to changes in the discount rate applied to the cash flows, due to the <a href=\"__GHOST_URL__/you-dont-understand-compound-growth/\">compounding of discounting</a>.</p><p>Since all companies are on some level simply a collection of various customer cohorts with variable and fixed costs layered on, the summed value of the individual cohorts determines the overall company's valuation.</p><p>Hence, the better your retention, the more sensitive and volatile your valuation is to changes in your discount rate or cost of capital. This contrasts with a high-churn company where customers last only a few months or years.</p><p><strong>Letâ€™s break out the spreadsheet and prove this to ourselves:</strong></p><ul><li>Imagine we acquire a cohort of customers who pay an annual amount growing or contracting at some constant yearly rate, which represents our revenue retention</li><li>Letâ€™s assume this expansion or contraction continues for 10 years, after which the revenue collected flattens out</li><li>Lastly, we assume some discount rate or cost of capital, which we will use to discount the value of those payments back to the present</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2019/10/DraggedImage-1.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Now we ask the question: assuming a base discount rate of 10%, how would an increase to 15% or 20% impact the present value of the cohortâ€™s revenue stream?</p><p>The answer is quite dramatic:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2019/10/DraggedImage-2.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p><strong>For a company with strong net retention of 130% (-30% revenue churn), an increase in discount rate from 10 to 15% cuts the companyâ€™s valuation in half.</strong></p><p>Notice how a company with 30% annual revenue churn only sees a 10% impact from a similar change in discount rate. This reflects the non-linear impact of the discount rate with respect to retention described earlier:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2019/10/DraggedImage-3.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><h2 id=\"theory-reality\">Theory â†’ Reality</h2><p>Many SaaS companies have gone public this year with strong net retention metrics of 100%+.</p><p>In recent months, however, these same companies have seen their valuations tank, often without any meaningful changes in operational performance.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2019/10/image.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>Source: <a href=\"https://www.linkedin.com/in/jonbma/\">Jon Ma</a> @ <a href=\"https://www.publiccomps.com/\">Public Comps</a></figcaption></figure><p>While some point to this as an example of the â€œ<a href=\"https://theconversation.com/fallout-from-weworks-failed-ipo-shows-the-folly-of-excessive-valuations-125014\">WeWork Effect</a>â€, these business are so fundamentally different in both business models and business performance that WeWorkâ€™s troubles cannot possibly explain these haircuts.</p><p>Letâ€™s go a level deeper. If lower churn leads to higher volatility we should be able to see it in the data.</p><p>I assembled the following set of SaaS stocks, finding their latest revenue growth and net retention data, along with the price decline they saw from 9/21 to 10/21.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2019/10/DraggedImage-4.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>If the theory is true, we should see companies with higher net revenue retention declined further in the recent valuation pullback.</p><p>Thatâ€™s exactly what we see:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2019/10/DraggedImage-5.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p><strong>Higher revenue retention, bigger valuation cut.</strong> On average, 10% higher retention lead to an additional 3.4% decline in price. The relationship is statistically significant at p &lt; 0.05 (in case you were wondering), and the \"low\" R-squared of 0.36 simply means you can't explain all of the variation in or predict the level of price change using only this single variable, despite the strong relationship. Given public stock movements are notoriously difficult to predict, this is not surprising.</p><p>And for good measure, if we decompose overall growth and examine the component reflecting only the addition of new customers (1 + overall growth - net retention), we see little correlation with the recent movement in SaaS stocks:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2019/11/image-1.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><h2 id=\"it-s-all-about-retention\">Itâ€™s all about retention</h2><p>Both in theory and in practice, <strong>better retention drives higher volatility.</strong></p><p>Why does this matter?</p><p>The Federal Reserve recently <a href=\"https://www.wsj.com/articles/fed-cuts-rates-by-quarter-point-11572458556\">cut interest rates</a> for the third time this year.</p><p><strong>The era of low interest rates won't last.</strong> If interest rates or the cost of capital spike, SaaS valuations will necessarily decline.</p><p>Keep this is mind when evaluating high-flying SaaS investments or the value of your company's equity: <strong>those with the best retention metrics will see the biggest drops.</strong></p><hr><p>If you want to comment, like or share this post you can use this tweet:</p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">With great retention... comes great volatility ðŸ’£<br><br>Volatility increases as SaaS revenue retention improves ðŸ“ˆ<br><br>Retention is therefore a double-edge sword âš”ï¸<br><br>How and why companies with strong revenue retention see the greatest volatility ðŸ“‰:<a href=\"https://t.co/RIPIjngWPs\">https://t.co/RIPIjngWPs</a></p>&mdash; Nnamdi Iregbulem (@whoisnnamdi) <a href=\"https://twitter.com/whoisnnamdi/status/1191487947528269827?ref_src=twsrc%5Etfw\">November 4, 2019</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><!--kg-card-begin: html--><section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: High Retention = High Volatility\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: html-->","comment_id":"5db52ef411e40f15bb24f9a0","plaintext":"> \"With great retention comes great volatility\" â€“ Uncle Ben in Spiderman\nOK â€“ that's not exactly what Uncle Ben said, but it makes an important point: \nretention is a double-edged sword.\n\nHigher retention means customers stick around and pay you longer. Customers\npaying you more over time is even better.\n\nImproving retention increases the value of your business, all else equal.\n\nHowever, higher retention also drives higher valuation volatility.\n\nThe reason is clear to anyone whoâ€™s ever traded bonds.\n\nCohort Math = Bond Math\nA cohort of customers can be likened to financial security â€“ a bond paying you\nsome amount periodically, perhaps indefinitely.\n\nThis â€œinterest rateâ€ fluctuates â€“ it changes over time. Some customers cancel,\nchurning out, and others maintain or even increase the size of their\nsubscription, paying more over time. Positive churn implies these payments\ndecline over time, while negative churn implies the opposite.\n\nA bond has some value associated with it, which is roughly equal to the present\ndiscounted value [https://www.investopedia.com/terms/p/presentvalue.asp] of all\nthe future payments from the bond.\n\nThis value varies inversely\n[https://www.thebalance.com/why-do-bond-prices-and-yields-move-in-opposite-directions-417082] \nwith the effective interest rate or yield of the bond. Similarly the value of a\nstream of cash flows varies inversely with the discount rate applied, or in the\ncase of a company, its cost of capital\n[https://hbr.org/2015/04/a-refresher-on-cost-of-capital].\n\nThis sensitivity to interest rates increases with the tenure of the bond. In\nothers words, the value of a 30-year bond is more sensitive to interest rates\nthan that of a 10-year bond.\n\nIn finance, this concept is called duration\n[https://www.blackrock.com/us/individual/education/understanding-duration].\nDuration measures the sensitivity of the value of a bond to a change in interest\nrates, which is tied to the lifetime of the bond. Bonds with longer tenure or\nback-loaded cash flows are more sensitive to changes in interest rates.\n\nDue to the multiplicative nature\n[https://nnamdi.net/you-dont-understand-compound-growth/] of discounting, the\npresent value of far-away payments is more sensitive to a change in interest\nrates than the value of soon-to-come payments.\n\nThis is exactly the situation companies with high retention face.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Cohort Lifetime = Bond Duration\nWith higher retention, more and more of the value of an acquired customer comes\nfrom its later years of life. \n\nAgain, the present value of these later years is more sensitive to changes in\nthe discount rate applied to the cash flows, due to the compounding of\ndiscounting [__GHOST_URL__/you-dont-understand-compound-growth/].\n\nSince all companies are on some level simply a collection of various customer\ncohorts with variable and fixed costs layered on, the summed value of the\nindividual cohorts determines the overall company's valuation.\n\nHence, the better your retention, the more sensitive and volatile your valuation\nis to changes in your discount rate or cost of capital. This contrasts with a\nhigh-churn company where customers last only a few months or years.\n\nLetâ€™s break out the spreadsheet and prove this to ourselves:\n\n * Imagine we acquire a cohort of customers who pay an annual amount growing or\n   contracting at some constant yearly rate, which represents our revenue\n   retention\n * Letâ€™s assume this expansion or contraction continues for 10 years, after\n   which the revenue collected flattens out\n * Lastly, we assume some discount rate or cost of capital, which we will use to\n   discount the value of those payments back to the present\n\nNow we ask the question: assuming a base discount rate of 10%, how would an\nincrease to 15% or 20% impact the present value of the cohortâ€™s revenue stream?\n\nThe answer is quite dramatic:\n\nFor a company with strong net retention of 130% (-30% revenue churn), an\nincrease in discount rate from 10 to 15% cuts the companyâ€™s valuation in half.\n\nNotice how a company with 30% annual revenue churn only sees a 10% impact from a\nsimilar change in discount rate. This reflects the non-linear impact of the\ndiscount rate with respect to retention described earlier:\n\nTheory â†’ Reality\nMany SaaS companies have gone public this year with strong net retention metrics\nof 100%+.\n\nIn recent months, however, these same companies have seen their valuations tank,\noften without any meaningful changes in operational performance.\n\nSource: Jon Ma [https://www.linkedin.com/in/jonbma/] @ Public Comps\n[https://www.publiccomps.com/]While some point to this as an example of the â€œWeWork Effect\n[https://theconversation.com/fallout-from-weworks-failed-ipo-shows-the-folly-of-excessive-valuations-125014]\nâ€, these business are so fundamentally different in both business models and\nbusiness performance that WeWorkâ€™s troubles cannot possibly explain these\nhaircuts.\n\nLetâ€™s go a level deeper. If lower churn leads to higher volatility we should be\nable to see it in the data.\n\nI assembled the following set of SaaS stocks, finding their latest revenue\ngrowth and net retention data, along with the price decline they saw from 9/21\nto 10/21.\n\nIf the theory is true, we should see companies with higher net revenue retention\ndeclined further in the recent valuation pullback.\n\nThatâ€™s exactly what we see:\n\nHigher revenue retention, bigger valuation cut. On average, 10% higher retention\nlead to an additional 3.4% decline in price. The relationship is statistically\nsignificant at p < 0.05 (in case you were wondering), and the \"low\" R-squared of\n0.36 simply means you can't explain all of the variation in or predict the level\nof price change using only this single variable, despite the strong\nrelationship. Given public stock movements are notoriously difficult to predict,\nthis is not surprising.\n\nAnd for good measure, if we decompose overall growth and examine the component\nreflecting only the addition of new customers (1 + overall growth - net\nretention), we see little correlation with the recent movement in SaaS stocks:\n\nItâ€™s all about retention\nBoth in theory and in practice, better retention drives higher volatility.\n\nWhy does this matter?\n\nThe Federal Reserve recently cut interest rates\n[https://www.wsj.com/articles/fed-cuts-rates-by-quarter-point-11572458556] for\nthe third time this year.\n\nThe era of low interest rates won't last. If interest rates or the cost of\ncapital spike, SaaS valuations will necessarily decline.\n\nKeep this is mind when evaluating high-flying SaaS investments or the value of\nyour company's equity: those with the best retention metrics will see the\nbiggest drops.\n\n\n--------------------------------------------------------------------------------\n\nIf you want to comment, like or share this post you can use this tweet:\n\n> With great retention... comes great volatility ðŸ’£\n\nVolatility increases as SaaS revenue retention improves ðŸ“ˆ\n\nRetention is therefore a double-edge sword âš”ï¸\n\nHow and why companies with strong revenue retention see the greatest volatility\nðŸ“‰:https://t.co/RIPIjngWPs\n\nâ€” Nnamdi Iregbulem (@whoisnnamdi) November 4, 2019\n[https://twitter.com/whoisnnamdi/status/1191487947528269827?ref_src=twsrc%5Etfw]\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2019/10/volatility.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2019-10-27T05:45:24.000Z","updated_at":"2022-01-24T17:58:24.000Z","published_at":"2019-11-04T18:39:50.000Z","custom_excerpt":"Why SaaS revenue retention is a double-edge sword","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5de426f9b468c5277c1750fe","uuid":"90d79f61-75d7-483b-8277-c02e1c0b38a1","title":"Pattern Matching is Dead. Long Live People Matching","slug":"people-matching","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"/content/images/2019/12/see-2.jpg\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"embed\",{\"url\":\"https://twitter.com/bwertz/status/1163885146048569344\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">VC&#39;s have always relied on the strength of their networks for dealflow.<br><br>As an increasing number of founders come from more diverse backgrounds, VC&#39;s will have to change to stay relevant.<br><br>More diverse partnerships, more openness towards cold emails, less pattern matching.</p>&mdash; Boris Wertz (@bwertz) <a href=\\\"https://twitter.com/bwertz/status/1163885146048569344?ref_src=twsrc%5Etfw\\\">August 20, 2019</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive my next thought in your inbox</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"I email every few months\\\" id=\\\"mce-EMAIL\\\" required>\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span>Go âš¡</span></button>\\n</form>\\n</section>\"}],[\"image\",{\"src\":\"/content/images/2019/12/analyze-2.jpg\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2019/12/demand-shift-2.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"embed\",{\"url\":\"https://twitter.com/bradfordcross/status/1043351318566293504\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">VC pattern matching and startup folklore are the path to mediocrity. Focus on commercial success and let data tell the story. Youâ€™ll be the next pattern people try to match. <a href=\\\"https://t.co/ggDZJmJWbV\\\">https://t.co/ggDZJmJWbV</a></p>&mdash; bradford cross (@bradfordcross) <a href=\\\"https://twitter.com/bradfordcross/status/1043351318566293504?ref_src=twsrc%5Etfw\\\">September 22, 2018</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\"}],[\"image\",{\"src\":\"/content/images/2019/12/win-2.jpg\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"embed\",{\"url\":\"https://twitter.com/briannekimmel/status/1201966954090655744\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">Talking to 43+ funds is a massive waste of time of everyoneâ€™s time <br><br>Now that access is completely commoditized, closing is the most valuable skill<br><br>Founders, find your lead first to remove noise &amp; get back to work<br><br>If itâ€™s unclear what value a participating firm offers, move on. <a href=\\\"https://t.co/o4zbodpENL\\\">https://t.co/o4zbodpENL</a></p>&mdash; Brianne Kimmel (@briannekimmel) <a href=\\\"https://twitter.com/briannekimmel/status/1201966954090655744?ref_src=twsrc%5Etfw\\\">December 3, 2019</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\"}],[\"embed\",{\"url\":\"https://twitter.com/paulbz/status/1196914235059691521\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">Pushing to win an investment I really want. Might lose it.<br><br>Founder in driver&#39;s seat. Some investors complain, I love it. Some call this a bubble, but everyone is being rational.<br><br>Founder/investor dynamic is reaching equilibrium and this is how it should be.</p>&mdash; Paul Murphy (@paulbz) <a href=\\\"https://twitter.com/paulbz/status/1196914235059691521?ref_src=twsrc%5Etfw\\\">November 19, 2019</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\"}]],\"markups\":[[\"strong\"],[\"em\"],[\"a\",[\"href\",\"https://www.fool.com/investing/general/2014/02/20/whats-in-your-anti-portfolio.aspx\"]],[\"a\",[\"href\",\"https://www.bizjournals.com/seattle/blog/techflash/2016/03/how-pattern-matching-by-investors-puts-female.html\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Rivalry_(economics)\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"An investor once shared with me a simple framework for the fundamental skills of venture capital:\"]]],[3,\"ul\",[[[0,[],0,\"ðŸ‘ See (the deal)\"]],[[0,[],0,\"ðŸ§  Analyze (the deal)\"]],[[0,[],0,\"â¤ï¸ Win (the deal)\"]]]],[1,\"p\",[[0,[],0,\"Success in VC demands all three. But that doesnâ€™t mean they're equally important.\"]]],[1,\"h2\",[[0,[],0,\"ðŸ‘ Out of sight, out of mind\"]]],[10,0],[1,\"p\",[[0,[],0,\"You canâ€™t analyze a deal you can't see. You also canâ€™t win a deal you can't see.\"]]],[1,\"p\",[[0,[],0,\"â€œSeeing the deal,â€ also referred to as â€œdeal flow,â€ continues to be an important differentiator between the best funds and the rest of the pack.\"]]],[1,\"p\",[[0,[],0,\"Networks and access are a potent currency in Silicon Valley. As I like to say: \"],[0,[0],1,\"you can be the smartest person in the room, but if you arenâ€™t even in the room, it doesnâ€™t matter.\"]]],[1,\"p\",[[0,[],0,\"As such, VC firms want to know about every deal being done, \"],[0,[1],1,\"even if they have little interest in doing the deal\"],[0,[],0,\". They want the option to say no. As in many domains, that optionality is incredibly valuable.\"]]],[1,\"p\",[[0,[],0,\"But simple awareness of a fundraise does not do much for you as a VC. These days, itâ€™s often common knowledge that a particular company is fundraising.\"]]],[1,\"p\",[[0,[],0,\"Even if you know a deal is going down, thereâ€™s no guarantee you will be able to insert yourself into the consideration set of potential partners. Iâ€™ve had entrepreneurs directly deny to me they were fundraising when they in fact were, only to admit it after the fundraise announced shortly thereafter.\"]]],[1,\"p\",[[0,[],0,\"The concept of an â€œ\"],[0,[2],1,\"anti-portfolio\"],[0,[],0,\"â€ proves that even if you see a deal you can still drop the ball.\"]]],[1,\"p\",[[0,[],0,\"Many VCs â€œsawâ€ the Facebook deal. Many VCs â€œsawâ€ the Google deal. And yet they missed the most explosive growth companies the world has ever seen.\"]]],[1,\"p\",[[0,[0],1,\"â€œSeeingâ€ is necessary but not sufficient.\"]]],[10,1],[1,\"p\",[[0,[],0,\"I donâ€™t mean to deny or discount the value of deal flow. Deal flow is a valuable resource, but itâ€™s exactly that â€” a resource. A resource must be extracted, enriched, and processed. Converting that resource into useful energy requires investment and effort. Otherwise, it remains inert.\"]]],[10,2],[1,\"h2\",[[0,[],0,\"ðŸ§  Signal in the noise\"]]],[10,3],[1,\"p\",[[0,[],0,\"Venture capitalists often talk about â€œpattern matching.â€ After years of investing and watching startups succeed or fail, VCs supposedly develop a keen sense of what drives success, detecting signals in the noise. These signals can take many forms, but the important claims are:\"]]],[3,\"ul\",[[[0,[],0,\"Patterns exist\"]],[[0,[],0,\"Patterns are discoverable\"]],[[0,[],0,\"Patterns are valuable\"]]]],[1,\"p\",[[0,[],0,\"Pattern matching epitomizes the â€œanalyzeâ€ skill.\"]]],[1,\"p\",[[0,[],0,\"There are three issues with basing your competitive advantage on pattern matching.\"]]],[1,\"p\",[[0,[],0,\"First, pattern matching is rarely differentiated. The important metrics and signs of traction are well-known these days. Increasingly, the â€œgoodâ€ founders are obvious â€” those with the best pedigrees or past successes.\"]]],[1,\"p\",[[0,[],0,\"Like in public equities, obvious patterns are priced in. If itâ€™s not priced in â€” most often â€” itâ€™s not a real pattern.\"]]],[1,\"p\",[[0,[],0,\"This dilutes the value of pattern matching. Suddenly, the well-worn patterns VCs rely on so heavily begin to work against them:\"]]],[3,\"ul\",[[[0,[],0,\"The founderâ€™s a Stanford grad? Everyone knows that, it will get priced in.\"]],[[0,[],0,\"Previously a Google product manager? Yep, the valuation will reflect that.\"]],[[0,[],0,\"Big, fragmented market ripe for consolidation? You bet the final valuation will incorporate this.\"]]]],[10,4],[1,\"p\",[[0,[],0,\"In a competitive environment, patterns carry the seeds of their own impotence.\"]]],[1,\"p\",[[0,[],0,\"Second, itâ€™s not at all obvious that pattern matching even helps much at the earliest stage. The drivers of success are indeterminate, and stories abound about ideas that seemed dumb at first but became winners. In some cases, even the VCs who funded the best companies had serious doubts going in.\"]]],[1,\"p\",[[0,[],0,\"If even the â€œsmartest guys in the roomâ€ are not \"],[0,[1],1,\"that smart\"],[0,[],0,\", we know we have a problem.\"]]],[10,5],[1,\"p\",[[0,[],0,\"Third, this all assumes the patterns are \"],[0,[1],1,\"correct\"],[0,[],0,\" â€” that they contain some useful information.\"]]],[1,\"p\",[[0,[1],1,\"This too is suspect.\"]]],[1,\"p\",[[0,[],0,\"Data in VC is notoriously spotty, unreliable, and often unavailable entirely. Tying cause to effect is quite difficult, and success or failure is often over-determined.\"]]],[1,\"p\",[[0,[],0,\"In this environment, our natural tendency as humans is to fall back on heuristics. Some of these are helpful, but many are problematic.\"]]],[1,\"p\",[[0,[],0,\"Another word for a problematic heuristic is \"],[0,[0],1,\"bias\"],[0,[],0,\".\"]]],[1,\"blockquote\",[[0,[1],0,\"\\\"Thereâ€™s quite substantial unconscious bias that most of my male investment colleagues donâ€™t see, where if a guy looks and smells the part with the pattern matching, (he) just (gets) such a break\\\" â€“ Linden Rhoads, General Manager of the W Fund (\"],[0,[3],1,\"Source\"],[0,[],1,\")\"]]],[1,\"p\",[[0,[],0,\"â€œPattern matchingâ€ seems increasingly tenuous. Either itâ€™s easy and reliable, in which case it gets priced in, or itâ€™s difficult to execute on in practice, making it easy to fool oneself into believing non-existent patterns, almost superstitiously.\"]]],[1,\"p\",[[0,[],0,\"Either way, itâ€™s fraught.\"]]],[1,\"h2\",[[0,[],0,\"â¤ï¸ All I do is win\"]]],[10,6],[1,\"p\",[[0,[],0,\"Venture capital is a match making service.\"]]],[1,\"p\",[[0,[],0,\"Winning in modern venture investing fundamentally concerns what I call \"],[0,[0],1,\"â€œpeople matchingâ€\"],[0,[],0,\" â€” bringing together the right combination of founders and investors to partner on a particular startup or idea.\"]]],[1,\"p\",[[0,[],0,\"Itâ€™s about the people, not the capital. Yes, capital is also matched or allocated to specific startups, but this function is being commoditized.\"]]],[1,\"p\",[[0,[],0,\"Showing up with a checkbook today is no longer cool or particularly notable.\"]]],[1,\"p\",[[0,[0],1,\"Not all funds can show up with the right partner\"],[0,[],0,\", however. A partner the entrepreneur wants to work with. Someone who will make both the founder and the startup better by their presence and involvement.\"]]],[1,\"p\",[[0,[],0,\"In this sense, the coveted â€œpartnerâ€ title is actually quite fitting.\"]]],[1,\"p\",[[0,[0],1,\"Partners partner.\"]]],[1,\"p\",[[0,[],0,\"In this model, venture capital firms are less allocators of capital â€” which is currently cheap, plentiful, and most importantly, homogeneous â€” and more \"],[0,[0],1,\"allocators of people\"],[0,[],0,\", who remain differentiated even in this hot house environment.\"]]],[1,\"p\",[[0,[],0,\"People are the truly limited and differentiated resource of VC firms. General Partners seek to maximize the capacity of the fund to generate returns for its Limited Partners, but ironically, \"],[0,[0],1,\"it is the General Partners who are â€œlimitedâ€\"],[0,[],0,\" â€” thereâ€™s only so many of them, and they must be deployed judiciously. And with all the capital flowing around these days, Limited Partners are increasingly \"],[0,[1],1,\"unlimited\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Unlike a publicly traded company, which can effectively absorb any amount of capital the market could realistically desire to invest, with prices regulating this flow, the typical startup cannot and does not want to take on every possible dollar from every willing investor. The best deals are often oversubscribed multiple times over. Financing rounds are \"],[0,[4],1,\"rivalrous\"],[0,[],0,\" â€” \"],[0,[0],1,\"we canâ€™t all do the deal.\"]]],[1,\"p\",[[0,[],0,\"The VC who can most quickly convince a founder that they are the right person to partner with will win the deal. And by winning the deal, others, by definition, lose the deal.\"]]],[10,7],[1,\"p\",[[0,[],0,\"Winning is therefore the fulcrum upon which success in venture turns. Two comparable firms can both see the deal, analyze the deal â€œcorrectlyâ€, and yet only one may win the deal in the end. The firm that does a better job of \"],[0,[0],1,\"people matching\"],[0,[],0,\" will, in the end, triumph.\"]]],[1,\"p\",[[0,[],0,\"This is why winning matters so much.\"]]],[1,\"h2\",[[0,[],0,\"ðŸ‘¥ More skin in a new game\"]]],[1,\"p\",[[0,[],0,\"Venture capital is evolving from a game of picking winners to a game of \"],[0,[1],1,\"being picked by winners\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Authentic relationships and credible ability to add value matter more than ever.\"]]],[1,\"p\",[[0,[],0,\"Venture capital is no longer where one goes to retire quietly after an illustrious operating career. Itâ€™s where one goes to \"],[0,[1],1,\"hustle\"],[0,[],0,\".\"]]],[10,8],[1,\"p\",[[0,[],0,\"I think this is a positive trend, encouraging deeper empathy between investors and founders. If anything, bringing VCs down a peg might humanize them â€” the gilded kings and queens of Silicon Valley become the humble servants of entrepreneurs.\"]]],[1,\"p\",[[0,[],0,\"Thereâ€™s some moral justice in this. Iâ€™ve always been irked by the very different lives lived by founders and their investors:\"]]],[3,\"ul\",[[[0,[],0,\"One is concentrated, the other is diversified\"]],[[0,[],0,\"One is expected to fail, the other is expected to at least breakeven\"]],[[0,[],0,\"One is a beggar, the other is a chooser\"]]]],[1,\"p\",[[0,[],0,\"This is out of balance. Entrepreneurs hustle, \"],[0,[0],1,\"why shouldnâ€™t VCs?\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p>An investor once shared with me a simple framework for the fundamental skills of venture capital:</p><ul><li>ðŸ‘ See (the deal)</li><li>ðŸ§  Analyze (the deal)</li><li>â¤ï¸ Win (the deal)</li></ul><p>Success in VC demands all three. But that doesnâ€™t mean they're equally important.</p><h2 id=\"-out-of-sight-out-of-mind\">ðŸ‘ Out of sight, out of mind</h2><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2019/12/see-2.jpg\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>You canâ€™t analyze a deal you can't see. You also canâ€™t win a deal you can't see.</p><p>â€œSeeing the deal,â€ also referred to as â€œdeal flow,â€ continues to be an important differentiator between the best funds and the rest of the pack.</p><p>Networks and access are a potent currency in Silicon Valley. As I like to say: <strong>you can be the smartest person in the room, but if you arenâ€™t even in the room, it doesnâ€™t matter.</strong></p><p>As such, VC firms want to know about every deal being done, <em>even if they have little interest in doing the deal</em>. They want the option to say no. As in many domains, that optionality is incredibly valuable.</p><p>But simple awareness of a fundraise does not do much for you as a VC. These days, itâ€™s often common knowledge that a particular company is fundraising.</p><p>Even if you know a deal is going down, thereâ€™s no guarantee you will be able to insert yourself into the consideration set of potential partners. Iâ€™ve had entrepreneurs directly deny to me they were fundraising when they in fact were, only to admit it after the fundraise announced shortly thereafter.</p><p>The concept of an â€œ<a href=\"https://www.fool.com/investing/general/2014/02/20/whats-in-your-anti-portfolio.aspx\">anti-portfolio</a>â€ proves that even if you see a deal you can still drop the ball.</p><p>Many VCs â€œsawâ€ the Facebook deal. Many VCs â€œsawâ€ the Google deal. And yet they missed the most explosive growth companies the world has ever seen.</p><p><strong>â€œSeeingâ€ is necessary but not sufficient.</strong></p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">VC&#39;s have always relied on the strength of their networks for dealflow.<br><br>As an increasing number of founders come from more diverse backgrounds, VC&#39;s will have to change to stay relevant.<br><br>More diverse partnerships, more openness towards cold emails, less pattern matching.</p>&mdash; Boris Wertz (@bwertz) <a href=\"https://twitter.com/bwertz/status/1163885146048569344?ref_src=twsrc%5Etfw\">August 20, 2019</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><p>I donâ€™t mean to deny or discount the value of deal flow. Deal flow is a valuable resource, but itâ€™s exactly that â€” a resource. A resource must be extracted, enriched, and processed. Converting that resource into useful energy requires investment and effort. Otherwise, it remains inert.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive my next thought in your inbox</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"I email every few months\" id=\"mce-EMAIL\" required>\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span>Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: html--><h2 id=\"-signal-in-the-noise\">ðŸ§  Signal in the noise</h2><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2019/12/analyze-2.jpg\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Venture capitalists often talk about â€œpattern matching.â€ After years of investing and watching startups succeed or fail, VCs supposedly develop a keen sense of what drives success, detecting signals in the noise. These signals can take many forms, but the important claims are:</p><ul><li>Patterns exist</li><li>Patterns are discoverable</li><li>Patterns are valuable</li></ul><p>Pattern matching epitomizes the â€œanalyzeâ€ skill.</p><p>There are three issues with basing your competitive advantage on pattern matching.</p><p>First, pattern matching is rarely differentiated. The important metrics and signs of traction are well-known these days. Increasingly, the â€œgoodâ€ founders are obvious â€” those with the best pedigrees or past successes.</p><p>Like in public equities, obvious patterns are priced in. If itâ€™s not priced in â€” most often â€” itâ€™s not a real pattern.</p><p>This dilutes the value of pattern matching. Suddenly, the well-worn patterns VCs rely on so heavily begin to work against them:</p><ul><li>The founderâ€™s a Stanford grad? Everyone knows that, it will get priced in.</li><li>Previously a Google product manager? Yep, the valuation will reflect that.</li><li>Big, fragmented market ripe for consolidation? You bet the final valuation will incorporate this.</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2019/12/demand-shift-2.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>In a competitive environment, patterns carry the seeds of their own impotence.</p><p>Second, itâ€™s not at all obvious that pattern matching even helps much at the earliest stage. The drivers of success are indeterminate, and stories abound about ideas that seemed dumb at first but became winners. In some cases, even the VCs who funded the best companies had serious doubts going in.</p><p>If even the â€œsmartest guys in the roomâ€ are not <em>that smart</em>, we know we have a problem.</p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">VC pattern matching and startup folklore are the path to mediocrity. Focus on commercial success and let data tell the story. Youâ€™ll be the next pattern people try to match. <a href=\"https://t.co/ggDZJmJWbV\">https://t.co/ggDZJmJWbV</a></p>&mdash; bradford cross (@bradfordcross) <a href=\"https://twitter.com/bradfordcross/status/1043351318566293504?ref_src=twsrc%5Etfw\">September 22, 2018</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><p>Third, this all assumes the patterns are <em>correct</em> â€” that they contain some useful information.</p><p><em>This too is suspect.</em></p><p>Data in VC is notoriously spotty, unreliable, and often unavailable entirely. Tying cause to effect is quite difficult, and success or failure is often over-determined.</p><p>In this environment, our natural tendency as humans is to fall back on heuristics. Some of these are helpful, but many are problematic.</p><p>Another word for a problematic heuristic is <strong>bias</strong>.</p><blockquote><em>\"Thereâ€™s quite substantial unconscious bias that most of my male investment colleagues donâ€™t see, where if a guy looks and smells the part with the pattern matching, (he) just (gets) such a break\" â€“ Linden Rhoads, General Manager of the W Fund (<a href=\"https://www.bizjournals.com/seattle/blog/techflash/2016/03/how-pattern-matching-by-investors-puts-female.html\">Source</a>)</em></blockquote><p>â€œPattern matchingâ€ seems increasingly tenuous. Either itâ€™s easy and reliable, in which case it gets priced in, or itâ€™s difficult to execute on in practice, making it easy to fool oneself into believing non-existent patterns, almost superstitiously.</p><p>Either way, itâ€™s fraught.</p><h2 id=\"-all-i-do-is-win\">â¤ï¸ All I do is win</h2><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2019/12/win-2.jpg\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Venture capital is a match making service.</p><p>Winning in modern venture investing fundamentally concerns what I call <strong>â€œpeople matchingâ€</strong> â€” bringing together the right combination of founders and investors to partner on a particular startup or idea.</p><p>Itâ€™s about the people, not the capital. Yes, capital is also matched or allocated to specific startups, but this function is being commoditized.</p><p>Showing up with a checkbook today is no longer cool or particularly notable.</p><p><strong>Not all funds can show up with the right partner</strong>, however. A partner the entrepreneur wants to work with. Someone who will make both the founder and the startup better by their presence and involvement.</p><p>In this sense, the coveted â€œpartnerâ€ title is actually quite fitting.</p><p><strong>Partners partner.</strong></p><p>In this model, venture capital firms are less allocators of capital â€” which is currently cheap, plentiful, and most importantly, homogeneous â€” and more <strong>allocators of people</strong>, who remain differentiated even in this hot house environment.</p><p>People are the truly limited and differentiated resource of VC firms. General Partners seek to maximize the capacity of the fund to generate returns for its Limited Partners, but ironically, <strong>it is the General Partners who are â€œlimitedâ€</strong> â€” thereâ€™s only so many of them, and they must be deployed judiciously. And with all the capital flowing around these days, Limited Partners are increasingly <em>unlimited</em>.</p><p>Unlike a publicly traded company, which can effectively absorb any amount of capital the market could realistically desire to invest, with prices regulating this flow, the typical startup cannot and does not want to take on every possible dollar from every willing investor. The best deals are often oversubscribed multiple times over. Financing rounds are <a href=\"https://en.wikipedia.org/wiki/Rivalry_(economics)\">rivalrous</a> â€” <strong>we canâ€™t all do the deal.</strong></p><p>The VC who can most quickly convince a founder that they are the right person to partner with will win the deal. And by winning the deal, others, by definition, lose the deal.</p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Talking to 43+ funds is a massive waste of time of everyoneâ€™s time <br><br>Now that access is completely commoditized, closing is the most valuable skill<br><br>Founders, find your lead first to remove noise &amp; get back to work<br><br>If itâ€™s unclear what value a participating firm offers, move on. <a href=\"https://t.co/o4zbodpENL\">https://t.co/o4zbodpENL</a></p>&mdash; Brianne Kimmel (@briannekimmel) <a href=\"https://twitter.com/briannekimmel/status/1201966954090655744?ref_src=twsrc%5Etfw\">December 3, 2019</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><p>Winning is therefore the fulcrum upon which success in venture turns. Two comparable firms can both see the deal, analyze the deal â€œcorrectlyâ€, and yet only one may win the deal in the end. The firm that does a better job of <strong>people matching</strong> will, in the end, triumph.</p><p>This is why winning matters so much.</p><h2 id=\"-more-skin-in-a-new-game\">ðŸ‘¥ More skin in a new game</h2><p>Venture capital is evolving from a game of picking winners to a game of <em>being picked by winners</em>.</p><p>Authentic relationships and credible ability to add value matter more than ever.</p><p>Venture capital is no longer where one goes to retire quietly after an illustrious operating career. Itâ€™s where one goes to <em>hustle</em>.</p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Pushing to win an investment I really want. Might lose it.<br><br>Founder in driver&#39;s seat. Some investors complain, I love it. Some call this a bubble, but everyone is being rational.<br><br>Founder/investor dynamic is reaching equilibrium and this is how it should be.</p>&mdash; Paul Murphy (@paulbz) <a href=\"https://twitter.com/paulbz/status/1196914235059691521?ref_src=twsrc%5Etfw\">November 19, 2019</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><p>I think this is a positive trend, encouraging deeper empathy between investors and founders. If anything, bringing VCs down a peg might humanize them â€” the gilded kings and queens of Silicon Valley become the humble servants of entrepreneurs.</p><p>Thereâ€™s some moral justice in this. Iâ€™ve always been irked by the very different lives lived by founders and their investors:</p><ul><li>One is concentrated, the other is diversified</li><li>One is expected to fail, the other is expected to at least breakeven</li><li>One is a beggar, the other is a chooser</li></ul><p>This is out of balance. Entrepreneurs hustle, <strong>why shouldnâ€™t VCs?</strong></p>","comment_id":"5de426f9b468c5277c1750fe","plaintext":"An investor once shared with me a simple framework for the fundamental skills of\nventure capital:\n\n * ðŸ‘ See (the deal)\n * ðŸ§  Analyze (the deal)\n * â¤ï¸ Win (the deal)\n\nSuccess in VC demands all three. But that doesnâ€™t mean they're equally\nimportant.\n\nðŸ‘ Out of sight, out of mind\nYou canâ€™t analyze a deal you can't see. You also canâ€™t win a deal you can't see.\n\nâ€œSeeing the deal,â€ also referred to as â€œdeal flow,â€ continues to be an important\ndifferentiator between the best funds and the rest of the pack.\n\nNetworks and access are a potent currency in Silicon Valley. As I like to say: \nyou can be the smartest person in the room, but if you arenâ€™t even in the room,\nit doesnâ€™t matter.\n\nAs such, VC firms want to know about every deal being done, even if they have\nlittle interest in doing the deal. They want the option to say no. As in many\ndomains, that optionality is incredibly valuable.\n\nBut simple awareness of a fundraise does not do much for you as a VC. These\ndays, itâ€™s often common knowledge that a particular company is fundraising.\n\nEven if you know a deal is going down, thereâ€™s no guarantee you will be able to\ninsert yourself into the consideration set of potential partners. Iâ€™ve had\nentrepreneurs directly deny to me they were fundraising when they in fact were,\nonly to admit it after the fundraise announced shortly thereafter.\n\nThe concept of an â€œanti-portfolio\n[https://www.fool.com/investing/general/2014/02/20/whats-in-your-anti-portfolio.aspx]\nâ€ proves that even if you see a deal you can still drop the ball.\n\nMany VCs â€œsawâ€ the Facebook deal. Many VCs â€œsawâ€ the Google deal. And yet they\nmissed the most explosive growth companies the world has ever seen.\n\nâ€œSeeingâ€ is necessary but not sufficient.\n\n> VC's have always relied on the strength of their networks for dealflow.\n\nAs an increasing number of founders come from more diverse backgrounds, VC's\nwill have to change to stay relevant.\n\nMore diverse partnerships, more openness towards cold emails, less pattern\nmatching.\n\nâ€” Boris Wertz (@bwertz) August 20, 2019\n[https://twitter.com/bwertz/status/1163885146048569344?ref_src=twsrc%5Etfw]\nI donâ€™t mean to deny or discount the value of deal flow. Deal flow is a valuable\nresource, but itâ€™s exactly that â€” a resource. A resource must be extracted,\nenriched, and processed. Converting that resource into useful energy requires\ninvestment and effort. Otherwise, it remains inert.\n\nReceive my next thought in your inbox\n\n\nGo âš¡ðŸ§  Signal in the noise\nVenture capitalists often talk about â€œpattern matching.â€ After years of\ninvesting and watching startups succeed or fail, VCs supposedly develop a keen\nsense of what drives success, detecting signals in the noise. These signals can\ntake many forms, but the important claims are:\n\n * Patterns exist\n * Patterns are discoverable\n * Patterns are valuable\n\nPattern matching epitomizes the â€œanalyzeâ€ skill.\n\nThere are three issues with basing your competitive advantage on pattern\nmatching.\n\nFirst, pattern matching is rarely differentiated. The important metrics and\nsigns of traction are well-known these days. Increasingly, the â€œgoodâ€ founders\nare obvious â€” those with the best pedigrees or past successes.\n\nLike in public equities, obvious patterns are priced in. If itâ€™s not priced in â€”\nmost often â€” itâ€™s not a real pattern.\n\nThis dilutes the value of pattern matching. Suddenly, the well-worn patterns VCs\nrely on so heavily begin to work against them:\n\n * The founderâ€™s a Stanford grad? Everyone knows that, it will get priced in.\n * Previously a Google product manager? Yep, the valuation will reflect that.\n * Big, fragmented market ripe for consolidation? You bet the final valuation\n   will incorporate this.\n\nIn a competitive environment, patterns carry the seeds of their own impotence.\n\nSecond, itâ€™s not at all obvious that pattern matching even helps much at the\nearliest stage. The drivers of success are indeterminate, and stories abound\nabout ideas that seemed dumb at first but became winners. In some cases, even\nthe VCs who funded the best companies had serious doubts going in.\n\nIf even the â€œsmartest guys in the roomâ€ are not that smart, we know we have a\nproblem.\n\n> VC pattern matching and startup folklore are the path to mediocrity. Focus on\ncommercial success and let data tell the story. Youâ€™ll be the next pattern\npeople try to match. https://t.co/ggDZJmJWbV\n\nâ€” bradford cross (@bradfordcross) September 22, 2018\n[https://twitter.com/bradfordcross/status/1043351318566293504?ref_src=twsrc%5Etfw]\nThird, this all assumes the patterns are correct â€” that they contain some useful\ninformation.\n\nThis too is suspect.\n\nData in VC is notoriously spotty, unreliable, and often unavailable entirely.\nTying cause to effect is quite difficult, and success or failure is often\nover-determined.\n\nIn this environment, our natural tendency as humans is to fall back on\nheuristics. Some of these are helpful, but many are problematic.\n\nAnother word for a problematic heuristic is bias.\n\n> \"Thereâ€™s quite substantial unconscious bias that most of my male investment\ncolleagues donâ€™t see, where if a guy looks and smells the part with the pattern\nmatching, (he) just (gets) such a break\" â€“ Linden Rhoads, General Manager of the\nW Fund (Source\n[https://www.bizjournals.com/seattle/blog/techflash/2016/03/how-pattern-matching-by-investors-puts-female.html]\n)\nâ€œPattern matchingâ€ seems increasingly tenuous. Either itâ€™s easy and reliable, in\nwhich case it gets priced in, or itâ€™s difficult to execute on in practice,\nmaking it easy to fool oneself into believing non-existent patterns, almost\nsuperstitiously.\n\nEither way, itâ€™s fraught.\n\nâ¤ï¸ All I do is win\nVenture capital is a match making service.\n\nWinning in modern venture investing fundamentally concerns what I call â€œpeople\nmatchingâ€ â€” bringing together the right combination of founders and investors to\npartner on a particular startup or idea.\n\nItâ€™s about the people, not the capital. Yes, capital is also matched or\nallocated to specific startups, but this function is being commoditized.\n\nShowing up with a checkbook today is no longer cool or particularly notable.\n\nNot all funds can show up with the right partner, however. A partner the\nentrepreneur wants to work with. Someone who will make both the founder and the\nstartup better by their presence and involvement.\n\nIn this sense, the coveted â€œpartnerâ€ title is actually quite fitting.\n\nPartners partner.\n\nIn this model, venture capital firms are less allocators of capital â€” which is\ncurrently cheap, plentiful, and most importantly, homogeneous â€” and more \nallocators of people, who remain differentiated even in this hot house\nenvironment.\n\nPeople are the truly limited and differentiated resource of VC firms. General\nPartners seek to maximize the capacity of the fund to generate returns for its\nLimited Partners, but ironically, it is the General Partners who are â€œlimitedâ€ â€”\nthereâ€™s only so many of them, and they must be deployed judiciously. And with\nall the capital flowing around these days, Limited Partners are increasingly \nunlimited.\n\nUnlike a publicly traded company, which can effectively absorb any amount of\ncapital the market could realistically desire to invest, with prices regulating\nthis flow, the typical startup cannot and does not want to take on every\npossible dollar from every willing investor. The best deals are often\noversubscribed multiple times over. Financing rounds are rivalrous\n[https://en.wikipedia.org/wiki/Rivalry_(economics)] â€” we canâ€™t all do the deal.\n\nThe VC who can most quickly convince a founder that they are the right person to\npartner with will win the deal. And by winning the deal, others, by definition,\nlose the deal.\n\n> Talking to 43+ funds is a massive waste of time of everyoneâ€™s time \n\nNow that access is completely commoditized, closing is the most valuable skill\n\nFounders, find your lead first to remove noise & get back to work\n\nIf itâ€™s unclear what value a participating firm offers, move on. \nhttps://t.co/o4zbodpENL\n\nâ€” Brianne Kimmel (@briannekimmel) December 3, 2019\n[https://twitter.com/briannekimmel/status/1201966954090655744?ref_src=twsrc%5Etfw]\nWinning is therefore the fulcrum upon which success in venture turns. Two\ncomparable firms can both see the deal, analyze the deal â€œcorrectlyâ€, and yet\nonly one may win the deal in the end. The firm that does a better job of people\nmatching will, in the end, triumph.\n\nThis is why winning matters so much.\n\nðŸ‘¥ More skin in a new game\nVenture capital is evolving from a game of picking winners to a game of being\npicked by winners.\n\nAuthentic relationships and credible ability to add value matter more than ever.\n\nVenture capital is no longer where one goes to retire quietly after an\nillustrious operating career. Itâ€™s where one goes to hustle.\n\n> Pushing to win an investment I really want. Might lose it.\n\nFounder in driver's seat. Some investors complain, I love it. Some call this a\nbubble, but everyone is being rational.\n\nFounder/investor dynamic is reaching equilibrium and this is how it should be.\n\nâ€” Paul Murphy (@paulbz) November 19, 2019\n[https://twitter.com/paulbz/status/1196914235059691521?ref_src=twsrc%5Etfw]\nI think this is a positive trend, encouraging deeper empathy between investors\nand founders. If anything, bringing VCs down a peg might humanize them â€” the\ngilded kings and queens of Silicon Valley become the humble servants of\nentrepreneurs.\n\nThereâ€™s some moral justice in this. Iâ€™ve always been irked by the very different\nlives lived by founders and their investors:\n\n * One is concentrated, the other is diversified\n * One is expected to fail, the other is expected to at least breakeven\n * One is a beggar, the other is a chooser\n\nThis is out of balance. Entrepreneurs hustle, why shouldnâ€™t VCs?","feature_image":"__GHOST_URL__/content/images/2019/12/people-matching-2-cropped-2.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2019-12-01T20:47:53.000Z","updated_at":"2019-12-13T06:58:18.000Z","published_at":"2019-12-10T17:35:27.000Z","custom_excerpt":"Venture capital is changing â€” for the better","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5e2ff75468a43d4de0d20931","uuid":"a9a3042e-eb39-4ca5-a381-11061424b500","title":"How Uber and Lyft Dominated Ridesharing By Seeing Red Where Others Saw Blue","slug":"red-ocean","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"/content/images/2020/01/red-vs-blue.png\",\"caption\":\"Source: <a href=\\\"https://www.blueoceanstrategy.com/what-is-blue-ocean-strategy/\\\">BlueOceanStrategy.com</a>\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive my next thought in your inbox</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"I email every few months\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: How Uber and Lyft Dominated Ridesharing By Seeing Red Where Others Saw Blue\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span>Go âš¡</span></button>\\n</form>\\n</section>\"}],[\"image\",{\"src\":\"/content/images/2020/01/Screen-Shot-2019-03-30-at-3.39.22-PM.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"(Shaded area represents size of market in dollar terms, i.e. price x quantity = market size)\"}],[\"image\",{\"src\":\"/content/images/2020/01/Screen-Shot-2019-03-30-at-3.37.56-PM.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2020/01/Screen-Shot-2019-03-30-at-3.38.08-PM.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}]],\"markups\":[[\"a\",[\"href\",\"https://www.blueoceanstrategy.com/\"]],[\"strong\"],[\"a\",[\"href\",\"https://www.inc.com/magazine/201307/christine-lagorio/companies-that-are-like-uber.html\"]],[\"a\",[\"href\",\"http://www.businessofapps.com/news/eight-uber-competitors-reinventing-taxi-apps/\"]],[\"a\",[\"href\",\"https://www.nytimes.com/2016/04/14/business/smallbusiness/ride-sharing-start-ups-compete-in-uber-for-children-niche.html\"]],[\"a\",[\"href\",\"https://www.fastcompany.com/3065089/the-ride-share-startup-thats-competing-with-uber-and-lyft-by-charging-1\"]],[\"em\"],[\"a\",[\"href\",\"https://www.forbes.com/sites/briansolomon/2016/01/25/is-uber-trying-to-kill-lyft-with-a-price-war/\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Cambrian_explosion\"]],[\"a\",[\"href\",\"__GHOST_URL__/entrepreneurs-ruin/\"]],[\"a\",[\"href\",\"https://andrewchen.co/marketplace-startups-best-essays/\"]],[\"a\",[\"href\",\"https://www.theverge.com/2013/5/23/4357666/lyft-international-expansion-60-million-andreesen-horowitz\"]],[\"a\",[\"href\",\"https://www.forbes.com/sites/briansolomon/2016/06/02/uber-is-breaking-all-the-rules-in-its-25-billion-arms-race/#41f2b0e22646\"]],[\"a\",[\"href\",\"http://nymag.com/intelligencer/2014/07/uberx-cutting-prices-by-20-percent-in-new-york.html\"]],[\"a\",[\"href\",\"https://www.vox.com/2015/1/9/7519237/the-48-cities-where-uber-is-cutting-prices\"]],[\"a\",[\"href\",\"http://time.com/4175148/uber-price-drops/\"]],[\"a\",[\"href\",\"https://www.cnbc.com/2014/07/29/lyfts-sacrifice-for-the-sake-of-its-nyc-launch.html\"]],[\"a\",[\"href\",\"https://www.uber.com/drive/atlanta/resources/driver-partner-incentive-guarantee-faq-questions/\"]],[\"a\",[\"href\",\"https://medium.com/ipg-media-lab/the-shift-towards-multimodal-transportation-the-future-of-mobility-d0c7c25d4a06\"]],[\"a\",[\"href\",\"https://www.huffpost.com/entry/uber-google-waze-ride-hailing-lyft_n_57c8558fe4b0a22de09485cc\"]],[\"a\",[\"href\",\"https://www.reuters.com/article/us-uber-usa/uber-boss-says-u-s-market-unprofitable-amid-tough-competition-from-lyft-idUSKBN1D9348\"]],[\"a\",[\"href\",\"https://mashable.com/article/lyft-ipo-self-driving-cars-investors/\"]],[\"a\",[\"href\",\"https://www.businessinsider.com/uber-lyft-self-driving-taxis-may-not-help-profitability-mit-2019-5\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Over a decade ago, INSEAD business strategy professors W. Chan Kim and RenÃ©e Mauborgne popularized the terms â€œ\"],[0,[0,1],2,\"blue ocean\"],[0,[],0,\"â€ â€” untapped markets where â€œdemand is created rather than fought overâ€, enabling profitable growth â€” and â€œ\"],[0,[1],1,\"red ocean\"],[0,[],0,\"â€ â€” zero-sum markets, where every fluid ounce of demand is bitterly fought over, like sharks fighting over a whale carcass.\"]]],[1,\"p\",[[0,[1],1,\"The early ridesharing market was a deeply red ocean, plagued by price wars, rife with cutthroat tactics, and littered with failed startups.\"]]],[10,0],[1,\"p\",[[0,[],0,\"However, many entrepreneurs and investors initially saw a blue ocean in the early ridesharing market. Ridesharing was a new, unexplored medium that promised to revolutionize and expand the ground transportation market wherever mobile devices were ubiquitous by â€œunlockingâ€ pent-up demand for one-tap transportation.\"]]],[1,\"p\",[[0,[],0,\"As a young investor, I balked at this characterization. While I agreed on the long-run impact of these next-generation transportation networks, I thought this view was dead wrong in the short-term.\"]]],[1,\"p\",[[0,[],0,\"Hereâ€™s why.\"]]],[10,1],[1,\"h2\",[[0,[],0,\"Demand-driven market growth\"]]],[1,\"p\",[[0,[],0,\"In the simple Economics 101 model of supply and demand, market growth comes in two flavors: demand-driven and supply-driven, characterized by increased willingness to buy or sell respectively at a given price.\"]]],[10,2],[1,\"p\",[[0,[],0,\"Many people miss the subtlety that the cause (supply or demand) behind the effect (growth) impacts how attractive a market is to new and existing entrants.\"]]],[1,\"p\",[[0,[],0,\"More demand translates into both higher prices and volume transacted. Hence, markets growing due to a buildup of demand are highly attractive to new entrants, as businesses can grow without necessarily taking share from others and avoid contentious, competitive battles over market share.\"]]],[10,3],[1,\"p\",[[0,[],0,\"Even with the arrival of new competitors, as long as the increased in demand outstrips the increase in supply, prices, and therefore profits, will be stable or increasing, and weâ€™ll see higher volume of transactions regardless.\"]]],[1,\"p\",[[0,[],0,\"This is both exciting to new market entrants and encouraging for existing suppliers.\"]]],[1,\"p\",[[0,[],0,\"Demand-driven growth is intuitive. It's what most people associate with a growing market. Itâ€™s easy to assume that market growth always comes from consumers demanding more.\"]]],[1,\"h2\",[[0,[],0,\"Supply-driven market growth\"]]],[1,\"p\",[[0,[],0,\"However, the sudden growth of ridesharing is better explained by activity on the supply-side â€” the founding of Uber, Lyft, and an \"],[0,[2],1,\"eclectic\"],[0,[],0,\" \"],[0,[3],1,\"cast\"],[0,[],0,\" of \"],[0,[4],1,\"competing\"],[0,[],0,\" \"],[0,[5],1,\"startups\"],[0,[],0,\", all focused on the same market, the same core idea.\"]]],[1,\"p\",[[0,[1],1,\"Ridesharing was not a demand-side phenomenon.\"],[0,[],0,\" The market was itself \"],[0,[6],1,\"created\"],[0,[],0,\" by the supply-side, which then generated supply-driven growth.\"]]],[1,\"p\",[[0,[],0,\"Supply-driven market growth causes prices to decline rather than increase. These price cuts eat away the profitability of suppliers and bar others from entering the market who cannot viably operate at these lower prices â€” like a sea wall breaking waves before they hit the shoreline.\"]]],[10,4],[1,\"p\",[[0,[],0,\"Further, gaining share requires either fierce competition along the product or marketing dimension or \"],[0,[7],1,\"aggressive price cuts\"],[0,[],0,\". Market share must either be taken from other suppliers, who originated the market growth in the first place, or created by offering the same or better product at lower prices.\"]]],[1,\"p\",[[0,[],0,\"The ridesharing market spawned out of the emergence of these new services â€” new sources of supply.\"]]],[1,\"p\",[[0,[],0,\"What funded this \"],[0,[8],1,\"Cambrian explosion\"],[0,[],0,\" of ridesharing? \"],[0,[1],1,\"Venture capital.\"]]],[1,\"p\",[[0,[],0,\"Capital is a key competitive advantage due to its ability to fund continuous price subsidies. These artificially deflated prices both undercut \"],[0,[9],1,\"capital-constrained\"],[0,[],0,\" competitors and drive consumer usage.\"]]],[1,\"p\",[[0,[],0,\"Prices down, volume up.\"]]],[1,\"p\",[[0,[],0,\"The flood of new customers impresses other investors and attracts more funding, enabling the early winners to cut prices further. Additionally, the increased ridership attracts and retains drivers, whose earning power is enhanced via two-sided network effects about which much has \"],[0,[10],1,\"previously been written\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"This completes the virtuous cycle:\"]]],[1,\"p\",[[0,[],0,\"Initial innovation â†’ venture capital â†’ lower prices â†’ more usage â†’ venture capital\"]]],[1,\"h2\",[[0,[],0,\"Swimming with sharks\"]]],[1,\"p\",[[0,[1],1,\"Lyft and Uber correctly saw the nascent ridesharing market as a red ocean.\"],[0,[],0,\" Despite dreams of a future where spend would shift from personal car purchases to ridesharing, they could not afford to wait for demand to arrive. In the near-term, supply would outpace demand, making the market much more competitive.\"]]],[1,\"p\",[[0,[],0,\"Appropriately, Uber and Lyft armed themselves for the fight, raising â€œ\"],[0,[11],1,\"war chests\"],[0,[],0,\"â€ of capital to fund a ridesharing â€œ\"],[0,[12],1,\"arms race\"],[0,[],0,\"â€.\"]]],[1,\"p\",[[0,[],0,\"Uber and Lyft expanded aggressively into new cities at a breakneck pace. They \"],[0,[13],1,\"cut prices\"],[0,[],0,\", then \"],[0,[14],1,\"cut them again\"],[0,[],0,\", and just \"],[0,[15],1,\"kept on cutting\"],[0,[],0,\". Already market leaders, they spent generously on \"],[0,[16],1,\"cash bonuses\"],[0,[],0,\" and other \"],[0,[17],1,\"driver incentives\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"In contrast, their early competitors bought into the eventually-true-but-not-yet promise of a \"],[0,[18],1,\"world transformed\"],[0,[],0,\" by app-based transportation, hoping to surf the seemingly blue \"],[0,[19],1,\"ridesharing wave\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Nothing wrong with being a small fish in a big, blue pond, right?\"]]],[1,\"p\",[[0,[],0,\"These hapless ride-surfers didnâ€™t realize supply-side sharks like Uber and Lyft were the entire reason for the wave in the first place.\"]]],[1,\"p\",[[0,[],0,\"How did this tidal wave impact other ridesharing startups?\"]]],[3,\"ul\",[[[0,[],0,\"Unable to match the subsidized prices, other players failed to attract users\"]],[[0,[],0,\"Fewer customers meant lower driver earnings, leading to an exodus of drivers\"]],[[0,[],0,\"Sparse supply on the driver-side lengthened wait times, degrading the rider experience, pushing more of them away\"]],[[0,[],0,\"Declining usage scared off new investors\"]],[[0,[],0,\"Incapable of raising fresh funds, the other fledging ridesharing startups, metaphorically, drowned.\"]]]],[1,\"p\",[[0,[],0,\"The â€œblue oceanâ€ turned red; the virtuous cycle turned vicious.\"]]],[1,\"p\",[[0,[],0,\"Acting with haste and fervor, Uber and Lyft established an insurmountable lead, effectively eliminating their U.S. competition before changing norms and consumer behavior on the demand-side had a chance to catch up.\"]]],[1,\"p\",[[0,[],0,\"In other words, they saw red where others saw blue.\"]]],[1,\"h2\",[[0,[],0,\"Lessons learned\"]]],[1,\"p\",[[0,[],0,\"A few key takeaways:\"]]],[1,\"blockquote\",[[0,[1],1,\"1. Supply is red, demand is blue\"]]],[3,\"ul\",[[[0,[],0,\"A merely growing market is not necessarily an attractive one\"]],[[0,[],0,\"The drivers of growth matter more than the level of growth\"]]]],[1,\"blockquote\",[[0,[1],1,\"2. The deep sea requires deep pockets\"]]],[3,\"ul\",[[[0,[],0,\"Capital can often be converted directly into market share\"]],[[0,[],0,\"Red ocean markets demand significant capital, as \"],[0,[20],1,\"growth is unprofitable\"],[0,[],0,\" in the short-run\"]]]],[1,\"blockquote\",[[0,[1],1,\"3. Cheap capital and disruptive innovation create supply-side tsunamis\"]]],[3,\"ul\",[[[0,[],0,\"When capital is inexpensive, supply reacts to innovation much faster than demand\"]]]],[1,\"p\",[[0,[],0,\"That the ridesharing market could consolidate so early in its existence is remarkable but also perhaps predictable if one understands itâ€™s supply-side origins.\"]]],[1,\"p\",[[0,[],0,\"And despite an evolution of norms around getting into a strangerâ€™s car, Uber and Lyft are \"],[0,[21],1,\"betting big\"],[0,[],0,\" on another supply-side innovation: \"],[0,[22],1,\"autonomous vehicles\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Why? Again: to push out the supply curve, drive down prices, expand usage, attract capital, and reinvest in more robotaxis.\"]]],[1,\"p\",[[0,[],0,\"In other words, itâ€™s the same supply-driven growth story all over again.\"]]],[1,\"p\",[[0,[],0,\"That the two ridesharing leaders continue to operate unprofitably at scale only further drives the point home. \"],[0,[1],1,\"This is not a demand-side story and never has been.\"]]],[1,\"p\",[[0,[],0,\"This is a cautionary tale for entrepreneurs and investors clamoring to capitalize on the latest â€œwaveâ€.\"]]],[1,\"p\",[[0,[],0,\"Sometimes, the right kind of rose-tinted glasses isnâ€™t such a bad thing.\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p>Over a decade ago, INSEAD business strategy professors W. Chan Kim and RenÃ©e Mauborgne popularized the terms â€œ<a href=\"https://www.blueoceanstrategy.com/\"><strong>blue ocean</strong></a>â€ â€” untapped markets where â€œdemand is created rather than fought overâ€, enabling profitable growth â€” and â€œ<strong>red ocean</strong>â€ â€” zero-sum markets, where every fluid ounce of demand is bitterly fought over, like sharks fighting over a whale carcass.</p><p><strong>The early ridesharing market was a deeply red ocean, plagued by price wars, rife with cutthroat tactics, and littered with failed startups.</strong></p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"/content/images/2020/01/red-vs-blue.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>Source: <a href=\"https://www.blueoceanstrategy.com/what-is-blue-ocean-strategy/\">BlueOceanStrategy.com</a></figcaption></figure><p>However, many entrepreneurs and investors initially saw a blue ocean in the early ridesharing market. Ridesharing was a new, unexplored medium that promised to revolutionize and expand the ground transportation market wherever mobile devices were ubiquitous by â€œunlockingâ€ pent-up demand for one-tap transportation.</p><p>As a young investor, I balked at this characterization. While I agreed on the long-run impact of these next-generation transportation networks, I thought this view was dead wrong in the short-term.</p><p>Hereâ€™s why.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive my next thought in your inbox</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"I email every few months\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: How Uber and Lyft Dominated Ridesharing By Seeing Red Where Others Saw Blue\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span>Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: html--><h2 id=\"demand-driven-market-growth\">Demand-driven market growth</h2><p>In the simple Economics 101 model of supply and demand, market growth comes in two flavors: demand-driven and supply-driven, characterized by increased willingness to buy or sell respectively at a given price.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"/content/images/2020/01/Screen-Shot-2019-03-30-at-3.39.22-PM.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>(Shaded area represents size of market in dollar terms, i.e. price x quantity = market size)</figcaption></figure><p>Many people miss the subtlety that the cause (supply or demand) behind the effect (growth) impacts how attractive a market is to new and existing entrants.</p><p>More demand translates into both higher prices and volume transacted. Hence, markets growing due to a buildup of demand are highly attractive to new entrants, as businesses can grow without necessarily taking share from others and avoid contentious, competitive battles over market share.</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/01/Screen-Shot-2019-03-30-at-3.37.56-PM.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Even with the arrival of new competitors, as long as the increased in demand outstrips the increase in supply, prices, and therefore profits, will be stable or increasing, and weâ€™ll see higher volume of transactions regardless.</p><p>This is both exciting to new market entrants and encouraging for existing suppliers.</p><p>Demand-driven growth is intuitive. It's what most people associate with a growing market. Itâ€™s easy to assume that market growth always comes from consumers demanding more.</p><h2 id=\"supply-driven-market-growth\">Supply-driven market growth</h2><p>However, the sudden growth of ridesharing is better explained by activity on the supply-side â€” the founding of Uber, Lyft, and an <a href=\"https://www.inc.com/magazine/201307/christine-lagorio/companies-that-are-like-uber.html\">eclectic</a> <a href=\"http://www.businessofapps.com/news/eight-uber-competitors-reinventing-taxi-apps/\">cast</a> of <a href=\"https://www.nytimes.com/2016/04/14/business/smallbusiness/ride-sharing-start-ups-compete-in-uber-for-children-niche.html\">competing</a> <a href=\"https://www.fastcompany.com/3065089/the-ride-share-startup-thats-competing-with-uber-and-lyft-by-charging-1\">startups</a>, all focused on the same market, the same core idea.</p><p><strong>Ridesharing was not a demand-side phenomenon.</strong> The market was itself <em>created</em> by the supply-side, which then generated supply-driven growth.</p><p>Supply-driven market growth causes prices to decline rather than increase. These price cuts eat away the profitability of suppliers and bar others from entering the market who cannot viably operate at these lower prices â€” like a sea wall breaking waves before they hit the shoreline.</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/01/Screen-Shot-2019-03-30-at-3.38.08-PM.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Further, gaining share requires either fierce competition along the product or marketing dimension or <a href=\"https://www.forbes.com/sites/briansolomon/2016/01/25/is-uber-trying-to-kill-lyft-with-a-price-war/\">aggressive price cuts</a>. Market share must either be taken from other suppliers, who originated the market growth in the first place, or created by offering the same or better product at lower prices.</p><p>The ridesharing market spawned out of the emergence of these new services â€” new sources of supply.</p><p>What funded this <a href=\"https://en.wikipedia.org/wiki/Cambrian_explosion\">Cambrian explosion</a> of ridesharing? <strong>Venture capital.</strong></p><p>Capital is a key competitive advantage due to its ability to fund continuous price subsidies. These artificially deflated prices both undercut <a href=\"__GHOST_URL__/entrepreneurs-ruin/\">capital-constrained</a> competitors and drive consumer usage.</p><p>Prices down, volume up.</p><p>The flood of new customers impresses other investors and attracts more funding, enabling the early winners to cut prices further. Additionally, the increased ridership attracts and retains drivers, whose earning power is enhanced via two-sided network effects about which much has <a href=\"https://andrewchen.co/marketplace-startups-best-essays/\">previously been written</a>.</p><p>This completes the virtuous cycle:</p><p>Initial innovation â†’ venture capital â†’ lower prices â†’ more usage â†’ venture capital</p><h2 id=\"swimming-with-sharks\">Swimming with sharks</h2><p><strong>Lyft and Uber correctly saw the nascent ridesharing market as a red ocean.</strong> Despite dreams of a future where spend would shift from personal car purchases to ridesharing, they could not afford to wait for demand to arrive. In the near-term, supply would outpace demand, making the market much more competitive.</p><p>Appropriately, Uber and Lyft armed themselves for the fight, raising â€œ<a href=\"https://www.theverge.com/2013/5/23/4357666/lyft-international-expansion-60-million-andreesen-horowitz\">war chests</a>â€ of capital to fund a ridesharing â€œ<a href=\"https://www.forbes.com/sites/briansolomon/2016/06/02/uber-is-breaking-all-the-rules-in-its-25-billion-arms-race/#41f2b0e22646\">arms race</a>â€.</p><p>Uber and Lyft expanded aggressively into new cities at a breakneck pace. They <a href=\"http://nymag.com/intelligencer/2014/07/uberx-cutting-prices-by-20-percent-in-new-york.html\">cut prices</a>, then <a href=\"https://www.vox.com/2015/1/9/7519237/the-48-cities-where-uber-is-cutting-prices\">cut them again</a>, and just <a href=\"http://time.com/4175148/uber-price-drops/\">kept on cutting</a>. Already market leaders, they spent generously on <a href=\"https://www.cnbc.com/2014/07/29/lyfts-sacrifice-for-the-sake-of-its-nyc-launch.html\">cash bonuses</a> and other <a href=\"https://www.uber.com/drive/atlanta/resources/driver-partner-incentive-guarantee-faq-questions/\">driver incentives</a>.</p><p>In contrast, their early competitors bought into the eventually-true-but-not-yet promise of a <a href=\"https://medium.com/ipg-media-lab/the-shift-towards-multimodal-transportation-the-future-of-mobility-d0c7c25d4a06\">world transformed</a> by app-based transportation, hoping to surf the seemingly blue <a href=\"https://www.huffpost.com/entry/uber-google-waze-ride-hailing-lyft_n_57c8558fe4b0a22de09485cc\">ridesharing wave</a>.</p><p>Nothing wrong with being a small fish in a big, blue pond, right?</p><p>These hapless ride-surfers didnâ€™t realize supply-side sharks like Uber and Lyft were the entire reason for the wave in the first place.</p><p>How did this tidal wave impact other ridesharing startups?</p><ul><li>Unable to match the subsidized prices, other players failed to attract users</li><li>Fewer customers meant lower driver earnings, leading to an exodus of drivers</li><li>Sparse supply on the driver-side lengthened wait times, degrading the rider experience, pushing more of them away</li><li>Declining usage scared off new investors</li><li>Incapable of raising fresh funds, the other fledging ridesharing startups, metaphorically, drowned.</li></ul><p>The â€œblue oceanâ€ turned red; the virtuous cycle turned vicious.</p><p>Acting with haste and fervor, Uber and Lyft established an insurmountable lead, effectively eliminating their U.S. competition before changing norms and consumer behavior on the demand-side had a chance to catch up.</p><p>In other words, they saw red where others saw blue.</p><h2 id=\"lessons-learned\">Lessons learned</h2><p>A few key takeaways:</p><blockquote><strong>1. Supply is red, demand is blue</strong></blockquote><ul><li>A merely growing market is not necessarily an attractive one</li><li>The drivers of growth matter more than the level of growth</li></ul><blockquote><strong>2. The deep sea requires deep pockets</strong></blockquote><ul><li>Capital can often be converted directly into market share</li><li>Red ocean markets demand significant capital, as <a href=\"https://www.reuters.com/article/us-uber-usa/uber-boss-says-u-s-market-unprofitable-amid-tough-competition-from-lyft-idUSKBN1D9348\">growth is unprofitable</a> in the short-run</li></ul><blockquote><strong>3. Cheap capital and disruptive innovation create supply-side tsunamis</strong></blockquote><ul><li>When capital is inexpensive, supply reacts to innovation much faster than demand</li></ul><p>That the ridesharing market could consolidate so early in its existence is remarkable but also perhaps predictable if one understands itâ€™s supply-side origins.</p><p>And despite an evolution of norms around getting into a strangerâ€™s car, Uber and Lyft are <a href=\"https://mashable.com/article/lyft-ipo-self-driving-cars-investors/\">betting big</a> on another supply-side innovation: <a href=\"https://www.businessinsider.com/uber-lyft-self-driving-taxis-may-not-help-profitability-mit-2019-5\">autonomous vehicles</a>.</p><p>Why? Again: to push out the supply curve, drive down prices, expand usage, attract capital, and reinvest in more robotaxis.</p><p>In other words, itâ€™s the same supply-driven growth story all over again.</p><p>That the two ridesharing leaders continue to operate unprofitably at scale only further drives the point home. <strong>This is not a demand-side story and never has been.</strong></p><p>This is a cautionary tale for entrepreneurs and investors clamoring to capitalize on the latest â€œwaveâ€.</p><p>Sometimes, the right kind of rose-tinted glasses isnâ€™t such a bad thing.</p>","comment_id":"5e2ff75468a43d4de0d20931","plaintext":"Over a decade ago, INSEAD business strategy professors W. Chan Kim and RenÃ©e\nMauborgne popularized the terms â€œblue ocean [https://www.blueoceanstrategy.com/]\nâ€ â€” untapped markets where â€œdemand is created rather than fought overâ€, enabling\nprofitable growth â€” and â€œred oceanâ€ â€” zero-sum markets, where every fluid ounce\nof demand is bitterly fought over, like sharks fighting over a whale carcass.\n\nThe early ridesharing market was a deeply red ocean, plagued by price wars, rife\nwith cutthroat tactics, and littered with failed startups.\n\nSource: BlueOceanStrategy.com\n[https://www.blueoceanstrategy.com/what-is-blue-ocean-strategy/]However, many\nentrepreneurs and investors initially saw a blue ocean in the early ridesharing\nmarket. Ridesharing was a new, unexplored medium that promised to revolutionize\nand expand the ground transportation market wherever mobile devices were\nubiquitous by â€œunlockingâ€ pent-up demand for one-tap transportation.\n\nAs a young investor, I balked at this characterization. While I agreed on the\nlong-run impact of these next-generation transportation networks, I thought this\nview was dead wrong in the short-term.\n\nHereâ€™s why.\n\nReceive my next thought in your inbox\n\n\nGo âš¡Demand-driven market growth\nIn the simple Economics 101 model of supply and demand, market growth comes in\ntwo flavors: demand-driven and supply-driven, characterized by increased\nwillingness to buy or sell respectively at a given price.\n\n(Shaded area represents size of market in dollar terms, i.e. price x quantity =\nmarket size)Many people miss the subtlety that the cause (supply or demand)\nbehind the effect (growth) impacts how attractive a market is to new and\nexisting entrants.\n\nMore demand translates into both higher prices and volume transacted. Hence,\nmarkets growing due to a buildup of demand are highly attractive to new\nentrants, as businesses can grow without necessarily taking share from others\nand avoid contentious, competitive battles over market share.\n\nEven with the arrival of new competitors, as long as the increased in demand\noutstrips the increase in supply, prices, and therefore profits, will be stable\nor increasing, and weâ€™ll see higher volume of transactions regardless.\n\nThis is both exciting to new market entrants and encouraging for existing\nsuppliers.\n\nDemand-driven growth is intuitive. It's what most people associate with a\ngrowing market. Itâ€™s easy to assume that market growth always comes from\nconsumers demanding more.\n\nSupply-driven market growth\nHowever, the sudden growth of ridesharing is better explained by activity on the\nsupply-side â€” the founding of Uber, Lyft, and an eclectic\n[https://www.inc.com/magazine/201307/christine-lagorio/companies-that-are-like-uber.html] \n cast\n[http://www.businessofapps.com/news/eight-uber-competitors-reinventing-taxi-apps/] \nof competing\n[https://www.nytimes.com/2016/04/14/business/smallbusiness/ride-sharing-start-ups-compete-in-uber-for-children-niche.html] \n startups\n[https://www.fastcompany.com/3065089/the-ride-share-startup-thats-competing-with-uber-and-lyft-by-charging-1]\n, all focused on the same market, the same core idea.\n\nRidesharing was not a demand-side phenomenon. The market was itself created by\nthe supply-side, which then generated supply-driven growth.\n\nSupply-driven market growth causes prices to decline rather than increase. These\nprice cuts eat away the profitability of suppliers and bar others from entering\nthe market who cannot viably operate at these lower prices â€” like a sea wall\nbreaking waves before they hit the shoreline.\n\nFurther, gaining share requires either fierce competition along the product or\nmarketing dimension or aggressive price cuts\n[https://www.forbes.com/sites/briansolomon/2016/01/25/is-uber-trying-to-kill-lyft-with-a-price-war/]\n. Market share must either be taken from other suppliers, who originated the\nmarket growth in the first place, or created by offering the same or better\nproduct at lower prices.\n\nThe ridesharing market spawned out of the emergence of these new services â€” new\nsources of supply.\n\nWhat funded this Cambrian explosion\n[https://en.wikipedia.org/wiki/Cambrian_explosion] of ridesharing? Venture\ncapital.\n\nCapital is a key competitive advantage due to its ability to fund continuous\nprice subsidies. These artificially deflated prices both undercut \ncapital-constrained [__GHOST_URL__/entrepreneurs-ruin/] competitors and drive\nconsumer usage.\n\nPrices down, volume up.\n\nThe flood of new customers impresses other investors and attracts more funding,\nenabling the early winners to cut prices further. Additionally, the increased\nridership attracts and retains drivers, whose earning power is enhanced via\ntwo-sided network effects about which much has previously been written\n[https://andrewchen.co/marketplace-startups-best-essays/].\n\nThis completes the virtuous cycle:\n\nInitial innovation â†’ venture capital â†’ lower prices â†’ more usage â†’ venture\ncapital\n\nSwimming with sharks\nLyft and Uber correctly saw the nascent ridesharing market as a red ocean. \nDespite dreams of a future where spend would shift from personal car purchases\nto ridesharing, they could not afford to wait for demand to arrive. In the\nnear-term, supply would outpace demand, making the market much more competitive.\n\nAppropriately, Uber and Lyft armed themselves for the fight, raising â€œwar chests\n[https://www.theverge.com/2013/5/23/4357666/lyft-international-expansion-60-million-andreesen-horowitz]\nâ€ of capital to fund a ridesharing â€œarms race\n[https://www.forbes.com/sites/briansolomon/2016/06/02/uber-is-breaking-all-the-rules-in-its-25-billion-arms-race/#41f2b0e22646]\nâ€.\n\nUber and Lyft expanded aggressively into new cities at a breakneck pace. They \ncut prices\n[http://nymag.com/intelligencer/2014/07/uberx-cutting-prices-by-20-percent-in-new-york.html]\n, then cut them again\n[https://www.vox.com/2015/1/9/7519237/the-48-cities-where-uber-is-cutting-prices]\n, and just kept on cutting [http://time.com/4175148/uber-price-drops/]. Already\nmarket leaders, they spent generously on cash bonuses\n[https://www.cnbc.com/2014/07/29/lyfts-sacrifice-for-the-sake-of-its-nyc-launch.html] \nand other driver incentives\n[https://www.uber.com/drive/atlanta/resources/driver-partner-incentive-guarantee-faq-questions/]\n.\n\nIn contrast, their early competitors bought into the eventually-true-but-not-yet\npromise of a world transformed\n[https://medium.com/ipg-media-lab/the-shift-towards-multimodal-transportation-the-future-of-mobility-d0c7c25d4a06] \nby app-based transportation, hoping to surf the seemingly blue ridesharing wave\n[https://www.huffpost.com/entry/uber-google-waze-ride-hailing-lyft_n_57c8558fe4b0a22de09485cc]\n.\n\nNothing wrong with being a small fish in a big, blue pond, right?\n\nThese hapless ride-surfers didnâ€™t realize supply-side sharks like Uber and Lyft\nwere the entire reason for the wave in the first place.\n\nHow did this tidal wave impact other ridesharing startups?\n\n * Unable to match the subsidized prices, other players failed to attract users\n * Fewer customers meant lower driver earnings, leading to an exodus of drivers\n * Sparse supply on the driver-side lengthened wait times, degrading the rider\n   experience, pushing more of them away\n * Declining usage scared off new investors\n * Incapable of raising fresh funds, the other fledging ridesharing startups,\n   metaphorically, drowned.\n\nThe â€œblue oceanâ€ turned red; the virtuous cycle turned vicious.\n\nActing with haste and fervor, Uber and Lyft established an insurmountable lead,\neffectively eliminating their U.S. competition before changing norms and\nconsumer behavior on the demand-side had a chance to catch up.\n\nIn other words, they saw red where others saw blue.\n\nLessons learned\nA few key takeaways:\n\n> 1. Supply is red, demand is blue\n * A merely growing market is not necessarily an attractive one\n * The drivers of growth matter more than the level of growth\n\n> 2. The deep sea requires deep pockets\n * Capital can often be converted directly into market share\n * Red ocean markets demand significant capital, as growth is unprofitable\n   [https://www.reuters.com/article/us-uber-usa/uber-boss-says-u-s-market-unprofitable-amid-tough-competition-from-lyft-idUSKBN1D9348] \n   in the short-run\n\n> 3. Cheap capital and disruptive innovation create supply-side tsunamis\n * When capital is inexpensive, supply reacts to innovation much faster than\n   demand\n\nThat the ridesharing market could consolidate so early in its existence is\nremarkable but also perhaps predictable if one understands itâ€™s supply-side\norigins.\n\nAnd despite an evolution of norms around getting into a strangerâ€™s car, Uber and\nLyft are betting big\n[https://mashable.com/article/lyft-ipo-self-driving-cars-investors/] on another\nsupply-side innovation: autonomous vehicles\n[https://www.businessinsider.com/uber-lyft-self-driving-taxis-may-not-help-profitability-mit-2019-5]\n.\n\nWhy? Again: to push out the supply curve, drive down prices, expand usage,\nattract capital, and reinvest in more robotaxis.\n\nIn other words, itâ€™s the same supply-driven growth story all over again.\n\nThat the two ridesharing leaders continue to operate unprofitably at scale only\nfurther drives the point home. This is not a demand-side story and never has\nbeen.\n\nThis is a cautionary tale for entrepreneurs and investors clamoring to\ncapitalize on the latest â€œwaveâ€.\n\nSometimes, the right kind of rose-tinted glasses isnâ€™t such a bad thing.","feature_image":"__GHOST_URL__/content/images/2020/01/91YCWH4jFdL.jpg","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-01-28T08:56:52.000Z","updated_at":"2020-03-23T16:31:14.000Z","published_at":"2020-01-29T19:21:20.000Z","custom_excerpt":"A quick visit to the Red Sea","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5e52c49cd2341b714b9b6d88","uuid":"395e4759-03b1-4d44-868c-8fb2069f4cac","title":"How Age, Race, and Gender Affect Software Engineering Pay","slug":"age-race-gender-software-engineering-pay","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive a report with the full results</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Your Email Address\\\" id=\\\"mce-EMAIL\\\" required>\\n<input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: How Age, Race, and Gender Affect Software Engineering Pay\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Send Report âš¡</span></button>\\n</form>\\n            </section>\"}],[\"html\",{\"html\":\"<div class=\\\"igraph\\\">\\n    <a href=\\\"https://plot.ly/~whoisnnamdi/49/?share_key=A4rtkRSqRGar7d19Zq3Xf6\\\" target=\\\"_blank\\\" title=\\\"Age\\\" style=\\\"text-align: center;\\\"><img src=\\\"https://plot.ly/~whoisnnamdi/49.png?share_key=AeS6BZEpGR5FXWfIFa29gc\\\" alt=\\\"Age\\\" style=\\\"max-width: 100%;width: 600px;\\\"  width=\\\"600\\\" onerror=\\\"this.onerror=null;this.src='https://plot.ly/404.png';\\\" /></a>\\n    <script data-plotly=\\\"whoisnnamdi:49\\\" sharekey-plotly=\\\"A4rtkRSqRGar7d19Zq3Xf6&link=false&logo=false\\\" src=\\\"https://plot.ly/embed.js\\\" async></script>\\n</div>\"}],[\"html\",{\"html\":\"<div class=\\\"igraph\\\">\\n    <a href=\\\"https://plot.ly/~whoisnnamdi/63/?share_key=zIzwrGKK43zEpTMXUKUt9A\\\" target=\\\"_blank\\\" title=\\\"45_50\\\" style=\\\"text-align: center;\\\"><img src=\\\"https://plot.ly/~whoisnnamdi/63.png?share_key=zIzwrGKK43zEpTMXUKUt9A\\\" alt=\\\"45_50\\\" style=\\\"max-width: 100%;width: 600px;\\\"  width=\\\"600\\\" onerror=\\\"this.onerror=null;this.src='https://plot.ly/404.png';\\\" /></a>\\n    <script data-plotly=\\\"whoisnnamdi:63\\\" sharekey-plotly=\\\"zIzwrGKK43zEpTMXUKUt9A&link=false&logo=false\\\" src=\\\"https://plot.ly/embed.js\\\" async></script>\\n</div>\"}],[\"html\",{\"html\":\"<div class=\\\"igraph\\\">\\n    <a href=\\\"https://plot.ly/~whoisnnamdi/42/?share_key=AeS6BZEpGR5FXWfIFa29gc\\\" target=\\\"_blank\\\" title=\\\"Ethnicity\\\" style=\\\"text-align: center;\\\"><img src=\\\"https://plot.ly/~whoisnnamdi/42.png?share_key=AeS6BZEpGR5FXWfIFa29gc\\\" alt=\\\"Ethnicity\\\" style=\\\"max-width: 100%;width: 600px;\\\"  width=\\\"600\\\" onerror=\\\"this.onerror=null;this.src='https://plot.ly/404.png';\\\" /></a>\\n    <script data-plotly=\\\"whoisnnamdi:42\\\" sharekey-plotly=\\\"AeS6BZEpGR5FXWfIFa29gc&link=false&logo=false\\\" src=\\\"https://plot.ly/embed.js\\\" async></script>\\n</div>\"}],[\"html\",{\"html\":\"<div class=\\\"igraph\\\">\\n    <a href=\\\"https://plot.ly/~whoisnnamdi/53/?share_key=u6QFIdd8N6y0GRHdUzflZT\\\" target=\\\"_blank\\\" title=\\\"East Asian\\\" style=\\\"text-align: center;\\\"><img src=\\\"https://plot.ly/~whoisnnamdi/53.png?share_key=u6QFIdd8N6y0GRHdUzflZT\\\" alt=\\\"East Asian\\\" style=\\\"max-width: 100%;width: 600px;\\\"  width=\\\"600\\\" onerror=\\\"this.onerror=null;this.src='https://plot.ly/404.png';\\\" /></a>\\n    <script data-plotly=\\\"whoisnnamdi:53\\\" sharekey-plotly=\\\"u6QFIdd8N6y0GRHdUzflZT&link=false&logo=false\\\" src=\\\"https://plot.ly/embed.js\\\" async></script>\\n</div>\"}],[\"html\",{\"html\":\"<div class=\\\"igraph\\\">\\n    <a href=\\\"https://plot.ly/~whoisnnamdi/55/?share_key=uWaEpRLPDnUZtrlzKx31LP\\\" target=\\\"_blank\\\" title=\\\"Black\\\" style=\\\"text-align: center;\\\"><img src=\\\"https://plot.ly/~whoisnnamdi/55.png?share_key=uWaEpRLPDnUZtrlzKx31LP\\\" alt=\\\"Black\\\" style=\\\"max-width: 100%;width: 600px;\\\"  width=\\\"600\\\" onerror=\\\"this.onerror=null;this.src='https://plot.ly/404.png';\\\" /></a>\\n    <script data-plotly=\\\"whoisnnamdi:55\\\" sharekey-plotly=\\\"uWaEpRLPDnUZtrlzKx31LP&link=false&logo=false\\\" src=\\\"https://plot.ly/embed.js\\\" async></script>\\n</div>\"}],[\"html\",{\"html\":\"<div class=\\\"igraph\\\">\\n    <a href=\\\"https://plot.ly/~whoisnnamdi/51/?share_key=D2GlnNRYyS41CEMS6rzhXy\\\" target=\\\"_blank\\\" title=\\\"Gender\\\" style=\\\"text-align: center;\\\"><img src=\\\"https://plot.ly/~whoisnnamdi/51.png?share_key=D2GlnNRYyS41CEMS6rzhXy\\\" alt=\\\"Ethnicity\\\" style=\\\"max-width: 100%;width: 600px;\\\"  width=\\\"600\\\" onerror=\\\"this.onerror=null;this.src='https://plot.ly/404.png';\\\" /></a>\\n    <script data-plotly=\\\"whoisnnamdi:51\\\" sharekey-plotly=\\\"D2GlnNRYyS41CEMS6rzhXy&link=false&logo=false\\\" src=\\\"https://plot.ly/embed.js\\\" async></script>\\n</div>\"}],[\"html\",{\"html\":\"<div class=\\\"igraph\\\">\\n    <a href=\\\"https://plot.ly/~whoisnnamdi/59/?share_key=QGU59riYZCzp45iDEoc7uJ\\\" target=\\\"_blank\\\" title=\\\"Woman\\\" style=\\\"text-align: center;\\\"><img src=\\\"https://plot.ly/~whoisnnamdi/59.png?share_key=QGU59riYZCzp45iDEoc7uJ\\\" alt=\\\"Woman\\\" style=\\\"max-width: 100%;width: 600px;\\\"  width=\\\"600\\\" onerror=\\\"this.onerror=null;this.src='https://plot.ly/404.png';\\\" /></a>\\n    <script data-plotly=\\\"whoisnnamdi:59\\\" sharekey-plotly=\\\"QGU59riYZCzp45iDEoc7uJ&link=false&logo=false\\\" src=\\\"https://plot.ly/embed.js\\\" async></script>\\n</div>\"}],[\"html\",{\"html\":\"<div class=\\\"igraph\\\">\\n    <a href=\\\"https://plot.ly/~whoisnnamdi/76/?share_key=9uXXMY4gKT4Ri9XCd2uQrx\\\" target=\\\"_blank\\\" title=\\\"Sexuality\\\" style=\\\"text-align: center;\\\"><img src=\\\"https://plot.ly/~whoisnnamdi/76.png?share_key=9uXXMY4gKT4Ri9XCd2uQrx\\\" alt=\\\"Sexuality\\\" style=\\\"max-width: 100%;width: 600px;\\\"  width=\\\"600\\\" onerror=\\\"this.onerror=null;this.src='https://plot.ly/404.png';\\\" /></a>\\n    <script data-plotly=\\\"whoisnnamdi:76\\\" sharekey-plotly=\\\"9uXXMY4gKT4Ri9XCd2uQrx&link=false&logo=false\\\" src=\\\"https://plot.ly/embed.js\\\" async></script>\\n</div>\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive a report with the full results</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Your Email Address\\\" id=\\\"mce-EMAIL\\\" required>\\n<input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Middle: How Age, Race, and Gender Affect Software Engineering Pay\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Send Report âš¡</span></button>\\n</form>\\n            </section>\"}],[\"html\",{\"html\":\"<div class=\\\"igraph\\\">\\n    <a href=\\\"https://plot.ly/~whoisnnamdi/65/?share_key=t51SFgyvKOWIwEl2u1Ld6N\\\" target=\\\"_blank\\\" title=\\\"Sexuality\\\" style=\\\"text-align: center;\\\"><img src=\\\"https://plot.ly/~whoisnnamdi/65.png?share_key=t51SFgyvKOWIwEl2u1Ld6N\\\" alt=\\\"Sexuality\\\" style=\\\"max-width: 100%;width: 600px;\\\"  width=\\\"600\\\" onerror=\\\"this.onerror=null;this.src='https://plot.ly/404.png';\\\" /></a>\\n    <script data-plotly=\\\"whoisnnamdi:65\\\" sharekey-plotly=\\\"t51SFgyvKOWIwEl2u1Ld6N&link=false&logo=false\\\" src=\\\"https://plot.ly/embed.js\\\" async></script>\\n</div>\"}],[\"html\",{\"html\":\"<div class=\\\"igraph\\\">\\n    <a href=\\\"https://plot.ly/~whoisnnamdi/67/?share_key=Sr50IIjPqYHtxWDS80yymI\\\" target=\\\"_blank\\\" title=\\\"gay_lesbian\\\" style=\\\"text-align: center;\\\"><img src=\\\"https://plot.ly/~whoisnnamdi/67.png?share_key=Sr50IIjPqYHtxWDS80yymI\\\" alt=\\\"gay_lesbian\\\" style=\\\"max-width: 100%;width: 600px;\\\"  width=\\\"600\\\" onerror=\\\"this.onerror=null;this.src='https://plot.ly/404.png';\\\" /></a>\\n    <script data-plotly=\\\"whoisnnamdi:67\\\" sharekey-plotly=\\\"Sr50IIjPqYHtxWDS80yymI&link=false&logo=false\\\" src=\\\"https://plot.ly/embed.js\\\" async></script>\\n</div>\"}],[\"html\",{\"html\":\"<div class=\\\"igraph\\\">\\n    <a href=\\\"https://plot.ly/~whoisnnamdi/69/?share_key=QxSeWndRHlY67kVOkXIxiF\\\" target=\\\"_blank\\\" title=\\\"bisexual\\\" style=\\\"text-align: center;\\\"><img src=\\\"https://plot.ly/~whoisnnamdi/69.png?share_key=QxSeWndRHlY67kVOkXIxiF\\\" alt=\\\"bisexual\\\" style=\\\"max-width: 100%;width: 600px;\\\"  width=\\\"600\\\" onerror=\\\"this.onerror=null;this.src='https://plot.ly/404.png';\\\" /></a>\\n    <script data-plotly=\\\"whoisnnamdi:69\\\" sharekey-plotly=\\\"QxSeWndRHlY67kVOkXIxiF&link=false&logo=false\\\" src=\\\"https://plot.ly/embed.js\\\" async></script>\\n</div>\"}],[\"html\",{\"html\":\"<div class=\\\"igraph\\\">\\n    <a href=\\\"https://plot.ly/~whoisnnamdi/71/?share_key=dWo5kDpYg4FllIVKqQa5Ae\\\" target=\\\"_blank\\\" title=\\\"Dependents\\\" style=\\\"text-align: center;\\\"><img src=\\\"https://plot.ly/~whoisnnamdi/71.png?share_key=dWo5kDpYg4FllIVKqQa5Ae\\\" alt=\\\"Dependents\\\" style=\\\"max-width: 100%;width: 600px;\\\"  width=\\\"600\\\" onerror=\\\"this.onerror=null;this.src='https://plot.ly/404.png';\\\" /></a>\\n    <script data-plotly=\\\"whoisnnamdi:71\\\" sharekey-plotly=\\\"dWo5kDpYg4FllIVKqQa5Ae&link=false&logo=false\\\" src=\\\"https://plot.ly/embed.js\\\" async></script>\\n</div>\"}],[\"html\",{\"html\":\"<div class=\\\"igraph\\\">\\n    <a href=\\\"https://plot.ly/~whoisnnamdi/73/?share_key=r1C05eXGR0rC3Qa0ZQja0q\\\" target=\\\"_blank\\\" title=\\\"yes\\\" style=\\\"text-align: center;\\\"><img src=\\\"https://plot.ly/~whoisnnamdi/73.png?share_key=r1C05eXGR0rC3Qa0ZQja0q\\\" alt=\\\"yes\\\" style=\\\"max-width: 100%;width: 600px;\\\"  width=\\\"600\\\" onerror=\\\"this.onerror=null;this.src='https://plot.ly/404.png';\\\" /></a>\\n    <script data-plotly=\\\"whoisnnamdi:73\\\" sharekey-plotly=\\\"r1C05eXGR0rC3Qa0ZQja0q&link=false&logo=false\\\" src=\\\"https://plot.ly/embed.js\\\" async></script>\\n</div>\"}]],\"markups\":[[\"em\"],[\"a\",[\"href\",\"__GHOST_URL__/highest-paid-software-engineers-2020\"]],[\"strong\"],[\"code\"],[\"a\",[\"href\",\"__GHOST_URL__/highest-paid-software-developer/\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Kernel_density_estimation\"]],[\"a\",[\"href\",\"https://insights.stackoverflow.com/survey/2019\"]]],\"sections\":[[1,\"p\",[[0,[0],0,\"This is part 1 of my 2020 analysis of software developer earnings. You can find the rest of the results and methodology \"],[0,[1],1,\"here\"],[0,[],1,\".\"]]],[1,\"p\",[[0,[],0,\"Age. Race. Gender. Sexual orientation.\"]]],[1,\"p\",[[0,[],0,\"In an ideal world, none of these factors would matter for what a software engineer earns. As characteristics, they shouldnâ€™t necessarily influence the productivity or value of a developer, and hence shouldnâ€™t affect pay.\"]]],[1,\"p\",[[0,[],0,\"Turns out, however, they do â€” though not always in the way or to the degree you might expect.\"]]],[1,\"p\",[[0,[],0,\"In this first part of my 2020 analysis of software engineering pay, I explore how these demographic characteristics match with developer pay, tease apart correlation from causation, and explain the confounding factors driving some of the more surprising results.\"]]],[1,\"p\",[[0,[2],1,\"Key findings:\"]]],[3,\"ul\",[[[0,[],0,\"Earnings peak around 45-50 years of \"],[0,[3],1,\"age\"],[0,[],0,\"\"]],[[0,[3],1,\"Racial minorities\"],[0,[],0,\" make up both the highest and lowest-paid developers\"]],[[0,[3],1,\"Female\"],[0,[],0,\" software engineers earn ~10% lower salaries than their male counterparts, but \"],[0,[3],1,\"professional experience\"],[0,[],0,\" explains most of the gap\"]],[[0,[3],1,\"Gay and lesbian\"],[0,[],0,\" engineers earn more than \"],[0,[3],1,\"straight\"],[0,[],0,\" engineers after adjusting for observable factors\"]],[[0,[3],1,\"Parents\"],[0,[],0,\" earn significantly more that \"],[0,[3],1,\"non-parents\"],[0,[],0,\", but this is explained by other factors\"]]]],[1,\"p\",[[0,[],0,\"If you havenâ€™t already, please check out the \"],[0,[1],1,\"methodology behind the analysis\"],[0,[],0,\", otherwise the numbers below might be difficult to interpret.\"]]],[10,0],[1,\"h2\",[[0,[],0,\"Age\"]]],[10,1],[1,\"h3\",[[0,[],0,\"Earnings peak in the late 40s\"]]],[1,\"p\",[[0,[],0,\"Developer earnings rise fairly steadily from the early 20s through the late 40s. \"],[0,[2],1,\"The late 40s represent the highest earnings of a developerâ€™s life\"],[0,[],0,\", where the average developer earns \"],[0,[2],1,\"28.7%\"],[0,[],0,\" more than the typical 26-30 year old (the most common age range in the data), after which pay stabilizes before finally beginning to decline in the early 60s.\"]]],[1,\"h3\",[[0,[],0,\"Age doesnâ€™t matter much after 35\"]]],[1,\"p\",[[0,[],0,\"However, adjusting for other characteristics, \"],[0,[3],1,\"age\"],[0,[],0,\" is most â€œadvantageousâ€ in the 31-35 range, when a developer can expect to earn \"],[0,[2],1,\"4.7%\"],[0,[],0,\" more than an equivalent developer five years their junior. This advantage is highly statistically significant.\"]]],[1,\"p\",[[0,[],0,\"The pay bump quickly dissipates with additional years however, losing statistical significance and even turning somewhat negative by the 51 to 55 range, though this is not precisely estimated.\"]]],[1,\"p\",[[0,[],0,\"The key point is that the additional income earned by older developers is entirely explained by factors unrelated to age. When we control for other factors, \"],[0,[2],0,\"pay does not vary much by \"],[0,[3],1,\"age\"],[0,[],1,\" after 35.\"]]],[1,\"h3\",[[0,[],0,\"Little causal impact of age\"]]],[1,\"p\",[[0,[],0,\"Why does the correlation between \"],[0,[3],1,\"age\"],[0,[],0,\" and income disappear after controlling for other factors? Letâ€™s dig in:\"]]],[10,2],[1,\"p\",[[0,[],0,\"The analytics demonstrate that \"],[0,[3],1,\"years of professional coding experience\"],[0,[],0,\" matters much more than age itself, which is what youâ€™d hope to see. These additional \"],[0,[3],1,\"years of professional experience\"],[0,[],0,\" effectively explain the entire earnings premium for older software engineers.\"]]],[1,\"p\",[[0,[],0,\"Additionally important variables include \"],[0,[3],1,\"self-rated competence\"],[0,[],0,\", having \"],[0,[3],1,\"influence over technology purchases\"],[0,[],0,\" in their organization, and \"],[0,[3],1,\"working remotely\"],[0,[],0,\" (which older workers are more likely to do), and having dependents.\"]]],[1,\"h2\",[[0,[],0,\"Race\"]]],[10,3],[1,\"h3\",[[0,[],0,\"Minorities are both the highest and lowest-paid software developers\"]]],[1,\"p\",[[0,[],0,\"As in \"],[0,[4],1,\"last yearâ€™s analysis\"],[0,[],0,\", the largest pay gaps are between minority groups, which make up both the highest and lowest-paid developers.\"]]],[1,\"p\",[[0,[3],1,\"East\"],[0,[],0,\" and \"],[0,[3],1,\"South Asians\"],[0,[],0,\" see the most statistically significant pay premiums relative to white developers with or without controls in the regression. In the case of \"],[0,[3],1,\"East Asians\"],[0,[],0,\", their pay premium \"],[0,[0],1,\"increases\"],[0,[],0,\" after controlling for various factors.\"]]],[1,\"p\",[[0,[],0,\"These premiums are large and meaningful â€” \"],[0,[3],1,\"East Asians\"],[0,[],0,\" earn \"],[0,[2],1,\"7.4%\"],[0,[],0,\" more than white developers and \"],[0,[2],1,\"13.9%\"],[0,[],0,\" more controlling for observable characteristics, while \"],[0,[3],1,\"South Asians\"],[0,[],0,\" earn \"],[0,[2],1,\"13.1%\"],[0,[],0,\" unadjusted and \"],[0,[2],1,\"8.1%\"],[0,[],0,\" adjusted more than \"],[0,[3],1,\"whites\"],[0,[],0,\" respectively.\"]]],[1,\"h3\",[[0,[],0,\"Examining the East Asian pay advantage\"]]],[1,\"p\",[[0,[],0,\"Breaking down the explainable \"],[0,[3],1,\"East Asian\"],[0,[],0,\" earnings premium yields some interesting findings:\"]]],[10,4],[1,\"p\",[[0,[],0,\"First â€” \"],[0,[3],1,\"years of professional coding experience\"],[0,[],0,\" is far and away the biggest factor holding down the pay of \"],[0,[3],1,\"East Asian\"],[0,[],0,\" software engineers. \"],[0,[3],1,\"East Asian\"],[0,[],0,\" developers typically have less work experience than whites, which holds down their earnings.\"]]],[3,\"ul\",[[[0,[],0,\"My calculations suggest that \"],[0,[3],1,\"East Asian\"],[0,[],0,\" developer would earn \"],[0,[2],1,\"8.0%\"],[0,[],0,\" more if they had similar amounts of professional experience as whites\"]],[[0,[],0,\"This rises to \"],[0,[2],1,\"9.0%\"],[0,[],0,\" if we add in additional, non-professional, coding experience.\"]]]],[1,\"p\",[[0,[3],1,\"Age\"],[0,[],0,\" also holds back \"],[0,[3],1,\"East Asian\"],[0,[],0,\" developers, as they are typically younger than white developers. This amounts to a \"],[0,[2],1,\"2.0%\"],[0,[],0,\" pay disadvantage.\"]]],[1,\"p\",[[0,[],0,\"Lastly, the sheer magnitude of the earnings premium enjoyed by \"],[0,[3],1,\"Asian\"],[0,[],0,\" developers should be noted. That the premium remains so large even after controlling for various factors is puzzling.\"]]],[1,\"h3\",[[0,[],0,\"Good and bad news for black software developers\"]]],[1,\"p\",[[0,[],0,\"Letâ€™s look at one more â€” the pay gap for \"],[0,[3],1,\"black\"],[0,[],0,\" developers. The unadjusted gap â€” which again simply compares average earnings of \"],[0,[3],1,\"black\"],[0,[],0,\" and \"],[0,[3],1,\"white\"],[0,[],0,\" developers â€” is \"],[0,[2],1,\"-7.6%\"],[0,[],0,\", while the adjusted gap contracts meaningfully to \"],[0,[2],1,\"-0.3%\"],[0,[],0,\", which is not statistically significant:\"]]],[10,5],[1,\"p\",[[0,[],0,\"Breaking down the explainable gap for \"],[0,[3],1,\"blacks\"],[0,[],0,\" reveals similar drivers as we saw in the \"],[0,[3],1,\"East Asian\"],[0,[],0,\" case. \"],[0,[3],1,\"Years of professional coding experience\"],[0,[],0,\" is the main contributor to lower pay for black software engineers relative to \"],[0,[3],1,\"whites\"],[0,[],0,\", in total driving \"],[0,[2],1,\"5.8\"],[0,[],0,\" percentage points of the overall 7.6% gap. Nothing else matters nearly as much.\"]]],[1,\"p\",[[0,[],0,\"In a sense, this is heartening. Assuming a \"],[0,[3],1,\"black\"],[0,[],0,\" engineer gets as much out of an additional year of work experience as anyone else, purely closing the gap there would bring black pay nearly in line with white pay.\"]]],[1,\"p\",[[0,[],0,\"On the other hand, that the unadjusted gap is explainable via \"],[0,[3],1,\"years of experience\"],[0,[],0,\" also means that the gap is unlikely to close anytime soon.\"]]],[1,\"p\",[[0,[],0,\"Why? The \"],[0,[3],1,\"age\"],[0,[],0,\" structure of the workplace is slow to change â€” it takes decades to see sizable shifts\"]]],[3,\"ul\",[[[0,[],0,\"Additionally, as the industry diversifies, by definition most \"],[0,[3],1,\"black\"],[0,[],0,\" professionals entering the software development career track start off at the bottom rung of the ladder\"]],[[0,[],0,\"Thus, the diversification of the industry in fact depresses average \"],[0,[3],1,\"black\"],[0,[],0,\" earnings, as fresh out of bootcamp developers donâ€™t earn nearly as much as seasoned veterans\"]]]],[1,\"p\",[[0,[],0,\"This is not a bad thing â€” but it does mean I canâ€™t conclude something nefarious is behind the slow convergence of \"],[0,[3],1,\"black\"],[0,[],0,\" and \"],[0,[3],1,\"white\"],[0,[],0,\" wages without other evidence.\"]]],[1,\"p\",[[0,[],0,\"The other factor worth touching on is \"],[0,[3],1,\"ImpSyn\"],[0,[],0,\" which is a variable representing a respondentâ€™s own \"],[0,[3],1,\"confidence\"],[0,[],0,\" in their skills as a software developer. More \"],[0,[3],1,\"confident\"],[0,[],0,\" developers earn more, and there appears to be a confidence gap between black and white developers driving \"],[0,[2],1,\"1.1%\"],[0,[],0,\" of the earnings gap.\"]]],[1,\"h2\",[[0,[],0,\"Gender\"]]],[10,6],[1,\"h3\",[[0,[],0,\"Young women entering the software development workforce pull down average female earnings\"]]],[1,\"p\",[[0,[3],1,\"Women\"],[0,[],0,\" earn \"],[0,[2],1,\"10.0%\"],[0,[],0,\" less than male software engineers on average, a sizable difference. However, this gap is effectively eliminated once we adjust for controllable factors, falling to only \"],[0,[2],1,\"1.4%\"],[0,[],0,\", which is not statistically significant.\"]]],[1,\"p\",[[0,[],0,\"In diagnosing the unadjusted 10.0% pay gap for \"],[0,[3],1,\"women\"],[0,[],0,\", \"],[0,[3],1,\"years of experience\"],[0,[],0,\" pops up once again as a dominant factor explaining most of the gap:\"]]],[10,7],[1,\"p\",[[0,[2],1,\"5.7\"],[0,[],0,\" percentage points of the \"],[0,[3],1,\"gender\"],[0,[],0,\" pay gap can be explained by the fact that \"],[0,[3],1,\"female\"],[0,[],0,\" developers have less professional experience than \"],[0,[3],1,\"male\"],[0,[],0,\" developers on average. Adding in overall \"],[0,[3],1,\"coding experience\"],[0,[],0,\" explains \"],[0,[2],1,\"7.1\"],[0,[],0,\" total percentage points of the overall gap.\"]]],[10,8],[1,\"p\",[[0,[],0,\"While \"],[0,[3],1,\"women\"],[0,[],0,\" are only 1.7 years younger than \"],[0,[3],1,\"men\"],[0,[],0,\" on average in the dataset, they have \"],[0,[2],1,\"3.3\"],[0,[],0,\" fewer \"],[0,[3],1,\"years of professional coding experience\"],[0,[],0,\" (7.1 years for \"],[0,[3],1,\"women\"],[0,[],0,\" vs. 10.4 for \"],[0,[3],1,\"men\"],[0,[],0,\"). We can see this in the histogram / \"],[0,[5],1,\"kernel density estimation\"],[0,[],0,\" comparing the respective distributions of \"],[0,[3],1,\"years of professional coding experience\"],[0,[],0,\" of \"],[0,[3],1,\"men\"],[0,[],0,\" and \"],[0,[3],1,\"women\"],[0,[],0,\", where the distribution for \"],[0,[3],1,\"women\"],[0,[],0,\" is shifted and more clustered to the left. This meaningful difference explains why \"],[0,[3],1,\"professional experience\"],[0,[],0,\" is such as major driver of the gender wage gap.\"]]],[1,\"p\",[[0,[3],1,\"Confidence\"],[0,[],0,\" (\"],[0,[3],1,\"ImpSyn\"],[0,[],0,\") comes up again as a factor pulling down \"],[0,[3],1,\"female\"],[0,[],0,\" wages. Here, the \"],[0,[3],1,\"confidence\"],[0,[],0,\" gap explains \"],[0,[2],1,\"1.0%\"],[0,[],0,\" of the overall \"],[0,[3],1,\"female-male\"],[0,[],0,\" \"],[0,[3],1,\"gender\"],[0,[],0,\" gap, very similar in magnitude to that of \"],[0,[3],1,\"black\"],[0,[],0,\" developers vs. \"],[0,[3],1,\"white\"],[0,[],0,\" developers.\"]]],[1,\"h3\",[[0,[],0,\"Small contribution from other factors\"]]],[1,\"p\",[[0,[],0,\"In line with other research, \"],[0,[3],1,\"women\"],[0,[],0,\" are also less confident about their own programming skills than \"],[0,[3],1,\"men\"],[0,[],0,\" are (who for all we know might be overconfident), which explains another \"],[0,[2],1,\"1.0%\"],[0,[],0,\" of the total gap (because higher confidence leads to higher pay, as I cover in a later post).\"]]],[1,\"p\",[[0,[],0,\"Experience and confidence collectively explain \"],[0,[2],1,\"8.1%\"],[0,[],0,\" of the gender pay gap among software engineers, leaving only a 1.9% gap, including the 1.4 percentage point difference that we cannot explain.\"]]],[10,9],[1,\"h2\",[[0,[],0,\"Sexual orientation\"]]],[10,10],[1,\"h3\",[[0,[],0,\"Earnings penalty for non-straight developers disappears after controlling for other factors\"]]],[1,\"p\",[[0,[],0,\"Unadjusted pay gaps among non-straight software engineers ranges from \"],[0,[2],1,\"2.5%\"],[0,[],0,\" for \"],[0,[3],1,\"gay\"],[0,[],0,\" and \"],[0,[3],1,\"lesbian\"],[0,[],0,\" developers to \"],[0,[2],1,\"9.6%\"],[0,[],0,\" for \"],[0,[3],1,\"bisexual\"],[0,[],0,\" developers, which simply means these individuals earn less on average than \"],[0,[3],1,\"straight\"],[0,[],0,\" engineers.\"]]],[1,\"p\",[[0,[],0,\"In the case of \"],[0,[3],1,\"gay\"],[0,[],0,\" and \"],[0,[3],1,\"lesbian\"],[0,[],0,\" developers however, this gap closes and actually reverses once I add controls. The gap becomes a pay \"],[0,[0],1,\"advantage\"],[0,[],0,\" of \"],[0,[2],1,\"3.4%\"],[0,[],0,\".\"]]],[10,11],[1,\"p\",[[0,[],0,\"Starting at the adjusted / unexplained 3.4% premium, the lower average unadjusted earnings is largely accounted for by \"],[0,[3],1,\"years of professional coding experience\"],[0,[],0,\" (a recurring theme) and \"],[0,[3],1,\"age\"],[0,[],0,\", suggesting that \"],[0,[3],1,\"gay\"],[0,[],0,\" and \"],[0,[3],1,\"lesbian\"],[0,[],0,\" developers are simply earlier in their careers than \"],[0,[3],1,\"straight\"],[0,[],0,\" developers, on average.\"]]],[1,\"p\",[[0,[],0,\"The decomposition of the difference in adjusted and unadjusted pay gaps is quite similar for \"],[0,[3],1,\"bisexual\"],[0,[],0,\" developers. \"],[0,[3],1,\"Professional experience\"],[0,[],0,\" and \"],[0,[3],1,\"age\"],[0,[],0,\" continue to the do the most explanatory work here:\"]]],[10,12],[1,\"h2\",[[0,[],0,\"Parenthood\"]]],[10,13],[1,\"h3\",[[0,[],0,\"Parents earn more, but this is largely explained by other factors\"]]],[1,\"p\",[[0,[],0,\"Software engineers with \"],[0,[3],1,\"dependents\"],[0,[],0,\" (typically children) earn \"],[0,[2],1,\"17.2%\"],[0,[],0,\" more than those without, but this earnings premium can be almost entirely accounted for via the other factors described in this analysis.\"]]],[10,14],[1,\"p\",[[0,[],0,\"Controlling for these variables reduces the parenthood earnings premium to \"],[0,[2],1,\"1.5%\"],[0,[],0,\", which is small but statistically significant.\"]]],[3,\"ul\",[[[0,[],0,\"Perhaps the data reflects that these developers earn extra income in order to take care of their \"],[0,[3],1,\"dependents\"],[0,[],0,\"\"]],[[0,[],0,\"Such a small bump in earnings like does not cover the additional expense of a child or other \"],[0,[3],1,\"dependent\"],[0,[],0,\", however\"]]]],[1,\"p\",[[0,[],0,\"Unsurprisingly, \"],[0,[3],1,\"years of software development experience\"],[0,[],0,\" and \"],[0,[3],1,\"age\"],[0,[],0,\" account for most of the earnings premium among parents. These are largely mid and late career engineers.\"]]],[1,\"p\",[[0,[3],1,\"Working remote\"],[0,[],0,\" explains another \"],[0,[2],1,\"1.1%\"],[0,[],0,\" of the pay premium among parents, as they are more likely to work from home, which makes sense given they may have a child to take care of.\"]]],[1,\"h2\",[[0,[],0,\"Conclusion: Significant progress on pay\"]]],[1,\"p\",[[0,[],0,\"Not to editorialize, but I was encouraged by many of the results here. In general, along most dimensions, discrimination in software developer earnings appears small once various factors are controlled for. In most cases, the biggest factors were some combination of \"],[0,[3],1,\"years of coding experience\"],[0,[],0,\" and \"],[0,[3],1,\"age\"],[0,[],0,\" which are both â€œproblemsâ€ that will largely fix themselves as the industry diversifies.\"]]],[1,\"p\",[[0,[],0,\"With the exception of \"],[0,[3],1,\"race\"],[0,[],0,\", most of the gaps are no more than a few percentage points in magnitude. In the case of race, the gaps are meaningful in some cases but difference is in fact \"],[0,[0],1,\"in favor\"],[0,[],0,\" of minority groups like \"],[0,[3],1,\"East Asian\"],[0,[],0,\", \"],[0,[3],1,\"South Asian\"],[0,[],0,\", and \"],[0,[3],1,\"Middle Eastern\"],[0,[],0,\" software developers. Their pay advantages are substantial, and the data from the \"],[0,[6],1,\"Stack Overflow\"],[0,[],0,\" survey fail to fully explain these gaps.\"]]],[1,\"p\",[[0,[],0,\"The usual caveats to pay analyses apply here as well. Finding little discrimination on pay, after controlling for factors such as \"],[0,[3],1,\"job title\"],[0,[],0,\", does not disprove discrimination in its entirety.\"]]],[3,\"ul\",[[[0,[],0,\"For example, if \"],[0,[3],1,\"female\"],[0,[],0,\" software engineers face discrimination in the form of reduced upward career mobility, that will not show up in this analysis, even though it depresses their earnings\"]],[[0,[],0,\"The same would apply to older software developers, who may be pressured out of their organizations to make room for cheaper, younger developers.\"]]]],[1,\"p\",[[0,[],0,\"Analogous statistical caveats abound.\"]]],[1,\"p\",[[0,[],0,\"That said, the data suggest the software development industry is well on its way to pay parity across the important dimensions of age, race, gender, and sexuality.\"]]],[1,\"p\",[[0,[0],0,\"Thanks for reading part 1 of my 2020 analysis of software developer pay. You can find the rest of the analysis and methodology \"],[0,[1],1,\"here\"],[0,[],1,\".\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p><em>This is part 1 of my 2020 analysis of software developer earnings. You can find the rest of the results and methodology <a href=\"__GHOST_URL__/highest-paid-software-engineers-2020\">here</a>.</em></p><p>Age. Race. Gender. Sexual orientation.</p><p>In an ideal world, none of these factors would matter for what a software engineer earns. As characteristics, they shouldnâ€™t necessarily influence the productivity or value of a developer, and hence shouldnâ€™t affect pay.</p><p>Turns out, however, they do â€” though not always in the way or to the degree you might expect.</p><p>In this first part of my 2020 analysis of software engineering pay, I explore how these demographic characteristics match with developer pay, tease apart correlation from causation, and explain the confounding factors driving some of the more surprising results.</p><p><strong>Key findings:</strong></p><ul><li>Earnings peak around 45-50 years of <code>age</code></li><li><code>Racial minorities</code> make up both the highest and lowest-paid developers</li><li><code>Female</code> software engineers earn ~10% lower salaries than their male counterparts, but <code>professional experience</code> explains most of the gap</li><li><code>Gay and lesbian</code> engineers earn more than <code>straight</code> engineers after adjusting for observable factors</li><li><code>Parents</code> earn significantly more that <code>non-parents</code>, but this is explained by other factors</li></ul><p>If you havenâ€™t already, please check out the <a href=\"__GHOST_URL__/highest-paid-software-engineers-2020\">methodology behind the analysis</a>, otherwise the numbers below might be difficult to interpret.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive a report with the full results</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Your Email Address\" id=\"mce-EMAIL\" required>\n<input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: How Age, Race, and Gender Affect Software Engineering Pay\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Send Report âš¡</span></button>\n</form>\n            </section><!--kg-card-end: html--><h2 id=\"age\">Age</h2><!--kg-card-begin: html--><div class=\"igraph\">\n    <a href=\"https://plot.ly/~whoisnnamdi/49/?share_key=A4rtkRSqRGar7d19Zq3Xf6\" target=\"_blank\" title=\"Age\" style=\"text-align: center;\"><img src=\"https://plot.ly/~whoisnnamdi/49.png?share_key=AeS6BZEpGR5FXWfIFa29gc\" alt=\"Age\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n    <script data-plotly=\"whoisnnamdi:49\" sharekey-plotly=\"A4rtkRSqRGar7d19Zq3Xf6&link=false&logo=false\" src=\"https://plot.ly/embed.js\" async></script>\n</div><!--kg-card-end: html--><h3 id=\"earnings-peak-in-the-late-40s\">Earnings peak in the late 40s</h3><p>Developer earnings rise fairly steadily from the early 20s through the late 40s. <strong>The late 40s represent the highest earnings of a developerâ€™s life</strong>, where the average developer earns <strong>28.7%</strong> more than the typical 26-30 year old (the most common age range in the data), after which pay stabilizes before finally beginning to decline in the early 60s.</p><h3 id=\"age-doesn-t-matter-much-after-35\">Age doesnâ€™t matter much after 35</h3><p>However, adjusting for other characteristics, <code>age</code> is most â€œadvantageousâ€ in the 31-35 range, when a developer can expect to earn <strong>4.7%</strong> more than an equivalent developer five years their junior. This advantage is highly statistically significant.</p><p>The pay bump quickly dissipates with additional years however, losing statistical significance and even turning somewhat negative by the 51 to 55 range, though this is not precisely estimated.</p><p>The key point is that the additional income earned by older developers is entirely explained by factors unrelated to age. When we control for other factors, <strong>pay does not vary much by <code>age</code> after 35.</strong></p><h3 id=\"little-causal-impact-of-age\">Little causal impact of age</h3><p>Why does the correlation between <code>age</code> and income disappear after controlling for other factors? Letâ€™s dig in:</p><!--kg-card-begin: html--><div class=\"igraph\">\n    <a href=\"https://plot.ly/~whoisnnamdi/63/?share_key=zIzwrGKK43zEpTMXUKUt9A\" target=\"_blank\" title=\"45_50\" style=\"text-align: center;\"><img src=\"https://plot.ly/~whoisnnamdi/63.png?share_key=zIzwrGKK43zEpTMXUKUt9A\" alt=\"45_50\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n    <script data-plotly=\"whoisnnamdi:63\" sharekey-plotly=\"zIzwrGKK43zEpTMXUKUt9A&link=false&logo=false\" src=\"https://plot.ly/embed.js\" async></script>\n</div><!--kg-card-end: html--><p>The analytics demonstrate that <code>years of professional coding experience</code> matters much more than age itself, which is what youâ€™d hope to see. These additional <code>years of professional experience</code> effectively explain the entire earnings premium for older software engineers.</p><p>Additionally important variables include <code>self-rated competence</code>, having <code>influence over technology purchases</code> in their organization, and <code>working remotely</code> (which older workers are more likely to do), and having dependents.</p><h2 id=\"race\">Race</h2><!--kg-card-begin: html--><div class=\"igraph\">\n    <a href=\"https://plot.ly/~whoisnnamdi/42/?share_key=AeS6BZEpGR5FXWfIFa29gc\" target=\"_blank\" title=\"Ethnicity\" style=\"text-align: center;\"><img src=\"https://plot.ly/~whoisnnamdi/42.png?share_key=AeS6BZEpGR5FXWfIFa29gc\" alt=\"Ethnicity\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n    <script data-plotly=\"whoisnnamdi:42\" sharekey-plotly=\"AeS6BZEpGR5FXWfIFa29gc&link=false&logo=false\" src=\"https://plot.ly/embed.js\" async></script>\n</div><!--kg-card-end: html--><h3 id=\"minorities-are-both-the-highest-and-lowest-paid-software-developers\">Minorities are both the highest and lowest-paid software developers</h3><p>As in <a href=\"__GHOST_URL__/highest-paid-software-developer/\">last yearâ€™s analysis</a>, the largest pay gaps are between minority groups, which make up both the highest and lowest-paid developers.</p><p><code>East</code> and <code>South Asians</code> see the most statistically significant pay premiums relative to white developers with or without controls in the regression. In the case of <code>East Asians</code>, their pay premium <em>increases</em> after controlling for various factors.</p><p>These premiums are large and meaningful â€” <code>East Asians</code> earn <strong>7.4%</strong> more than white developers and <strong>13.9%</strong> more controlling for observable characteristics, while <code>South Asians</code> earn <strong>13.1%</strong> unadjusted and <strong>8.1%</strong> adjusted more than <code>whites</code> respectively.</p><h3 id=\"examining-the-east-asian-pay-advantage\">Examining the East Asian pay advantage</h3><p>Breaking down the explainable <code>East Asian</code> earnings premium yields some interesting findings:</p><!--kg-card-begin: html--><div class=\"igraph\">\n    <a href=\"https://plot.ly/~whoisnnamdi/53/?share_key=u6QFIdd8N6y0GRHdUzflZT\" target=\"_blank\" title=\"East Asian\" style=\"text-align: center;\"><img src=\"https://plot.ly/~whoisnnamdi/53.png?share_key=u6QFIdd8N6y0GRHdUzflZT\" alt=\"East Asian\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n    <script data-plotly=\"whoisnnamdi:53\" sharekey-plotly=\"u6QFIdd8N6y0GRHdUzflZT&link=false&logo=false\" src=\"https://plot.ly/embed.js\" async></script>\n</div><!--kg-card-end: html--><p>First â€” <code>years of professional coding experience</code> is far and away the biggest factor holding down the pay of <code>East Asian</code> software engineers. <code>East Asian</code> developers typically have less work experience than whites, which holds down their earnings.</p><ul><li>My calculations suggest that <code>East Asian</code> developer would earn <strong>8.0%</strong> more if they had similar amounts of professional experience as whites</li><li>This rises to <strong>9.0%</strong> if we add in additional, non-professional, coding experience.</li></ul><p><code>Age</code> also holds back <code>East Asian</code> developers, as they are typically younger than white developers. This amounts to a <strong>2.0%</strong> pay disadvantage.</p><p>Lastly, the sheer magnitude of the earnings premium enjoyed by <code>Asian</code> developers should be noted. That the premium remains so large even after controlling for various factors is puzzling.</p><h3 id=\"good-and-bad-news-for-black-software-developers\">Good and bad news for black software developers</h3><p>Letâ€™s look at one more â€” the pay gap for <code>black</code> developers. The unadjusted gap â€” which again simply compares average earnings of <code>black</code> and <code>white</code> developers â€” is <strong>-7.6%</strong>, while the adjusted gap contracts meaningfully to <strong>-0.3%</strong>, which is not statistically significant:</p><!--kg-card-begin: html--><div class=\"igraph\">\n    <a href=\"https://plot.ly/~whoisnnamdi/55/?share_key=uWaEpRLPDnUZtrlzKx31LP\" target=\"_blank\" title=\"Black\" style=\"text-align: center;\"><img src=\"https://plot.ly/~whoisnnamdi/55.png?share_key=uWaEpRLPDnUZtrlzKx31LP\" alt=\"Black\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n    <script data-plotly=\"whoisnnamdi:55\" sharekey-plotly=\"uWaEpRLPDnUZtrlzKx31LP&link=false&logo=false\" src=\"https://plot.ly/embed.js\" async></script>\n</div><!--kg-card-end: html--><p>Breaking down the explainable gap for <code>blacks</code> reveals similar drivers as we saw in the <code>East Asian</code> case. <code>Years of professional coding experience</code> is the main contributor to lower pay for black software engineers relative to <code>whites</code>, in total driving <strong>5.8</strong> percentage points of the overall 7.6% gap. Nothing else matters nearly as much.</p><p>In a sense, this is heartening. Assuming a <code>black</code> engineer gets as much out of an additional year of work experience as anyone else, purely closing the gap there would bring black pay nearly in line with white pay.</p><p>On the other hand, that the unadjusted gap is explainable via <code>years of experience</code> also means that the gap is unlikely to close anytime soon.</p><p>Why? The <code>age</code> structure of the workplace is slow to change â€” it takes decades to see sizable shifts</p><ul><li>Additionally, as the industry diversifies, by definition most <code>black</code> professionals entering the software development career track start off at the bottom rung of the ladder</li><li>Thus, the diversification of the industry in fact depresses average <code>black</code> earnings, as fresh out of bootcamp developers donâ€™t earn nearly as much as seasoned veterans</li></ul><p>This is not a bad thing â€” but it does mean I canâ€™t conclude something nefarious is behind the slow convergence of <code>black</code> and <code>white</code> wages without other evidence.</p><p>The other factor worth touching on is <code>ImpSyn</code> which is a variable representing a respondentâ€™s own <code>confidence</code> in their skills as a software developer. More <code>confident</code> developers earn more, and there appears to be a confidence gap between black and white developers driving <strong>1.1%</strong> of the earnings gap.</p><h2 id=\"gender\">Gender</h2><!--kg-card-begin: html--><div class=\"igraph\">\n    <a href=\"https://plot.ly/~whoisnnamdi/51/?share_key=D2GlnNRYyS41CEMS6rzhXy\" target=\"_blank\" title=\"Gender\" style=\"text-align: center;\"><img src=\"https://plot.ly/~whoisnnamdi/51.png?share_key=D2GlnNRYyS41CEMS6rzhXy\" alt=\"Ethnicity\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n    <script data-plotly=\"whoisnnamdi:51\" sharekey-plotly=\"D2GlnNRYyS41CEMS6rzhXy&link=false&logo=false\" src=\"https://plot.ly/embed.js\" async></script>\n</div><!--kg-card-end: html--><h3 id=\"young-women-entering-the-software-development-workforce-pull-down-average-female-earnings\">Young women entering the software development workforce pull down average female earnings</h3><p><code>Women</code> earn <strong>10.0%</strong> less than male software engineers on average, a sizable difference. However, this gap is effectively eliminated once we adjust for controllable factors, falling to only <strong>1.4%</strong>, which is not statistically significant.</p><p>In diagnosing the unadjusted 10.0% pay gap for <code>women</code>, <code>years of experience</code> pops up once again as a dominant factor explaining most of the gap:</p><!--kg-card-begin: html--><div class=\"igraph\">\n    <a href=\"https://plot.ly/~whoisnnamdi/59/?share_key=QGU59riYZCzp45iDEoc7uJ\" target=\"_blank\" title=\"Woman\" style=\"text-align: center;\"><img src=\"https://plot.ly/~whoisnnamdi/59.png?share_key=QGU59riYZCzp45iDEoc7uJ\" alt=\"Woman\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n    <script data-plotly=\"whoisnnamdi:59\" sharekey-plotly=\"QGU59riYZCzp45iDEoc7uJ&link=false&logo=false\" src=\"https://plot.ly/embed.js\" async></script>\n</div><!--kg-card-end: html--><p><strong>5.7</strong> percentage points of the <code>gender</code> pay gap can be explained by the fact that <code>female</code> developers have less professional experience than <code>male</code> developers on average. Adding in overall <code>coding experience</code> explains <strong>7.1</strong> total percentage points of the overall gap.</p><!--kg-card-begin: html--><div class=\"igraph\">\n    <a href=\"https://plot.ly/~whoisnnamdi/76/?share_key=9uXXMY4gKT4Ri9XCd2uQrx\" target=\"_blank\" title=\"Sexuality\" style=\"text-align: center;\"><img src=\"https://plot.ly/~whoisnnamdi/76.png?share_key=9uXXMY4gKT4Ri9XCd2uQrx\" alt=\"Sexuality\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n    <script data-plotly=\"whoisnnamdi:76\" sharekey-plotly=\"9uXXMY4gKT4Ri9XCd2uQrx&link=false&logo=false\" src=\"https://plot.ly/embed.js\" async></script>\n</div><!--kg-card-end: html--><p>While <code>women</code> are only 1.7 years younger than <code>men</code> on average in the dataset, they have <strong>3.3</strong> fewer <code>years of professional coding experience</code> (7.1 years for <code>women</code> vs. 10.4 for <code>men</code>). We can see this in the histogram / <a href=\"https://en.wikipedia.org/wiki/Kernel_density_estimation\">kernel density estimation</a> comparing the respective distributions of <code>years of professional coding experience</code> of <code>men</code> and <code>women</code>, where the distribution for <code>women</code> is shifted and more clustered to the left. This meaningful difference explains why <code>professional experience</code> is such as major driver of the gender wage gap.</p><p><code>Confidence</code> (<code>ImpSyn</code>) comes up again as a factor pulling down <code>female</code> wages. Here, the <code>confidence</code> gap explains <strong>1.0%</strong> of the overall <code>female-male</code> <code>gender</code> gap, very similar in magnitude to that of <code>black</code> developers vs. <code>white</code> developers.</p><h3 id=\"small-contribution-from-other-factors\">Small contribution from other factors</h3><p>In line with other research, <code>women</code> are also less confident about their own programming skills than <code>men</code> are (who for all we know might be overconfident), which explains another <strong>1.0%</strong> of the total gap (because higher confidence leads to higher pay, as I cover in a later post).</p><p>Experience and confidence collectively explain <strong>8.1%</strong> of the gender pay gap among software engineers, leaving only a 1.9% gap, including the 1.4 percentage point difference that we cannot explain.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive a report with the full results</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Your Email Address\" id=\"mce-EMAIL\" required>\n<input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Middle: How Age, Race, and Gender Affect Software Engineering Pay\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Send Report âš¡</span></button>\n</form>\n            </section><!--kg-card-end: html--><h2 id=\"sexual-orientation\">Sexual orientation</h2><!--kg-card-begin: html--><div class=\"igraph\">\n    <a href=\"https://plot.ly/~whoisnnamdi/65/?share_key=t51SFgyvKOWIwEl2u1Ld6N\" target=\"_blank\" title=\"Sexuality\" style=\"text-align: center;\"><img src=\"https://plot.ly/~whoisnnamdi/65.png?share_key=t51SFgyvKOWIwEl2u1Ld6N\" alt=\"Sexuality\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n    <script data-plotly=\"whoisnnamdi:65\" sharekey-plotly=\"t51SFgyvKOWIwEl2u1Ld6N&link=false&logo=false\" src=\"https://plot.ly/embed.js\" async></script>\n</div><!--kg-card-end: html--><h3 id=\"earnings-penalty-for-non-straight-developers-disappears-after-controlling-for-other-factors\">Earnings penalty for non-straight developers disappears after controlling for other factors</h3><p>Unadjusted pay gaps among non-straight software engineers ranges from <strong>2.5%</strong> for <code>gay</code> and <code>lesbian</code> developers to <strong>9.6%</strong> for <code>bisexual</code> developers, which simply means these individuals earn less on average than <code>straight</code> engineers.</p><p>In the case of <code>gay</code> and <code>lesbian</code> developers however, this gap closes and actually reverses once I add controls. The gap becomes a pay <em>advantage</em> of <strong>3.4%</strong>.</p><!--kg-card-begin: html--><div class=\"igraph\">\n    <a href=\"https://plot.ly/~whoisnnamdi/67/?share_key=Sr50IIjPqYHtxWDS80yymI\" target=\"_blank\" title=\"gay_lesbian\" style=\"text-align: center;\"><img src=\"https://plot.ly/~whoisnnamdi/67.png?share_key=Sr50IIjPqYHtxWDS80yymI\" alt=\"gay_lesbian\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n    <script data-plotly=\"whoisnnamdi:67\" sharekey-plotly=\"Sr50IIjPqYHtxWDS80yymI&link=false&logo=false\" src=\"https://plot.ly/embed.js\" async></script>\n</div><!--kg-card-end: html--><p>Starting at the adjusted / unexplained 3.4% premium, the lower average unadjusted earnings is largely accounted for by <code>years of professional coding experience</code> (a recurring theme) and <code>age</code>, suggesting that <code>gay</code> and <code>lesbian</code> developers are simply earlier in their careers than <code>straight</code> developers, on average.</p><p>The decomposition of the difference in adjusted and unadjusted pay gaps is quite similar for <code>bisexual</code> developers. <code>Professional experience</code> and <code>age</code> continue to the do the most explanatory work here:</p><!--kg-card-begin: html--><div class=\"igraph\">\n    <a href=\"https://plot.ly/~whoisnnamdi/69/?share_key=QxSeWndRHlY67kVOkXIxiF\" target=\"_blank\" title=\"bisexual\" style=\"text-align: center;\"><img src=\"https://plot.ly/~whoisnnamdi/69.png?share_key=QxSeWndRHlY67kVOkXIxiF\" alt=\"bisexual\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n    <script data-plotly=\"whoisnnamdi:69\" sharekey-plotly=\"QxSeWndRHlY67kVOkXIxiF&link=false&logo=false\" src=\"https://plot.ly/embed.js\" async></script>\n</div><!--kg-card-end: html--><h2 id=\"parenthood\">Parenthood</h2><!--kg-card-begin: html--><div class=\"igraph\">\n    <a href=\"https://plot.ly/~whoisnnamdi/71/?share_key=dWo5kDpYg4FllIVKqQa5Ae\" target=\"_blank\" title=\"Dependents\" style=\"text-align: center;\"><img src=\"https://plot.ly/~whoisnnamdi/71.png?share_key=dWo5kDpYg4FllIVKqQa5Ae\" alt=\"Dependents\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n    <script data-plotly=\"whoisnnamdi:71\" sharekey-plotly=\"dWo5kDpYg4FllIVKqQa5Ae&link=false&logo=false\" src=\"https://plot.ly/embed.js\" async></script>\n</div><!--kg-card-end: html--><h3 id=\"parents-earn-more-but-this-is-largely-explained-by-other-factors\">Parents earn more, but this is largely explained by other factors</h3><p>Software engineers with <code>dependents</code> (typically children) earn <strong>17.2%</strong> more than those without, but this earnings premium can be almost entirely accounted for via the other factors described in this analysis.</p><!--kg-card-begin: html--><div class=\"igraph\">\n    <a href=\"https://plot.ly/~whoisnnamdi/73/?share_key=r1C05eXGR0rC3Qa0ZQja0q\" target=\"_blank\" title=\"yes\" style=\"text-align: center;\"><img src=\"https://plot.ly/~whoisnnamdi/73.png?share_key=r1C05eXGR0rC3Qa0ZQja0q\" alt=\"yes\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n    <script data-plotly=\"whoisnnamdi:73\" sharekey-plotly=\"r1C05eXGR0rC3Qa0ZQja0q&link=false&logo=false\" src=\"https://plot.ly/embed.js\" async></script>\n</div><!--kg-card-end: html--><p>Controlling for these variables reduces the parenthood earnings premium to <strong>1.5%</strong>, which is small but statistically significant.</p><ul><li>Perhaps the data reflects that these developers earn extra income in order to take care of their <code>dependents</code></li><li>Such a small bump in earnings like does not cover the additional expense of a child or other <code>dependent</code>, however</li></ul><p>Unsurprisingly, <code>years of software development experience</code> and <code>age</code> account for most of the earnings premium among parents. These are largely mid and late career engineers.</p><p><code>Working remote</code> explains another <strong>1.1%</strong> of the pay premium among parents, as they are more likely to work from home, which makes sense given they may have a child to take care of.</p><h2 id=\"conclusion-significant-progress-on-pay\">Conclusion: Significant progress on pay</h2><p>Not to editorialize, but I was encouraged by many of the results here. In general, along most dimensions, discrimination in software developer earnings appears small once various factors are controlled for. In most cases, the biggest factors were some combination of <code>years of coding experience</code> and <code>age</code> which are both â€œproblemsâ€ that will largely fix themselves as the industry diversifies.</p><p>With the exception of <code>race</code>, most of the gaps are no more than a few percentage points in magnitude. In the case of race, the gaps are meaningful in some cases but difference is in fact <em>in favor</em> of minority groups like <code>East Asian</code>, <code>South Asian</code>, and <code>Middle Eastern</code> software developers. Their pay advantages are substantial, and the data from the <a href=\"https://insights.stackoverflow.com/survey/2019\">Stack Overflow</a> survey fail to fully explain these gaps.</p><p>The usual caveats to pay analyses apply here as well. Finding little discrimination on pay, after controlling for factors such as <code>job title</code>, does not disprove discrimination in its entirety.</p><ul><li>For example, if <code>female</code> software engineers face discrimination in the form of reduced upward career mobility, that will not show up in this analysis, even though it depresses their earnings</li><li>The same would apply to older software developers, who may be pressured out of their organizations to make room for cheaper, younger developers.</li></ul><p>Analogous statistical caveats abound.</p><p>That said, the data suggest the software development industry is well on its way to pay parity across the important dimensions of age, race, gender, and sexuality.</p><p><em>Thanks for reading part 1 of my 2020 analysis of software developer pay. You can find the rest of the analysis and methodology <a href=\"__GHOST_URL__/highest-paid-software-engineers-2020\">here</a>.</em></p>","comment_id":"5e52c49cd2341b714b9b6d88","plaintext":"This is part 1 of my 2020 analysis of software developer earnings. You can find\nthe rest of the results and methodology here\n[__GHOST_URL__/highest-paid-software-engineers-2020].\n\nAge. Race. Gender. Sexual orientation.\n\nIn an ideal world, none of these factors would matter for what a software\nengineer earns. As characteristics, they shouldnâ€™t necessarily influence the\nproductivity or value of a developer, and hence shouldnâ€™t affect pay.\n\nTurns out, however, they do â€” though not always in the way or to the degree you\nmight expect.\n\nIn this first part of my 2020 analysis of software engineering pay, I explore\nhow these demographic characteristics match with developer pay, tease apart\ncorrelation from causation, and explain the confounding factors driving some of\nthe more surprising results.\n\nKey findings:\n\n * Earnings peak around 45-50 years of age\n * Racial minorities make up both the highest and lowest-paid developers\n * Female software engineers earn ~10% lower salaries than their male\n   counterparts, but professional experience explains most of the gap\n * Gay and lesbian engineers earn more than straight engineers after adjusting\n   for observable factors\n * Parents earn significantly more that non-parents, but this is explained by\n   other factors\n\nIf you havenâ€™t already, please check out the methodology behind the analysis\n[__GHOST_URL__/highest-paid-software-engineers-2020], otherwise the numbers\nbelow might be difficult to interpret.\n\nReceive a report with the full results\n\n\nSend Report âš¡ Age\n[https://plot.ly/~whoisnnamdi/49/?share_key=A4rtkRSqRGar7d19Zq3Xf6] Earnings\npeak in the late 40s\nDeveloper earnings rise fairly steadily from the early 20s through the late 40s. \nThe late 40s represent the highest earnings of a developerâ€™s life, where the\naverage developer earns 28.7% more than the typical 26-30 year old (the most\ncommon age range in the data), after which pay stabilizes before finally\nbeginning to decline in the early 60s.\n\nAge doesnâ€™t matter much after 35\nHowever, adjusting for other characteristics, age is most â€œadvantageousâ€ in the\n31-35 range, when a developer can expect to earn 4.7% more than an equivalent\ndeveloper five years their junior. This advantage is highly statistically\nsignificant.\n\nThe pay bump quickly dissipates with additional years however, losing\nstatistical significance and even turning somewhat negative by the 51 to 55\nrange, though this is not precisely estimated.\n\nThe key point is that the additional income earned by older developers is\nentirely explained by factors unrelated to age. When we control for other\nfactors, pay does not vary much by age after 35.\n\nLittle causal impact of age\nWhy does the correlation between age and income disappear after controlling for\nother factors? Letâ€™s dig in:\n\n[https://plot.ly/~whoisnnamdi/63/?share_key=zIzwrGKK43zEpTMXUKUt9A] The\nanalytics demonstrate that years of professional coding experience matters much\nmore than age itself, which is what youâ€™d hope to see. These additional years of\nprofessional experience effectively explain the entire earnings premium for\nolder software engineers.\n\nAdditionally important variables include self-rated competence, having influence\nover technology purchases in their organization, and working remotely (which\nolder workers are more likely to do), and having dependents.\n\nRace\n[https://plot.ly/~whoisnnamdi/42/?share_key=AeS6BZEpGR5FXWfIFa29gc] Minorities\nare both the highest and lowest-paid software developers\nAs in last yearâ€™s analysis [__GHOST_URL__/highest-paid-software-developer/], the\nlargest pay gaps are between minority groups, which make up both the highest and\nlowest-paid developers.\n\nEast and South Asians see the most statistically significant pay premiums\nrelative to white developers with or without controls in the regression. In the\ncase of East Asians, their pay premium increases after controlling for various\nfactors.\n\nThese premiums are large and meaningful â€” East Asians earn 7.4% more than white\ndevelopers and 13.9% more controlling for observable characteristics, while \nSouth Asians earn 13.1% unadjusted and 8.1% adjusted more than whites \nrespectively.\n\nExamining the East Asian pay advantage\nBreaking down the explainable East Asian earnings premium yields some\ninteresting findings:\n\n[https://plot.ly/~whoisnnamdi/53/?share_key=u6QFIdd8N6y0GRHdUzflZT] First â€” years of professional coding experience is far and away the biggest\nfactor holding down the pay of East Asian software engineers. East Asian \ndevelopers typically have less work experience than whites, which holds down\ntheir earnings.\n\n * My calculations suggest that East Asian developer would earn 8.0% more if\n   they had similar amounts of professional experience as whites\n * This rises to 9.0% if we add in additional, non-professional, coding\n   experience.\n\nAge also holds back East Asian developers, as they are typically younger than\nwhite developers. This amounts to a 2.0% pay disadvantage.\n\nLastly, the sheer magnitude of the earnings premium enjoyed by Asian developers\nshould be noted. That the premium remains so large even after controlling for\nvarious factors is puzzling.\n\nGood and bad news for black software developers\nLetâ€™s look at one more â€” the pay gap for black developers. The unadjusted gap â€”\nwhich again simply compares average earnings of black and white developers â€” is \n-7.6%, while the adjusted gap contracts meaningfully to -0.3%, which is not\nstatistically significant:\n\n[https://plot.ly/~whoisnnamdi/55/?share_key=uWaEpRLPDnUZtrlzKx31LP] Breaking\ndown the explainable gap for blacks reveals similar drivers as we saw in the \nEast Asian case. Years of professional coding experience is the main contributor\nto lower pay for black software engineers relative to whites, in total driving \n5.8 percentage points of the overall 7.6% gap. Nothing else matters nearly as\nmuch.\n\nIn a sense, this is heartening. Assuming a black engineer gets as much out of an\nadditional year of work experience as anyone else, purely closing the gap there\nwould bring black pay nearly in line with white pay.\n\nOn the other hand, that the unadjusted gap is explainable via years of\nexperience also means that the gap is unlikely to close anytime soon.\n\nWhy? The age structure of the workplace is slow to change â€” it takes decades to\nsee sizable shifts\n\n * Additionally, as the industry diversifies, by definition most black \n   professionals entering the software development career track start off at the\n   bottom rung of the ladder\n * Thus, the diversification of the industry in fact depresses average black \n   earnings, as fresh out of bootcamp developers donâ€™t earn nearly as much as\n   seasoned veterans\n\nThis is not a bad thing â€” but it does mean I canâ€™t conclude something nefarious\nis behind the slow convergence of black and white wages without other evidence.\n\nThe other factor worth touching on is ImpSyn which is a variable representing a\nrespondentâ€™s own confidence in their skills as a software developer. More \nconfident developers earn more, and there appears to be a confidence gap between\nblack and white developers driving 1.1% of the earnings gap.\n\nGender\n[https://plot.ly/~whoisnnamdi/51/?share_key=D2GlnNRYyS41CEMS6rzhXy] Young women\nentering the software development workforce pull down average female earnings\nWomen earn 10.0% less than male software engineers on average, a sizable\ndifference. However, this gap is effectively eliminated once we adjust for\ncontrollable factors, falling to only 1.4%, which is not statistically\nsignificant.\n\nIn diagnosing the unadjusted 10.0% pay gap for women, years of experience pops\nup once again as a dominant factor explaining most of the gap:\n\n[https://plot.ly/~whoisnnamdi/59/?share_key=QGU59riYZCzp45iDEoc7uJ] 5.7 percentage points of the gender pay gap can be explained by the fact that \nfemale developers have less professional experience than male developers on\naverage. Adding in overall coding experience explains 7.1 total percentage\npoints of the overall gap.\n\n[https://plot.ly/~whoisnnamdi/76/?share_key=9uXXMY4gKT4Ri9XCd2uQrx] While women are only 1.7 years younger than men on average in the dataset, they\nhave 3.3 fewer years of professional coding experience (7.1 years for women vs.\n10.4 for men). We can see this in the histogram / kernel density estimation\n[https://en.wikipedia.org/wiki/Kernel_density_estimation] comparing the\nrespective distributions of years of professional coding experience of men and \nwomen, where the distribution for women is shifted and more clustered to the\nleft. This meaningful difference explains why professional experience is such as\nmajor driver of the gender wage gap.\n\nConfidence (ImpSyn) comes up again as a factor pulling down female wages. Here,\nthe confidence gap explains 1.0% of the overall female-male gender gap, very\nsimilar in magnitude to that of black developers vs. white developers.\n\nSmall contribution from other factors\nIn line with other research, women are also less confident about their own\nprogramming skills than men are (who for all we know might be overconfident),\nwhich explains another 1.0% of the total gap (because higher confidence leads to\nhigher pay, as I cover in a later post).\n\nExperience and confidence collectively explain 8.1% of the gender pay gap among\nsoftware engineers, leaving only a 1.9% gap, including the 1.4 percentage point\ndifference that we cannot explain.\n\nReceive a report with the full results\n\n\nSend Report âš¡ Sexual orientation\n[https://plot.ly/~whoisnnamdi/65/?share_key=t51SFgyvKOWIwEl2u1Ld6N] Earnings\npenalty for non-straight developers disappears after controlling for other\nfactors\nUnadjusted pay gaps among non-straight software engineers ranges from 2.5% for \ngay and lesbian developers to 9.6% for bisexual developers, which simply means\nthese individuals earn less on average than straight engineers.\n\nIn the case of gay and lesbian developers however, this gap closes and actually\nreverses once I add controls. The gap becomes a pay advantage of 3.4%.\n\n[https://plot.ly/~whoisnnamdi/67/?share_key=Sr50IIjPqYHtxWDS80yymI] Starting at\nthe adjusted / unexplained 3.4% premium, the lower average unadjusted earnings\nis largely accounted for by years of professional coding experience (a recurring\ntheme) and age, suggesting that gay and lesbian developers are simply earlier in\ntheir careers than straight developers, on average.\n\nThe decomposition of the difference in adjusted and unadjusted pay gaps is quite\nsimilar for bisexual developers. Professional experience and age continue to the\ndo the most explanatory work here:\n\n[https://plot.ly/~whoisnnamdi/69/?share_key=QxSeWndRHlY67kVOkXIxiF] Parenthood\n[https://plot.ly/~whoisnnamdi/71/?share_key=dWo5kDpYg4FllIVKqQa5Ae] Parents earn\nmore, but this is largely explained by other factors\nSoftware engineers with dependents (typically children) earn 17.2% more than\nthose without, but this earnings premium can be almost entirely accounted for\nvia the other factors described in this analysis.\n\n[https://plot.ly/~whoisnnamdi/73/?share_key=r1C05eXGR0rC3Qa0ZQja0q] Controlling\nfor these variables reduces the parenthood earnings premium to 1.5%, which is\nsmall but statistically significant.\n\n * Perhaps the data reflects that these developers earn extra income in order to\n   take care of their dependents\n * Such a small bump in earnings like does not cover the additional expense of a\n   child or other dependent, however\n\nUnsurprisingly, years of software development experience and age account for\nmost of the earnings premium among parents. These are largely mid and late\ncareer engineers.\n\nWorking remote explains another 1.1% of the pay premium among parents, as they\nare more likely to work from home, which makes sense given they may have a child\nto take care of.\n\nConclusion: Significant progress on pay\nNot to editorialize, but I was encouraged by many of the results here. In\ngeneral, along most dimensions, discrimination in software developer earnings\nappears small once various factors are controlled for. In most cases, the\nbiggest factors were some combination of years of coding experience and age \nwhich are both â€œproblemsâ€ that will largely fix themselves as the industry\ndiversifies.\n\nWith the exception of race, most of the gaps are no more than a few percentage\npoints in magnitude. In the case of race, the gaps are meaningful in some cases\nbut difference is in fact in favor of minority groups like East Asian, South\nAsian, and Middle Eastern software developers. Their pay advantages are\nsubstantial, and the data from the Stack Overflow\n[https://insights.stackoverflow.com/survey/2019] survey fail to fully explain\nthese gaps.\n\nThe usual caveats to pay analyses apply here as well. Finding little\ndiscrimination on pay, after controlling for factors such as job title, does not\ndisprove discrimination in its entirety.\n\n * For example, if female software engineers face discrimination in the form of\n   reduced upward career mobility, that will not show up in this analysis, even\n   though it depresses their earnings\n * The same would apply to older software developers, who may be pressured out\n   of their organizations to make room for cheaper, younger developers.\n\nAnalogous statistical caveats abound.\n\nThat said, the data suggest the software development industry is well on its way\nto pay parity across the important dimensions of age, race, gender, and\nsexuality.\n\nThanks for reading part 1 of my 2020 analysis of software developer pay. You can\nfind the rest of the analysis and methodology here\n[__GHOST_URL__/highest-paid-software-engineers-2020].","feature_image":"__GHOST_URL__/content/images/2020/02/Ethnicity-10.jpg","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-02-23T18:29:48.000Z","updated_at":"2020-03-01T00:13:52.000Z","published_at":"2020-02-24T18:11:43.000Z","custom_excerpt":"Progress on narrowing pay gaps among software developers","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5e52de08d2341b714b9b6e5b","uuid":"915fed51-7d17-41bf-965c-824211c831dc","title":"The Highest-Paid Software Engineers: 2020 Edition","slug":"highest-paid-software-engineers-2020","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive a report with the full results</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Your Email Address\\\" id=\\\"mce-EMAIL\\\" required>\\n<input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: The Highest-Paid Software Engineers: 2020 Edition\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Send Report âš¡</span></button>\\n</form>\\n            </section>\"}],[\"markdown\",{\"markdown\":\"* [Part 1: How Age, Race, and Gender Affect Software Engineering Pay](/age-race-gender-software-engineering-pay)\\n    * How `age`, `race`, `gender` and other characteristics affect pay and the extent of pay discrimination in the software development industry\\n* [Part 2: Do College Degrees Matter for Software Engineers?](/college-degrees-software-engineers/)\\n    * Does `education` matter for how software engineers get paid? The answer: maybe\\n* Part 3: The Characteristics of the Best-Paid Software Engineers and Best-Paying Companies (coming soon)\\n    * The highest and lowest-paid `engineering roles`, how much big Big Tech pays, the `experience` advantage, and more\\n* Part 4: The Highest-Paid Programming Languages, Databases, and Frameworks (coming soon)\\n    * Does `React.js` pay better than `AngularJS`? How do `operating systems` affect developer earnings? How important is fluency with `cloud infrastructure`?\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive a report with the full results</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Your Email Address\\\" id=\\\"mce-EMAIL\\\" required>\\n<input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Middle: The Highest-Paid Software Engineers: 2020 Edition\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Send Report âš¡</span></button>\\n</form>\\n            </section>\"}],[\"markdown\",{\"markdown\":\"* **Interactive charts via Plot.ly**\\n    * Hover over the charts for additional data points\\n* **Uncontrolled and controlled differences**\\n    * Uncontrolled effects correspond to the statement: â€œDevelopers of type X earn Y% more than developers of type Zâ€\\n    * Controlled effects correspond to the statement: â€œAll else equal (that we can control for) developers of type X earn Y% more than developers of type Zâ€\\n* **Deep dives into the drivers behind unadjusted pay gaps**\\n    * Disaggregation of the explainable pay gaps\\n    * Decomposition follows methodology of ([Gelbach 2016](https://www.journals.uchicago.edu/doi/abs/10.1086/683668))\"}]],\"markups\":[[\"a\",[\"href\",\"https://medium.com/@rrhoover/the-rise-of-no-code-e733d7c0944d\"]],[\"strong\"],[\"a\",[\"href\",\"__GHOST_URL__/highest-paid-software-developer/\"]],[\"a\",[\"href\",\"https://insights.stackoverflow.com/survey/2019\"]],[\"a\",[\"href\",\"https://github.com/whoisnnamdi/\"]],[\"code\"],[\"a\",[\"href\",\"http://home.uchicago.edu/ourminsky/Variable_Selection\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Engineers are the basic economic unit of modern software development.\"]]],[1,\"p\",[[0,[],0,\"The software production function depends critically on developer productivity and compensation. No developers, no software.\"]]],[1,\"p\",[[0,[],0,\"Yes â€œ\"],[0,[0],1,\"no code\"],[0,[],0,\"â€ is a thing â€” but even the no code systems themselves are developer-built. You canâ€™t get around it.\"]]],[1,\"p\",[[0,[],0,\"And yet software engineering pay remains poorly understood. Different employers pay differently for the same engineering talent. Engineers with similar resumes are paid varying salaries by the same employer.\"]]],[1,\"p\",[[0,[],0,\"This guide explains why.\"]]],[1,\"p\",[[0,[],0,\"Developer compensation is a critical piece of technology's economic impact. Awareness of this data makes you a better informed citizen of the industry.\"]]],[1,\"p\",[[0,[1],1,\"I am dedicated to enhancing the careers of software developers and the functioning of the organizations that employ them.\"],[0,[],0,\" Compiling this report \"],[0,[2],1,\"every year\"],[0,[],0,\" is one way I do this.\"]]],[1,\"p\",[[0,[],0,\"If youâ€™re aâ€¦\"]]],[3,\"ul\",[[[0,[],0,\"developer,\"]],[[0,[],0,\"founder,\"]],[[0,[],0,\"manager,\"]],[[0,[],0,\"or executive\"]]]],[1,\"p\",[[0,[],0,\"... then this guide is for you.\"]]],[10,0],[1,\"h2\",[[0,[],0,\"Table of contents\"]]],[10,1],[1,\"h2\",[[0,[],0,\"About this guide\"]]],[1,\"h3\",[[0,[],0,\"The data\"]]],[1,\"p\",[[0,[],0,\"As with \"],[0,[2],1,\"last yearâ€™s analysis\"],[0,[],0,\", the data in this report is based on a subset of \"],[0,[3],1,\"Stack Overflowâ€™s annual developer survey\"],[0,[],0,\". They have run this survey for a while now and each year graciously open source the responses in an easy work with CSV file.\"]]],[1,\"p\",[[0,[],0,\"The survey is global, but here I focus on 10,355 U.S. based individuals employed as software engineers on either a part-time, full-time, or independent basis.\"]]],[1,\"p\",[[0,[],0,\"The data is entirely self-reported, so I implicitly assume respondents make accurate claims as to their income, personal characteristics, qualifications, etc. To the extent there are obviously false responses, I have attempted to remove them.\"]]],[1,\"p\",[[0,[],0,\"I used Python for the analysis, and if youâ€™d like to reproduce the results, Iâ€™ll be releasing the code I wrote after publishing the full results on my \"],[0,[4],1,\"GitHub\"],[0,[],0,\".\"]]],[1,\"h3\",[[0,[],0,\"Why itâ€™s important to adjust pay gaps for observable factors\"]]],[1,\"p\",[[0,[],0,\"Two possible statements comparing the pay of different groups of software developers:\"]]],[3,\"ol\",[[[0,[],0,\"Developers of \"],[0,[5],1,\"type A\"],[0,[],0,\" make X% more than developers of \"],[0,[5],1,\"type B\"],[0,[],0,\", on average\"]],[[0,[],0,\"Developers of \"],[0,[5],1,\"type A\"],[0,[],0,\" make Y% more than developers of \"],[0,[5],1,\"type B\"],[0,[],0,\", all else equal\"]]]],[1,\"p\",[[0,[],0,\"X and Y are rarely the same number. X compares the average earnings of the group A and B. Y compares hypothetical As and Bs who are similar in all dimensions except one, allowing us to attribute the difference to that single trait.\"]]],[1,\"p\",[[0,[],0,\"Most analyses of pay gaps stop at statement #1 and call it a day. \"],[0,[1],1,\"This is lazy and misleading.\"]]],[1,\"p\",[[0,[],0,\"Though weâ€™d love to know both X and Y, it is Y that corresponds better to our intuitive meaning of â€œpay gapsâ€ â€” the difference between the earnings of two groups who are equivalent except for a single trait of interest (\"],[0,[5],1,\"age\"],[0,[],0,\", \"],[0,[5],1,\"gender\"],[0,[],0,\", \"],[0,[5],1,\"years of experience\"],[0,[],0,\", etc.).\"]]],[1,\"p\",[[0,[],0,\"Identifying Y requires additional data on characteristics that may correlate with earnings.\"]]],[10,2],[1,\"h3\",[[0,[],0,\"We canâ€™t explain everything\"]]],[1,\"p\",[[0,[],0,\"Using the above methodology, Iâ€™ll use the following terms in this report:\"]]],[3,\"ul\",[[[0,[1],1,\"Total / Unadjusted gap:\"],[0,[],0,\" X, as above, the average difference between groups (e.g. pay difference between white and black engineers)\"]],[[0,[1],1,\"Unexplained / Adjusted gap:\"],[0,[],0,\" Y, as above, the difference between groups who vary on some dimension that canâ€™t be explained by that variance (e.g. pay difference between similar white and black engineers)\"]],[[0,[1],1,\"Explained gap:\"],[0,[],0,\" X - Y, the portion of the total gap that is explainable by factors other than the trait of interest (e.g. pay difference between white and black engineers explained by factors unrelated to race)\"]]]],[1,\"p\",[[0,[],0,\"Note â€” the unexplained gap is exactly that, unexplained. We cannot say for certain that the entire unexplained gap between, say, white and black software engineers is due to discrimination on race, for example. If we use different controls, the â€œunexplainedâ€ gap would change. At best, the unexplained gap provides an upper bound estimate of the gap attributable to that trait.\"]]],[1,\"p\",[[0,[],0,\"How do we know what to control for? The Stack Overflow survey upon which this analysis is based provides a rich set of data on each developer based on their answers to various questions. Itâ€™s too complicated to cover here, but I do principled covariate selection using Double Lasso per (\"],[0,[6],1,\"Chernozhukov, Hansen, Urminsky 2016\"],[0,[],0,\") for find the best set of controls for each gap I examine.\"]]],[1,\"p\",[[0,[],0,\"All references to statistical significance are at the p < 0.05 level. Confidence intervals are upward skewed because the original regressions used log-transformed income as the dependent variable.\"]]],[1,\"h3\",[[0,[],0,\"It gets better every year\"]]],[1,\"p\",[[0,[],0,\"This yearâ€™s new and improved analysis comes with the following enhancements:\"]]],[10,3],[1,\"p\",[[0,[],0,\"I am also releasing a developer earnings calculator (coming soon). Answer a few questions, and the calculator will output a pay estimate and confidence range based on the same data in this analysis.\"]]],[1,\"p\",[[0,[],0,\"Check out \"],[0,[2],1,\"last yearâ€™s report\"],[0,[],0,\" to see how the numbers changed year-over-year.\"]]],[1,\"h2\",[[0,[],0,\"Knowledge (of money) is power\"]]],[1,\"p\",[[0,[],0,\"I do this analysis every year because I think itâ€™s vital to understand how developers, \"],[0,[1],1,\"the basic economic unit of software development\"],[0,[],0,\", are compensated and rewarded for their efforts.\"]]],[1,\"p\",[[0,[],0,\"By the end of this analysis, you will:\"]]],[3,\"ul\",[[[0,[],0,\"Enhance your knowledge and understanding of the factors driving software developer earnings\"]],[[0,[],0,\"See why some software engineers are paid more than others\"]],[[0,[],0,\"Understand progress on eliminating discrimination in engineering pay\"]],[[0,[],0,\"Develop an appreciation for how various factors intermingle and interact\"]]]],[1,\"p\",[[0,[],0,\"I hope this 2020 guide to software engineering pay is valuable to you. The many hours spent conducting and assembling this analysis were certainly valuable to me!\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p>Engineers are the basic economic unit of modern software development.</p><p>The software production function depends critically on developer productivity and compensation. No developers, no software.</p><p>Yes â€œ<a href=\"https://medium.com/@rrhoover/the-rise-of-no-code-e733d7c0944d\">no code</a>â€ is a thing â€” but even the no code systems themselves are developer-built. You canâ€™t get around it.</p><p>And yet software engineering pay remains poorly understood. Different employers pay differently for the same engineering talent. Engineers with similar resumes are paid varying salaries by the same employer.</p><p>This guide explains why.</p><p>Developer compensation is a critical piece of technology's economic impact. Awareness of this data makes you a better informed citizen of the industry.</p><p><strong>I am dedicated to enhancing the careers of software developers and the functioning of the organizations that employ them.</strong> Compiling this report <a href=\"__GHOST_URL__/highest-paid-software-developer/\">every year</a> is one way I do this.</p><p>If youâ€™re aâ€¦</p><ul><li>developer,</li><li>founder,</li><li>manager,</li><li>or executive</li></ul><p>... then this guide is for you.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive a report with the full results</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Your Email Address\" id=\"mce-EMAIL\" required>\n<input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: The Highest-Paid Software Engineers: 2020 Edition\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Send Report âš¡</span></button>\n</form>\n            </section><!--kg-card-end: html--><h2 id=\"table-of-contents\">Table of contents</h2><!--kg-card-begin: markdown--><ul>\n<li><a href=\"/age-race-gender-software-engineering-pay\">Part 1: How Age, Race, and Gender Affect Software Engineering Pay</a>\n<ul>\n<li>How <code>age</code>, <code>race</code>, <code>gender</code> and other characteristics affect pay and the extent of pay discrimination in the software development industry</li>\n</ul>\n</li>\n<li><a href=\"/college-degrees-software-engineers/\">Part 2: Do College Degrees Matter for Software Engineers?</a>\n<ul>\n<li>Does <code>education</code> matter for how software engineers get paid? The answer: maybe</li>\n</ul>\n</li>\n<li>Part 3: The Characteristics of the Best-Paid Software Engineers and Best-Paying Companies (coming soon)\n<ul>\n<li>The highest and lowest-paid <code>engineering roles</code>, how much big Big Tech pays, the <code>experience</code> advantage, and more</li>\n</ul>\n</li>\n<li>Part 4: The Highest-Paid Programming Languages, Databases, and Frameworks (coming soon)\n<ul>\n<li>Does <code>React.js</code> pay better than <code>AngularJS</code>? How do <code>operating systems</code> affect developer earnings? How important is fluency with <code>cloud infrastructure</code>?</li>\n</ul>\n</li>\n</ul>\n<!--kg-card-end: markdown--><h2 id=\"about-this-guide\">About this guide</h2><h3 id=\"the-data\">The data</h3><p>As with <a href=\"__GHOST_URL__/highest-paid-software-developer/\">last yearâ€™s analysis</a>, the data in this report is based on a subset of <a href=\"https://insights.stackoverflow.com/survey/2019\">Stack Overflowâ€™s annual developer survey</a>. They have run this survey for a while now and each year graciously open source the responses in an easy work with CSV file.</p><p>The survey is global, but here I focus on 10,355 U.S. based individuals employed as software engineers on either a part-time, full-time, or independent basis.</p><p>The data is entirely self-reported, so I implicitly assume respondents make accurate claims as to their income, personal characteristics, qualifications, etc. To the extent there are obviously false responses, I have attempted to remove them.</p><p>I used Python for the analysis, and if youâ€™d like to reproduce the results, Iâ€™ll be releasing the code I wrote after publishing the full results on my <a href=\"https://github.com/whoisnnamdi/\">GitHub</a>.</p><h3 id=\"why-it-s-important-to-adjust-pay-gaps-for-observable-factors\">Why itâ€™s important to adjust pay gaps for observable factors</h3><p>Two possible statements comparing the pay of different groups of software developers:</p><ol><li>Developers of <code>type A</code> make X% more than developers of <code>type B</code>, on average</li><li>Developers of <code>type A</code> make Y% more than developers of <code>type B</code>, all else equal</li></ol><p>X and Y are rarely the same number. X compares the average earnings of the group A and B. Y compares hypothetical As and Bs who are similar in all dimensions except one, allowing us to attribute the difference to that single trait.</p><p>Most analyses of pay gaps stop at statement #1 and call it a day. <strong>This is lazy and misleading.</strong></p><p>Though weâ€™d love to know both X and Y, it is Y that corresponds better to our intuitive meaning of â€œpay gapsâ€ â€” the difference between the earnings of two groups who are equivalent except for a single trait of interest (<code>age</code>, <code>gender</code>, <code>years of experience</code>, etc.).</p><p>Identifying Y requires additional data on characteristics that may correlate with earnings.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive a report with the full results</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Your Email Address\" id=\"mce-EMAIL\" required>\n<input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Middle: The Highest-Paid Software Engineers: 2020 Edition\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Send Report âš¡</span></button>\n</form>\n            </section><!--kg-card-end: html--><h3 id=\"we-can-t-explain-everything\">We canâ€™t explain everything</h3><p>Using the above methodology, Iâ€™ll use the following terms in this report:</p><ul><li><strong>Total / Unadjusted gap:</strong> X, as above, the average difference between groups (e.g. pay difference between white and black engineers)</li><li><strong>Unexplained / Adjusted gap:</strong> Y, as above, the difference between groups who vary on some dimension that canâ€™t be explained by that variance (e.g. pay difference between similar white and black engineers)</li><li><strong>Explained gap:</strong> X - Y, the portion of the total gap that is explainable by factors other than the trait of interest (e.g. pay difference between white and black engineers explained by factors unrelated to race)</li></ul><p>Note â€” the unexplained gap is exactly that, unexplained. We cannot say for certain that the entire unexplained gap between, say, white and black software engineers is due to discrimination on race, for example. If we use different controls, the â€œunexplainedâ€ gap would change. At best, the unexplained gap provides an upper bound estimate of the gap attributable to that trait.</p><p>How do we know what to control for? The Stack Overflow survey upon which this analysis is based provides a rich set of data on each developer based on their answers to various questions. Itâ€™s too complicated to cover here, but I do principled covariate selection using Double Lasso per (<a href=\"http://home.uchicago.edu/ourminsky/Variable_Selection\">Chernozhukov, Hansen, Urminsky 2016</a>) for find the best set of controls for each gap I examine.</p><p>All references to statistical significance are at the p &lt; 0.05 level. Confidence intervals are upward skewed because the original regressions used log-transformed income as the dependent variable.</p><h3 id=\"it-gets-better-every-year\">It gets better every year</h3><p>This yearâ€™s new and improved analysis comes with the following enhancements:</p><!--kg-card-begin: markdown--><ul>\n<li><strong>Interactive charts via Plot.ly</strong>\n<ul>\n<li>Hover over the charts for additional data points</li>\n</ul>\n</li>\n<li><strong>Uncontrolled and controlled differences</strong>\n<ul>\n<li>Uncontrolled effects correspond to the statement: â€œDevelopers of type X earn Y% more than developers of type Zâ€</li>\n<li>Controlled effects correspond to the statement: â€œAll else equal (that we can control for) developers of type X earn Y% more than developers of type Zâ€</li>\n</ul>\n</li>\n<li><strong>Deep dives into the drivers behind unadjusted pay gaps</strong>\n<ul>\n<li>Disaggregation of the explainable pay gaps</li>\n<li>Decomposition follows methodology of (<a href=\"https://www.journals.uchicago.edu/doi/abs/10.1086/683668\">Gelbach 2016</a>)</li>\n</ul>\n</li>\n</ul>\n<!--kg-card-end: markdown--><p>I am also releasing a developer earnings calculator (coming soon). Answer a few questions, and the calculator will output a pay estimate and confidence range based on the same data in this analysis.</p><p>Check out <a href=\"__GHOST_URL__/highest-paid-software-developer/\">last yearâ€™s report</a> to see how the numbers changed year-over-year.</p><h2 id=\"knowledge-of-money-is-power\">Knowledge (of money) is power</h2><p>I do this analysis every year because I think itâ€™s vital to understand how developers, <strong>the basic economic unit of software development</strong>, are compensated and rewarded for their efforts.</p><p>By the end of this analysis, you will:</p><ul><li>Enhance your knowledge and understanding of the factors driving software developer earnings</li><li>See why some software engineers are paid more than others</li><li>Understand progress on eliminating discrimination in engineering pay</li><li>Develop an appreciation for how various factors intermingle and interact</li></ul><p>I hope this 2020 guide to software engineering pay is valuable to you. The many hours spent conducting and assembling this analysis were certainly valuable to me!</p>","comment_id":"5e52de08d2341b714b9b6e5b","plaintext":"Engineers are the basic economic unit of modern software development.\n\nThe software production function depends critically on developer productivity\nand compensation. No developers, no software.\n\nYes â€œno code [https://medium.com/@rrhoover/the-rise-of-no-code-e733d7c0944d]â€ is\na thing â€” but even the no code systems themselves are developer-built. You canâ€™t\nget around it.\n\nAnd yet software engineering pay remains poorly understood. Different employers\npay differently for the same engineering talent. Engineers with similar resumes\nare paid varying salaries by the same employer.\n\nThis guide explains why.\n\nDeveloper compensation is a critical piece of technology's economic impact.\nAwareness of this data makes you a better informed citizen of the industry.\n\nI am dedicated to enhancing the careers of software developers and the\nfunctioning of the organizations that employ them. Compiling this report every\nyear [__GHOST_URL__/highest-paid-software-developer/] is one way I do this.\n\nIf youâ€™re aâ€¦\n\n * developer,\n * founder,\n * manager,\n * or executive\n\n... then this guide is for you.\n\nReceive a report with the full results\n\n\nSend Report âš¡ Table of contents\n * Part 1: How Age, Race, and Gender Affect Software Engineering Pay\n   [/age-race-gender-software-engineering-pay] * How age, race, gender and other characteristics affect pay and the extent\n      of pay discrimination in the software development industry\n   \n   \n * Part 2: Do College Degrees Matter for Software Engineers?\n   [/college-degrees-software-engineers/] * Does education matter for how software engineers get paid? The answer:\n      maybe\n   \n   \n * Part 3: The Characteristics of the Best-Paid Software Engineers and\n   Best-Paying Companies (coming soon) * The highest and lowest-paid engineering roles, how much big Big Tech pays,\n      the experience advantage, and more\n   \n   \n * Part 4: The Highest-Paid Programming Languages, Databases, and Frameworks\n   (coming soon) * Does React.js pay better than AngularJS? How do operating systems affect\n      developer earnings? How important is fluency with cloud infrastructure?\n   \n   \n\nAbout this guide\nThe data\nAs with last yearâ€™s analysis [__GHOST_URL__/highest-paid-software-developer/],\nthe data in this report is based on a subset of Stack Overflowâ€™s annual\ndeveloper survey [https://insights.stackoverflow.com/survey/2019]. They have run\nthis survey for a while now and each year graciously open source the responses\nin an easy work with CSV file.\n\nThe survey is global, but here I focus on 10,355 U.S. based individuals employed\nas software engineers on either a part-time, full-time, or independent basis.\n\nThe data is entirely self-reported, so I implicitly assume respondents make\naccurate claims as to their income, personal characteristics, qualifications,\netc. To the extent there are obviously false responses, I have attempted to\nremove them.\n\nI used Python for the analysis, and if youâ€™d like to reproduce the results, Iâ€™ll\nbe releasing the code I wrote after publishing the full results on my GitHub\n[https://github.com/whoisnnamdi/].\n\nWhy itâ€™s important to adjust pay gaps for observable factors\nTwo possible statements comparing the pay of different groups of software\ndevelopers:\n\n 1. Developers of type A make X% more than developers of type B, on average\n 2. Developers of type A make Y% more than developers of type B, all else equal\n\nX and Y are rarely the same number. X compares the average earnings of the group\nA and B. Y compares hypothetical As and Bs who are similar in all dimensions\nexcept one, allowing us to attribute the difference to that single trait.\n\nMost analyses of pay gaps stop at statement #1 and call it a day. This is lazy\nand misleading.\n\nThough weâ€™d love to know both X and Y, it is Y that corresponds better to our\nintuitive meaning of â€œpay gapsâ€ â€” the difference between the earnings of two\ngroups who are equivalent except for a single trait of interest (age, gender, \nyears of experience, etc.).\n\nIdentifying Y requires additional data on characteristics that may correlate\nwith earnings.\n\nReceive a report with the full results\n\n\nSend Report âš¡ We canâ€™t explain everything\nUsing the above methodology, Iâ€™ll use the following terms in this report:\n\n * Total / Unadjusted gap: X, as above, the average difference between groups\n   (e.g. pay difference between white and black engineers)\n * Unexplained / Adjusted gap: Y, as above, the difference between groups who\n   vary on some dimension that canâ€™t be explained by that variance (e.g. pay\n   difference between similar white and black engineers)\n * Explained gap: X - Y, the portion of the total gap that is explainable by\n   factors other than the trait of interest (e.g. pay difference between white\n   and black engineers explained by factors unrelated to race)\n\nNote â€” the unexplained gap is exactly that, unexplained. We cannot say for\ncertain that the entire unexplained gap between, say, white and black software\nengineers is due to discrimination on race, for example. If we use different\ncontrols, the â€œunexplainedâ€ gap would change. At best, the unexplained gap\nprovides an upper bound estimate of the gap attributable to that trait.\n\nHow do we know what to control for? The Stack Overflow survey upon which this\nanalysis is based provides a rich set of data on each developer based on their\nanswers to various questions. Itâ€™s too complicated to cover here, but I do\nprincipled covariate selection using Double Lasso per (Chernozhukov, Hansen,\nUrminsky 2016 [http://home.uchicago.edu/ourminsky/Variable_Selection]) for find\nthe best set of controls for each gap I examine.\n\nAll references to statistical significance are at the p < 0.05 level. Confidence\nintervals are upward skewed because the original regressions used\nlog-transformed income as the dependent variable.\n\nIt gets better every year\nThis yearâ€™s new and improved analysis comes with the following enhancements:\n\n * Interactive charts via Plot.ly * Hover over the charts for additional data\n      points\n   \n   \n * Uncontrolled and controlled differences * Uncontrolled effects correspond to\n      the statement: â€œDevelopers of type X earn Y% more than developers of type\n      Zâ€\n    * Controlled effects correspond to\n      the statement: â€œAll else equal (that we can control for) developers of\n      type X earn Y% more than developers of type Zâ€\n   \n   \n * Deep dives into the drivers behind unadjusted pay gaps * Disaggregation of\n      the explainable pay gaps\n    * Decomposition\n      follows methodology of (Gelbach 2016\n      [https://www.journals.uchicago.edu/doi/abs/10.1086/683668])\n   \n   \n\nI am also releasing a developer earnings calculator (coming soon). Answer a few\nquestions, and the calculator will output a pay estimate and confidence range\nbased on the same data in this analysis.\n\nCheck out last yearâ€™s report [__GHOST_URL__/highest-paid-software-developer/] to\nsee how the numbers changed year-over-year.\n\nKnowledge (of money) is power\nI do this analysis every year because I think itâ€™s vital to understand how\ndevelopers, the basic economic unit of software development, are compensated and\nrewarded for their efforts.\n\nBy the end of this analysis, you will:\n\n * Enhance your knowledge and understanding of the factors driving software\n   developer earnings\n * See why some software engineers are paid more than others\n * Understand progress on eliminating discrimination in engineering pay\n * Develop an appreciation for how various factors intermingle and interact\n\nI hope this 2020 guide to software engineering pay is valuable to you. The many\nhours spent conducting and assembling this analysis were certainly valuable to\nme!","feature_image":"__GHOST_URL__/content/images/2020/02/clip-programming.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-02-23T20:18:16.000Z","updated_at":"2020-06-05T07:45:27.000Z","published_at":"2020-02-24T17:15:07.000Z","custom_excerpt":"Engineers are the basic economic unit of modern software development.\n\nThe software production function depends critically on developer productivity and compensation.\n\nAnd yet software engineering pay remains poorly understood.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5e540531d2341b714b9b6ed3","uuid":"175ca958-eaba-4632-bce1-247485564443","title":"Newsletter","slug":"newsletter","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Sign-up to receive my monthly newsletter</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Your Email Address\\\" id=\\\"mce-EMAIL\\\" required>\\n<input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: Newsletter\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span>Go âš¡</span></button>\\n</form>\\n            </section>\"}]],\"markups\":[[\"strong\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Hey there!\"]]],[1,\"p\",[[0,[],0,\"I publish monthly musings on the economics of technology, entrepreneurship, and venture capital. I regularly:\"]]],[3,\"ul\",[[[0,[],0,\"Uncover \"],[0,[0],1,\"trends in the shifting technology landscape\"]],[[0,[],0,\"Expose \"],[0,[0],1,\"incorrect analysis\"],[0,[],0,\" or \"],[0,[0],1,\"flawed mental models\"]],[[0,[],0,\"Translate \"],[0,[0],1,\"difficult technical concepts\"],[0,[],0,\" into plain language\"]],[[0,[],0,\"Share \"],[0,[0],1,\"interesting ideas\"],[0,[],0,\" off the beaten path\"]]]],[1,\"p\",[[0,[],0,\"Sign up for my free newsletter below.\"]]],[1,\"p\",[[0,[],0,\"â€” Nnamdi\"]]],[10,0],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}","html":"<p>Hey there!</p><p>I publish monthly musings on the economics of technology, entrepreneurship, and venture capital. I regularly:</p><ul><li>Uncover <strong>trends in the shifting technology landscape</strong></li><li>Expose <strong>incorrect analysis</strong> or <strong>flawed mental models</strong></li><li>Translate <strong>difficult technical concepts</strong> into plain language</li><li>Share <strong>interesting ideas</strong> off the beaten path</li></ul><p>Sign up for my free newsletter below.</p><p>â€” Nnamdi</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Sign-up to receive my monthly newsletter</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Your Email Address\" id=\"mce-EMAIL\" required>\n<input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: Newsletter\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span>Go âš¡</span></button>\n</form>\n            </section><!--kg-card-end: html-->","comment_id":"5e540531d2341b714b9b6ed3","plaintext":"Hey there!\n\nI publish monthly musings on the economics of technology, entrepreneurship, and\nventure capital. I regularly:\n\n * Uncover trends in the shifting technology landscape\n * Expose incorrect analysis or flawed mental models\n * Translate difficult technical concepts into plain language\n * Share interesting ideas off the beaten path\n\nSign up for my free newsletter below.\n\nâ€” Nnamdi\n\nSign-up to receive my monthly newsletter\n\n\nGo âš¡","feature_image":null,"featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-02-24T17:17:37.000Z","updated_at":"2020-03-31T17:18:14.000Z","published_at":"2020-02-24T17:28:30.000Z","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"page","email_recipient_filter":"none"},{"id":"5e7567292115750c14ed2d4a","uuid":"0d0cf84c-9092-49f6-97be-2caf2d5f77b6","title":"Remote Software Developers Earn 22% More Than Non-Remote Developers","slug":"remote-software-developers-earn-more","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"html\":\"<div class=\\\"igraph\\\">\\n    <a href=\\\"https://plot.ly/~whoisnnamdi/82/?share_key=A4rtkRSqRGar7d19Zq3Xf6\\\" target=\\\"_blank\\\" title=\\\"Remote Work\\\" style=\\\"text-align: center;\\\"><img src=\\\"https://plot.ly/~whoisnnamdi/82.png?share_key=AeS6BZEpGR5FXWfIFa29gc\\\" alt=\\\"Remote Work\\\" style=\\\"max-width: 100%;width: 600px;\\\"  width=\\\"600\\\" onerror=\\\"this.onerror=null;this.src='https://plot.ly/404.png';\\\" /></a>\\n    <script data-plotly=\\\"whoisnnamdi:82\\\" sharekey-plotly=\\\"A4rtkRSqRGar7d19Zq3Xf6&link=false&logo=false\\\" src=\\\"https://plot.ly/embed.js\\\" async></script>\\n</div>\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive a report with the full results</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Your Email Address\\\" id=\\\"mce-EMAIL\\\" required>\\n<input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Middle: Remote Software Developers Earn 22% More Than Non-Remote Developers\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Send Report âš¡</span></button>\\n</form>\\n            </section>\\n<!--<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive my next thought in your inbox</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email address\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Middle: Remote Software Developers Earn 22% More Than Non-Remote Developers\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span>Subscribe</span></button>\\n</form>\\n</section>-->\"}],[\"html\",{\"html\":\"<div class=\\\"igraph\\\">\\n    <a href=\\\"https://plot.ly/~whoisnnamdi/84/?share_key=A4rtkRSqRGar7d19Zq3Xf6\\\" target=\\\"_blank\\\" title=\\\"Explaining  Remote Work\\\" style=\\\"text-align: center;\\\"><img src=\\\"https://plot.ly/~whoisnnamdi/84.png?share_key=AeS6BZEpGR5FXWfIFa29gc\\\" alt=\\\"Explaining Remote Work\\\" style=\\\"max-width: 100%;width: 600px;\\\"  width=\\\"600\\\" onerror=\\\"this.onerror=null;this.src='https://plot.ly/404.png';\\\" /></a>\\n    <script data-plotly=\\\"whoisnnamdi:84\\\" sharekey-plotly=\\\"A4rtkRSqRGar7d19Zq3Xf6&link=false&logo=false\\\" src=\\\"https://plot.ly/embed.js\\\" async></script>\\n</div>\"}],[\"html\",{\"html\":\"<div class=\\\"igraph\\\">\\n    <a href=\\\"https://plot.ly/~whoisnnamdi/80/?share_key=A4rtkRSqRGar7d19Zq3Xf6\\\" target=\\\"_blank\\\" title=\\\"Years of Professional Coding Experience vs. Remote Work\\\" style=\\\"text-align: center;\\\"><img src=\\\"https://plot.ly/~whoisnnamdi/80.png?share_key=AeS6BZEpGR5FXWfIFa29gc\\\" alt=\\\"Years of Professional Coding Experience vs. Remote Work\\\" style=\\\"max-width: 100%;width: 600px;\\\"  width=\\\"600\\\" onerror=\\\"this.onerror=null;this.src='https://plot.ly/404.png';\\\" /></a>\\n    <script data-plotly=\\\"whoisnnamdi:80\\\" sharekey-plotly=\\\"A4rtkRSqRGar7d19Zq3Xf6&link=false&logo=false\\\" src=\\\"https://plot.ly/embed.js\\\" async></script>\\n</div>\"}]],\"markups\":[[\"em\"],[\"a\",[\"href\",\"__GHOST_URL__/highest-paid-software-engineers-2020/\"]],[\"a\",[\"href\",\"https://www.cdc.gov/coronavirus/2019-ncov/index.html\"]],[\"a\",[\"href\",\"https://about.gitlab.com/company/culture/all-remote/\"]],[\"strong\"],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Controlling_for_a_variable\"]],[\"code\"],[\"a\",[\"href\",\"https://towardsdatascience.com/causal-vs-statistical-inference-3f2c3e617220\"]],[\"a\",[\"href\",\"https://www.theanalysisfactor.com/what-is-a-confounding-variable/\"]]],\"sections\":[[1,\"p\",[[0,[0],0,\"This post is an excerpt from my \"],[0,[1],1,\"2020 software developer pay analysis\"],[0,[],0,\". Read the rest of the analysis \"],[0,[1],1,\"here\"],[0,[],1,\".\"]]],[1,\"p\",[[0,[],0,\"Organizations around the world have pivoted to remote work to shield themselves against the \"],[0,[2],1,\"novel coronavirus / COVID-19\"],[0,[],0,\" threat.\"]]],[1,\"p\",[[0,[],0,\"The sudden change prompts numerous questions. To start, how will this new (for some \"],[0,[3],1,\"but not all\"],[0,[],0,\") paradigm affect the way we work and collaborate?\"]]],[1,\"p\",[[0,[],0,\"One piece of good news among all the dreadâ€”remote work could lead to higher take-home pay, at least for software engineers.\"]]],[1,\"h2\",[[0,[],0,\"Remote work pays\"]]],[10,0],[1,\"p\",[[0,[],0,\"Fully-remote software developers earn \"],[0,[4],1,\"21.9%\"],[0,[],0,\" more than developers who never or rarely work remote.\"]]],[1,\"p\",[[0,[],0,\"Even once I \"],[0,[5],1,\"control\"],[0,[],0,\" for various observable factors (including \"],[0,[6],1,\"age\"],[0,[],0,\", \"],[0,[6],1,\"experience\"],[0,[],0,\", \"],[0,[6],1,\"hours worked\"],[0,[],0,\", \"],[0,[6],1,\"size of employer\"],[0,[],0,\", \"],[0,[6],1,\"programming languages\"],[0,[],0,\", and \"],[0,[1],1,\"more\"],[0,[],0,\"), fully-remote software developers earn \"],[0,[4],1,\"9.4%\"],[0,[],0,\" more than developers who never or only rarely work remotely.\"]]],[1,\"p\",[[0,[],0,\"Further, the remote work pay advantage increases proportionately with the time spent working remotely. Therefore, fully-remote developers earn more than\"]]],[3,\"ul\",[[[0,[],0,\"those who work remotely more than half the time, who earn more than\"]],[[0,[],0,\"those who work remotely roughly half the time, who earn more than\"]],[[0,[],0,\"those who work remotely less than half the time.\"]]]],[1,\"p\",[[0,[],0,\"Even working only a few days each month yields a substantial pay advantage of \"],[0,[4],1,\"15.5%\"],[0,[],0,\" on average and \"],[0,[4],1,\"4.9%\"],[0,[],0,\" controlling for observable factors, and the estimates are quite precise.\"]]],[1,\"p\",[[0,[],0,\"In other words, \"],[0,[4],1,\"half or more of the benefit comes from being able to work remotely at least a small portion of the time\"],[0,[],0,\" (vs. not at all), while the remainder comes from increased remote time, maxing out at fully-remote.\"]]],[1,\"p\",[[0,[],0,\"This is an impressive result.\"]]],[1,\"p\",[[0,[],0,\"While I canâ€™t be sure this is \"],[0,[7],1,\"causal\"],[0,[],0,\", the \"],[0,[4],1,\"large apparent effects\"],[0,[],0,\" (even after controlling for other variables) paired with the \"],[0,[4],1,\"clear upward trend\"],[0,[],0,\" as remote work increases gives me confidence there is something real here.\"]]],[10,1],[1,\"h2\",[[0,[],0,\"Wait but why?\"]]],[1,\"p\",[[0,[],0,\"The obvious next question isâ€¦ \"],[0,[0],1,\"why\"],[0,[],0,\"?\"]]],[1,\"p\",[[0,[],0,\"Hard to sayâ€”by definition the adjusted pay premium already controls for any other data I had access to.\"]]],[1,\"p\",[[0,[],0,\"However, I can show how the other factors contribute to the explainable premium (i.e. the gap between the unadjusted and adjusted pay premium):\"]]],[10,2],[1,\"p\",[[0,[],0,\"Here we can see some of the other factors contributing to the pay advantage for fully-remote developers:\"]]],[3,\"ul\",[[[0,[6],1,\"years of professional coding experience\"],[0,[],0,\",\"]],[[0,[6],1,\"age\"],[0,[],0,\",\"]],[[0,[],0,\"and a variable that proxies for the \"],[0,[6],1,\"influence\"],[0,[],0,\" a developer has within their organization (their decision making power over new technology purchases)\"]]]],[1,\"p\",[[0,[],0,\"Combined with other \"],[0,[8],1,\"confounding variables\"],[0,[],0,\", these account for \"],[0,[4],1,\"12.5 percentage points\"],[0,[],0,\" of the 21.9 percentage point pay advantage.\"]]],[1,\"p\",[[0,[],0,\"Much of the apparent premium earned by remote developers is in fact driven by seniority and tenure. These are older, more experienced developers who either prefer to work remote or whose organizations grant them that privilege.\"]]],[10,3],[1,\"p\",[[0,[],0,\"That said, the remaining \"],[0,[4],1,\"9.4%\"],[0,[],0,\" adjusted pay advantage for fully-remote developers is nothing to scoff at. The other variables cannot explain this meaningful earnings bump.\"]]],[1,\"h2\",[[0,[],0,\"This one weird trick\"]]],[1,\"p\",[[0,[],0,\"I find an economically and statistically significant pay premium for remote developers, even those who are only away from the office a few days each month. In fact, \"],[0,[0],1,\"most of the earnings gains\"],[0,[],0,\" come from this initial foray into remote work, while the rest come with additional hours spent away from the office.\"]]],[1,\"p\",[[0,[],0,\"Would this hold in a world where remote work is more the norm than the exception? No idea.\"]]],[1,\"p\",[[0,[],0,\"Does this apply to non-software developers? Again, canâ€™t say.\"]]],[1,\"p\",[[0,[],0,\"But itâ€™s an interesting result nonetheless, and one that deserves further investigation as more knowledge workers shift their work online and away from the corporate officeâ€”\"],[0,[2],1,\"virus\"],[0,[],0,\" or no virus.\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p><em>This post is an excerpt from my <a href=\"__GHOST_URL__/highest-paid-software-engineers-2020/\">2020 software developer pay analysis</a>. Read the rest of the analysis <a href=\"__GHOST_URL__/highest-paid-software-engineers-2020/\">here</a>.</em></p><p>Organizations around the world have pivoted to remote work to shield themselves against the <a href=\"https://www.cdc.gov/coronavirus/2019-ncov/index.html\">novel coronavirus / COVID-19</a> threat.</p><p>The sudden change prompts numerous questions. To start, how will this new (for some <a href=\"https://about.gitlab.com/company/culture/all-remote/\">but not all</a>) paradigm affect the way we work and collaborate?</p><p>One piece of good news among all the dreadâ€”remote work could lead to higher take-home pay, at least for software engineers.</p><h2 id=\"remote-work-pays\">Remote work pays</h2><!--kg-card-begin: html--><div class=\"igraph\">\n    <a href=\"https://plot.ly/~whoisnnamdi/82/?share_key=A4rtkRSqRGar7d19Zq3Xf6\" target=\"_blank\" title=\"Remote Work\" style=\"text-align: center;\"><img src=\"https://plot.ly/~whoisnnamdi/82.png?share_key=AeS6BZEpGR5FXWfIFa29gc\" alt=\"Remote Work\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n    <script data-plotly=\"whoisnnamdi:82\" sharekey-plotly=\"A4rtkRSqRGar7d19Zq3Xf6&link=false&logo=false\" src=\"https://plot.ly/embed.js\" async></script>\n</div><!--kg-card-end: html--><p>Fully-remote software developers earn <strong>21.9%</strong> more than developers who never or rarely work remote.</p><p>Even once I <a href=\"https://en.wikipedia.org/wiki/Controlling_for_a_variable\">control</a> for various observable factors (including <code>age</code>, <code>experience</code>, <code>hours worked</code>, <code>size of employer</code>, <code>programming languages</code>, and <a href=\"__GHOST_URL__/highest-paid-software-engineers-2020/\">more</a>), fully-remote software developers earn <strong>9.4%</strong> more than developers who never or only rarely work remotely.</p><p>Further, the remote work pay advantage increases proportionately with the time spent working remotely. Therefore, fully-remote developers earn more than</p><ul><li>those who work remotely more than half the time, who earn more than</li><li>those who work remotely roughly half the time, who earn more than</li><li>those who work remotely less than half the time.</li></ul><p>Even working only a few days each month yields a substantial pay advantage of <strong>15.5%</strong> on average and <strong>4.9%</strong> controlling for observable factors, and the estimates are quite precise.</p><p>In other words, <strong>half or more of the benefit comes from being able to work remotely at least a small portion of the time</strong> (vs. not at all), while the remainder comes from increased remote time, maxing out at fully-remote.</p><p>This is an impressive result.</p><p>While I canâ€™t be sure this is <a href=\"https://towardsdatascience.com/causal-vs-statistical-inference-3f2c3e617220\">causal</a>, the <strong>large apparent effects</strong> (even after controlling for other variables) paired with the <strong>clear upward trend</strong> as remote work increases gives me confidence there is something real here.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive a report with the full results</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Your Email Address\" id=\"mce-EMAIL\" required>\n<input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Middle: Remote Software Developers Earn 22% More Than Non-Remote Developers\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Send Report âš¡</span></button>\n</form>\n            </section>\n<!--<section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive my next thought in your inbox</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email address\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Middle: Remote Software Developers Earn 22% More Than Non-Remote Developers\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span>Subscribe</span></button>\n</form>\n</section>--><!--kg-card-end: html--><h2 id=\"wait-but-why\">Wait but why?</h2><p>The obvious next question isâ€¦ <em>why</em>?</p><p>Hard to sayâ€”by definition the adjusted pay premium already controls for any other data I had access to.</p><p>However, I can show how the other factors contribute to the explainable premium (i.e. the gap between the unadjusted and adjusted pay premium):</p><!--kg-card-begin: html--><div class=\"igraph\">\n    <a href=\"https://plot.ly/~whoisnnamdi/84/?share_key=A4rtkRSqRGar7d19Zq3Xf6\" target=\"_blank\" title=\"Explaining  Remote Work\" style=\"text-align: center;\"><img src=\"https://plot.ly/~whoisnnamdi/84.png?share_key=AeS6BZEpGR5FXWfIFa29gc\" alt=\"Explaining Remote Work\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n    <script data-plotly=\"whoisnnamdi:84\" sharekey-plotly=\"A4rtkRSqRGar7d19Zq3Xf6&link=false&logo=false\" src=\"https://plot.ly/embed.js\" async></script>\n</div><!--kg-card-end: html--><p>Here we can see some of the other factors contributing to the pay advantage for fully-remote developers:</p><ul><li><code>years of professional coding experience</code>,</li><li><code>age</code>,</li><li>and a variable that proxies for the <code>influence</code> a developer has within their organization (their decision making power over new technology purchases)</li></ul><p>Combined with other <a href=\"https://www.theanalysisfactor.com/what-is-a-confounding-variable/\">confounding variables</a>, these account for <strong>12.5 percentage points</strong> of the 21.9 percentage point pay advantage.</p><p>Much of the apparent premium earned by remote developers is in fact driven by seniority and tenure. These are older, more experienced developers who either prefer to work remote or whose organizations grant them that privilege.</p><!--kg-card-begin: html--><div class=\"igraph\">\n    <a href=\"https://plot.ly/~whoisnnamdi/80/?share_key=A4rtkRSqRGar7d19Zq3Xf6\" target=\"_blank\" title=\"Years of Professional Coding Experience vs. Remote Work\" style=\"text-align: center;\"><img src=\"https://plot.ly/~whoisnnamdi/80.png?share_key=AeS6BZEpGR5FXWfIFa29gc\" alt=\"Years of Professional Coding Experience vs. Remote Work\" style=\"max-width: 100%;width: 600px;\"  width=\"600\" onerror=\"this.onerror=null;this.src='https://plot.ly/404.png';\" /></a>\n    <script data-plotly=\"whoisnnamdi:80\" sharekey-plotly=\"A4rtkRSqRGar7d19Zq3Xf6&link=false&logo=false\" src=\"https://plot.ly/embed.js\" async></script>\n</div><!--kg-card-end: html--><p>That said, the remaining <strong>9.4%</strong> adjusted pay advantage for fully-remote developers is nothing to scoff at. The other variables cannot explain this meaningful earnings bump.</p><h2 id=\"this-one-weird-trick\">This one weird trick</h2><p>I find an economically and statistically significant pay premium for remote developers, even those who are only away from the office a few days each month. In fact, <em>most of the earnings gains</em> come from this initial foray into remote work, while the rest come with additional hours spent away from the office.</p><p>Would this hold in a world where remote work is more the norm than the exception? No idea.</p><p>Does this apply to non-software developers? Again, canâ€™t say.</p><p>But itâ€™s an interesting result nonetheless, and one that deserves further investigation as more knowledge workers shift their work online and away from the corporate officeâ€”<a href=\"https://www.cdc.gov/coronavirus/2019-ncov/index.html\">virus</a> or no virus.</p>","comment_id":"5e7567292115750c14ed2d4a","plaintext":"This post is an excerpt from my 2020 software developer pay analysis\n[__GHOST_URL__/highest-paid-software-engineers-2020/]. Read the rest of the\nanalysis here [__GHOST_URL__/highest-paid-software-engineers-2020/].\n\nOrganizations around the world have pivoted to remote work to shield themselves\nagainst the novel coronavirus / COVID-19\n[https://www.cdc.gov/coronavirus/2019-ncov/index.html] threat.\n\nThe sudden change prompts numerous questions. To start, how will this new (for\nsome but not all [https://about.gitlab.com/company/culture/all-remote/])\nparadigm affect the way we work and collaborate?\n\nOne piece of good news among all the dreadâ€”remote work could lead to higher\ntake-home pay, at least for software engineers.\n\nRemote work pays\n[https://plot.ly/~whoisnnamdi/82/?share_key=A4rtkRSqRGar7d19Zq3Xf6] Fully-remote\nsoftware developers earn 21.9% more than developers who never or rarely work\nremote.\n\nEven once I control [https://en.wikipedia.org/wiki/Controlling_for_a_variable] \nfor various observable factors (including age, experience, hours worked, size of\nemployer, programming languages, and more\n[__GHOST_URL__/highest-paid-software-engineers-2020/]), fully-remote software\ndevelopers earn 9.4% more than developers who never or only rarely work\nremotely.\n\nFurther, the remote work pay advantage increases proportionately with the time\nspent working remotely. Therefore, fully-remote developers earn more than\n\n * those who work remotely more than half the time, who earn more than\n * those who work remotely roughly half the time, who earn more than\n * those who work remotely less than half the time.\n\nEven working only a few days each month yields a substantial pay advantage of \n15.5% on average and 4.9% controlling for observable factors, and the estimates\nare quite precise.\n\nIn other words, half or more of the benefit comes from being able to work\nremotely at least a small portion of the time (vs. not at all), while the\nremainder comes from increased remote time, maxing out at fully-remote.\n\nThis is an impressive result.\n\nWhile I canâ€™t be sure this is causal\n[https://towardsdatascience.com/causal-vs-statistical-inference-3f2c3e617220],\nthe large apparent effects (even after controlling for other variables) paired\nwith the clear upward trend as remote work increases gives me confidence there\nis something real here.\n\nReceive a report with the full results\n\n\nSend Report âš¡ Wait but why?\nThe obvious next question isâ€¦ why?\n\nHard to sayâ€”by definition the adjusted pay premium already controls for any\nother data I had access to.\n\nHowever, I can show how the other factors contribute to the explainable premium\n(i.e. the gap between the unadjusted and adjusted pay premium):\n\n[https://plot.ly/~whoisnnamdi/84/?share_key=A4rtkRSqRGar7d19Zq3Xf6] Here we can\nsee some of the other factors contributing to the pay advantage for fully-remote\ndevelopers:\n\n * years of professional coding experience,\n * age,\n * and a variable that proxies for the influence a developer has within their\n   organization (their decision making power over new technology purchases)\n\nCombined with other confounding variables\n[https://www.theanalysisfactor.com/what-is-a-confounding-variable/], these\naccount for 12.5 percentage points of the 21.9 percentage point pay advantage.\n\nMuch of the apparent premium earned by remote developers is in fact driven by\nseniority and tenure. These are older, more experienced developers who either\nprefer to work remote or whose organizations grant them that privilege.\n\n[https://plot.ly/~whoisnnamdi/80/?share_key=A4rtkRSqRGar7d19Zq3Xf6] That said,\nthe remaining 9.4% adjusted pay advantage for fully-remote developers is nothing\nto scoff at. The other variables cannot explain this meaningful earnings bump.\n\nThis one weird trick\nI find an economically and statistically significant pay premium for remote\ndevelopers, even those who are only away from the office a few days each month.\nIn fact, most of the earnings gains come from this initial foray into remote\nwork, while the rest come with additional hours spent away from the office.\n\nWould this hold in a world where remote work is more the norm than the\nexception? No idea.\n\nDoes this apply to non-software developers? Again, canâ€™t say.\n\nBut itâ€™s an interesting result nonetheless, and one that deserves further\ninvestigation as more knowledge workers shift their work online and away from\nthe corporate officeâ€”virus\n[https://www.cdc.gov/coronavirus/2019-ncov/index.html] or no virus.","feature_image":"__GHOST_URL__/content/images/2020/03/WorkRemote-5.jpg","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-03-21T01:00:25.000Z","updated_at":"2020-04-21T23:44:15.000Z","published_at":"2020-03-23T16:07:39.000Z","custom_excerpt":"Working remote even just a few days per month leads to higher pay","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5e81aca3a1b4a869a793155e","uuid":"cf5ff48d-83e1-4c55-b870-eddeba0f544f","title":"Byron Deeter and Jason Lemkin on the State of VC and the Cloud","slug":"deeter-lemkin-state-of-vc-and-cloud","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive my next thought in your inbox</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"I email every few weeks\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Byron Deeter and Jason Lemkin on the State of VC and the Cloud\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span>Go âš¡</span></button>\\n</form>\\n</section>\"}],[\"hr\",{}],[\"image\",{\"src\":\"/content/images/2020/03/usual.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2020/03/fund.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2020/03/vc-survey.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive my next thought in your inbox</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"I email every few weeks\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Middle: Byron Deeter and Jason Lemkin on the State of VC and the Cloud\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span>Go âš¡</span></button>\\n</form>\\n</section>\"}],[\"image\",{\"src\":\"/content/images/2020/03/raise.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2020/03/burn.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2020/03/contractions.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2020/03/bvp.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2020/03/SaaS-08-09.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2020/03/cnbc.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}]],\"markups\":[[\"a\",[\"href\",\"https://www.bvp.com/team/byron-deeter/\"]],[\"a\",[\"href\",\"https://www.bvp.com/\"]],[\"a\",[\"href\",\"https://twitter.com/jasonlk\"]],[\"a\",[\"href\",\"https://www.saastr.com/\"]],[\"a\",[\"href\",\"http://go2.saastr.com/n0Rv0yf03jo30TS0Za001ta\"]],[\"a\",[\"href\",\"http://go2.saastr.com/Y01at0gov00jZ0033SR0zTa\"]],[\"em\"],[\"strong\"]],\"sections\":[[1,\"p\",[[0,[0],1,\"Byron Deeter\"],[0,[],0,\", Partner at \"],[0,[1],1,\"Bessemer Venture Partners\"],[0,[],0,\", and \"],[0,[2],1,\"Jason Lemkin\"],[0,[],0,\" of \"],[0,[3],1,\"SaaStr\"],[0,[],0,\" hosted a live Zoom discussion last week on the current state of venture capital and cloud software in the wake of the coronavirus turmoil.\"]]],[1,\"p\",[[0,[],0,\"They covered:\"]]],[3,\"ul\",[[[0,[],0,\"What's happening in venture today\"]],[[0,[],0,\"When founders should raise capital and what to expect\"]],[[0,[],0,\"The \\\"new normal\\\" for VCs and founders\"]],[[0,[],0,\"Changes in cloud software / SaaS\"]]]],[1,\"p\",[[0,[],0,\"The call was so fantastic that I wanted to share my summarized notes and takeaways with you.\"]]],[1,\"p\",[[0,[],0,\"You can find:\"]]],[3,\"ul\",[[[0,[],0,\"the Zoom recording \"],[0,[4],1,\"here\"],[0,[],0,\"\"]],[[0,[],0,\"the slides \"],[0,[5],1,\"here\"]],[[0,[],0,\"my notes below\"]]]],[1,\"p\",[[0,[],0,\"Enjoy!\"]]],[10,0],[10,1],[1,\"h2\",[[0,[],0,\"Whatâ€™s happening in venture today\"]]],[1,\"h3\",[[0,[],0,\"Things are not â€œbusiness as usualâ€, even for VCs who have capital to deploy\"]]],[10,2],[1,\"p\",[[0,[],0,\"VCs are going through an internal triage of portfolio companies, figuring out where the most damage has been done and what they can do to support their companies.\"]]],[1,\"p\",[[0,[],0,\"The best firms have plenty of reserves and will stand by and support their companies, especially the shining stars. The portfolio companies that arenâ€™t doing so well, who are tight on cashâ€¦ those are going to be the difficult situations.\"]]],[10,3],[1,\"p\",[[0,[],0,\"If a VC has just raised a fund, or itâ€™s only their first fund, and they havenâ€™t yet called the capital from Limited Partners, there \"],[0,[6],1,\"may\"],[0,[],0,\" be some risk there.\"]]],[1,\"p\",[[0,[],0,\"We may see LPs pull back on commitments theyâ€™ve made to certain funds in order to handle their commitments to other funds. As there are tiers of venture firms, there are tiers of LPs, and the \"],[0,[7],1,\"lower tier LPs are the ones more likely to pull out\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"With all the turmoil on both the portfolio and LP side, VCs are spending less time on new deals. Net new checks are definitely going to decline:\"]]],[10,4],[1,\"blockquote\",[[0,[],0,\"As a firm, we are trying to be careful with our time. Bessemer is taking no courtesy meetings right now. Anyone we meet with is someone we think could actually be an interesting investment â€” Byron Deeter\"]]],[1,\"p\",[[0,[],0,\"If a VC calls, \"],[0,[7],1,\"you should still take it\"],[0,[],0,\", but donâ€™t have too many expectations. Many â€œfalse signalsâ€ (i.e. mild, but not serious interest) right now.\"]]],[1,\"h2\",[[0,[],0,\"When founders should raise capital and what to expect\"]]],[1,\"h3\",[[0,[],0,\"Go or no go?\"]]],[1,\"p\",[[0,[],0,\"Driving net new conversations is going to be hard right now. VCs are simply busy right now, and thereâ€™s not much you can do about it.\"]]],[1,\"p\",[[0,[],0,\"Itâ€™s very difficult to start a deal process right now unless itâ€™s being lead by one of your existing investors or someone youâ€™ve already met and gotten to know well pre-crisis.\"]]],[1,\"p\",[[0,[],0,\"If a VC ghosts on you, donâ€™t take it personallyâ€”reach back out in a few weeks once things have settled down.\"]]],[1,\"blockquote\",[[0,[],0,\"If you already deep in negotiation and have most of the terms locked down, get the deal done immediately. Emphasize speed over greed â€” Bryon Deeter\"]]],[1,\"p\",[[0,[],0,\"For companies that were right about to kick off a financing and donâ€™t have a big cash balance in reserve, thatâ€™s where the question of bridge financing comes up.\"]]],[1,\"p\",[[0,[],0,\"Given current conditions, bridge financings will be smaller in dollar terms than they typically are, but those dialogues are definitely happening.\"]]],[1,\"blockquote\",[[0,[],0,\"Founders should definitely ask their VCs for bridges, donâ€™t be afraid to ask â€” Jason Lemkin\"]]],[1,\"p\",[[0,[],0,\"If you donâ€™t already have discussions underway, donâ€™t be afraid to hit pause. People will become more deal-minded in the coming months and will be looking to the broader market to inform pricing.\"]]],[1,\"h3\",[[0,[],0,\"Term sheets are a slippery concept\"]]],[1,\"p\",[[0,[],0,\"Some people may try to take advantage of the current situation and retract term sheets.\"]]],[1,\"p\",[[0,[],0,\"Donâ€™t freak outâ€”these things happen.\"]]],[1,\"p\",[[0,[],0,\"See it as more of a temporary dynamic based off the current market situation than any judgement of your startup or idea. Itâ€™s not a death knell.\"]]],[1,\"p\",[[0,[],0,\"On re-pricing:\"]]],[1,\"blockquote\",[[0,[],0,\"If an investor comes to you and wants to re-discuss pricing, I would encourage you to be open-minded to that. Try to close the current deal if you can, but if they want to reprice, thatâ€™s probably OK. Meeting somewhere in the middle is good, focus on getting the deal closed â€” Byron Deeter\"]]],[1,\"h3\",[[0,[],0,\"Alternative financing options\"]]],[1,\"p\",[[0,[],0,\"Consider venture debt as an option:\"]]],[1,\"blockquote\",[[0,[],0,\"If youâ€™ve already locked down a venture debt line and think you might need it in the next 12 months, I would encourage you to draw it down right now â€” Byron Deeter\"]]],[1,\"p\",[[0,[6],1,\"Careful though\"],[0,[],0,\"â€”in 2008 several debt providers withdrew venture lines they had extended to certain startups. In some cases, \"],[0,[7],1,\"this ended up taking down the company\"],[0,[],0,\", as they couldnâ€™t survive without the debt financing.\"]]],[1,\"p\",[[0,[],0,\"This is less of risk with the tier one debt providers, but be careful with others.\"]]],[10,5],[1,\"h2\",[[0,[],0,\"The â€œnew normalâ€ for VCs and founders\"]]],[1,\"h3\",[[0,[],0,\"Not all is lost\"]]],[10,6],[1,\"p\",[[0,[],0,\"The fundamentals of most startup businesses are \"],[0,[6],1,\"much\"],[0,[],0,\" better now than they used to be. Bookings will slow, churn will go up, but startup fundamentals are still much better than the 2000 or 2008 period where many companies went to zero.\"]]],[1,\"p\",[[0,[],0,\"Startups will get a little bit of a pass right now on financial performance from investors. Everyone understands that things are crazy right now. That free pass should last at least a few quarters.\"]]],[1,\"p\",[[0,[],0,\"The disruption may end up actually helping companies build a better foundation for the long-term by focusing on product and other critical areas and while deprioritizing go-to-market for the time being.\"]]],[1,\"p\",[[0,[],0,\"Even more reason to take a pause on go-to-market: some companies are reporting a spike in requests for demos right now, but \"],[0,[7],1,\"this is another false signal\"],[0,[],0,\". People are at home and bored, so they are signing up for demos on a whim. The conversion rate to actual deals will be \"],[0,[6],1,\"much\"],[0,[],0,\" lower than is typical.\"]]],[1,\"p\",[[0,[],0,\"Great entrepreneurship happens across all cycles, but your ability to scale will be moderated during this recessionary period.\"]]],[1,\"p\",[[0,[],0,\"If you have made a ton of progress since your last round, \"],[0,[7],1,\"up-rounds can still happen\"],[0,[],0,\". But if you have any worries, take what you can get as far as capital.\"]]],[1,\"p\",[[0,[],0,\"You have to accept that multiples before were simply fantastic. Now they may just be OK to good.\"]]],[1,\"p\",[[0,[],0,\"If you are in a structured program or accelerator like Y Combinator, donâ€™t be surprised if you donâ€™t find an investor as you exit the program. Typically, completing one of these programs without receiving funding is a bit of a black mark. The current situation is an exception to that.\"]]],[1,\"h3\",[[0,[],0,\"Batten down the hatches\"]]],[1,\"p\",[[0,[],0,\"That said, times are grim in more ways than one.\"]]],[1,\"p\",[[0,[7],1,\"Flat is the new up\"],[0,[],0,\"â€”if revenue doesnâ€™t decline you are doing something right.\"]]],[1,\"p\",[[0,[],0,\"Get your burn under control.\"]]],[10,7],[1,\"p\",[[0,[],0,\"Every late-stage CEO should be striving to get to the point of infinite runway, i.e. \"],[0,[7],1,\"breakeven profitability\"],[0,[],0,\". Early-stage CEOs should be targeting \"],[0,[7],1,\"18-24 months of runway\"],[0,[],0,\". Careful thoughâ€”18 months of runway is really 12 months of runway because it takes time to fundraise, especially in bad times.\"]]],[1,\"p\",[[0,[7],1,\"Sensitize all your projections.\"],[0,[],0,\" If bookings falls off, burn goes up, and thatâ€™s really tough on your cash runway.\"]]],[1,\"p\",[[0,[],0,\"If youâ€™re approaching an exit, know that the M&A market is likely heat up later this year. Many companies have been stockpiling cash, waiting for this moment. (The others are getting bailed out).\"]]],[1,\"p\",[[0,[],0,\"Companies that have been waiting to be aggressive will soon jump in. That should be true for transactions large and small.\"]]],[1,\"p\",[[0,[],0,\"Start building relationships and partnerships with potential strategic buyers \"],[0,[6],1,\"now\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"And if you were planning a public offering, be warnedâ€”the IPO market is \"],[0,[6],1,\"unlikely\"],[0,[],0,\" to recover in the same way.\"]]],[1,\"h2\",[[0,[],0,\"Changes in cloud software / SaaS\"]]],[1,\"h3\",[[0,[],0,\"SaaS valuations remain above long-term averages\"]]],[10,8],[1,\"p\",[[0,[],0,\"We have just seen one of the fastest 30% declines in market history. Itâ€™s almost unprecedented.\"]]],[1,\"p\",[[0,[],0,\"The good news is that itâ€™s driven by an external shock that didnâ€™t have to do with economic fundamentals. Therefore, optimistically we should see a solid rebound once things settle down, a vaccine is prepared, etc.\"]]],[1,\"p\",[[0,[],0,\"SaaS is fetching 8-10x multiples on revenue in the public markets, which is still much better than any other industry. Many of the well-known SaaS companies today grew up in an era where 8-10x revenue was the norm, and they did fine.\"]]],[1,\"p\",[[0,[],0,\"In hindsight these will seems like very reasonable numbers given whatâ€™s happening right now.\"]]],[10,9],[1,\"p\",[[0,[],0,\"Many people thought â€™08-09 was horrible, that we were never going to recover from it, but we did:\"]]],[1,\"blockquote\",[[0,[],0,\"Citibank told me to take my startupâ€™s cash and put it under a mattress. One of the biggest banks in the world had no confidence there would be an improvement in the market â€” Jason Lemkin\"]]],[1,\"p\",[[0,[],0,\"SaaS is particularly resilient relative to the overall economy:\"]]],[10,10],[1,\"h3\",[[0,[],0,\"Some industries and verticals will be harder hit than others\"]]],[10,11],[1,\"p\",[[0,[],0,\"While the macro picture for SaaS overall is far from dire, certain sub-sectors will see significant near-term pain.\"]]],[1,\"p\",[[0,[],0,\"There will be complete dislocations in certain industry verticals like travel. If your product serves SMBs, \"],[0,[7],1,\"be ready to take a hit\"],[0,[],0,\". Small businesses are seeing the worst disruption in the current environment.\"]]],[1,\"p\",[[0,[7],1,\"Recruiting solutions\"],[0,[],0,\" will probably have a tough go of it for the next few quarters, as will \"],[0,[7],1,\"marketing tech\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"The more core your product is to your customerâ€™s systems, the more resilient your revenue will probably be.\"]]],[1,\"p\",[[0,[],0,\"That said, prepare for some economic hit, no matter what industry you are in. Things can change very fastâ€”companies that were reporting no impact last week are now seeing \"],[0,[7],1,\"30-40%\"],[0,[],0,\" declines in new business.\"]]],[1,\"p\",[[0,[7],1,\"Get ahead of this\"],[0,[],0,\"â€”figure out what your leading indicators are for potential problems. Poor customer health, will ultimately lead to churn, which will lead to revenue and business impact.\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p><a href=\"https://www.bvp.com/team/byron-deeter/\">Byron Deeter</a>, Partner at <a href=\"https://www.bvp.com/\">Bessemer Venture Partners</a>, and <a href=\"https://twitter.com/jasonlk\">Jason Lemkin</a> of <a href=\"https://www.saastr.com/\">SaaStr</a> hosted a live Zoom discussion last week on the current state of venture capital and cloud software in the wake of the coronavirus turmoil.</p><p>They covered:</p><ul><li>What's happening in venture today</li><li>When founders should raise capital and what to expect</li><li>The \"new normal\" for VCs and founders</li><li>Changes in cloud software / SaaS</li></ul><p>The call was so fantastic that I wanted to share my summarized notes and takeaways with you.</p><p>You can find:</p><ul><li>the Zoom recording <a href=\"http://go2.saastr.com/n0Rv0yf03jo30TS0Za001ta\">here</a></li><li>the slides <a href=\"http://go2.saastr.com/Y01at0gov00jZ0033SR0zTa\">here</a></li><li>my notes below</li></ul><p>Enjoy!</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive my next thought in your inbox</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"I email every few weeks\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Byron Deeter and Jason Lemkin on the State of VC and the Cloud\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span>Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: html--><hr><h2 id=\"what-s-happening-in-venture-today\">Whatâ€™s happening in venture today</h2><h3 id=\"things-are-not-business-as-usual-even-for-vcs-who-have-capital-to-deploy\">Things are not â€œbusiness as usualâ€, even for VCs who have capital to deploy</h3><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/03/usual.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>VCs are going through an internal triage of portfolio companies, figuring out where the most damage has been done and what they can do to support their companies.</p><p>The best firms have plenty of reserves and will stand by and support their companies, especially the shining stars. The portfolio companies that arenâ€™t doing so well, who are tight on cashâ€¦ those are going to be the difficult situations.</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/03/fund.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>If a VC has just raised a fund, or itâ€™s only their first fund, and they havenâ€™t yet called the capital from Limited Partners, there <em>may</em> be some risk there.</p><p>We may see LPs pull back on commitments theyâ€™ve made to certain funds in order to handle their commitments to other funds. As there are tiers of venture firms, there are tiers of LPs, and the <strong>lower tier LPs are the ones more likely to pull out</strong>.</p><p>With all the turmoil on both the portfolio and LP side, VCs are spending less time on new deals. Net new checks are definitely going to decline:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/03/vc-survey.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><blockquote>As a firm, we are trying to be careful with our time. Bessemer is taking no courtesy meetings right now. Anyone we meet with is someone we think could actually be an interesting investment â€” Byron Deeter</blockquote><p>If a VC calls, <strong>you should still take it</strong>, but donâ€™t have too many expectations. Many â€œfalse signalsâ€ (i.e. mild, but not serious interest) right now.</p><h2 id=\"when-founders-should-raise-capital-and-what-to-expect\">When founders should raise capital and what to expect</h2><h3 id=\"go-or-no-go\">Go or no go?</h3><p>Driving net new conversations is going to be hard right now. VCs are simply busy right now, and thereâ€™s not much you can do about it.</p><p>Itâ€™s very difficult to start a deal process right now unless itâ€™s being lead by one of your existing investors or someone youâ€™ve already met and gotten to know well pre-crisis.</p><p>If a VC ghosts on you, donâ€™t take it personallyâ€”reach back out in a few weeks once things have settled down.</p><blockquote>If you already deep in negotiation and have most of the terms locked down, get the deal done immediately. Emphasize speed over greed â€” Bryon Deeter</blockquote><p>For companies that were right about to kick off a financing and donâ€™t have a big cash balance in reserve, thatâ€™s where the question of bridge financing comes up.</p><p>Given current conditions, bridge financings will be smaller in dollar terms than they typically are, but those dialogues are definitely happening.</p><blockquote>Founders should definitely ask their VCs for bridges, donâ€™t be afraid to ask â€” Jason Lemkin</blockquote><p>If you donâ€™t already have discussions underway, donâ€™t be afraid to hit pause. People will become more deal-minded in the coming months and will be looking to the broader market to inform pricing.</p><h3 id=\"term-sheets-are-a-slippery-concept\">Term sheets are a slippery concept</h3><p>Some people may try to take advantage of the current situation and retract term sheets.</p><p>Donâ€™t freak outâ€”these things happen.</p><p>See it as more of a temporary dynamic based off the current market situation than any judgement of your startup or idea. Itâ€™s not a death knell.</p><p>On re-pricing:</p><blockquote>If an investor comes to you and wants to re-discuss pricing, I would encourage you to be open-minded to that. Try to close the current deal if you can, but if they want to reprice, thatâ€™s probably OK. Meeting somewhere in the middle is good, focus on getting the deal closed â€” Byron Deeter</blockquote><h3 id=\"alternative-financing-options\">Alternative financing options</h3><p>Consider venture debt as an option:</p><blockquote>If youâ€™ve already locked down a venture debt line and think you might need it in the next 12 months, I would encourage you to draw it down right now â€” Byron Deeter</blockquote><p><em>Careful though</em>â€”in 2008 several debt providers withdrew venture lines they had extended to certain startups. In some cases, <strong>this ended up taking down the company</strong>, as they couldnâ€™t survive without the debt financing.</p><p>This is less of risk with the tier one debt providers, but be careful with others.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive my next thought in your inbox</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"I email every few weeks\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Middle: Byron Deeter and Jason Lemkin on the State of VC and the Cloud\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span>Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: html--><h2 id=\"the-new-normal-for-vcs-and-founders\">The â€œnew normalâ€ for VCs and founders</h2><h3 id=\"not-all-is-lost\">Not all is lost</h3><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/03/raise.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>The fundamentals of most startup businesses are <em>much</em> better now than they used to be. Bookings will slow, churn will go up, but startup fundamentals are still much better than the 2000 or 2008 period where many companies went to zero.</p><p>Startups will get a little bit of a pass right now on financial performance from investors. Everyone understands that things are crazy right now. That free pass should last at least a few quarters.</p><p>The disruption may end up actually helping companies build a better foundation for the long-term by focusing on product and other critical areas and while deprioritizing go-to-market for the time being.</p><p>Even more reason to take a pause on go-to-market: some companies are reporting a spike in requests for demos right now, but <strong>this is another false signal</strong>. People are at home and bored, so they are signing up for demos on a whim. The conversion rate to actual deals will be <em>much</em> lower than is typical.</p><p>Great entrepreneurship happens across all cycles, but your ability to scale will be moderated during this recessionary period.</p><p>If you have made a ton of progress since your last round, <strong>up-rounds can still happen</strong>. But if you have any worries, take what you can get as far as capital.</p><p>You have to accept that multiples before were simply fantastic. Now they may just be OK to good.</p><p>If you are in a structured program or accelerator like Y Combinator, donâ€™t be surprised if you donâ€™t find an investor as you exit the program. Typically, completing one of these programs without receiving funding is a bit of a black mark. The current situation is an exception to that.</p><h3 id=\"batten-down-the-hatches\">Batten down the hatches</h3><p>That said, times are grim in more ways than one.</p><p><strong>Flat is the new up</strong>â€”if revenue doesnâ€™t decline you are doing something right.</p><p>Get your burn under control.</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/03/burn.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Every late-stage CEO should be striving to get to the point of infinite runway, i.e. <strong>breakeven profitability</strong>. Early-stage CEOs should be targeting <strong>18-24 months of runway</strong>. Careful thoughâ€”18 months of runway is really 12 months of runway because it takes time to fundraise, especially in bad times.</p><p><strong>Sensitize all your projections.</strong> If bookings falls off, burn goes up, and thatâ€™s really tough on your cash runway.</p><p>If youâ€™re approaching an exit, know that the M&amp;A market is likely heat up later this year. Many companies have been stockpiling cash, waiting for this moment. (The others are getting bailed out).</p><p>Companies that have been waiting to be aggressive will soon jump in. That should be true for transactions large and small.</p><p>Start building relationships and partnerships with potential strategic buyers <em>now</em>.</p><p>And if you were planning a public offering, be warnedâ€”the IPO market is <em>unlikely</em> to recover in the same way.</p><h2 id=\"changes-in-cloud-software-saas\">Changes in cloud software / SaaS</h2><h3 id=\"saas-valuations-remain-above-long-term-averages\">SaaS valuations remain above long-term averages</h3><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/03/contractions.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>We have just seen one of the fastest 30% declines in market history. Itâ€™s almost unprecedented.</p><p>The good news is that itâ€™s driven by an external shock that didnâ€™t have to do with economic fundamentals. Therefore, optimistically we should see a solid rebound once things settle down, a vaccine is prepared, etc.</p><p>SaaS is fetching 8-10x multiples on revenue in the public markets, which is still much better than any other industry. Many of the well-known SaaS companies today grew up in an era where 8-10x revenue was the norm, and they did fine.</p><p>In hindsight these will seems like very reasonable numbers given whatâ€™s happening right now.</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/03/bvp.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Many people thought â€™08-09 was horrible, that we were never going to recover from it, but we did:</p><blockquote>Citibank told me to take my startupâ€™s cash and put it under a mattress. One of the biggest banks in the world had no confidence there would be an improvement in the market â€” Jason Lemkin</blockquote><p>SaaS is particularly resilient relative to the overall economy:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/03/SaaS-08-09.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><h3 id=\"some-industries-and-verticals-will-be-harder-hit-than-others\">Some industries and verticals will be harder hit than others</h3><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/03/cnbc.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>While the macro picture for SaaS overall is far from dire, certain sub-sectors will see significant near-term pain.</p><p>There will be complete dislocations in certain industry verticals like travel. If your product serves SMBs, <strong>be ready to take a hit</strong>. Small businesses are seeing the worst disruption in the current environment.</p><p><strong>Recruiting solutions</strong> will probably have a tough go of it for the next few quarters, as will <strong>marketing tech</strong>.</p><p>The more core your product is to your customerâ€™s systems, the more resilient your revenue will probably be.</p><p>That said, prepare for some economic hit, no matter what industry you are in. Things can change very fastâ€”companies that were reporting no impact last week are now seeing <strong>30-40%</strong> declines in new business.</p><p><strong>Get ahead of this</strong>â€”figure out what your leading indicators are for potential problems. Poor customer health, will ultimately lead to churn, which will lead to revenue and business impact.</p>","comment_id":"5e81aca3a1b4a869a793155e","plaintext":"Byron Deeter [https://www.bvp.com/team/byron-deeter/], Partner at Bessemer\nVenture Partners [https://www.bvp.com/], and Jason Lemkin\n[https://twitter.com/jasonlk] of SaaStr [https://www.saastr.com/] hosted a live\nZoom discussion last week on the current state of venture capital and cloud\nsoftware in the wake of the coronavirus turmoil.\n\nThey covered:\n\n * What's happening in venture today\n * When founders should raise capital and what to expect\n * The \"new normal\" for VCs and founders\n * Changes in cloud software / SaaS\n\nThe call was so fantastic that I wanted to share my summarized notes and\ntakeaways with you.\n\nYou can find:\n\n * the Zoom recording here [http://go2.saastr.com/n0Rv0yf03jo30TS0Za001ta]\n * the slides here [http://go2.saastr.com/Y01at0gov00jZ0033SR0zTa]\n * my notes below\n\nEnjoy!\n\nReceive my next thought in your inbox\n\n\nGo âš¡\n--------------------------------------------------------------------------------\n\nWhatâ€™s happening in venture today\nThings are not â€œbusiness as usualâ€, even for VCs who have capital to deploy\nVCs are going through an internal triage of portfolio companies, figuring out\nwhere the most damage has been done and what they can do to support their\ncompanies.\n\nThe best firms have plenty of reserves and will stand by and support their\ncompanies, especially the shining stars. The portfolio companies that arenâ€™t\ndoing so well, who are tight on cashâ€¦ those are going to be the difficult\nsituations.\n\nIf a VC has just raised a fund, or itâ€™s only their first fund, and they havenâ€™t\nyet called the capital from Limited Partners, there may be some risk there.\n\nWe may see LPs pull back on commitments theyâ€™ve made to certain funds in order\nto handle their commitments to other funds. As there are tiers of venture firms,\nthere are tiers of LPs, and the lower tier LPs are the ones more likely to pull\nout.\n\nWith all the turmoil on both the portfolio and LP side, VCs are spending less\ntime on new deals. Net new checks are definitely going to decline:\n\n> As a firm, we are trying to be careful with our time. Bessemer is taking no\ncourtesy meetings right now. Anyone we meet with is someone we think could\nactually be an interesting investment â€” Byron Deeter\nIf a VC calls, you should still take it, but donâ€™t have too many expectations.\nMany â€œfalse signalsâ€ (i.e. mild, but not serious interest) right now.\n\nWhen founders should raise capital and what to expect\nGo or no go?\nDriving net new conversations is going to be hard right now. VCs are simply busy\nright now, and thereâ€™s not much you can do about it.\n\nItâ€™s very difficult to start a deal process right now unless itâ€™s being lead by\none of your existing investors or someone youâ€™ve already met and gotten to know\nwell pre-crisis.\n\nIf a VC ghosts on you, donâ€™t take it personallyâ€”reach back out in a few weeks\nonce things have settled down.\n\n> If you already deep in negotiation and have most of the terms locked down, get\nthe deal done immediately. Emphasize speed over greed â€” Bryon Deeter\nFor companies that were right about to kick off a financing and donâ€™t have a big\ncash balance in reserve, thatâ€™s where the question of bridge financing comes up.\n\nGiven current conditions, bridge financings will be smaller in dollar terms than\nthey typically are, but those dialogues are definitely happening.\n\n> Founders should definitely ask their VCs for bridges, donâ€™t be afraid to ask â€”\nJason Lemkin\nIf you donâ€™t already have discussions underway, donâ€™t be afraid to hit pause.\nPeople will become more deal-minded in the coming months and will be looking to\nthe broader market to inform pricing.\n\nTerm sheets are a slippery concept\nSome people may try to take advantage of the current situation and retract term\nsheets.\n\nDonâ€™t freak outâ€”these things happen.\n\nSee it as more of a temporary dynamic based off the current market situation\nthan any judgement of your startup or idea. Itâ€™s not a death knell.\n\nOn re-pricing:\n\n> If an investor comes to you and wants to re-discuss pricing, I would encourage\nyou to be open-minded to that. Try to close the current deal if you can, but if\nthey want to reprice, thatâ€™s probably OK. Meeting somewhere in the middle is\ngood, focus on getting the deal closed â€” Byron Deeter\nAlternative financing options\nConsider venture debt as an option:\n\n> If youâ€™ve already locked down a venture debt line and think you might need it in\nthe next 12 months, I would encourage you to draw it down right now â€” Byron\nDeeter\nCareful thoughâ€”in 2008 several debt providers withdrew venture lines they had\nextended to certain startups. In some cases, this ended up taking down the\ncompany, as they couldnâ€™t survive without the debt financing.\n\nThis is less of risk with the tier one debt providers, but be careful with\nothers.\n\nReceive my next thought in your inbox\n\n\nGo âš¡The â€œnew normalâ€ for VCs and founders\nNot all is lost\nThe fundamentals of most startup businesses are much better now than they used\nto be. Bookings will slow, churn will go up, but startup fundamentals are still\nmuch better than the 2000 or 2008 period where many companies went to zero.\n\nStartups will get a little bit of a pass right now on financial performance from\ninvestors. Everyone understands that things are crazy right now. That free pass\nshould last at least a few quarters.\n\nThe disruption may end up actually helping companies build a better foundation\nfor the long-term by focusing on product and other critical areas and while\ndeprioritizing go-to-market for the time being.\n\nEven more reason to take a pause on go-to-market: some companies are reporting a\nspike in requests for demos right now, but this is another false signal. People\nare at home and bored, so they are signing up for demos on a whim. The\nconversion rate to actual deals will be much lower than is typical.\n\nGreat entrepreneurship happens across all cycles, but your ability to scale will\nbe moderated during this recessionary period.\n\nIf you have made a ton of progress since your last round, up-rounds can still\nhappen. But if you have any worries, take what you can get as far as capital.\n\nYou have to accept that multiples before were simply fantastic. Now they may\njust be OK to good.\n\nIf you are in a structured program or accelerator like Y Combinator, donâ€™t be\nsurprised if you donâ€™t find an investor as you exit the program. Typically,\ncompleting one of these programs without receiving funding is a bit of a black\nmark. The current situation is an exception to that.\n\nBatten down the hatches\nThat said, times are grim in more ways than one.\n\nFlat is the new upâ€”if revenue doesnâ€™t decline you are doing something right.\n\nGet your burn under control.\n\nEvery late-stage CEO should be striving to get to the point of infinite runway,\ni.e. breakeven profitability. Early-stage CEOs should be targeting 18-24 months\nof runway. Careful thoughâ€”18 months of runway is really 12 months of runway\nbecause it takes time to fundraise, especially in bad times.\n\nSensitize all your projections. If bookings falls off, burn goes up, and thatâ€™s\nreally tough on your cash runway.\n\nIf youâ€™re approaching an exit, know that the M&A market is likely heat up later\nthis year. Many companies have been stockpiling cash, waiting for this moment.\n(The others are getting bailed out).\n\nCompanies that have been waiting to be aggressive will soon jump in. That should\nbe true for transactions large and small.\n\nStart building relationships and partnerships with potential strategic buyers \nnow.\n\nAnd if you were planning a public offering, be warnedâ€”the IPO market is unlikely \nto recover in the same way.\n\nChanges in cloud software / SaaS\nSaaS valuations remain above long-term averages\nWe have just seen one of the fastest 30% declines in market history. Itâ€™s almost\nunprecedented.\n\nThe good news is that itâ€™s driven by an external shock that didnâ€™t have to do\nwith economic fundamentals. Therefore, optimistically we should see a solid\nrebound once things settle down, a vaccine is prepared, etc.\n\nSaaS is fetching 8-10x multiples on revenue in the public markets, which is\nstill much better than any other industry. Many of the well-known SaaS companies\ntoday grew up in an era where 8-10x revenue was the norm, and they did fine.\n\nIn hindsight these will seems like very reasonable numbers given whatâ€™s\nhappening right now.\n\nMany people thought â€™08-09 was horrible, that we were never going to recover\nfrom it, but we did:\n\n> Citibank told me to take my startupâ€™s cash and put it under a mattress. One of\nthe biggest banks in the world had no confidence there would be an improvement\nin the market â€” Jason Lemkin\nSaaS is particularly resilient relative to the overall economy:\n\nSome industries and verticals will be harder hit than others\nWhile the macro picture for SaaS overall is far from dire, certain sub-sectors\nwill see significant near-term pain.\n\nThere will be complete dislocations in certain industry verticals like travel.\nIf your product serves SMBs, be ready to take a hit. Small businesses are seeing\nthe worst disruption in the current environment.\n\nRecruiting solutions will probably have a tough go of it for the next few\nquarters, as will marketing tech.\n\nThe more core your product is to your customerâ€™s systems, the more resilient\nyour revenue will probably be.\n\nThat said, prepare for some economic hit, no matter what industry you are in.\nThings can change very fastâ€”companies that were reporting no impact last week\nare now seeing 30-40% declines in new business.\n\nGet ahead of thisâ€”figure out what your leading indicators are for potential\nproblems. Poor customer health, will ultimately lead to churn, which will lead\nto revenue and business impact.","feature_image":"__GHOST_URL__/content/images/2020/03/cover.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-03-30T08:24:03.000Z","updated_at":"2020-04-03T03:31:56.000Z","published_at":"2020-03-30T08:42:02.000Z","custom_excerpt":"When to raise capital, what to expect from VCs, and the \"new normal\"","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5e976b9c78b03e501b8d069e","uuid":"3a6ac394-7e8b-4018-8e7b-6a9625192f43","title":"Pandemiconomics: Viral Volatility","slug":"viral-volatility","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"/content/images/2020/04/uCUJlflCUA.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2020/04/MIAEpsbozj.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2020/04/LRy9A11nIY.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Middle: Pandemiconomics: Viral Volatility\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span>Subscribe</span></button>\\n</form>\\n</section>\"}],[\"image\",{\"src\":\"/content/images/2020/04/c1Qu9XtY6N.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2020/04/iN6ihzWBPg.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2020/04/gWelVoIq73.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}]],\"markups\":[[\"strong\"],[\"a\",[\"href\",\"https://www.nber.org/papers/w26945\"]],[\"em\"],[\"a\",[\"href\",\"https://www.nber.org/papers/w26950\"]],[\"a\",[\"href\",\"https://www.newyorkfed.org/medialibrary/media/research/staff_reports/sr920.pdf\"]],[\"a\",[\"href\",\"https://www.hoover.org/research/feds-depression-and-birth-new-deal\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"The sky fell. Then it bounced off the ground and rose a bit. Then it fell some more, and then it rose again. Now weâ€™re not really sure what itâ€™s doing.\"]]],[1,\"p\",[[0,[],0,\"Stock analysts and market watchers are understandably baffled and bewitched by the multi-month corona-coaster:\"]]],[10,0],[1,\"p\",[[0,[0],1,\"The volatility generated by the coronavirus pandemic beats out even the Great Depression and the global financial crisis of 2008.\"],[0,[],0,\" Never before has an infectious disease generated such volatility in the markets. This includes every previous pandemic on record, which typically have only tiny effects on the U.S. stock market. Even the Spanish Flu of 1919-1920, which killed 2% of the world's population, did not generate such market movement.\"]]],[1,\"h2\",[[0,[],0,\"The views of the news\"]]],[1,\"p\",[[0,[],0,\"We can quantify this differential impact by counting how often journalists attributed market volatility to ongoing pandemics or the accompanied policy responses. \"],[0,[1],1,\"Researchers did exactly this\"],[0,[],0,\", and what they found was striking:\"]]],[10,1],[1,\"p\",[[0,[],0,\"Of the 1,116 times since 1900 the stock market moved more than 2.5% in a single day prior to the Coronavirus, not once was the jump attributed in any way to a pandemic. Not once.\"]]],[1,\"p\",[[0,[],0,\"In contrast, of the 18 days between February 24 and March 24, 2020 where the market moved more than 2.5%, journalists attributed \"],[0,[0],1,\"7 days\"],[0,[],0,\" to the coronavirus and \"],[0,[0],1,\"8\"],[0,[],0,\" to the federal government's response to the virus. In other words, \"],[0,[0],1,\"15 of the 18 episodes of high volatility were virus-related\"],[0,[],0,\". This suggests updated information about the coronavirus caused nearly all outsized market movements.\"]]],[1,\"p\",[[0,[],0,\"In the words of the researchers, \"],[0,[0],1,\"\\\"no previous infectious disease episode led to daily stock market swings that even remotely resemble the response in the past month to the COVID-19 developments.\\\"\"]]],[1,\"p\",[[0,[],0,\"Letâ€™s stay on this theme of news coverage and look at this another way. Take the percentage of news articles talking about volatility, and subset those that mention an ongoing infectious disease pandemic. Here's what the same researchers found across multiple disease episodes:\"]]],[10,2],[1,\"p\",[[0,[],0,\"Coronavirus reigns supreme. Focus on the column â€œ\"],[0,[2],1,\"(2) % of EMV Articles with Infectious Disease Terms\"],[0,[],0,\"â€, where you can see the ramp in volatility coverage mentioning the coronavirus. \"],[0,[0],1,\"91% of volatility-related news articles in March 2020 mentioned the coronavirus\"],[0,[],0,\". This compares to peak news share of 5% for the Bird Flu of 1997-1998, 8% for SARS, 4% for Swine Flu / H1N1, and 11% for Ebola and MERS.\"]]],[10,3],[1,\"h2\",[[0,[],0,\"Can we trade on this?\"]]],[1,\"p\",[[0,[],0,\"Ok, so the virus clearly drives volatility.\"]]],[1,\"p\",[[0,[],0,\"Let's take the next logical step â€” \"],[0,[0],1,\"can we predict stock market movements using updated information on the virus?\"],[0,[],0,\" Even further, \"],[0,[0],1,\"can we use predictions of the virus' spread to predict market movements?\"]]],[1,\"p\",[[0,[],0,\"According to one of my old economics professors, we can. Sort of.\"]]],[1,\"p\",[[0,[3],1,\"Peter Schott of Yale and a team of fellow researchers\"],[0,[],0,\" explore this idea with a simple exponential growth model of COVID-19. They trained the model on actual data, updating its forecasts for every additional daily data point, noting how the model's predictions change day-to-day. These updates represent the predictive value of the daily stream of new information about the spread of the virus.\"]]],[1,\"p\",[[0,[],0,\"They then plotted these prediction updates against the daily changes of the Wilshire 5000 index, which you can see below. They found a noisy but negative relationship between projection updates and the stock market:\"]]],[10,4],[1,\"p\",[[0,[],0,\"They go further and estimate linear regressions of this relationship, summarized below:\"]]],[10,5],[1,\"p\",[[0,[],0,\"Focus on column \"],[0,[0],1,\"(2)\"],[0,[],0,\". The coefficient of -0.086 implies that a doubling of predicted cases leads to a 8.6% lower closing price for the Wilshire 5000 index on that same day. Scaling this down, a 10% increase in predicted COVID-19 cases yields a 0.86% drop in the market.\"]]],[1,\"p\",[[0,[],0,\"Per columns \"],[0,[0],1,\"(5)\"],[0,[],0,\" and \"],[0,[0],1,\"(6)\"],[0,[],0,\", the relationship holds even after controlling for the governmentâ€™s response to the virus, showing that we can separate the impact of the virus itself from the impact of our response to the virus.\"]]],[1,\"p\",[[0,[],0,\"Let's not get ahead of ourselves. Though the relationship is statistically significant, the R^2 of the regression is only 0.105, which simply means you can't predict the market very well using only an exponential viral growth model as your only input. The sample is also small, containing only 41 days of data. That said, there is clear informational value contained in these updated forecasts, which suggests they drive market movements.\"]]],[1,\"h2\",[[0,[],0,\"The upshot\"]]],[1,\"p\",[[0,[0],1,\"If epidemiological uncertainty drives stock volatility, volatility should taper as uncertainty declines.\"]]],[1,\"p\",[[0,[],0,\"This is happening right now, in real-time.\"]]],[1,\"p\",[[0,[],0,\"Though the crisis is far from over, our forecasts are improving. This is good news in a time of mostly bad.\"]]],[1,\"p\",[[0,[],0,\"Meanwhile, a \"],[0,[4],1,\"paper out of the NY Fed\"],[0,[],0,\" this month shows the economic impact of the \\\"sudden stop\\\" in economic activity. This reflects not so much the virus itself but policy responses to the virus, which have been meaningful, if not always swift:\"]]],[10,6],[1,\"p\",[[0,[],0,\"People often blame the severity of the Great Depression on \"],[0,[5],1,\"misguided policies of the Federal Reserve\"],[0,[],0,\", but this is a man-made recession like nothing we've ever seen.\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p>The sky fell. Then it bounced off the ground and rose a bit. Then it fell some more, and then it rose again. Now weâ€™re not really sure what itâ€™s doing.</p><p>Stock analysts and market watchers are understandably baffled and bewitched by the multi-month corona-coaster:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/04/uCUJlflCUA.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p><strong>The volatility generated by the coronavirus pandemic beats out even the Great Depression and the global financial crisis of 2008.</strong> Never before has an infectious disease generated such volatility in the markets. This includes every previous pandemic on record, which typically have only tiny effects on the U.S. stock market. Even the Spanish Flu of 1919-1920, which killed 2% of the world's population, did not generate such market movement.</p><h2 id=\"the-views-of-the-news\">The views of the news</h2><p>We can quantify this differential impact by counting how often journalists attributed market volatility to ongoing pandemics or the accompanied policy responses. <a href=\"https://www.nber.org/papers/w26945\">Researchers did exactly this</a>, and what they found was striking:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/04/MIAEpsbozj.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Of the 1,116 times since 1900 the stock market moved more than 2.5% in a single day prior to the Coronavirus, not once was the jump attributed in any way to a pandemic. Not once.</p><p>In contrast, of the 18 days between February 24 and March 24, 2020 where the market moved more than 2.5%, journalists attributed <strong>7 days</strong> to the coronavirus and <strong>8</strong> to the federal government's response to the virus. In other words, <strong>15 of the 18 episodes of high volatility were virus-related</strong>. This suggests updated information about the coronavirus caused nearly all outsized market movements.</p><p>In the words of the researchers, <strong>\"no previous infectious disease episode led to daily stock market swings that even remotely resemble the response in the past month to the COVID-19 developments.\"</strong></p><p>Letâ€™s stay on this theme of news coverage and look at this another way. Take the percentage of news articles talking about volatility, and subset those that mention an ongoing infectious disease pandemic. Here's what the same researchers found across multiple disease episodes:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/04/LRy9A11nIY.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Coronavirus reigns supreme. Focus on the column â€œ<em>(2) % of EMV Articles with Infectious Disease Terms</em>â€, where you can see the ramp in volatility coverage mentioning the coronavirus. <strong>91% of volatility-related news articles in March 2020 mentioned the coronavirus</strong>. This compares to peak news share of 5% for the Bird Flu of 1997-1998, 8% for SARS, 4% for Swine Flu / H1N1, and 11% for Ebola and MERS.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Middle: Pandemiconomics: Viral Volatility\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span>Subscribe</span></button>\n</form>\n</section><!--kg-card-end: html--><h2 id=\"can-we-trade-on-this\">Can we trade on this?</h2><p>Ok, so the virus clearly drives volatility.</p><p>Let's take the next logical step â€” <strong>can we predict stock market movements using updated information on the virus?</strong> Even further, <strong>can we use predictions of the virus' spread to predict market movements?</strong></p><p>According to one of my old economics professors, we can. Sort of.</p><p><a href=\"https://www.nber.org/papers/w26950\">Peter Schott of Yale and a team of fellow researchers</a> explore this idea with a simple exponential growth model of COVID-19. They trained the model on actual data, updating its forecasts for every additional daily data point, noting how the model's predictions change day-to-day. These updates represent the predictive value of the daily stream of new information about the spread of the virus.</p><p>They then plotted these prediction updates against the daily changes of the Wilshire 5000 index, which you can see below. They found a noisy but negative relationship between projection updates and the stock market:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/04/c1Qu9XtY6N.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>They go further and estimate linear regressions of this relationship, summarized below:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/04/iN6ihzWBPg.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Focus on column <strong>(2)</strong>. The coefficient of -0.086 implies that a doubling of predicted cases leads to a 8.6% lower closing price for the Wilshire 5000 index on that same day. Scaling this down, a 10% increase in predicted COVID-19 cases yields a 0.86% drop in the market.</p><p>Per columns <strong>(5)</strong> and <strong>(6)</strong>, the relationship holds even after controlling for the governmentâ€™s response to the virus, showing that we can separate the impact of the virus itself from the impact of our response to the virus.</p><p>Let's not get ahead of ourselves. Though the relationship is statistically significant, the R^2 of the regression is only 0.105, which simply means you can't predict the market very well using only an exponential viral growth model as your only input. The sample is also small, containing only 41 days of data. That said, there is clear informational value contained in these updated forecasts, which suggests they drive market movements.</p><h2 id=\"the-upshot\">The upshot</h2><p><strong>If epidemiological uncertainty drives stock volatility, volatility should taper as uncertainty declines.</strong></p><p>This is happening right now, in real-time.</p><p>Though the crisis is far from over, our forecasts are improving. This is good news in a time of mostly bad.</p><p>Meanwhile, a <a href=\"https://www.newyorkfed.org/medialibrary/media/research/staff_reports/sr920.pdf\">paper out of the NY Fed</a> this month shows the economic impact of the \"sudden stop\" in economic activity. This reflects not so much the virus itself but policy responses to the virus, which have been meaningful, if not always swift:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/04/gWelVoIq73.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>People often blame the severity of the Great Depression on <a href=\"https://www.hoover.org/research/feds-depression-and-birth-new-deal\">misguided policies of the Federal Reserve</a>, but this is a man-made recession like nothing we've ever seen.</p>","comment_id":"5e976b9c78b03e501b8d069e","plaintext":"The sky fell. Then it bounced off the ground and rose a bit. Then it fell some\nmore, and then it rose again. Now weâ€™re not really sure what itâ€™s doing.\n\nStock analysts and market watchers are understandably baffled and bewitched by\nthe multi-month corona-coaster:\n\nThe volatility generated by the coronavirus pandemic beats out even the Great\nDepression and the global financial crisis of 2008. Never before has an\ninfectious disease generated such volatility in the markets. This includes every\nprevious pandemic on record, which typically have only tiny effects on the U.S.\nstock market. Even the Spanish Flu of 1919-1920, which killed 2% of the world's\npopulation, did not generate such market movement.\n\nThe views of the news\nWe can quantify this differential impact by counting how often journalists\nattributed market volatility to ongoing pandemics or the accompanied policy\nresponses. Researchers did exactly this [https://www.nber.org/papers/w26945],\nand what they found was striking:\n\nOf the 1,116 times since 1900 the stock market moved more than 2.5% in a single\nday prior to the Coronavirus, not once was the jump attributed in any way to a\npandemic. Not once.\n\nIn contrast, of the 18 days between February 24 and March 24, 2020 where the\nmarket moved more than 2.5%, journalists attributed 7 days to the coronavirus\nand 8 to the federal government's response to the virus. In other words, 15 of\nthe 18 episodes of high volatility were virus-related. This suggests updated\ninformation about the coronavirus caused nearly all outsized market movements.\n\nIn the words of the researchers, \"no previous infectious disease episode led to\ndaily stock market swings that even remotely resemble the response in the past\nmonth to the COVID-19 developments.\"\n\nLetâ€™s stay on this theme of news coverage and look at this another way. Take the\npercentage of news articles talking about volatility, and subset those that\nmention an ongoing infectious disease pandemic. Here's what the same researchers\nfound across multiple disease episodes:\n\nCoronavirus reigns supreme. Focus on the column â€œ(2) % of EMV Articles with\nInfectious Disease Termsâ€, where you can see the ramp in volatility coverage\nmentioning the coronavirus. 91% of volatility-related news articles in March\n2020 mentioned the coronavirus. This compares to peak news share of 5% for the\nBird Flu of 1997-1998, 8% for SARS, 4% for Swine Flu / H1N1, and 11% for Ebola\nand MERS.\n\nReceive my next long-form post\nThoughtful analysis of the business and economics of tech\n\n\n\nSubscribeCan we trade on this?\nOk, so the virus clearly drives volatility.\n\nLet's take the next logical step â€” can we predict stock market movements using\nupdated information on the virus? Even further, can we use predictions of the\nvirus' spread to predict market movements?\n\nAccording to one of my old economics professors, we can. Sort of.\n\nPeter Schott of Yale and a team of fellow researchers\n[https://www.nber.org/papers/w26950] explore this idea with a simple exponential\ngrowth model of COVID-19. They trained the model on actual data, updating its\nforecasts for every additional daily data point, noting how the model's\npredictions change day-to-day. These updates represent the predictive value of\nthe daily stream of new information about the spread of the virus.\n\nThey then plotted these prediction updates against the daily changes of the\nWilshire 5000 index, which you can see below. They found a noisy but negative\nrelationship between projection updates and the stock market:\n\nThey go further and estimate linear regressions of this relationship, summarized\nbelow:\n\nFocus on column (2). The coefficient of -0.086 implies that a doubling of\npredicted cases leads to a 8.6% lower closing price for the Wilshire 5000 index\non that same day. Scaling this down, a 10% increase in predicted COVID-19 cases\nyields a 0.86% drop in the market.\n\nPer columns (5) and (6), the relationship holds even after controlling for the\ngovernmentâ€™s response to the virus, showing that we can separate the impact of\nthe virus itself from the impact of our response to the virus.\n\nLet's not get ahead of ourselves. Though the relationship is statistically\nsignificant, the R^2 of the regression is only 0.105, which simply means you\ncan't predict the market very well using only an exponential viral growth model\nas your only input. The sample is also small, containing only 41 days of data.\nThat said, there is clear informational value contained in these updated\nforecasts, which suggests they drive market movements.\n\nThe upshot\nIf epidemiological uncertainty drives stock volatility, volatility should taper\nas uncertainty declines.\n\nThis is happening right now, in real-time.\n\nThough the crisis is far from over, our forecasts are improving. This is good\nnews in a time of mostly bad.\n\nMeanwhile, a paper out of the NY Fed\n[https://www.newyorkfed.org/medialibrary/media/research/staff_reports/sr920.pdf] \nthis month shows the economic impact of the \"sudden stop\" in economic activity.\nThis reflects not so much the virus itself but policy responses to the virus,\nwhich have been meaningful, if not always swift:\n\nPeople often blame the severity of the Great Depression on misguided policies\nof\nthe Federal Reserve\n[https://www.hoover.org/research/feds-depression-and-birth-new-deal], but this\nis a man-made recession like nothing we've ever seen.","feature_image":"__GHOST_URL__/content/images/2020/04/header.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-04-15T20:16:28.000Z","updated_at":"2020-04-21T15:29:55.000Z","published_at":"2020-04-15T21:22:57.000Z","custom_excerpt":"How the virus rocked stocks","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5ec4903e78b03e501b8d06d5","uuid":"4ca3370e-01e4-4494-b759-ac81ecfeb467","title":"Do College Degrees Matter for Software Engineers? Maybe","slug":"college-degrees-software-engineers","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"/content/images/2020/05/EdLevel-1.png\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive a report with the full results</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Your Email Address\\\" id=\\\"mce-EMAIL\\\" required>\\n<input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Middle: Do College Degrees Matter for Software Engineers? Maybe\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Send Report âš¡</span></button>\\n</form>\\n            </section>\\n<!--<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive my next thought in your inbox</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email address\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Middle: Remote Software Developers Earn 22% More Than Non-Remote Developers\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span>Subscribe</span></button>\\n</form>\\n</section>-->\"}],[\"image\",{\"src\":\"/content/images/2020/05/DraggedImage.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2020/05/DraggedImage-1.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}]],\"markups\":[[\"em\"],[\"a\",[\"href\",\"__GHOST_URL__/highest-paid-software-engineers-2020/\"]],[\"a\",[\"href\",\"https://lambdaschool.com/about\"]],[\"strong\"],[\"a\",[\"href\",\"__GHOST_URL__/age-race-gender-software-engineering-pay/\"]],[\"code\"],[\"a\",[\"href\",\"https://research.stlouisfed.org/publications/review/2019/10/15/is-college-still-worth-it-the-new-calculus-of-falling-returns\"]],[\"a\",[\"href\",\"https://lambdaschool.com/\"]],[\"a\",[\"href\",\"https://www.theinformation.com/articles/lambda-schools-growing-pains-big-buzz-student-complaints\"]]],\"sections\":[[1,\"p\",[[0,[0],0,\"This post is an excerpt from my \"],[0,[1],1,\"2020 software developer pay analysis\"],[0,[],0,\". Read the rest of the analysis \"],[0,[1],1,\"here\"],[0,[],1,\".\"]]],[1,\"p\",[[0,[],0,\"Coding bootcamps say \"],[0,[2],1,\"the traditional model of education is broken\"],[0,[],0,\" and that anyone can become a software developer with the proper effort.\"]]],[1,\"p\",[[0,[],0,\"Further, they claim that traditional institutions arenâ€™t incentivized to ensure their graduates get hired post-school.\"]]],[1,\"p\",[[0,[],0,\"Regardless of your views, these claims ignore an important question: letâ€™s say you get the job â€” \"],[0,[3],1,\"will you earn less as a software developer without a college degree\"],[0,[],0,\"?\"]]],[1,\"h2\",[[0,[],0,\"Yes, but itâ€™s not as bad as you might think\"]]],[10,0],[1,\"p\",[[0,[],0,\"Developers with college degrees earn \"],[0,[3],1,\"7.5%\"],[0,[],0,\" more than developers with no college education.\"]]],[1,\"p\",[[0,[],0,\"As in \"],[0,[4],1,\"previous analyses\"],[0,[],0,\", I additionally control for various observable factors like \"],[0,[5],1,\"age\"],[0,[],0,\", \"],[0,[5],1,\"experience\"],[0,[],0,\", \"],[0,[5],1,\"hours worked\"],[0,[],0,\", \"],[0,[5],1,\"size of employer\"],[0,[],0,\", \"],[0,[5],1,\"programming languages\"],[0,[],0,\" \"],[0,[1],1,\"and more\"],[0,[],0,\". Interestingly, accounting for these factors doesnâ€™t change the college wage premium.\"]]],[1,\"p\",[[0,[],0,\"Advanced degrees carry greater benefits â€” masterâ€™s degree holders earn \"],[0,[3],1,\"13.3%\"],[0,[],0,\" more than college degree holders, while those with doctoral degrees (i.e. PhDs) earn \"],[0,[3],1,\"20.5%\"],[0,[],0,\" more. These numbers decrease meaningfully though once I add in the controls I mentioned above, falling to \"],[0,[3],1,\"4.1%\"],[0,[],0,\" and \"],[0,[3],1,\"7.8%\"],[0,[],0,\" respectively.\"]]],[10,1],[1,\"h2\",[[0,[],0,\"Is this a big deal?\"]]],[1,\"p\",[[0,[],0,\"Now, a 7.5% college degree advantage is nothing to scoff at.\"]]],[1,\"p\",[[0,[],0,\"But 7.5% is \"],[0,[0],1,\"tiny\"],[0,[],0,\" relative to the college wage premium earned by the public at large.\"]]],[1,\"p\",[[0,[],0,\"A review of the evidence around higher education shows that the college wage premium is much higher for the overall population. In \"],[0,[6],1,\"my favorite study\"],[0,[],0,\" on this topic, researchers at the Federal Reserve Bank of St. Louis show that, controlling for age and level of degree (college vs. graduate), college graduates earn \"],[0,[3],1,\"~50% \"],[0,[],0,\"more than non-graduates (the data is similar for other ethnicities):\"]]],[10,2],[1,\"p\",[[0,[],0,\"So the college degree wage premium for software developers is much smaller than the broader population benefit. This is not that surprising â€” income variation within careers is typically much narrower than across careers.\"]]],[1,\"h2\",[[0,[],0,\"Getting the gig\"]]],[1,\"p\",[[0,[],0,\"Of course, this all assumes you get the job in the first place.\"]]],[1,\"p\",[[0,[],0,\"It doesnâ€™t matter how much a college degree impacts oneâ€™s earnings as a software developer if not having one effectively locks you out of the career.\"]]],[1,\"p\",[[0,[],0,\"Itâ€™s hard to judge how true this is. If you believe the hype around \"],[0,[7],1,\"Lambda School\"],[0,[],0,\" and other bootcamp programs, a college degree is not necessarily a barrier to becoming a software developer. Realistically, few people without a college degree bother to pursue software engineering, but that doesnâ€™t mean they couldnâ€™t if they put their mind to it.\"]]],[10,3],[1,\"p\",[[0,[],0,\"If bootcamps and other alternative forms of education can successfully train and place students in legitimate software engineering roles, then a college degree might not be required.\"]]],[1,\"p\",[[0,[],0,\"I think the jury is still out. \"],[0,[8],1,\"Recent media reports\"],[0,[],0,\" have not been kind to coding bootcamps like Lambda. Then again, anecdotes may not represent the full story. For now, only the schools themselves have the data to prove their own efficacy.\"]]],[1,\"p\",[[0,[],0,\"That said, we can finally put some numbers behind the claim that college degrees donâ€™t matter for software engineers. They matter, but not much, assuming you can get hired as a developer. Once in the seat, your degree matters much less than other factors, like on the job performance, competence, etc.\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p><em>This post is an excerpt from my <a href=\"__GHOST_URL__/highest-paid-software-engineers-2020/\">2020 software developer pay analysis</a>. Read the rest of the analysis <a href=\"__GHOST_URL__/highest-paid-software-engineers-2020/\">here</a>.</em></p><p>Coding bootcamps say <a href=\"https://lambdaschool.com/about\">the traditional model of education is broken</a> and that anyone can become a software developer with the proper effort.</p><p>Further, they claim that traditional institutions arenâ€™t incentivized to ensure their graduates get hired post-school.</p><p>Regardless of your views, these claims ignore an important question: letâ€™s say you get the job â€” <strong>will you earn less as a software developer without a college degree</strong>?</p><h2 id=\"yes-but-it-s-not-as-bad-as-you-might-think\">Yes, but itâ€™s not as bad as you might think</h2><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/05/EdLevel-1.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Developers with college degrees earn <strong>7.5%</strong> more than developers with no college education.</p><p>As in <a href=\"__GHOST_URL__/age-race-gender-software-engineering-pay/\">previous analyses</a>, I additionally control for various observable factors like <code>age</code>, <code>experience</code>, <code>hours worked</code>, <code>size of employer</code>, <code>programming languages</code> <a href=\"__GHOST_URL__/highest-paid-software-engineers-2020/\">and more</a>. Interestingly, accounting for these factors doesnâ€™t change the college wage premium.</p><p>Advanced degrees carry greater benefits â€” masterâ€™s degree holders earn <strong>13.3%</strong> more than college degree holders, while those with doctoral degrees (i.e. PhDs) earn <strong>20.5%</strong> more. These numbers decrease meaningfully though once I add in the controls I mentioned above, falling to <strong>4.1%</strong> and <strong>7.8%</strong> respectively.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive a report with the full results</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Your Email Address\" id=\"mce-EMAIL\" required>\n<input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Middle: Do College Degrees Matter for Software Engineers? Maybe\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Send Report âš¡</span></button>\n</form>\n            </section>\n<!--<section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive my next thought in your inbox</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email address\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Middle: Remote Software Developers Earn 22% More Than Non-Remote Developers\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span>Subscribe</span></button>\n</form>\n</section>--><!--kg-card-end: html--><h2 id=\"is-this-a-big-deal\">Is this a big deal?</h2><p>Now, a 7.5% college degree advantage is nothing to scoff at.</p><p>But 7.5% is <em>tiny</em> relative to the college wage premium earned by the public at large.</p><p>A review of the evidence around higher education shows that the college wage premium is much higher for the overall population. In <a href=\"https://research.stlouisfed.org/publications/review/2019/10/15/is-college-still-worth-it-the-new-calculus-of-falling-returns\">my favorite study</a> on this topic, researchers at the Federal Reserve Bank of St. Louis show that, controlling for age and level of degree (college vs. graduate), college graduates earn <strong>~50% </strong>more than non-graduates (the data is similar for other ethnicities):</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/05/DraggedImage.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>So the college degree wage premium for software developers is much smaller than the broader population benefit. This is not that surprising â€” income variation within careers is typically much narrower than across careers.</p><h2 id=\"getting-the-gig\">Getting the gig</h2><p>Of course, this all assumes you get the job in the first place.</p><p>It doesnâ€™t matter how much a college degree impacts oneâ€™s earnings as a software developer if not having one effectively locks you out of the career.</p><p>Itâ€™s hard to judge how true this is. If you believe the hype around <a href=\"https://lambdaschool.com/\">Lambda School</a> and other bootcamp programs, a college degree is not necessarily a barrier to becoming a software developer. Realistically, few people without a college degree bother to pursue software engineering, but that doesnâ€™t mean they couldnâ€™t if they put their mind to it.</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/05/DraggedImage-1.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>If bootcamps and other alternative forms of education can successfully train and place students in legitimate software engineering roles, then a college degree might not be required.</p><p>I think the jury is still out. <a href=\"https://www.theinformation.com/articles/lambda-schools-growing-pains-big-buzz-student-complaints\">Recent media reports</a> have not been kind to coding bootcamps like Lambda. Then again, anecdotes may not represent the full story. For now, only the schools themselves have the data to prove their own efficacy.</p><p>That said, we can finally put some numbers behind the claim that college degrees donâ€™t matter for software engineers. They matter, but not much, assuming you can get hired as a developer. Once in the seat, your degree matters much less than other factors, like on the job performance, competence, etc.</p>","comment_id":"5ec4903e78b03e501b8d06d5","plaintext":"This post is an excerpt from my 2020 software developer pay analysis\n[__GHOST_URL__/highest-paid-software-engineers-2020/]. Read the rest of the\nanalysis here [__GHOST_URL__/highest-paid-software-engineers-2020/].\n\nCoding bootcamps say the traditional model of education is broken\n[https://lambdaschool.com/about] and that anyone can become a software developer\nwith the proper effort.\n\nFurther, they claim that traditional institutions arenâ€™t incentivized to ensure\ntheir graduates get hired post-school.\n\nRegardless of your views, these claims ignore an important question: letâ€™s say\nyou get the job â€” will you earn less as a software developer without a college\ndegree?\n\nYes, but itâ€™s not as bad as you might think\nDevelopers with college degrees earn 7.5% more than developers with no college\neducation.\n\nAs in previous analyses\n[__GHOST_URL__/age-race-gender-software-engineering-pay/], I additionally\ncontrol for various observable factors like age, experience, hours worked, size\nof employer, programming languages and more\n[__GHOST_URL__/highest-paid-software-engineers-2020/]. Interestingly, accounting\nfor these factors doesnâ€™t change the college wage premium.\n\nAdvanced degrees carry greater benefits â€” masterâ€™s degree holders earn 13.3% \nmore than college degree holders, while those with doctoral degrees (i.e. PhDs)\nearn 20.5% more. These numbers decrease meaningfully though once I add in the\ncontrols I mentioned above, falling to 4.1% and 7.8% respectively.\n\nReceive a report with the full results\n\n\nSend Report âš¡ Is this a big deal?\nNow, a 7.5% college degree advantage is nothing to scoff at.\n\nBut 7.5% is tiny relative to the college wage premium earned by the public at\nlarge.\n\nA review of the evidence around higher education shows that the college wage\npremium is much higher for the overall population. In my favorite study\n[https://research.stlouisfed.org/publications/review/2019/10/15/is-college-still-worth-it-the-new-calculus-of-falling-returns] \non this topic, researchers at the Federal Reserve Bank of St. Louis show that,\ncontrolling for age and level of degree (college vs. graduate), college\ngraduates earn ~50% more than non-graduates (the data is similar for other\nethnicities):\n\nSo the college degree wage premium for software developers is much smaller than\nthe broader population benefit. This is not that surprising â€” income variation\nwithin careers is typically much narrower than across careers.\n\nGetting the gig\nOf course, this all assumes you get the job in the first place.\n\nIt doesnâ€™t matter how much a college degree impacts oneâ€™s earnings as a software\ndeveloper if not having one effectively locks you out of the career.\n\nItâ€™s hard to judge how true this is. If you believe the hype around Lambda\nSchool [https://lambdaschool.com/] and other bootcamp programs, a college degree\nis not necessarily a barrier to becoming a software developer. Realistically,\nfew people without a college degree bother to pursue software engineering, but\nthat doesnâ€™t mean they couldnâ€™t if they put their mind to it.\n\nIf bootcamps and other alternative forms of education can successfully train and\nplace students in legitimate software engineering roles, then a college degree\nmight not be required.\n\nI think the jury is still out. Recent media reports\n[https://www.theinformation.com/articles/lambda-schools-growing-pains-big-buzz-student-complaints] \nhave not been kind to coding bootcamps like Lambda. Then again, anecdotes may\nnot represent the full story. For now, only the schools themselves have the data\nto prove their own efficacy.\n\nThat said, we can finally put some numbers behind the claim that college degrees\ndonâ€™t matter for software engineers. They matter, but not much, assuming you can\nget hired as a developer. Once in the seat, your degree matters much less than\nother factors, like on the job performance, competence, etc.","feature_image":"__GHOST_URL__/content/images/2020/05/EdLevel_header-3.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-05-20T02:04:46.000Z","updated_at":"2020-05-20T15:52:22.000Z","published_at":"2020-05-20T15:39:14.000Z","custom_excerpt":"Do college-educated developers earn more? Yes, but less than you might think","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5eea4c812fa60d0ab28d5ca5","uuid":"8d399fcf-8a21-4fe5-85ee-cfa69fc77b99","title":"The Value of College May Be Negative for the COVID Generation","slug":"the-value-of-college","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/06/CleanShot-2020-05-23-at-01.21.24@2x.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: The Value of College May Be Negative for the COVID Generation\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Subscribe</span></button>\\n</form>\\n</section>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/06/CleanShot-2020-05-23-at-01.22.20@2x.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/06/CleanShot-2020-05-23-at-01.41.03@2x.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/06/CleanShot-2020-05-25-at-02.04.33@2x.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Middle: The Value of College May Be Negative for the COVID Generation\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Subscribe</span></button>\\n</form>\\n</section>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/06/DraggedImage.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/06/DraggedImage-1.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/06/CleanShot-2020-05-29-at-23.47.16@2x.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/06/CleanShot-2020-05-23-at-01.16.34@2x.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"\"}]],\"markups\":[[\"a\",[\"href\",\"https://research.stlouisfed.org/publications/review/2019/10/15/is-college-still-worth-it-the-new-calculus-of-falling-returns\"]],[\"em\"],[\"strong\"],[\"a\",[\"href\",\"__GHOST_URL__/remote-software-developers-earn-more/\"]],[\"a\",[\"href\",\"https://opinionator.blogs.nytimes.com/2014/03/01/college-the-great-unleveler/\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Garbage_in,_garbage_out\"]],[\"a\",[\"href\",\"__GHOST_URL__/you-dont-understand-compound-growth/\"]],[\"a\",[\"href\",\"https://www.pewtrusts.org/~/media/legacy/uploadedfiles/pcs_assets/2013/pewcollegegradsrecessionreportpdf.pdf\"]],[\"a\",[\"href\",\"https://www.stlouisfed.org/household-financial-stability/staff-profiles/william-r-emmons/bio\"]],[\"a\",[\"href\",\"https://www.stlouisfed.org/household-financial-stability/staff-profiles/ana-hernandez-kent/bio\"]],[\"a\",[\"href\",\"https://www.stlouisfed.org/household-financial-stability/staff-profiles/lowell-r-ricketts/bio\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"The value of a college degree is crashing toward zero and may even be negative for today's COVID-graduates.\"]]],[1,\"p\",[[0,[],0,\"This is the stunning implication of \"],[0,[0],1,\"recent research\"],[0,[],0,\" by the Federal Reserve into the precipitously falling financial returns of higher education.\"]]],[1,\"p\",[[0,[],0,\"You might be thinking â€” â€œ\"],[0,[1],1,\"but I thought the benefit of a college degree has been increasing all this time?\"],[0,[],0,\"â€\"]]],[1,\"p\",[[0,[],0,\"You would be wrong, though understandably so.\"]]],[1,\"p\",[[0,[],0,\"Hereâ€™s a sketch of the basic argument:\"]]],[3,\"ol\",[[[0,[],0,\"College graduates continue to earn significantly more than non-college graduates\"]],[[0,[],0,\"However, the \"],[0,[1],1,\"causal\"],[0,[],0,\" (key word) income effect of college has \"],[0,[2],1,\"not\"],[0,[],0,\" increased and, if anything, has declined\"]],[[0,[],0,\"Meanwhile, the cost of attending college has ballooned\"]],[[0,[],0,\"Therefore, the wealth-generating power of a college degree has evaporated\"]]]],[1,\"p\",[[0,[],0,\"Letâ€™s walk through these points, one by one.\"]]],[1,\"h2\",[[0,[],0,\"College graduates earn more\"]]],[1,\"p\",[[0,[2],1,\"Point one\"],[0,[],0,\" represents the common (and, it should be said, \"],[0,[1],1,\"true\"],[0,[],0,\") belief that college graduates earn more than non-graduates. Another way of saying this is college education is \"],[0,[1],1,\"correlated\"],[0,[],0,\" with higher income. We can compare the simple average (or median) earnings of college degree holders and non-holders. Lo and behold, one is higher than the other, therefore, correlation.\"]]],[1,\"p\",[[0,[],0,\"Thatâ€™s really all there is to this point, so letâ€™s get it out of the way first. Iâ€™ll drop this chart in here for good measure, which makes the point visually:\"]]],[10,0],[1,\"p\",[[0,[],0,\"In words â€” the median family with a bachelor degree-holding head of household earns ~100% more income than the median family without a college degree.\"]]],[1,\"p\",[[0,[],0,\"Unfortunately, this is where most mainstream analysis of higher education ends.\"]]],[1,\"p\",[[0,[],0,\"Letâ€™s go further.\"]]],[10,1],[1,\"h2\",[[0,[],0,\"A degree is only one of many factors\"]]],[1,\"p\",[[0,[2],1,\"Point two\"],[0,[],0,\" is where things get interesting. As Iâ€™ve discussed in \"],[0,[3],1,\"prior analyses\"],[0,[],0,\", \"],[0,[1],1,\"correlation is not causation\"],[0,[],0,\". But thatâ€™s not very interesting. Whatâ€™s interesting is exactly how much correlation is in fact causation vs. not. It turns out, college degrees do raise incomes but not as much as simple correlations like above would suggest.\"]]],[1,\"p\",[[0,[],0,\"Iâ€™ll spend some time on this point, as itâ€™s the most important one to grasp.\"]]],[1,\"p\",[[0,[],0,\"To quote the authors of this same study:\"]]],[1,\"blockquote\",[[0,[],0,\"The choice to attend and subsequently complete college \"],[0,[2],1,\"is not random or arbitrary\"],[0,[],0,\"; it is instead related to numerous financial and non-financial considerations, among them parentsâ€™ wealth, intelligence, socio-cognitive skills, race, financial acumen, and parentsâ€™ educationâ€¦ Although terminal college graduates and postgraduates enjoy significant income and wealth advantages over non-grads, \"],[0,[2],1,\"attributing these premiums solely to the effect of college would be a mistake\"],[0,[],0,\". (Emphasis mine)\"]]],[1,\"p\",[[0,[],0,\"In general, people who choose to attend college have led different lives than those who donâ€™t and will experience different lives after the fact, even if they make the same choice at this juncture. These pre-existing differences interact with the effect of college itself, leading to different outcomes.\"]]],[1,\"p\",[[0,[],0,\"College is not the â€œ\"],[0,[4],1,\"great leveler\"],[0,[],0,\"â€ it is often advertised as. Different inputs do not lead to the same output. \"],[0,[5],1,\"GIGO\"],[0,[],0,\", meet DIDO: different input, different output.\"]]],[1,\"p\",[[0,[],0,\"What are some examples of these different inputs? One is parentâ€™s education and financial acumen. Individuals with college educated and financially savvy parents do better than those without and are also more likely to attend in the first place. This confounds any simple analysis of the benefit of a college education, as some of that benefit comes not from college itself but from oneâ€™s parents.\"]]],[1,\"p\",[[0,[],0,\"The authors of the previously cited analysis explore this idea and conclude:\"]]],[1,\"blockquote\",[[0,[],0,\"Failing to account for parentsâ€™ education \"],[0,[2],1,\"overinflated\"],[0,[],0,\" the college and post-graduate income and wealth premiumsâ€¦ Clearly, \"],[0,[2],1,\"parentsâ€™ education and financial acumen\"],[0,[],0,\" were important variables previously omitted in estimations of the college and post-graduate premiumsâ€¦ Part of the effect of college would be \"],[0,[2],1,\"transmitting the effect of parentsâ€™ education\"],[0,[],0,\". (Emphasis mine)\"]]],[1,\"p\",[[0,[],0,\"Said more colorfully, rather than simply being a â€œleveler,â€ college is increasingly the vehicle through which the \"],[0,[1],1,\"already advantaged\"],[0,[],0,\" \"],[0,[2],1,\"express\"],[0,[],0,\" and \"],[0,[2,6],2,\"compound\"],[0,[],0,\" their advantages. Mathematically, this accounts for some of the correlation I identified earlier, leaving less to be explained by true â€œcausalityâ€ or, as the authors put it, â€œthe true college premium.â€\"]]],[1,\"p\",[[0,[],0,\"So how do we identify this â€œtrueâ€ premium? There are multiple methods, but the most straightforward is to run a large regression of income on college attendance, controlling for all the appropriate variables that may correlate with college attendance or income. This is harder than it sounds, both because the choice of controls is subjective and because those variables might not be available to you.\"]]],[1,\"p\",[[0,[],0,\"So the authorâ€™s take a simpler approach, essentially controlling only for age. Surprisingly, that alone is enough to meaningfully reduce the supposed income benefit of college from 100% to only 50% for whites born in the 1980s:\"]]],[10,2],[1,\"p\",[[0,[],0,\"Two things to note here.\"]]],[1,\"p\",[[0,[],0,\"First, notice that, contrary to popular belief, the premium has \"],[0,[1],1,\"not\"],[0,[],0,\" grown over time and has in fact slightly decreased. It is \"],[0,[1],1,\"not\"],[0,[],0,\" the case that college is increasingly important from an income generation standpoint.\"]]],[1,\"p\",[[0,[],0,\"Second, while 50% is still large number, remember that this \"],[0,[1],1,\"only controlled for age\"],[0,[],0,\". There are numerous other variables that arenâ€™t being accounted for, like parental education or income, which we know affect future earnings. Adding these in would very likely reduce the income premium even further, but these data are hard to come by.\"]]],[1,\"p\",[[0,[],0,\"As the authors put it:\"]]],[1,\"blockquote\",[[0,[],0,\"â€¦ \"],[0,[2],1,\"these figures may exaggerate the trueâ€”that is, causalâ€”college premium.\"],[0,[],0,\" Other variables, chief among them oneâ€™s parentsâ€™ education, may play a role in potential earnings and wealth accumulationâ€¦ \"],[0,[2],1,\"Those premiums may be upwardly biased estimates of the true income and wealth premiums.\"],[0,[],0,\" (Emphasis mine)\"]]],[1,\"h2\",[[0,[],0,\"College is only getting more expensive\"]]],[1,\"p\",[[0,[2],1,\"Point three\"],[0,[],0,\" like point one, is relatively uncontroversial. The real cost of college in the United States has increased meaningfully over time, as tuition growth continues to outpace overall inflation.\"]]],[1,\"p\",[[0,[],0,\"College is increasingly â€œpriced to perfection.â€\"]]],[1,\"p\",[[0,[],0,\"Again, in case there are any doubts, hereâ€™s some data showing the growth in the cost of college vs. broader prices in the economy since 1978. You donâ€™t need a legend to know which line is which:\"]]],[10,3],[1,\"p\",[[0,[],0,\"These surging costs are fueling an explosion of consumer debt. We can get some sense of this from the following table, which shows the median debt-to-income ratios among college degree holders across multiple birth decades at various years of age:\"]]],[10,4],[1,\"p\",[[0,[],0,\"So for example, the median American born in the 1960s owed debt equal to \"],[0,[2],1,\"34%\"],[0,[],0,\" of their annual income at the age of 26, while Americans born in the 1980s owed debt of \"],[0,[2],1,\"109%\"],[0,[],0,\" of income, \"],[0,[2],1,\"a tripling of the typical debt burden for young adults\"],[0,[],0,\". While much of this relates to the broader availability of mortgage debt, at the age of 26, one has to assume that much of it comes college borrowings yet to be paid off. In fact, the authors note that â€œdebt ratios generally are higher among college grads than non-grads.â€\"]]],[1,\"p\",[[0,[],0,\"That debt levies a pernicious tax on the debt holder in the form of regular interest payments and often leaves them with negative net worth until the debt can be sufficiently paid down.\"]]],[10,5],[1,\"h2\",[[0,[],0,\"The grand finale\"]]],[1,\"p\",[[0,[],0,\"Add all that up and you arrive at the sobering conclusion that, \"],[0,[2],1,\"college may no longer be beneficial from the standpoint of individual wealth generation\"],[0,[],0,\". This doesnâ€™t mean that it doesnâ€™t have all sorts of \"],[0,[1],1,\"other\"],[0,[],0,\" value (such as non-monetary or â€œsocialâ€ value), but on this important dimension the returns seem to have fallen to zero or potentially even lower.\"]]],[1,\"p\",[[0,[],0,\"Unconvinced? Here is possibly the most important chart in higher education, showing the expected impact of a bachelorâ€™s degree on the net worth of graduates born across various decades, again controlling for age:\"]]],[10,6],[10,7],[1,\"p\",[[0,[],0,\"What does this say? A white college graduate born in the 1930s could have expected to achieve \"],[0,[2],1,\"247%\"],[0,[],0,\" higher net worth than their non-college educated peers, while one born in the 1980s can only expect to own \"],[0,[2],1,\"42%\"],[0,[],0,\" more.\"]]],[1,\"p\",[[0,[],0,\"For black grads the story is even worse.\"]]],[1,\"p\",[[0,[],0,\"While the 1930s cohort (an extremely small group it should be noted) could be expected to own 509% more wealth compared to similarly aged blacks without a degree, those born in the 1980s only achieve 6% more wealth as a result of their degree, an effect â€œstatistically indistinguishable from zero,â€ as the researchers put it.\"]]],[1,\"p\",[[0,[],0,\"This is a \"],[0,[2],1,\"big\"],[0,[],0,\" deal.\"]]],[1,\"p\",[[0,[],0,\"The collapse in the financial value of a college degree can be traced directly to the explosive growth in the cost of attending college, financed by ever-growing debt burdens.\"]]],[1,\"p\",[[0,[],0,\"Notice that the chart ends at the 1980s birth cohort. If these trends have continued, recent graduates born in the 90s may do even worse relative to non-graduates, reflecting further erosion in the wealth effect of a college education.\"]]],[1,\"p\",[[0,[],0,\"If youâ€™ve read this far, you should be disturbed and alarmed.\"]]],[1,\"p\",[[0,[],0,\"Why arenâ€™t these sobering facts receiving more attention? Itâ€™s a good question â€”and I donâ€™t have an answer â€” but I hope to at least point the public in the right direction by shining a light on the growing problem of ineffectual â€œdegreeism.â€\"]]],[1,\"p\",[[0,[],0,\"But there might be a counterintuitive â€œsilver liningâ€ to this situation.\"]]],[1,\"h2\",[[0,[],0,\"COVID College Online\"]]],[1,\"p\",[[0,[],0,\"College graduates do better in recessions than non-graduates. Their incomes do not fall as significantly, nor do their unemployment rates surge to the same extent, as we can see in \"],[0,[7],1,\"data from the Great Recession\"],[0,[],0,\":\"]]],[10,8],[10,9],[1,\"p\",[[0,[],0,\"In this sense, a college degree serves as downside protection or insurance against the worst outcomes. Thus, in tough times the relative value of a college degree increases. Given the way COVID disproportionately impacts low-wage workers, this is even truer right now.\"]]],[1,\"p\",[[0,[],0,\"Many of this yearâ€™s graduates are rightfully disappointed about their curtailed college experiences and graduating into a major recession. Itâ€™s important to remember though that, ironically, degrees are in fact \"],[0,[1],1,\"more\"],[0,[],0,\" valuable during recessions.\"]]],[1,\"h2\",[[0,[],0,\"Thereâ€™s no such thing as a free lunch\"]]],[1,\"p\",[[0,[],0,\"College is not a free lunch. Itâ€™s the furthest thing from free, and its impact on individual wealth generation is dubious.\"]]],[1,\"p\",[[0,[],0,\"College is no longer a â€œsure thing.â€ Weâ€™re paying more for it and getting less. How much of this shift is being driven by colleges themselves vs. changes in the underlying economy is unclear, so we shouldnâ€™t point fingers just yet.\"]]],[1,\"p\",[[0,[],0,\"Whatâ€™s clear is that the calculus of college must change.\"]]],[1,\"p\",[[0,[1],0,\"Many kudos to \"],[0,[8],1,\"William Emmons\"],[0,[],0,\", \"],[0,[9],1,\"Ana Kent\"],[0,[],0,\", and \"],[0,[10],1,\"Lowell Ricketts\"],[0,[],0,\", the authors of \"],[0,[0],1,\"the study\"],[0,[],1,\" from which much of this post is derived.\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p>The value of a college degree is crashing toward zero and may even be negative for today's COVID-graduates.</p><p>This is the stunning implication of <a href=\"https://research.stlouisfed.org/publications/review/2019/10/15/is-college-still-worth-it-the-new-calculus-of-falling-returns\">recent research</a> by the Federal Reserve into the precipitously falling financial returns of higher education.</p><p>You might be thinking â€” â€œ<em>but I thought the benefit of a college degree has been increasing all this time?</em>â€</p><p>You would be wrong, though understandably so.</p><p>Hereâ€™s a sketch of the basic argument:</p><ol><li>College graduates continue to earn significantly more than non-college graduates</li><li>However, the <em>causal</em> (key word) income effect of college has <strong>not</strong> increased and, if anything, has declined</li><li>Meanwhile, the cost of attending college has ballooned</li><li>Therefore, the wealth-generating power of a college degree has evaporated</li></ol><p>Letâ€™s walk through these points, one by one.</p><h2 id=\"college-graduates-earn-more\">College graduates earn more</h2><p><strong>Point one</strong> represents the common (and, it should be said, <em>true</em>) belief that college graduates earn more than non-graduates. Another way of saying this is college education is <em>correlated</em> with higher income. We can compare the simple average (or median) earnings of college degree holders and non-holders. Lo and behold, one is higher than the other, therefore, correlation.</p><p>Thatâ€™s really all there is to this point, so letâ€™s get it out of the way first. Iâ€™ll drop this chart in here for good measure, which makes the point visually:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/06/CleanShot-2020-05-23-at-01.21.24@2x.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>In words â€” the median family with a bachelor degree-holding head of household earns ~100% more income than the median family without a college degree.</p><p>Unfortunately, this is where most mainstream analysis of higher education ends.</p><p>Letâ€™s go further.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: The Value of College May Be Negative for the COVID Generation\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Subscribe</span></button>\n</form>\n</section><!--kg-card-end: html--><h2 id=\"a-degree-is-only-one-of-many-factors\">A degree is only one of many factors</h2><p><strong>Point two</strong> is where things get interesting. As Iâ€™ve discussed in <a href=\"__GHOST_URL__/remote-software-developers-earn-more/\">prior analyses</a>, <em>correlation is not causation</em>. But thatâ€™s not very interesting. Whatâ€™s interesting is exactly how much correlation is in fact causation vs. not. It turns out, college degrees do raise incomes but not as much as simple correlations like above would suggest.</p><p>Iâ€™ll spend some time on this point, as itâ€™s the most important one to grasp.</p><p>To quote the authors of this same study:</p><blockquote>The choice to attend and subsequently complete college <strong>is not random or arbitrary</strong>; it is instead related to numerous financial and non-financial considerations, among them parentsâ€™ wealth, intelligence, socio-cognitive skills, race, financial acumen, and parentsâ€™ educationâ€¦ Although terminal college graduates and postgraduates enjoy significant income and wealth advantages over non-grads, <strong>attributing these premiums solely to the effect of college would be a mistake</strong>. (Emphasis mine)</blockquote><p>In general, people who choose to attend college have led different lives than those who donâ€™t and will experience different lives after the fact, even if they make the same choice at this juncture. These pre-existing differences interact with the effect of college itself, leading to different outcomes.</p><p>College is not the â€œ<a href=\"https://opinionator.blogs.nytimes.com/2014/03/01/college-the-great-unleveler/\">great leveler</a>â€ it is often advertised as. Different inputs do not lead to the same output. <a href=\"https://en.wikipedia.org/wiki/Garbage_in,_garbage_out\">GIGO</a>, meet DIDO: different input, different output.</p><p>What are some examples of these different inputs? One is parentâ€™s education and financial acumen. Individuals with college educated and financially savvy parents do better than those without and are also more likely to attend in the first place. This confounds any simple analysis of the benefit of a college education, as some of that benefit comes not from college itself but from oneâ€™s parents.</p><p>The authors of the previously cited analysis explore this idea and conclude:</p><blockquote>Failing to account for parentsâ€™ education <strong>overinflated</strong> the college and post-graduate income and wealth premiumsâ€¦ Clearly, <strong>parentsâ€™ education and financial acumen</strong> were important variables previously omitted in estimations of the college and post-graduate premiumsâ€¦ Part of the effect of college would be <strong>transmitting the effect of parentsâ€™ education</strong>. (Emphasis mine)</blockquote><p>Said more colorfully, rather than simply being a â€œleveler,â€ college is increasingly the vehicle through which the <em>already advantaged</em> <strong>express</strong> and <strong><a href=\"__GHOST_URL__/you-dont-understand-compound-growth/\">compound</a></strong> their advantages. Mathematically, this accounts for some of the correlation I identified earlier, leaving less to be explained by true â€œcausalityâ€ or, as the authors put it, â€œthe true college premium.â€</p><p>So how do we identify this â€œtrueâ€ premium? There are multiple methods, but the most straightforward is to run a large regression of income on college attendance, controlling for all the appropriate variables that may correlate with college attendance or income. This is harder than it sounds, both because the choice of controls is subjective and because those variables might not be available to you.</p><p>So the authorâ€™s take a simpler approach, essentially controlling only for age. Surprisingly, that alone is enough to meaningfully reduce the supposed income benefit of college from 100% to only 50% for whites born in the 1980s:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/06/CleanShot-2020-05-23-at-01.22.20@2x.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Two things to note here.</p><p>First, notice that, contrary to popular belief, the premium has <em>not</em> grown over time and has in fact slightly decreased. It is <em>not</em> the case that college is increasingly important from an income generation standpoint.</p><p>Second, while 50% is still large number, remember that this <em>only controlled for age</em>. There are numerous other variables that arenâ€™t being accounted for, like parental education or income, which we know affect future earnings. Adding these in would very likely reduce the income premium even further, but these data are hard to come by.</p><p>As the authors put it:</p><blockquote>â€¦ <strong>these figures may exaggerate the trueâ€”that is, causalâ€”college premium.</strong> Other variables, chief among them oneâ€™s parentsâ€™ education, may play a role in potential earnings and wealth accumulationâ€¦ <strong>Those premiums may be upwardly biased estimates of the true income and wealth premiums.</strong> (Emphasis mine)</blockquote><h2 id=\"college-is-only-getting-more-expensive\">College is only getting more expensive</h2><p><strong>Point three</strong> like point one, is relatively uncontroversial. The real cost of college in the United States has increased meaningfully over time, as tuition growth continues to outpace overall inflation.</p><p>College is increasingly â€œpriced to perfection.â€</p><p>Again, in case there are any doubts, hereâ€™s some data showing the growth in the cost of college vs. broader prices in the economy since 1978. You donâ€™t need a legend to know which line is which:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/06/CleanShot-2020-05-23-at-01.41.03@2x.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>These surging costs are fueling an explosion of consumer debt. We can get some sense of this from the following table, which shows the median debt-to-income ratios among college degree holders across multiple birth decades at various years of age:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/06/CleanShot-2020-05-25-at-02.04.33@2x.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>So for example, the median American born in the 1960s owed debt equal to <strong>34%</strong> of their annual income at the age of 26, while Americans born in the 1980s owed debt of <strong>109%</strong> of income, <strong>a tripling of the typical debt burden for young adults</strong>. While much of this relates to the broader availability of mortgage debt, at the age of 26, one has to assume that much of it comes college borrowings yet to be paid off. In fact, the authors note that â€œdebt ratios generally are higher among college grads than non-grads.â€</p><p>That debt levies a pernicious tax on the debt holder in the form of regular interest payments and often leaves them with negative net worth until the debt can be sufficiently paid down.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Middle: The Value of College May Be Negative for the COVID Generation\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Subscribe</span></button>\n</form>\n</section><!--kg-card-end: html--><h2 id=\"the-grand-finale\">The grand finale</h2><p>Add all that up and you arrive at the sobering conclusion that, <strong>college may no longer be beneficial from the standpoint of individual wealth generation</strong>. This doesnâ€™t mean that it doesnâ€™t have all sorts of <em>other</em> value (such as non-monetary or â€œsocialâ€ value), but on this important dimension the returns seem to have fallen to zero or potentially even lower.</p><p>Unconvinced? Here is possibly the most important chart in higher education, showing the expected impact of a bachelorâ€™s degree on the net worth of graduates born across various decades, again controlling for age:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/06/DraggedImage.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/06/DraggedImage-1.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>What does this say? A white college graduate born in the 1930s could have expected to achieve <strong>247%</strong> higher net worth than their non-college educated peers, while one born in the 1980s can only expect to own <strong>42%</strong> more.</p><p>For black grads the story is even worse.</p><p>While the 1930s cohort (an extremely small group it should be noted) could be expected to own 509% more wealth compared to similarly aged blacks without a degree, those born in the 1980s only achieve 6% more wealth as a result of their degree, an effect â€œstatistically indistinguishable from zero,â€ as the researchers put it.</p><p>This is a <strong>big</strong> deal.</p><p>The collapse in the financial value of a college degree can be traced directly to the explosive growth in the cost of attending college, financed by ever-growing debt burdens.</p><p>Notice that the chart ends at the 1980s birth cohort. If these trends have continued, recent graduates born in the 90s may do even worse relative to non-graduates, reflecting further erosion in the wealth effect of a college education.</p><p>If youâ€™ve read this far, you should be disturbed and alarmed.</p><p>Why arenâ€™t these sobering facts receiving more attention? Itâ€™s a good question â€”and I donâ€™t have an answer â€” but I hope to at least point the public in the right direction by shining a light on the growing problem of ineffectual â€œdegreeism.â€</p><p>But there might be a counterintuitive â€œsilver liningâ€ to this situation.</p><h2 id=\"covid-college-online\">COVID College Online</h2><p>College graduates do better in recessions than non-graduates. Their incomes do not fall as significantly, nor do their unemployment rates surge to the same extent, as we can see in <a href=\"https://www.pewtrusts.org/~/media/legacy/uploadedfiles/pcs_assets/2013/pewcollegegradsrecessionreportpdf.pdf\">data from the Great Recession</a>:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/06/CleanShot-2020-05-29-at-23.47.16@2x.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/06/CleanShot-2020-05-23-at-01.16.34@2x.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>In this sense, a college degree serves as downside protection or insurance against the worst outcomes. Thus, in tough times the relative value of a college degree increases. Given the way COVID disproportionately impacts low-wage workers, this is even truer right now.</p><p>Many of this yearâ€™s graduates are rightfully disappointed about their curtailed college experiences and graduating into a major recession. Itâ€™s important to remember though that, ironically, degrees are in fact <em>more</em> valuable during recessions.</p><h2 id=\"there-s-no-such-thing-as-a-free-lunch\">Thereâ€™s no such thing as a free lunch</h2><p>College is not a free lunch. Itâ€™s the furthest thing from free, and its impact on individual wealth generation is dubious.</p><p>College is no longer a â€œsure thing.â€ Weâ€™re paying more for it and getting less. How much of this shift is being driven by colleges themselves vs. changes in the underlying economy is unclear, so we shouldnâ€™t point fingers just yet.</p><p>Whatâ€™s clear is that the calculus of college must change.</p><p><em>Many kudos to <a href=\"https://www.stlouisfed.org/household-financial-stability/staff-profiles/william-r-emmons/bio\">William Emmons</a>, <a href=\"https://www.stlouisfed.org/household-financial-stability/staff-profiles/ana-hernandez-kent/bio\">Ana Kent</a>, and <a href=\"https://www.stlouisfed.org/household-financial-stability/staff-profiles/lowell-r-ricketts/bio\">Lowell Ricketts</a>, the authors of <a href=\"https://research.stlouisfed.org/publications/review/2019/10/15/is-college-still-worth-it-the-new-calculus-of-falling-returns\">the study</a> from which much of this post is derived.</em></p>","comment_id":"5eea4c812fa60d0ab28d5ca5","plaintext":"The value of a college degree is crashing toward zero and may even be negative\nfor today's COVID-graduates.\n\nThis is the stunning implication of recent research\n[https://research.stlouisfed.org/publications/review/2019/10/15/is-college-still-worth-it-the-new-calculus-of-falling-returns] \nby the Federal Reserve into the precipitously falling financial returns of\nhigher education.\n\nYou might be thinking â€” â€œbut I thought the benefit of a college degree has been\nincreasing all this time?â€\n\nYou would be wrong, though understandably so.\n\nHereâ€™s a sketch of the basic argument:\n\n 1. College graduates continue to earn significantly more than non-college\n    graduates\n 2. However, the causal (key word) income effect of college has not increased\n    and, if anything, has declined\n 3. Meanwhile, the cost of attending college has ballooned\n 4. Therefore, the wealth-generating power of a college degree has evaporated\n\nLetâ€™s walk through these points, one by one.\n\nCollege graduates earn more\nPoint one represents the common (and, it should be said, true) belief that\ncollege graduates earn more than non-graduates. Another way of saying this is\ncollege education is correlated with higher income. We can compare the simple\naverage (or median) earnings of college degree holders and non-holders. Lo and\nbehold, one is higher than the other, therefore, correlation.\n\nThatâ€™s really all there is to this point, so letâ€™s get it out of the way first.\nIâ€™ll drop this chart in here for good measure, which makes the point visually:\n\nIn words â€” the median family with a bachelor degree-holding head of household\nearns ~100% more income than the median family without a college degree.\n\nUnfortunately, this is where most mainstream analysis of higher education ends.\n\nLetâ€™s go further.\n\nReceive my next long-form post\nThoughtful analysis of the business and economics of tech\n\n\n\nSubscribeA degree is only one of many factors\nPoint two is where things get interesting. As Iâ€™ve discussed in prior analyses\n[https://nnamdi.net/remote-software-developers-earn-more/], correlation is not\ncausation. But thatâ€™s not very interesting. Whatâ€™s interesting is exactly how\nmuch correlation is in fact causation vs. not. It turns out, college degrees do\nraise incomes but not as much as simple correlations like above would suggest.\n\nIâ€™ll spend some time on this point, as itâ€™s the most important one to grasp.\n\nTo quote the authors of this same study:\n\n> The choice to attend and subsequently complete college is not random or\narbitrary; it is instead related to numerous financial and non-financial\nconsiderations, among them parentsâ€™ wealth, intelligence, socio-cognitive\nskills, race, financial acumen, and parentsâ€™ educationâ€¦ Although terminal\ncollege graduates and postgraduates enjoy significant income and wealth\nadvantages over non-grads, attributing these premiums solely to the effect of\ncollege would be a mistake. (Emphasis mine)\nIn general, people who choose to attend college have led different lives than\nthose who donâ€™t and will experience different lives after the fact, even if they\nmake the same choice at this juncture. These pre-existing differences interact\nwith the effect of college itself, leading to different outcomes.\n\nCollege is not the â€œgreat leveler\n[https://opinionator.blogs.nytimes.com/2014/03/01/college-the-great-unleveler/]â€\nit is often advertised as. Different inputs do not lead to the same output. GIGO\n[https://en.wikipedia.org/wiki/Garbage_in,_garbage_out], meet DIDO: different\ninput, different output.\n\nWhat are some examples of these different inputs? One is parentâ€™s education and\nfinancial acumen. Individuals with college educated and financially savvy\nparents do better than those without and are also more likely to attend in the\nfirst place. This confounds any simple analysis of the benefit of a college\neducation, as some of that benefit comes not from college itself but from oneâ€™s\nparents.\n\nThe authors of the previously cited analysis explore this idea and conclude:\n\n> Failing to account for parentsâ€™ education overinflated the college and\npost-graduate income and wealth premiumsâ€¦ Clearly, parentsâ€™ education and\nfinancial acumen were important variables previously omitted in estimations of\nthe college and post-graduate premiumsâ€¦ Part of the effect of college would be \ntransmitting the effect of parentsâ€™ education. (Emphasis mine)\nSaid more colorfully, rather than simply being a â€œleveler,â€ college is\nincreasingly the vehicle through which the already advantaged express and \ncompound [__GHOST_URL__/you-dont-understand-compound-growth/] their advantages.\nMathematically, this accounts for some of the correlation I identified earlier,\nleaving less to be explained by true â€œcausalityâ€ or, as the authors put it, â€œthe\ntrue college premium.â€\n\nSo how do we identify this â€œtrueâ€ premium? There are multiple methods, but the\nmost straightforward is to run a large regression of income on college\nattendance, controlling for all the appropriate variables that may correlate\nwith college attendance or income. This is harder than it sounds, both because\nthe choice of controls is subjective and because those variables might not be\navailable to you.\n\nSo the authorâ€™s take a simpler approach, essentially controlling only for age.\nSurprisingly, that alone is enough to meaningfully reduce the supposed income\nbenefit of college from 100% to only 50% for whites born in the 1980s:\n\nTwo things to note here.\n\nFirst, notice that, contrary to popular belief, the premium has not grown over\ntime and has in fact slightly decreased. It is not the case that college is\nincreasingly important from an income generation standpoint.\n\nSecond, while 50% is still large number, remember that this only controlled for\nage. There are numerous other variables that arenâ€™t being accounted for, like\nparental education or income, which we know affect future earnings. Adding these\nin would very likely reduce the income premium even further, but these data are\nhard to come by.\n\nAs the authors put it:\n\n> â€¦ these figures may exaggerate the trueâ€”that is, causalâ€”college premium. Other\nvariables, chief among them oneâ€™s parentsâ€™ education, may play a role in\npotential earnings and wealth accumulationâ€¦ Those premiums may be upwardly\nbiased estimates of the true income and wealth premiums. (Emphasis mine)\nCollege is only getting more expensive\nPoint three like point one, is relatively uncontroversial. The real cost of\ncollege in the United States has increased meaningfully over time, as tuition\ngrowth continues to outpace overall inflation.\n\nCollege is increasingly â€œpriced to perfection.â€\n\nAgain, in case there are any doubts, hereâ€™s some data showing the growth in the\ncost of college vs. broader prices in the economy since 1978. You donâ€™t need a\nlegend to know which line is which:\n\nThese surging costs are fueling an explosion of consumer debt. We can get some\nsense of this from the following table, which shows the median debt-to-income\nratios among college degree holders across multiple birth decades at various\nyears of age:\n\nSo for example, the median American born in the 1960s owed debt equal to 34% of\ntheir annual income at the age of 26, while Americans born in the 1980s owed\ndebt of 109% of income, a tripling of the typical debt burden for young adults.\nWhile much of this relates to the broader availability of mortgage debt, at the\nage of 26, one has to assume that much of it comes college borrowings yet to be\npaid off. In fact, the authors note that â€œdebt ratios generally are higher among\ncollege grads than non-grads.â€\n\nThat debt levies a pernicious tax on the debt holder in the form of regular\ninterest payments and often leaves them with negative net worth until the debt\ncan be sufficiently paid down.\n\nReceive my next long-form post\nThoughtful analysis of the business and economics of tech\n\n\n\nSubscribeThe grand finale\nAdd all that up and you arrive at the sobering conclusion that, college may no\nlonger be beneficial from the standpoint of individual wealth generation. This\ndoesnâ€™t mean that it doesnâ€™t have all sorts of other value (such as non-monetary\nor â€œsocialâ€ value), but on this important dimension the returns seem to have\nfallen to zero or potentially even lower.\n\nUnconvinced? Here is possibly the most important chart in higher education,\nshowing the expected impact of a bachelorâ€™s degree on the net worth of graduates\nborn across various decades, again controlling for age:\n\nWhat does this say? A white college graduate born in the 1930s could have\nexpected to achieve 247% higher net worth than their non-college educated peers,\nwhile one born in the 1980s can only expect to own 42% more.\n\nFor black grads the story is even worse.\n\nWhile the 1930s cohort (an extremely small group it should be noted) could be\nexpected to own 509% more wealth compared to similarly aged blacks without a\ndegree, those born in the 1980s only achieve 6% more wealth as a result of their\ndegree, an effect â€œstatistically indistinguishable from zero,â€ as the\nresearchers put it.\n\nThis is a big deal.\n\nThe collapse in the financial value of a college degree can be traced directly\nto the explosive growth in the cost of attending college, financed by\never-growing debt burdens.\n\nNotice that the chart ends at the 1980s birth cohort. If these trends have\ncontinued, recent graduates born in the 90s may do even worse relative to\nnon-graduates, reflecting further erosion in the wealth effect of a college\neducation.\n\nIf youâ€™ve read this far, you should be disturbed and alarmed.\n\nWhy arenâ€™t these sobering facts receiving more attention? Itâ€™s a good question\nâ€”and I donâ€™t have an answer â€” but I hope to at least point the public in the\nright direction by shining a light on the growing problem of ineffectual\nâ€œdegreeism.â€\n\nBut there might be a counterintuitive â€œsilver liningâ€ to this situation.\n\nCOVID College Online\nCollege graduates do better in recessions than non-graduates. Their incomes do\nnot fall as significantly, nor do their unemployment rates surge to the same\nextent, as we can see in data from the Great Recession\n[https://www.pewtrusts.org/~/media/legacy/uploadedfiles/pcs_assets/2013/pewcollegegradsrecessionreportpdf.pdf]\n:\n\nIn this sense, a college degree serves as downside protection or insurance\nagainst the worst outcomes. Thus, in tough times the relative value of a college\ndegree increases. Given the way COVID disproportionately impacts low-wage\nworkers, this is even truer right now.\n\nMany of this yearâ€™s graduates are rightfully disappointed about their curtailed\ncollege experiences and graduating into a major recession. Itâ€™s important to\nremember though that, ironically, degrees are in fact more valuable during\nrecessions.\n\nThereâ€™s no such thing as a free lunch\nCollege is not a free lunch. Itâ€™s the furthest thing from free, and its impact\non individual wealth generation is dubious.\n\nCollege is no longer a â€œsure thing.â€ Weâ€™re paying more for it and getting less.\nHow much of this shift is being driven by colleges themselves vs. changes in the\nunderlying economy is unclear, so we shouldnâ€™t point fingers just yet.\n\nWhatâ€™s clear is that the calculus of college must change.\n\nMany kudos to William Emmons\n[https://www.stlouisfed.org/household-financial-stability/staff-profiles/william-r-emmons/bio]\n, Ana Kent\n[https://www.stlouisfed.org/household-financial-stability/staff-profiles/ana-hernandez-kent/bio]\n, and Lowell Ricketts\n[https://www.stlouisfed.org/household-financial-stability/staff-profiles/lowell-r-ricketts/bio]\n, the authors of the study\n[https://research.stlouisfed.org/publications/review/2019/10/15/is-college-still-worth-it-the-new-calculus-of-falling-returns] \nfrom which much of this post is derived.","feature_image":"__GHOST_URL__/content/images/2020/06/black-college-wealth.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-06-17T17:01:53.000Z","updated_at":"2020-06-17T17:26:43.000Z","published_at":"2020-06-17T17:26:43.000Z","custom_excerpt":"You might think the value of a college degree has been increasing. You would be wrong.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5eff048a2fa60d0ab28d5cd4","uuid":"6933681e-5353-4f38-8759-a70a5ffb7dcc","title":"Why Don't VCs Index Invest?","slug":"vcs-index-invest","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"/content/images/2020/07/640px-Long_tail.svg.png\",\"alt\":\"640px-Long_tail.svg\",\"title\":\"\",\"caption\":\"Source: <a href=\\\"https://commons.wikimedia.org/w/index.php?curid=1449504\\\">Wikipedia</a>\"}],[\"image\",{\"src\":\"/content/images/2020/07/normal-v-pld-tail.png\",\"alt\":\"https://i0.wp.com/reactionwheel.net/wp-content/uploads/2015/06/normal-v-pld-tail.png?resize=606%2C287\",\"title\":\"\",\"caption\":\"Source: <a href=\\\"http://reactionwheel.net/2015/06/power-laws-in-venture.html\\\">Reaction Wheel</a>\"}],[\"image\",{\"src\":\"/content/images/2020/07/pld-tails.png\",\"alt\":\"https://i2.wp.com/reactionwheel.net/wp-content/uploads/2015/06/pld-tails.png?resize=611%2C287\",\"title\":\"\",\"caption\":\"Source: <a href=\\\"http://reactionwheel.net/2015/06/power-laws-in-venture.html\\\">Reaction Wheel</a>\"}],[\"image\",{\"src\":\"/content/images/2020/07/chart_2.png\",\"alt\":\"Distribution of hypothetical manager returns showing the market return outperforms\",\"title\":\"\",\"caption\":\"Source: <a href=\\\"https://angel.co/blog/what-angellist-data-says-about-power-law-returns-in-venture-capital\\\">AngelList</a>\"}],[\"image\",{\"src\":\"/content/images/2020/07/H5qNMNZPFO.png\",\"alt\":\"img\",\"title\":\"\",\"caption\":\"Source: <a href=\\\"https://angel.co/pdf/lp-performance.pdf\\\">AngelList</a>\"}],[\"image\",{\"src\":\"/content/images/2020/07/image-20200624134947087.png\",\"alt\":\"image-20200624134947087\",\"title\":\"\",\"caption\":\"Source: <a href=\\\"https://books.google.com/books?id=gRdOBrus_9wC&amp;pg=PA4&amp;lpg=PA4&amp;dq=your+money+and+your+brain+harry+markowitz&amp;source=bl&amp;ots=awRnIfiMs4&amp;sig=sY4wPziYOjm9oB5f3MN_z7gloMw&amp;hl=en&amp;sa=X&amp;ei=bEM3VKT9MIjIsATj_4Fw#v=onepage&amp;q&amp;f=false\\\">Your Money and Your Brain</a>\"}]],\"markups\":[[\"a\",[\"href\",\"https://www.investopedia.com/terms/i/index-investing.asp\"]],[\"a\",[\"href\",\"https://www.investopedia.com/terms/s/stockpick.asp\"]],[\"em\"],[\"strong\"],[\"a\",[\"href\",\"http://reactionwheel.net/2015/06/power-laws-in-venture.html\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Normal_distribution\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/2001.10488\"]],[\"a\",[\"href\",\"https://angel.co/\"]],[\"a\",[\"href\",\"https://angel.co/blog/venture-returns\"]],[\"a\",[\"href\",\"https://www.investopedia.com/terms/b/basispoint.asp\"]],[\"a\",[\"href\",\"https://www.macroresilience.com/2010/07/08/heuristics-and-robustness-in-asset-allocation/\"]],[\"a\",[\"href\",\"https://alphaarchitect.com/2014/10/17/harry-markowitz-an-equal-weight-investor/\"]],[\"a\",[\"href\",\"http://faculty.london.edu/avmiguel/DeMiguel-Garlappi-Uppal-RFS.pdf\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=jwG_qR6XmDQ\"]],[\"a\",[\"href\",\"https://blog.samaltman.com/party-rounds\"]],[\"a\",[\"href\",\"http://blog.eladgil.com/2010/09/party-rounds-how-to-get-high-valuation.html\"]],[\"s\"],[\"a\",[\"href\",\"https://blakemasters.com/post/21869934240/peter-thiels-cs183-startup-class-7-notes-essay\"]],[\"a\",[\"href\",\"__GHOST_URL__/people-matching/\"]],[\"a\",[\"href\",\"https://marginalrevolution.com/marginalrevolution/2020/02/why-is-vc-twitter-so-peculiar.html\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Planck_length\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Math and data say early-stage VCs should \"],[0,[0],1,\"index invest\"],[0,[],0,\", and late-stage investors should \"],[0,[1],1,\"stock pick\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[2],1,\"Yet they do the opposite.\"]]],[1,\"p\",[[0,[],0,\"The reason is counterintuitive: VCs are picky, not because they have so many options but \"],[0,[3],1,\"because they have so few\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"More deals, better performance\"]]],[1,\"p\",[[0,[],0,\"Theoretical modeling and empirical data both suggest that early-stage VCs do better when they spread the wealth wider.\"]]],[1,\"p\",[[0,[],0,\"Let's start with the theory.\"]]],[1,\"p\",[[0,[],0,\"First, we need to define the \"],[0,[4],1,\"power law distribution\"],[0,[],0,\":\"]]],[10,0],[1,\"p\",[[0,[],0,\"A power law distribution is one where large, consequential events (the Googles, Amazons, and Facebooks of the venture world) are rare but much more common than you might expect if the world were \"],[0,[5],1,\"normally distributed\"],[0,[],0,\".\"]]],[10,1],[1,\"p\",[[0,[],0,\"These events happen with some frequency, and that frequency can be characterized by a \\\"shape\\\" or \\\"tail parameter\\\" that governs the \\\"fatness\\\" of the tail, typically represented by the symbol \\\\(\\\\alpha\\\\).\"]]],[1,\"p\",[[0,[],0,\"The smaller \\\\(\\\\alpha\\\\), the \\\"fatter\\\" the tail of the power law distribution. The fatter the tail, the higher the frequency and size of outlier startups.\"]]],[10,2],[1,\"p\",[[0,[],0,\"If \\\\(\\\\alpha\\\\) is sufficiently small, strange things begin to happen. With a small enough \\\\(\\\\alpha\\\\), \"],[0,[3],1,\"making investments nearly at random will increase a portfolio's expected return\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"The exact mathematical reasons for this are \"],[0,[6],1,\"somewhat esoteric\"],[0,[],0,\", but intuitively, if there are enough potential Googles, Amazons, and Facebooks out there, they will more than cover the losses from the duds thanks to the shape of the power law distribution. When fat tails dominate returns it's not worth having an extremely high bar if it might cause you to miss out on one of these future juggernauts.\"]]],[1,\"p\",[[0,[],0,\"VCs often talk about power laws, but few have sufficient data to rigorously demonstrate them. However, \"],[0,[7],1,\"AngelList\"],[0,[],0,\" does, and their head data scientist, Abe Othman, has \"],[0,[8],1,\"done the work\"],[0,[],0,\" to analyze returns from the thousands of deals syndicated by AngelList, finding that:\"]]],[1,\"blockquote\",[[0,[],0,\"... \"],[0,[3],1,\"the regret an investor could have for missing a winning seed-stage investment is theoretically infinite\"],[0,[],0,\", a phenomenon that does not appear to hold for later-stage investments. The implication is that \"],[0,[3],1,\"investors increase their expected return by indexing as broadly as possible at the seed stage\"],[0,[],0,\" (i.e., by putting money into every credible deal), because \"],[0,[3],1,\"any selective policy for seed-stage investingâ€”absent perfect foresightâ€”will eventually be outperformed by an indexing approach\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"By creating power law-based mathematical model, fitting it to the AngelList returns data, and simulating 50,000 portfolios with 10 early-stage companies each, he created the following synthetic distribution of venture capital returns:\"]]],[10,3],[1,\"p\",[[0,[],0,\"The vertical black line represents the \"],[0,[2],1,\"market return\"],[0,[],0,\": the return you'd earn if you invested an equal amount in every AngelList deal in the sample (of which there were 1,808). Notice the long tail trailing off to the right side of the chart. In a world where most barely return their fund, some shower their LPs with 5x returns. \"],[0,[3],1,\"Notice how most 10-company portfolios underperform the simple (1,808-company) strategy.\"]]],[1,\"p\",[[0,[],0,\"Technically, this is still a theoretical result. Yes, the model was fit to real data, but the outputs are still simulated. Now let's look at real data.\"]]],[1,\"p\",[[0,[],0,\"Here again we turn to AngelList, who analyze the relationship between portfolio size and performance among 10,000+ investors on the platform. They grouped the investors by number of companies in their portfolio and plotted the median return for each group. The chart confirms the theoretical results - larger portfolios generate greater returns:\"]]],[10,4],[1,\"blockquote\",[[0,[],0,\"The coefficient of the regression term is 9.0 \"],[0,[9],1,\"basis points\"],[0,[],0,\"... implying that \"],[0,[3],1,\"the typical annual return of a portfolio of 100 investments is almost 9% higher than the typical annual return of a portfolio with a single investment\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Note these are median returns, so they don't reflect a handful of 100-count portfolios simply getting lucky and pulling up the average. \"],[0,[3],1,\"Financial upside is easier to come by when you're exposed to a larger patch of the startup landscape.\"]]],[1,\"p\",[[0,[],0,\"Theory and data agree - most early-stage venture investors would do better by indexing, investing a small amount in every reasonable startup they can find:\"]]],[1,\"blockquote\",[[0,[],0,\"Simulations on 10-year investing windows for seed-stage deals suggest \"],[0,[3],1,\"fewer than 10% of investors will beat the index\"],[0,[],0,\", even if those investors have skill in picking deals. Like Vanguard has taught us in the public markets, \"],[0,[3],1,\"individual investors could benefit from viewing the index as the default\"],[0,[],0,\" and then overlaying individual deals that they like.\"]]],[1,\"h2\",[[0,[],0,\"1/N\"]]],[1,\"p\",[[0,[],0,\"Behavioral finance theorists have a name for this strategy: \"],[0,[10],1,\"the 1/N heuristic\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"It goes like this: take every investable asset of a group of N assets and invest 1/Nth of your capital in each one, with no regard to the fundamentals, mean return, or volatility of returns.\"]]],[1,\"p\",[[0,[],0,\"This might sound like a dumb, simplistic strategy. While it's certainly simple, it's definitely not dumb.\"]]],[1,\"p\",[[0,[],0,\"Ironically, 1990 Nobel Laureate and famed inventor of mean-variance portfolio optimization, Harry Markowitz, reportedly used this exact heuristic for investing his own money, eschewing his own complicated theory in favor of a simpler approach:\"]]],[1,\"blockquote\",[[0,[],0,\"I should have computed the historical covariance of the asset classes and drawn an efficient frontierâ€¦I split my contributions 50/50 between bonds and equities. - \"],[0,[11],1,\"Harry Markowitz\"]]],[10,5],[1,\"p\",[[0,[],0,\"In fact, \"],[0,[12],1,\"one study\"],[0,[],0,\" found that the 1/N strategy dominates numerous others:\"]]],[1,\"blockquote\",[[0,[],0,\"Of the 14 models we evaluate across seven empirical datasets, \"],[0,[3],1,\"none is consistently better than the 1/N rule\"],[0,[],0,\" in terms of Sharpe ratio, certainty-equivalent return, or turnover, which indicates that, out of sample, \"],[0,[3],1,\"the gain from optimal diversification is more than offset by estimation error\"],[0,[],0,\"...  That is, the effect of estimation error is so large that \"],[0,[3],1,\"it erodes completely the gains from optimal diversification\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Which is a fancy way of saying \\\"\"],[0,[2],1,\"don't overcomplicate it.\"],[0,[],0,\"\\\"\"]]],[1,\"p\",[[0,[],0,\"A \"],[0,[2],1,\"slightly\"],[0,[],0,\" more sophisticated reading of the results might be, \\\"\"],[0,[2],0,\"unless you are \"],[0,[3],1,\"very\"],[0,[],1,\" sure about the structure of the world, don't overcomplicate your investing strategy.\"],[0,[],0,\"\\\"\"]]],[1,\"p\",[[0,[],0,\"The study found a negative return to overthinking and overfitting yourself to the past data, to what you \"],[0,[2],1,\"think\"],[0,[],0,\" you know about these assets. In venture, similar overintellectualization has been the root cause of numerous \\\"misses\\\" over the years - career, fund, and firm-defining deals that put certain VCs on the map and left others in desperate obscurity.\"]]],[1,\"p\",[[0,[],0,\"In some \"],[0,[2],1,\"subtle\"],[0,[],0,\" way, trying to pick the exact right startup based on a complex model of the world is like trying to buy a certain lottery ticket with a certain serial number because you think it's a \\\"lucky ticket.\\\" One \"],[0,[2],1,\"seems\"],[0,[],0,\" much more superstitious, but are they closer than they appear?\"]]],[1,\"h2\",[[0,[],0,\"How the other half lives\"]]],[1,\"p\",[[0,[],0,\"Late stage investors on the other hand, \"],[0,[2],1,\"can\"],[0,[],0,\" afford to stock pick:\"]]],[1,\"blockquote\",[[0,[],0,\"... our results also suggest that the opportunity cost for missing a winning investment in these later rounds is bounded... Consequently, \"],[0,[3],1,\"it is entirely appropriate that later-stage investors should reject the â€œspray and prayâ€ idea and be thoughtful and discerning when they participate\"],[0,[],0,\"...\"]]],[1,\"p\",[[0,[],0,\"Translation: late-stage deals have lower opportunity cost than early-stage investments, as their returns are capped much lower. To channel Jeff Bezos' \"],[0,[13],1,\"regret minimization framework\"],[0,[],0,\": there isn't much regret to minimize when it comes to late-stage deals. So feel free to be picky.\"]]],[1,\"p\",[[0,[],0,\"Another take from the 1/N study:\"]]],[1,\"blockquote\",[[0,[],0,\"... we conclude that portfolio strategies from the optimizing models are expected to outperform the 1/N benchmark if: \"],[0,[3],1,\"(i) the estimation window is long\"],[0,[],0,\"; (ii) the ex ante (true) Sharpe ratio of the mean-variance efficient portfolio is substantially higher than that of the 1/N portfolio; and \"],[0,[3],1,\"(iii) the number of assets is small\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"In other words, it makes sense to be picky and particular when you have a large amount of data collected over a long period of time and when the number of choices is small. Both are more true of later-stage investments relative to early-stage. By definition, late-stage companies have a longer track record by which to evaluate them, and there are fewer of them. Thus, it makes sense to be a discerning capital allocator at the late-stage.\"]]],[1,\"p\",[[0,[],0,\"And yet we've seen the exact \"],[0,[2],1,\"opposite\"],[0,[],0,\" in recent years.\"]]],[1,\"p\",[[0,[],0,\"Though few would publicly characterize themselves as such, I know of at least a few firms who have explicit goals of creating, effectively, \\\"indices of late-stage venture\\\" via their large portfolios. Late-stage funds are raising and deploying capital at unprecedented rates. Many appear principally focused on putting \\\"dollars to work,\\\" rather than earning the maximum return on their capital. They've taken to heart the approach discussed earlier, investing in every company that meets some minimum threshold.\"]]],[1,\"p\",[[0,[],0,\"This has led to serious perversion at the late-stage, as there are not nearly enough investable assets to support the capital inflows at reasonable valuations. \"],[0,[3],1,\"Asset values grow not simply due to improvement in fundamental startup value but also because late-stage funds need somewhere to park their money\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"In this model, late-stage startups become \\\"\"],[0,[2],1,\"capital vehicles\"],[0,[],0,\",\\\" absorbing meaningful capital and earning a \\\"\"],[0,[2],1,\"capital storage\"],[0,[],0,\"\\\" premium for their efforts.\"]]],[1,\"p\",[[0,[14],1,\"Party rounds\"],[0,[],0,\", long known to greatly \"],[0,[15],1,\"inflate early-stage valuations\"],[0,[],0,\", have reached the late-stage.\"]]],[1,\"p\",[[0,[],0,\"But all parties must come to end eventually...\"]]],[1,\"h2\",[[0,[2],0,\"Caveat \"],[0,[16],1,\"emptor\"],[0,[],1,\" indexor\"]]],[1,\"p\",[[0,[],0,\"So that's the theory, but there are some real practical hurdles to creating an early-stage index:\"]]],[3,\"ul\",[[[0,[],0,\"Determining the right minimum threshold\"]],[[0,[],0,\"No one sees every deal\"]],[[0,[],0,\"Deals must be won\"]],[[0,[],0,\"Fund and check size restrictions\"]]]],[1,\"h3\",[[0,[],0,\"How high should the bar be?\"]]],[1,\"p\",[[0,[],0,\"AngelList recommends investing in every \"],[0,[2],1,\"credible\"],[0,[],0,\" early-stage deal, where the word \\\"credible\\\" does a lot of work. They add:\"]]],[1,\"blockquote\",[[0,[],0,\"We worry that \"],[0,[3],1,\"an investor promising to blindly fund every whisper of a new company would fundamentally alter the investment universe they are exposed to by introducing a huge number of new money losing investments\"],[0,[],0,\" that otherwise would not have been created but for the investorâ€™s universal funding policy. Consequently, our results suggest that at the seed stage investors should put money into every investment that \"],[0,[3],1,\"clears some minimum threshold\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"But how to set that threshold? It's not obvious.\"]]],[1,\"p\",[[0,[],0,\"There must be some bar, even if very low, otherwise you'll do a series of bad deals and get fleeced.\"]]],[1,\"p\",[[0,[17],1,\"Peter Thiel\"],[0,[],0,\" puts it this way:\"]]],[1,\"blockquote\",[[0,[],0,\"There just arenâ€™t that many businesses that you can have the requisite high degree of conviction about. A better model is to invest in maybe 7 or 8 promising companies from which you think you can get a 10x return.\"]]],[1,\"p\",[[0,[],0,\"Part of the reason indexing even works in say, public markets, is that there is some minimum threshold a company has to reach to even go public. Additionally, the AngelList data from which this theory comes only includes deals that got done, by definition. We don't know if the indexing strategy carries over to deals that wouldn't have otherwise got done or to companies with lower quality than the typical AngelList deal.\"]]],[1,\"p\",[[0,[],0,\"Since the AngelList data comes from deals that successfully completed, you could proxy for this by setting the bar such that you would do any deal that some other reasonable person would do.\"]]],[1,\"h3\",[[0,[],0,\"You must see the deal to do the deal\"]]],[1,\"p\",[[0,[],0,\"You can't hit a target you can't see, and \"],[0,[18],1,\"you can't do a deal you can't see either\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"The AngelList recommendation assumes the investor could invest in any deal they want. If you don't have access to all the deals, this logic breaks down.\"]]],[1,\"p\",[[0,[],0,\"Unless you are a top tier fund or individual investor, the specific subset of deals you see is almost certainly poor relative to the full distribution. You are likely missing some serious outliers.\"]]],[1,\"p\",[[0,[],0,\"This is why so many VCs spend so much time burnishing their public and private reputations. \"],[0,[19],1,\"VC Twitter says hi.\"]]],[1,\"h3\",[[0,[],0,\"You must also win\"]]],[1,\"p\",[[0,[],0,\"Let's say you set the right threshold and see all the deals that meet it. You still then must \"],[0,[18],1,\"win the deal\"],[0,[],0,\", which is far from guaranteed.\"]]],[1,\"p\",[[0,[],0,\"Further, the greater extent to which a deal exceeds any given threshold, the more competitive the deal will be. Assuming there's signal there and not simply noise, your portfolio will probabilistically skew lower quality simply due to losing out on those winners, even though you recognized them as such.\"]]],[1,\"p\",[[0,[],0,\"This completely screws up the indexing strategy, which implicitly relies on free and open access to all deals across the quality spectrum.\"]]],[1,\"h3\",[[0,[],0,\"A fund cannot be sliced into a thousand pieces\"]]],[1,\"p\",[[0,[],0,\"Even if the above caveats don't apply, a VC still runs up against fundamental limits of the venture universe.\"]]],[1,\"p\",[[0,[],0,\"Like the \"],[0,[20],1,\"Planck length\"],[0,[],0,\" represents the smallest distance at which conventional physics applies, micro-checks become infeasible below a certain size, both for the startups themselves and the would-be index investor.\"]]],[1,\"p\",[[0,[],0,\"The complement of this is that, assuming some minimum check size, you might not be able to raise a fund large enough to write all those checks.\"]]],[1,\"h2\",[[0,[],0,\"Masters of the universe?\"]]],[1,\"p\",[[0,[],0,\"VCs are picky, not because they have so many options but \"],[0,[3],1,\"because they have so few\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"The 1/N study tells us that stock picking makes sense when there are few options to choose from.\"]]],[1,\"p\",[[0,[],0,\"The AngelList data tells us that, in a hypothetical world of perfect access to all investments, you'd do better to spread your bets widely.\"]]],[1,\"p\",[[0,[],0,\"In other words, the picky behavior of early-stage venture capitalists in light of the data and theory around power laws can only be justified by their \"],[0,[2],1,\"lack\"],[0,[],0,\" of options. They only have a few shots on goal and must use them wisely.\"]]],[1,\"p\",[[0,[],0,\"People often assume this pickiness comes from the fact that most startups fail, and VCs obviously want to avoid the numerous duds. \"],[0,[3],1,\"But this isn't really true.\"],[0,[],0,\" Even in a world where most startups fail it can make sense to invest in many more than the typical investor does currently, as shown above.\"]]],[1,\"p\",[[0,[],0,\"Far from masters of the universe, selectively picking among desperate founders looking for funding, \"],[0,[3],1,\"VCs are themselves starved of options\"],[0,[],0,\", making them extremely cautious with the few they have.\"]]],[1,\"p\",[[0,[],0,\"In a future article, I'll extend this idea and demonstrate why it shows venture capitalists aren't funding nearly enough startups.\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p>Math and data say early-stage VCs should <a href=\"https://www.investopedia.com/terms/i/index-investing.asp\">index invest</a>, and late-stage investors should <a href=\"https://www.investopedia.com/terms/s/stockpick.asp\">stock pick</a>.</p><p><em>Yet they do the opposite.</em></p><p>The reason is counterintuitive: VCs are picky, not because they have so many options but <strong>because they have so few</strong>.</p><h2 id=\"more-deals-better-performance\">More deals, better performance</h2><p>Theoretical modeling and empirical data both suggest that early-stage VCs do better when they spread the wealth wider.</p><p>Let's start with the theory.</p><p>First, we need to define the <a href=\"http://reactionwheel.net/2015/06/power-laws-in-venture.html\">power law distribution</a>:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"/content/images/2020/07/640px-Long_tail.svg.png\" class=\"kg-image\" alt=\"640px-Long_tail.svg\" loading=\"lazy\"><figcaption>Source: <a href=\"https://commons.wikimedia.org/w/index.php?curid=1449504\">Wikipedia</a></figcaption></figure><p>A power law distribution is one where large, consequential events (the Googles, Amazons, and Facebooks of the venture world) are rare but much more common than you might expect if the world were <a href=\"https://en.wikipedia.org/wiki/Normal_distribution\">normally distributed</a>.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"/content/images/2020/07/normal-v-pld-tail.png\" class=\"kg-image\" alt=\"https://i0.wp.com/reactionwheel.net/wp-content/uploads/2015/06/normal-v-pld-tail.png?resize=606%2C287\" loading=\"lazy\"><figcaption>Source: <a href=\"http://reactionwheel.net/2015/06/power-laws-in-venture.html\">Reaction Wheel</a></figcaption></figure><p>These events happen with some frequency, and that frequency can be characterized by a \"shape\" or \"tail parameter\" that governs the \"fatness\" of the tail, typically represented by the symbol \\(\\alpha\\).</p><p>The smaller \\(\\alpha\\), the \"fatter\" the tail of the power law distribution. The fatter the tail, the higher the frequency and size of outlier startups.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"/content/images/2020/07/pld-tails.png\" class=\"kg-image\" alt=\"https://i2.wp.com/reactionwheel.net/wp-content/uploads/2015/06/pld-tails.png?resize=611%2C287\" loading=\"lazy\"><figcaption>Source: <a href=\"http://reactionwheel.net/2015/06/power-laws-in-venture.html\">Reaction Wheel</a></figcaption></figure><p>If \\(\\alpha\\) is sufficiently small, strange things begin to happen. With a small enough \\(\\alpha\\), <strong>making investments nearly at random will increase a portfolio's expected return</strong>.</p><p>The exact mathematical reasons for this are <a href=\"https://arxiv.org/abs/2001.10488\">somewhat esoteric</a>, but intuitively, if there are enough potential Googles, Amazons, and Facebooks out there, they will more than cover the losses from the duds thanks to the shape of the power law distribution. When fat tails dominate returns it's not worth having an extremely high bar if it might cause you to miss out on one of these future juggernauts.</p><p>VCs often talk about power laws, but few have sufficient data to rigorously demonstrate them. However, <a href=\"https://angel.co/\">AngelList</a> does, and their head data scientist, Abe Othman, has <a href=\"https://angel.co/blog/venture-returns\">done the work</a> to analyze returns from the thousands of deals syndicated by AngelList, finding that:</p><blockquote>... <strong>the regret an investor could have for missing a winning seed-stage investment is theoretically infinite</strong>, a phenomenon that does not appear to hold for later-stage investments. The implication is that <strong>investors increase their expected return by indexing as broadly as possible at the seed stage</strong> (i.e., by putting money into every credible deal), because <strong>any selective policy for seed-stage investingâ€”absent perfect foresightâ€”will eventually be outperformed by an indexing approach</strong>.</blockquote><p>By creating power law-based mathematical model, fitting it to the AngelList returns data, and simulating 50,000 portfolios with 10 early-stage companies each, he created the following synthetic distribution of venture capital returns:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"/content/images/2020/07/chart_2.png\" class=\"kg-image\" alt=\"Distribution of hypothetical manager returns showing the market return outperforms\" loading=\"lazy\"><figcaption>Source: <a href=\"https://angel.co/blog/what-angellist-data-says-about-power-law-returns-in-venture-capital\">AngelList</a></figcaption></figure><p>The vertical black line represents the <em>market return</em>: the return you'd earn if you invested an equal amount in every AngelList deal in the sample (of which there were 1,808). Notice the long tail trailing off to the right side of the chart. In a world where most barely return their fund, some shower their LPs with 5x returns. <strong>Notice how most 10-company portfolios underperform the simple (1,808-company) strategy.</strong></p><p>Technically, this is still a theoretical result. Yes, the model was fit to real data, but the outputs are still simulated. Now let's look at real data.</p><p>Here again we turn to AngelList, who analyze the relationship between portfolio size and performance among 10,000+ investors on the platform. They grouped the investors by number of companies in their portfolio and plotted the median return for each group. The chart confirms the theoretical results - larger portfolios generate greater returns:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"/content/images/2020/07/H5qNMNZPFO.png\" class=\"kg-image\" alt=\"img\" loading=\"lazy\"><figcaption>Source: <a href=\"https://angel.co/pdf/lp-performance.pdf\">AngelList</a></figcaption></figure><blockquote>The coefficient of the regression term is 9.0 <a href=\"https://www.investopedia.com/terms/b/basispoint.asp\">basis points</a>... implying that <strong>the typical annual return of a portfolio of 100 investments is almost 9% higher than the typical annual return of a portfolio with a single investment</strong>.</blockquote><p>Note these are median returns, so they don't reflect a handful of 100-count portfolios simply getting lucky and pulling up the average. <strong>Financial upside is easier to come by when you're exposed to a larger patch of the startup landscape.</strong></p><p>Theory and data agree - most early-stage venture investors would do better by indexing, investing a small amount in every reasonable startup they can find:</p><blockquote>Simulations on 10-year investing windows for seed-stage deals suggest <strong>fewer than 10% of investors will beat the index</strong>, even if those investors have skill in picking deals. Like Vanguard has taught us in the public markets, <strong>individual investors could benefit from viewing the index as the default</strong> and then overlaying individual deals that they like.</blockquote><h2 id=\"1-n\">1/N</h2><p>Behavioral finance theorists have a name for this strategy: <a href=\"https://www.macroresilience.com/2010/07/08/heuristics-and-robustness-in-asset-allocation/\">the 1/N heuristic</a>.</p><p>It goes like this: take every investable asset of a group of N assets and invest 1/Nth of your capital in each one, with no regard to the fundamentals, mean return, or volatility of returns.</p><p>This might sound like a dumb, simplistic strategy. While it's certainly simple, it's definitely not dumb.</p><p>Ironically, 1990 Nobel Laureate and famed inventor of mean-variance portfolio optimization, Harry Markowitz, reportedly used this exact heuristic for investing his own money, eschewing his own complicated theory in favor of a simpler approach:</p><blockquote>I should have computed the historical covariance of the asset classes and drawn an efficient frontierâ€¦I split my contributions 50/50 between bonds and equities. - <a href=\"https://alphaarchitect.com/2014/10/17/harry-markowitz-an-equal-weight-investor/\">Harry Markowitz</a></blockquote><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"/content/images/2020/07/image-20200624134947087.png\" class=\"kg-image\" alt=\"image-20200624134947087\" loading=\"lazy\"><figcaption>Source: <a href=\"https://books.google.com/books?id=gRdOBrus_9wC&amp;pg=PA4&amp;lpg=PA4&amp;dq=your+money+and+your+brain+harry+markowitz&amp;source=bl&amp;ots=awRnIfiMs4&amp;sig=sY4wPziYOjm9oB5f3MN_z7gloMw&amp;hl=en&amp;sa=X&amp;ei=bEM3VKT9MIjIsATj_4Fw#v=onepage&amp;q&amp;f=false\">Your Money and Your Brain</a></figcaption></figure><p>In fact, <a href=\"http://faculty.london.edu/avmiguel/DeMiguel-Garlappi-Uppal-RFS.pdf\">one study</a> found that the 1/N strategy dominates numerous others:</p><blockquote>Of the 14 models we evaluate across seven empirical datasets, <strong>none is consistently better than the 1/N rule</strong> in terms of Sharpe ratio, certainty-equivalent return, or turnover, which indicates that, out of sample, <strong>the gain from optimal diversification is more than offset by estimation error</strong>... Â That is, the effect of estimation error is so large that <strong>it erodes completely the gains from optimal diversification</strong>.</blockquote><p>Which is a fancy way of saying \"<em>don't overcomplicate it.</em>\"</p><p>A <em>slightly</em> more sophisticated reading of the results might be, \"<em>unless you are <strong>very</strong> sure about the structure of the world, don't overcomplicate your investing strategy.</em>\"</p><p>The study found a negative return to overthinking and overfitting yourself to the past data, to what you <em>think</em> you know about these assets. In venture, similar overintellectualization has been the root cause of numerous \"misses\" over the years - career, fund, and firm-defining deals that put certain VCs on the map and left others in desperate obscurity.</p><p>In some <em>subtle</em> way, trying to pick the exact right startup based on a complex model of the world is like trying to buy a certain lottery ticket with a certain serial number because you think it's a \"lucky ticket.\" One <em>seems</em> much more superstitious, but are they closer than they appear?</p><h2 id=\"how-the-other-half-lives\">How the other half lives</h2><p>Late stage investors on the other hand, <em>can</em> afford to stock pick:</p><blockquote>... our results also suggest that the opportunity cost for missing a winning investment in these later rounds is bounded... Consequently, <strong>it is entirely appropriate that later-stage investors should reject the â€œspray and prayâ€ idea and be thoughtful and discerning when they participate</strong>...</blockquote><p>Translation: late-stage deals have lower opportunity cost than early-stage investments, as their returns are capped much lower. To channel Jeff Bezos' <a href=\"https://www.youtube.com/watch?v=jwG_qR6XmDQ\">regret minimization framework</a>: there isn't much regret to minimize when it comes to late-stage deals. So feel free to be picky.</p><p>Another take from the 1/N study:</p><blockquote>... we conclude that portfolio strategies from the optimizing models are expected to outperform the 1/N benchmark if: <strong>(i) the estimation window is long</strong>; (ii) the ex ante (true) Sharpe ratio of the mean-variance efficient portfolio is substantially higher than that of the 1/N portfolio; and <strong>(iii) the number of assets is small</strong>.</blockquote><p>In other words, it makes sense to be picky and particular when you have a large amount of data collected over a long period of time and when the number of choices is small. Both are more true of later-stage investments relative to early-stage. By definition, late-stage companies have a longer track record by which to evaluate them, and there are fewer of them. Thus, it makes sense to be a discerning capital allocator at the late-stage.</p><p>And yet we've seen the exact <em>opposite</em> in recent years.</p><p>Though few would publicly characterize themselves as such, I know of at least a few firms who have explicit goals of creating, effectively, \"indices of late-stage venture\" via their large portfolios. Late-stage funds are raising and deploying capital at unprecedented rates. Many appear principally focused on putting \"dollars to work,\" rather than earning the maximum return on their capital. They've taken to heart the approach discussed earlier, investing in every company that meets some minimum threshold.</p><p>This has led to serious perversion at the late-stage, as there are not nearly enough investable assets to support the capital inflows at reasonable valuations. <strong>Asset values grow not simply due to improvement in fundamental startup value but also because late-stage funds need somewhere to park their money</strong>.</p><p>In this model, late-stage startups become \"<em>capital vehicles</em>,\" absorbing meaningful capital and earning a \"<em>capital storage</em>\" premium for their efforts.</p><p><a href=\"https://blog.samaltman.com/party-rounds\">Party rounds</a>, long known to greatly <a href=\"http://blog.eladgil.com/2010/09/party-rounds-how-to-get-high-valuation.html\">inflate early-stage valuations</a>, have reached the late-stage.</p><p>But all parties must come to end eventually...</p><h2 id=\"caveat-emptor-indexor\"><em>Caveat <s>emptor</s> indexor</em></h2><p>So that's the theory, but there are some real practical hurdles to creating an early-stage index:</p><ul><li>Determining the right minimum threshold</li><li>No one sees every deal</li><li>Deals must be won</li><li>Fund and check size restrictions</li></ul><h3 id=\"how-high-should-the-bar-be\">How high should the bar be?</h3><p>AngelList recommends investing in every <em>credible</em> early-stage deal, where the word \"credible\" does a lot of work. They add:</p><blockquote>We worry that <strong>an investor promising to blindly fund every whisper of a new company would fundamentally alter the investment universe they are exposed to by introducing a huge number of new money losing investments</strong> that otherwise would not have been created but for the investorâ€™s universal funding policy. Consequently, our results suggest that at the seed stage investors should put money into every investment that <strong>clears some minimum threshold</strong>.</blockquote><p>But how to set that threshold? It's not obvious.</p><p>There must be some bar, even if very low, otherwise you'll do a series of bad deals and get fleeced.</p><p><a href=\"https://blakemasters.com/post/21869934240/peter-thiels-cs183-startup-class-7-notes-essay\">Peter Thiel</a> puts it this way:</p><blockquote>There just arenâ€™t that many businesses that you can have the requisite high degree of conviction about. A better model is to invest in maybe 7 or 8 promising companies from which you think you can get a 10x return.</blockquote><p>Part of the reason indexing even works in say, public markets, is that there is some minimum threshold a company has to reach to even go public. Additionally, the AngelList data from which this theory comes only includes deals that got done, by definition. We don't know if the indexing strategy carries over to deals that wouldn't have otherwise got done or to companies with lower quality than the typical AngelList deal.</p><p>Since the AngelList data comes from deals that successfully completed, you could proxy for this by setting the bar such that you would do any deal that some other reasonable person would do.</p><h3 id=\"you-must-see-the-deal-to-do-the-deal\">You must see the deal to do the deal</h3><p>You can't hit a target you can't see, and <a href=\"__GHOST_URL__/people-matching/\">you can't do a deal you can't see either</a>.</p><p>The AngelList recommendation assumes the investor could invest in any deal they want. If you don't have access to all the deals, this logic breaks down.</p><p>Unless you are a top tier fund or individual investor, the specific subset of deals you see is almost certainly poor relative to the full distribution. You are likely missing some serious outliers.</p><p>This is why so many VCs spend so much time burnishing their public and private reputations. <a href=\"https://marginalrevolution.com/marginalrevolution/2020/02/why-is-vc-twitter-so-peculiar.html\">VC Twitter says hi.</a></p><h3 id=\"you-must-also-win\">You must also win</h3><p>Let's say you set the right threshold and see all the deals that meet it. You still then must <a href=\"__GHOST_URL__/people-matching/\">win the deal</a>, which is far from guaranteed.</p><p>Further, the greater extent to which a deal exceeds any given threshold, the more competitive the deal will be. Assuming there's signal there and not simply noise, your portfolio will probabilistically skew lower quality simply due to losing out on those winners, even though you recognized them as such.</p><p>This completely screws up the indexing strategy, which implicitly relies on free and open access to all deals across the quality spectrum.</p><h3 id=\"a-fund-cannot-be-sliced-into-a-thousand-pieces\">A fund cannot be sliced into a thousand pieces</h3><p>Even if the above caveats don't apply, a VC still runs up against fundamental limits of the venture universe.</p><p>Like the <a href=\"https://en.wikipedia.org/wiki/Planck_length\">Planck length</a> represents the smallest distance at which conventional physics applies, micro-checks become infeasible below a certain size, both for the startups themselves and the would-be index investor.</p><p>The complement of this is that, assuming some minimum check size, you might not be able to raise a fund large enough to write all those checks.</p><h2 id=\"masters-of-the-universe\">Masters of the universe?</h2><p>VCs are picky, not because they have so many options but <strong>because they have so few</strong>.</p><p>The 1/N study tells us that stock picking makes sense when there are few options to choose from.</p><p>The AngelList data tells us that, in a hypothetical world of perfect access to all investments, you'd do better to spread your bets widely.</p><p>In other words, the picky behavior of early-stage venture capitalists in light of the data and theory around power laws can only be justified by their <em>lack</em> of options. They only have a few shots on goal and must use them wisely.</p><p>People often assume this pickiness comes from the fact that most startups fail, and VCs obviously want to avoid the numerous duds. <strong>But this isn't really true.</strong> Even in a world where most startups fail it can make sense to invest in many more than the typical investor does currently, as shown above.</p><p>Far from masters of the universe, selectively picking among desperate founders looking for funding, <strong>VCs are themselves starved of options</strong>, making them extremely cautious with the few they have.</p><p>In a future article, I'll extend this idea and demonstrate why it shows venture capitalists aren't funding nearly enough startups.</p>","comment_id":"5eff048a2fa60d0ab28d5cd4","plaintext":"Math and data say early-stage VCs should index invest\n[https://www.investopedia.com/terms/i/index-investing.asp], and late-stage\ninvestors should stock pick [https://www.investopedia.com/terms/s/stockpick.asp]\n.\n\nYet they do the opposite.\n\nThe reason is counterintuitive: VCs are picky, not because they have so many\noptions but because they have so few.\n\nMore deals, better performance\nTheoretical modeling and empirical data both suggest that early-stage VCs do\nbetter when they spread the wealth wider.\n\nLet's start with the theory.\n\nFirst, we need to define the power law distribution\n[http://reactionwheel.net/2015/06/power-laws-in-venture.html]:\n\nSource: Wikipedia [https://commons.wikimedia.org/w/index.php?curid=1449504]A\npower law distribution is one where large, consequential events (the Googles,\nAmazons, and Facebooks of the venture world) are rare but much more common than\nyou might expect if the world were normally distributed\n[https://en.wikipedia.org/wiki/Normal_distribution].\n\nSource: Reaction Wheel\n[http://reactionwheel.net/2015/06/power-laws-in-venture.html]These events happen\nwith some frequency, and that frequency can be characterized by a \"shape\" or\n\"tail parameter\" that governs the \"fatness\" of the tail, typically represented\nby the symbol \\(\\alpha\\).\n\nThe smaller \\(\\alpha\\), the \"fatter\" the tail of the power law distribution. The\nfatter the tail, the higher the frequency and size of outlier startups.\n\nSource: Reaction Wheel\n[http://reactionwheel.net/2015/06/power-laws-in-venture.html]If \\(\\alpha\\) is\nsufficiently small, strange things begin to happen. With a small enough\n\\(\\alpha\\), making investments nearly at random will increase a portfolio's\nexpected return.\n\nThe exact mathematical reasons for this are somewhat esoteric\n[https://arxiv.org/abs/2001.10488], but intuitively, if there are enough\npotential Googles, Amazons, and Facebooks out there, they will more than cover\nthe losses from the duds thanks to the shape of the power law distribution. When\nfat tails dominate returns it's not worth having an extremely high bar if it\nmight cause you to miss out on one of these future juggernauts.\n\nVCs often talk about power laws, but few have sufficient data to rigorously\ndemonstrate them. However, AngelList [https://angel.co/] does, and their head\ndata scientist, Abe Othman, has done the work\n[https://angel.co/blog/venture-returns] to analyze returns from the thousands of\ndeals syndicated by AngelList, finding that:\n\n> ... the regret an investor could have for missing a winning seed-stage\ninvestment is theoretically infinite, a phenomenon that does not appear to hold\nfor later-stage investments. The implication is that investors increase their\nexpected return by indexing as broadly as possible at the seed stage (i.e., by\nputting money into every credible deal), because any selective policy for\nseed-stage investingâ€”absent perfect foresightâ€”will eventually be outperformed by\nan indexing approach.\nBy creating power law-based mathematical model, fitting it to the AngelList\nreturns data, and simulating 50,000 portfolios with 10 early-stage companies\neach, he created the following synthetic distribution of venture capital\nreturns:\n\nSource: AngelList\n[https://angel.co/blog/what-angellist-data-says-about-power-law-returns-in-venture-capital]\nThe vertical black line represents the market return: the return you'd earn if\nyou invested an equal amount in every AngelList deal in the sample (of which\nthere were 1,808). Notice the long tail trailing off to the right side of the\nchart. In a world where most barely return their fund, some shower their LPs\nwith 5x returns. Notice how most 10-company portfolios underperform the simple\n(1,808-company) strategy.\n\nTechnically, this is still a theoretical result. Yes, the model was fit to real\ndata, but the outputs are still simulated. Now let's look at real data.\n\nHere again we turn to AngelList, who analyze the relationship between portfolio\nsize and performance among 10,000+ investors on the platform. They grouped the\ninvestors by number of companies in their portfolio and plotted the median\nreturn for each group. The chart confirms the theoretical results - larger\nportfolios generate greater returns:\n\nSource: AngelList [https://angel.co/pdf/lp-performance.pdf]> The coefficient of\nthe regression term is 9.0 basis points\n[https://www.investopedia.com/terms/b/basispoint.asp]... implying that the\ntypical annual return of a portfolio of 100 investments is almost 9% higher than\nthe typical annual return of a portfolio with a single investment.\nNote these are median returns, so they don't reflect a handful of 100-count\nportfolios simply getting lucky and pulling up the average. Financial upside is\neasier to come by when you're exposed to a larger patch of the startup\nlandscape.\n\nTheory and data agree - most early-stage venture investors would do better by\nindexing, investing a small amount in every reasonable startup they can find:\n\n> Simulations on 10-year investing windows for seed-stage deals suggest fewer than\n10% of investors will beat the index, even if those investors have skill in\npicking deals. Like Vanguard has taught us in the public markets, individual\ninvestors could benefit from viewing the index as the default and then\noverlaying individual deals that they like.\n1/N\nBehavioral finance theorists have a name for this strategy: the 1/N heuristic\n[https://www.macroresilience.com/2010/07/08/heuristics-and-robustness-in-asset-allocation/]\n.\n\nIt goes like this: take every investable asset of a group of N assets and invest\n1/Nth of your capital in each one, with no regard to the fundamentals, mean\nreturn, or volatility of returns.\n\nThis might sound like a dumb, simplistic strategy. While it's certainly simple,\nit's definitely not dumb.\n\nIronically, 1990 Nobel Laureate and famed inventor of mean-variance portfolio\noptimization, Harry Markowitz, reportedly used this exact heuristic for\ninvesting his own money, eschewing his own complicated theory in favor of a\nsimpler approach:\n\n> I should have computed the historical covariance of the asset classes and drawn\nan efficient frontierâ€¦I split my contributions 50/50 between bonds and equities.\n- Harry Markowitz\n[https://alphaarchitect.com/2014/10/17/harry-markowitz-an-equal-weight-investor/]\nSource: Your Money and Your Brain\n[https://books.google.com/books?id=gRdOBrus_9wC&pg=PA4&lpg=PA4&dq=your+money+and+your+brain+harry+markowitz&source=bl&ots=awRnIfiMs4&sig=sY4wPziYOjm9oB5f3MN_z7gloMw&hl=en&sa=X&ei=bEM3VKT9MIjIsATj_4Fw#v=onepage&q&f=false]\nIn fact, one study\n[http://faculty.london.edu/avmiguel/DeMiguel-Garlappi-Uppal-RFS.pdf] found that\nthe 1/N strategy dominates numerous others:\n\n> Of the 14 models we evaluate across seven empirical datasets, none is\nconsistently better than the 1/N rule in terms of Sharpe ratio,\ncertainty-equivalent return, or turnover, which indicates that, out of sample, \nthe gain from optimal diversification is more than offset by estimation error...\nÂ That is, the effect of estimation error is so large that it erodes completely\nthe gains from optimal diversification.\nWhich is a fancy way of saying \"don't overcomplicate it.\"\n\nA slightly more sophisticated reading of the results might be, \"unless you are \nvery sure about the structure of the world, don't overcomplicate your investing\nstrategy.\"\n\nThe study found a negative return to overthinking and overfitting yourself to\nthe past data, to what you think you know about these assets. In venture,\nsimilar overintellectualization has been the root cause of numerous \"misses\"\nover the years - career, fund, and firm-defining deals that put certain VCs on\nthe map and left others in desperate obscurity.\n\nIn some subtle way, trying to pick the exact right startup based on a complex\nmodel of the world is like trying to buy a certain lottery ticket with a certain\nserial number because you think it's a \"lucky ticket.\" One seems much more\nsuperstitious, but are they closer than they appear?\n\nHow the other half lives\nLate stage investors on the other hand, can afford to stock pick:\n\n> ... our results also suggest that the opportunity cost for missing a winning\ninvestment in these later rounds is bounded... Consequently, it is entirely\nappropriate that later-stage investors should reject the â€œspray and prayâ€ idea\nand be thoughtful and discerning when they participate...\nTranslation: late-stage deals have lower opportunity cost than early-stage\ninvestments, as their returns are capped much lower. To channel Jeff Bezos' \nregret minimization framework [https://www.youtube.com/watch?v=jwG_qR6XmDQ]:\nthere isn't much regret to minimize when it comes to late-stage deals. So feel\nfree to be picky.\n\nAnother take from the 1/N study:\n\n> ... we conclude that portfolio strategies from the optimizing models are\nexpected to outperform the 1/N benchmark if: (i) the estimation window is long;\n(ii) the ex ante (true) Sharpe ratio of the mean-variance efficient portfolio is\nsubstantially higher than that of the 1/N portfolio; and (iii) the number of\nassets is small.\nIn other words, it makes sense to be picky and particular when you have a large\namount of data collected over a long period of time and when the number of\nchoices is small. Both are more true of later-stage investments relative to\nearly-stage. By definition, late-stage companies have a longer track record by\nwhich to evaluate them, and there are fewer of them. Thus, it makes sense to be\na discerning capital allocator at the late-stage.\n\nAnd yet we've seen the exact opposite in recent years.\n\nThough few would publicly characterize themselves as such, I know of at least a\nfew firms who have explicit goals of creating, effectively, \"indices of\nlate-stage venture\" via their large portfolios. Late-stage funds are raising and\ndeploying capital at unprecedented rates. Many appear principally focused on\nputting \"dollars to work,\" rather than earning the maximum return on their\ncapital. They've taken to heart the approach discussed earlier, investing in\nevery company that meets some minimum threshold.\n\nThis has led to serious perversion at the late-stage, as there are not nearly\nenough investable assets to support the capital inflows at reasonable\nvaluations. Asset values grow not simply due to improvement in fundamental\nstartup value but also because late-stage funds need somewhere to park their\nmoney.\n\nIn this model, late-stage startups become \"capital vehicles,\" absorbing\nmeaningful capital and earning a \"capital storage\" premium for their efforts.\n\nParty rounds [https://blog.samaltman.com/party-rounds], long known to greatly \ninflate early-stage valuations\n[http://blog.eladgil.com/2010/09/party-rounds-how-to-get-high-valuation.html],\nhave reached the late-stage.\n\nBut all parties must come to end eventually...\n\nCaveat emptor indexor\nSo that's the theory, but there are some real practical hurdles to creating an\nearly-stage index:\n\n * Determining the right minimum threshold\n * No one sees every deal\n * Deals must be won\n * Fund and check size restrictions\n\nHow high should the bar be?\nAngelList recommends investing in every credible early-stage deal, where the\nword \"credible\" does a lot of work. They add:\n\n> We worry that an investor promising to blindly fund every whisper of a new\ncompany would fundamentally alter the investment universe they are exposed to by\nintroducing a huge number of new money losing investments that otherwise would\nnot have been created but for the investorâ€™s universal funding policy.\nConsequently, our results suggest that at the seed stage investors should put\nmoney into every investment that clears some minimum threshold.\nBut how to set that threshold? It's not obvious.\n\nThere must be some bar, even if very low, otherwise you'll do a series of bad\ndeals and get fleeced.\n\nPeter Thiel\n[https://blakemasters.com/post/21869934240/peter-thiels-cs183-startup-class-7-notes-essay] \nputs it this way:\n\n> There just arenâ€™t that many businesses that you can have the requisite high\ndegree of conviction about. A better model is to invest in maybe 7 or 8\npromising companies from which you think you can get a 10x return.\nPart of the reason indexing even works in say, public markets, is that there is\nsome minimum threshold a company has to reach to even go public. Additionally,\nthe AngelList data from which this theory comes only includes deals that got\ndone, by definition. We don't know if the indexing strategy carries over to\ndeals that wouldn't have otherwise got done or to companies with lower quality\nthan the typical AngelList deal.\n\nSince the AngelList data comes from deals that successfully completed, you could\nproxy for this by setting the bar such that you would do any deal that some\nother reasonable person would do.\n\nYou must see the deal to do the deal\nYou can't hit a target you can't see, and you can't do a deal you can't see\neither [__GHOST_URL__/people-matching/].\n\nThe AngelList recommendation assumes the investor could invest in any deal they\nwant. If you don't have access to all the deals, this logic breaks down.\n\nUnless you are a top tier fund or individual investor, the specific subset of\ndeals you see is almost certainly poor relative to the full distribution. You\nare likely missing some serious outliers.\n\nThis is why so many VCs spend so much time burnishing their public and private\nreputations. VC Twitter says hi.\n[https://marginalrevolution.com/marginalrevolution/2020/02/why-is-vc-twitter-so-peculiar.html]\n\nYou must also win\nLet's say you set the right threshold and see all the deals that meet it. You\nstill then must win the deal [__GHOST_URL__/people-matching/], which is far from\nguaranteed.\n\nFurther, the greater extent to which a deal exceeds any given threshold, the\nmore competitive the deal will be. Assuming there's signal there and not simply\nnoise, your portfolio will probabilistically skew lower quality simply due to\nlosing out on those winners, even though you recognized them as such.\n\nThis completely screws up the indexing strategy, which implicitly relies on free\nand open access to all deals across the quality spectrum.\n\nA fund cannot be sliced into a thousand pieces\nEven if the above caveats don't apply, a VC still runs up against fundamental\nlimits of the venture universe.\n\nLike the Planck length [https://en.wikipedia.org/wiki/Planck_length] represents\nthe smallest distance at which conventional physics applies, micro-checks become\ninfeasible below a certain size, both for the startups themselves and the\nwould-be index investor.\n\nThe complement of this is that, assuming some minimum check size, you might not\nbe able to raise a fund large enough to write all those checks.\n\nMasters of the universe?\nVCs are picky, not because they have so many options but because they have so\nfew.\n\nThe 1/N study tells us that stock picking makes sense when there are few options\nto choose from.\n\nThe AngelList data tells us that, in a hypothetical world of perfect access to\nall investments, you'd do better to spread your bets widely.\n\nIn other words, the picky behavior of early-stage venture capitalists in light\nof the data and theory around power laws can only be justified by their lack of\noptions. They only have a few shots on goal and must use them wisely.\n\nPeople often assume this pickiness comes from the fact that most startups fail,\nand VCs obviously want to avoid the numerous duds. But this isn't really true. \nEven in a world where most startups fail it can make sense to invest in many\nmore than the typical investor does currently, as shown above.\n\nFar from masters of the universe, selectively picking among desperate founders\nlooking for funding, VCs are themselves starved of options, making them\nextremely cautious with the few they have.\n\nIn a future article, I'll extend this idea and demonstrate why it shows venture\ncapitalists aren't funding nearly enough startups.","feature_image":"__GHOST_URL__/content/images/2020/07/header.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-07-03T10:12:26.000Z","updated_at":"2020-07-04T21:48:07.000Z","published_at":"2020-07-03T16:54:02.000Z","custom_excerpt":"VCs are picky, not because they have so many options but because they have so few.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5f0d75ab2fc931237d113877","uuid":"3e5a8639-0389-458b-baec-842a95b8cf1a","title":"Six Trends Shaping Developer Productivity","slug":"developer-productivity-trends","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive a report with the full results</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Your Email Address\\\" id=\\\"mce-EMAIL\\\" required>\\n<input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Six Trends Shaping Developer Productivity\\\">\\n<input type=\\\"checkbox\\\" value=\\\"4\\\" name=\\\"group[78549][4]\\\" id=\\\"mce-group[78549]-78549-0\\\" style=\\\"display:none\\\" checked>\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Send Report âš¡</span></button>\\n</form>\\n            </section>\"}],[\"image\",{\"src\":\"/content/images/2020/07/dev-power.png\"}],[\"image\",{\"src\":\"/content/images/2020/07/app-sec-left.png\"}],[\"image\",{\"src\":\"/content/images/2020/07/distributed-cloud.png\"}],[\"image\",{\"src\":\"/content/images/2020/07/remote-development.png\"}],[\"image\",{\"src\":\"/content/images/2020/07/python-spark-big-data-growth.png\"}],[\"image\",{\"src\":\"/content/images/2020/07/devops-dataops-mlops.png\"}]],\"markups\":[[\"a\",[\"href\",\"https://www.linkedin.com/in/clio-smurro-31967b9/\"]],[\"strong\"],[\"a\",[\"href\",\"__GHOST_URL__/developer-productivity-strategic-priorities/\"]],[\"a\",[\"href\",\"__GHOST_URL__/developer-productivity-challenges/\"]],[\"a\",[\"href\",\"__GHOST_URL__/developer-productivity-trends/#trend-1-developers-have-the-power-and-the-purse\"]],[\"a\",[\"href\",\"__GHOST_URL__/developer-productivity-trends/#trend-2-application-security-is-shifting-left\"]],[\"a\",[\"href\",\"__GHOST_URL__/developer-productivity-trends/#trend-3-the-distributed-cloud-is-having-its-covid-moment\"]],[\"a\",[\"href\",\"__GHOST_URL__/developer-productivity-trends/#trend-4-remote-software-development-is-here-to-stay\"]],[\"a\",[\"href\",\"__GHOST_URL__/developer-productivity-trends/#trend-5-the-growth-of-python-spark-and-big-data\"]],[\"a\",[\"href\",\"__GHOST_URL__/developer-productivity-trends/#trend-6-transfer-learning-from-devops-to-data-science-and-data-engineering\"]],[\"a\",[\"href\",\"https://www.jenkins.io/\"]],[\"a\",[\"href\",\"__GHOST_URL__/remote-software-developers-earn-more/\"]],[\"em\"],[\"a\",[\"href\",\"https://dask.org/\"]],[\"a\",[\"href\",\"https://ray.io/\"]],[\"a\",[\"href\",\"https://spark.apache.org/\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Developer productivity is undergoing a tectonic shift. New software development paradigms and tooling have accelerated the pace and productivity of modern software teams, quickening the \\\"shipping speed\\\" of new software.\"]]],[1,\"p\",[[0,[],0,\"To dissect these trends, my good friend and colleague, \"],[0,[0],1,\"Clio Smurro\"],[0,[],0,\", and I interviewed founders and executives at next-generation software and infrastructure startups pushing the developer productivity frontier to get their thoughts and insights. They shared their views on:\"]]],[3,\"ul\",[[[0,[1],1,\"major industry trends (you are here)\"],[0,[],0,\",\"]],[[0,[2],1,\"top strategic priorities\"],[0,[],0,\", and\"]],[[0,[3],1,\"biggest challenges and pain points\"]]]],[1,\"p\",[[0,[],0,\"In this first chapter, we share our findings on the important trends shaping developer productivity, including:\"]]],[3,\"ul\",[[[0,[],0,\"Trend #1: \"],[0,[4],1,\"Developers have the power... and the purse\"]],[[0,[],0,\"Trend #2: \"],[0,[5],1,\"Application security is \\\"shifting left\\\"\"]],[[0,[],0,\"Trend #3: \"],[0,[6],1,\"The distributed cloud is having its COVID moment\"]],[[0,[],0,\"Trend #4: \"],[0,[7],1,\"Remote software development is here to stay\"]],[[0,[],0,\"Trend #5: \"],[0,[8],1,\"The growth of Python, Spark, and Big Data\"]],[[0,[],0,\"Trend #6: \"],[0,[9],1,\"Transfer learning from DevOps to data science and data engineering\"]]]],[1,\"p\",[[0,[],0,\"Want to be notified when we publish part two of our findings? Subscribe below, and we'll also send you a nicely formatted PDF of our research!\"]]],[10,0],[1,\"h2\",[[0,[],0,\"Trend #1: Developers have the power... and the purse\"]]],[10,1],[1,\"blockquote\",[[0,[],0,\"\\\"\"],[0,[1],1,\"Buying products that save developer time is no longer an argument you need to explain\"],[0,[],0,\". People get it.\\\" â€” Executive, Developer Tools Startup\"]]],[1,\"p\",[[0,[],0,\"Software engineers continue to be a scarce resource in most organizations. Companies are increasingly focused on enhancing the productivity of developers. In doing so, power and autonomy flow to developers, and the dollars are quick to follow.\"]]],[1,\"p\",[[0,[],0,\"Vendors are reflecting this new reality in their go-to-market positioning and sales efforts:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"In our sales conversation, \"],[0,[1],1,\"we frame things in terms of productivity and developer time saved\"],[0,[],0,\"... You're comparing the cost of the product against engineering time saved.\\\" â€” Executive, Developer Tools Startup\"]]],[1,\"p\",[[0,[],0,\"Even before sales gets involved, developers are adopting software they need to get their work done on their own, often without the involvement or permission of procurement or upper management. Developers know what they want, the tools they love, and the technologies that enable their ideal architectures and designs.\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"\"],[0,[1],1,\"We're seeing lots of self-serve.\"],[0,[],0,\" Developers are getting more autonomy as buyers. \"],[0,[1],1,\"Most of our sign-ups are via bottoms-up\"],[0,[],0,\" â€” people signing themselves up, after which our sales team eventually reaches out to them.\\\" â€” Executive, Developer Tools Startup\"]]],[1,\"p\",[[0,[],0,\"Unlike many other domains of enterprise software, where features are built to appease higher and higher levels of management rather than end users themselves, the core developer experience remains hugely important. If anything, analogous trends in observability and monitoring are developing in a symbiotic rather than antagonistic fashion with developer productivity.\"]]],[1,\"p\",[[0,[],0,\"As engineering teams scale, the need for agile workflows becomes apparent, drawing many toward the burgeoning DevOps paradigm and its associated ecosystem of tools. DevOps enables ongoing operation of and rapid iteration on software via Git-based version control, continuous integration, continuous deployment, security testing, and more.\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"DevOps hasnâ€™t been around for long, but more companies are realizing the need/value for it.\\\" â€” Developer Advocate, Application Infrastructure Startup\"]]],[1,\"p\",[[0,[],0,\"To the extent that vendors are attempting to appease management, they are doing so by building unified product ecosystems. These enable customers to purchase multiple component tools of the overall software development lifecycle in a single package. While these do carry some benefits for end users, most still prefer to purchase the best solution for each task, again reflecting in influence and clout of individual software developers:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"GitHub, Atlassian, Microsoft... \"],[0,[1],1,\"Theyâ€™re trying to get everyone to adopt a unified tool system.\"],[0,[],0,\" But most people still go with best-of-breed, as far as tools go. The idea though is that some people will eventually go with more of a â€œyou canâ€™t get fired for buying IBMâ€ approach, where you buy everything from a single vendor.\\\" â€” Executive, Application Security Startup\"]]],[1,\"h2\",[[0,[],0,\"Trend #2: Application security is \\\"shifting left\\\"\"]]],[10,2],[1,\"p\",[[0,[],0,\"In past eras, application security was oftentimes dealt with after the fact. Software would be largely complete by the time security analysts had a chance to examine and poke holes in its defenses. In main cases, this might not even happen until after code is already running in production, where any vulnerabilities may have already been exploited by nefarious actors:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"Once the code is built, the artifact goes into a registry. The security team wants to know...\"],[0,[1],1,\"what are the risks? Is this meeting my policies?\"],[0,[],0,\"\\\" â€” Executive, Application Security Startup\"]]],[1,\"p\",[[0,[],0,\"No longer. Application security is now a tier one priority in many organizations:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"Security used to be an afterthought. In the past, someone would write code, someone would deploy code, and then someone else would handle security. \"],[0,[1],1,\"That boundary doesnâ€™t exist anymore.\"],[0,[],0,\"\\\" â€” Executive, Developer Tools Startup\"]]],[1,\"p\",[[0,[],0,\"Spurred by the rash of high-profile security incidents and gaffes at major corporations around the world, organizations are challenging their development teams to take on more of the security burden upfront, well before software is even ready for production or artifacts have been built. \\\"DevSecOps\\\" is born:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"\"],[0,[1],1,\"Shifting left means move everything towards the developer.\"],[0,[],0,\" It doesn't have to be a security person's responsibility to ensure secrets are secure â€” the developer can do this now too. The more tooling you give, earlier on in the process of writing the application, the easier this is.\\\" â€” Director, Developer Tools Startup\"]]],[1,\"p\",[[0,[],0,\"Security vendors continue to sell mostly to security teams but realize their tools are increasingly landing directly in the hands of developers themselves:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"We don't sell to developers, we sell to security teams...but at the end of the day, \"],[0,[1],1,\"itâ€™s the developers who need to take more upfront responsibility for security.\"],[0,[],0,\"\\\" â€” Executive, Application Security Startup\"]]],[1,\"p\",[[0,[],0,\"It's easy to think these new tools are only valuable to large enterprises paranoid about breaches, hacks, and other threats to application security. Not true, say some of the security leaders we spoke to, who emphasized that the heightened focus on security is reverberating through the software development industry, at both large organization and small:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"These security initiatives are not just for big companies...\"],[0,[1],1,\"every company needs them\"],[0,[],0,\".\\\" â€” Executive, Developer Tools Startup\"]]],[1,\"p\",[[0,[],0,\"Then there's the concept of \\\"low trust\\\" or even \\\"no trust\\\", where applications do not give each other the benefit of the doubt and every app must prove its credentials in order to send and receive requests and data from other apps and microservices. This adds new complexity to software development, heightening the important of thinking through security implications early on in development:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"In low trust or no trust environments, how do you make sure applications can talk to each other?\\\" â€” Executive, Developer Tools Startup\"]]],[1,\"p\",[[0,[],0,\"These complexities are inevitable, but vendors also know there are limits to developer patience. They are keen to insert security tooling into workflows as seamlessly as possible. Usability drives usage â€” if a tool is to difficult to use or increases cycle times too dramatically, developers won't use it, defeating the purpose entirely:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"DevOps folks are often not security experts. \"],[0,[1],1,\"Theyâ€™re looking for usability.\"],[0,[],0,\" How easy is this to access? Does it fit in our existing workflows? Can it plug into \"],[0,[10],1,\"Jenkins\"],[0,[],0,\"? I don't want my developers having to use a new tool.\\\" â€” Executive, Application Security Startup\"]]],[1,\"p\",[[0,[],0,\"As development and security increasingly merge, buying patterns and processes will incorporate the needs of both stakeholders, and vendors will need to adjust their tactics appropriately:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"\"],[0,[1],1,\"DevOps needs to like it, SecOps needs to buy it\"],[0,[],0,\". Both are involved in the purchase process.\\\" â€” Executive, Application Security Startup\"]]],[1,\"h2\",[[0,[],0,\"Trend #3: The distributed cloud is having its COVID moment\"]]],[10,3],[1,\"p\",[[0,[],0,\"Demand for distributed computing is growing and that demand has only surged in the COVID era.\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"\"],[0,[1],1,\"COVID has caused a 2-3 year acceleration in everyone's journey to the cloud.\"],[0,[],0,\" The companies who have survived and thrived are the ones which evolved sooner.\\\" â€” Executive, Developer Tools Startup\"]]],[1,\"p\",[[0,[],0,\"Elastic scaling of compute, storage, and other resources is important in a divergent set of scenarios. Some businesses (Zoom, Fastly, Amazon, Instacart, etc.) have seen demand for their services surge, requiring rapid scale up of existing deployments, assisted by prescient decisions to factor applications into microservices.\"]]],[1,\"p\",[[0,[],0,\"On the other hand, certain companies have seen business dry up overnight. This makes the ability to scale down equally important, allowing costs to flex proportionately with revenue:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"Do only what's needed. That's key for dynamic shifts in needs. \"],[0,[1],1,\"You need to design software for scaling up, but the infrastructure also needs to be able to scale down\"],[0,[],0,\".\\\" â€” Executive, Developer Tools Startup\"]]],[1,\"p\",[[0,[],0,\"But what if your business runs on legacy applications or infrastructure technologies? You're in a much tougher position, which is prompting many organizations to ask the question â€” can you accelerate developer productivity within legacy application development?\"]]],[1,\"blockquote\",[[0,[],0,\"There's a lot of legacy .NET applications from 10 years ago that weren't originally built with containers. Organizations want to get those into containers. A question people are asking â€” \"],[0,[1],1,\"can you get developer productivity with legacy applications too?\"],[0,[],0,\" â€” Executive, Application Security Startup\"]]],[1,\"p\",[[0,[],0,\"Increasingly, the answer is â€” yes. Legacy applications are being refactored from monolithic to microservices-based architectures, leveraging the power of containers and other associated advancements:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"We are seeing a movement from cloud \\\"greenfield\\\", only using the cloud for new applications, to \\\"lift and shift\\\", getting legacy applications into containers and into the cloud. We've started working with Windows-based containers.\\\" â€” Executive, Application Security Startup\"]]],[1,\"p\",[[0,[],0,\"While old-school organizations and engineering teams play catch up, next-gen startups and technology companies aren't waiting around.\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"\"],[0,[1],1,\"The biggest trend right now is the move to serverless\"],[0,[],0,\" â€” functions as a service, hiding more complexity from developers. Serverless is a way for developers to just focus on stateless applications, to just focus on what they use most directly.\\\" â€” Executive, Application Infrastructure Startup\"]]],[1,\"p\",[[0,[],0,\"Serverless has emerged as a major trend. Leveraging the \\\"infinite\\\" scalability of the major cloud providers, serverless promises to decompose applications into a series of function calls â€” without regard to the underlying infrastructure.\"]]],[1,\"p\",[[0,[],0,\"While the cloud providers have always had a clear incentive to push such a regime, it seems like development teams themselves are warming up to the idea, thought it's full realization is still years away:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"At our company, we talk about nodes and clusters today. We think of elastic pools of storage and compute that you can just use. But, \"],[0,[1],1,\"a few years from now, we won't even be worried about literal nodes and clusters\"],[0,[],0,\".\\\" â€” Executive, Application Infrastructure Startup\"]]],[1,\"h2\",[[0,[],0,\"Trend #4: Remote software development is here to stay\"]]],[10,4],[1,\"p\",[[0,[],0,\"In conducting our interviews, we were struck at how little COVID had affected the productivity of most software development teams. Perhaps we had a biased sample (we mostly spoke with startups), but the near-universal response was that the move to mandatory remote work had been relatively smooth. Many already had significant portions of their development teams working remotely, which helped to ease the transition.\"]]],[1,\"p\",[[0,[],0,\"Further, many had seen little disruption in their go-to-market efforts, given their focus on selling to developers who had themselves seen little interruption in their work.\"]]],[1,\"p\",[[0,[],0,\"If it is true that at least some teams and organizations can be nearly as productive working remotely as in-person, we may see some aspects of this new work paradigm stick around long after COVID subsides.\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"The shift to working remote is happening... It's month three of the new normal, and I think \"],[0,[1],1,\"there will be long-term changes as a result of this\"],[0,[],0,\".\\\" â€” Executive, Developer Tools Startup\"]]],[1,\"p\",[[0,[],0,\"Software developers who enjoy this new style of work may have other reasons to rejoice too. \"],[0,[11],1,\"As I've previously written about\"],[0,[],0,\", developers who work remotely earn up to 22% more than developers who don't. Of course, as with many aspects of a \"],[0,[12],1,\"forced\"],[0,[],0,\" transition to remote work, it's not clear whether this result applies when organizations had no choice about the move.\"]]],[1,\"h2\",[[0,[],0,\"Trend #5: The growth of Python, Spark, and Big Data\"]]],[10,5],[1,\"blockquote\",[[0,[],0,\"\\\"From our perspective, \"],[0,[1],1,\"Python is winning\"],[0,[],0,\", and we see that trend continuing.\\\" â€” Executive, Data Science Startup\"]]],[1,\"p\",[[0,[],0,\"Teams love Python for its ease-of-use and rapid time-to-value even for relatively non-technical individuals, who can quickly get up to speed with the language and generate value output:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"\"],[0,[1],1,\"Itâ€™s easy to learnâ€¦.people can learn it in 8 weeks and then be useful in a Fortune 1000 company\"],[0,[],0,\".\\\" â€” Executive, Data Science Startup\"]]],[1,\"p\",[[0,[],0,\"In addition to its user-friendliness, Python is revered for its ecosystem of packages for tackling difficult data science challenges and processing large data sets.\"]]],[1,\"p\",[[0,[],0,\"Speaking of large data sets, after much hype and suspense, Big Data has finally arrived and is a major driver of Python's massive popularity:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"Big Data is not just trendy anymore, but \"],[0,[1],1,\"itâ€™s actually happening now\"],[0,[],0,\". Not like 5 years ago when it was first hyped.\\\" â€” Executive, Data Science Startup\"]]],[1,\"p\",[[0,[],0,\"These large datasets are increasingly shifting to the cloud, where various storage offerings from S3 to Snowflake and more have proliferated, offering no shortage of options at competitive prices for various performance levels and data access frequencies. Leaders agree that Python is the preeminent language for handling data in the cloud:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"We are seeing a shift to the cloud, and \"],[0,[1],1,\"Python is dominant for data in the cloud\"],[0,[],0,\".\\\" â€” Executive, Data Science Startup\"]]],[1,\"p\",[[0,[],0,\"However, having been conceived well before the microservices revolution or the cloud generally, Python out-of-the-box does not come with much distributed computing functionality, though multiple vendors and technologies have arisen in recent years to cover this gap (\"],[0,[13],1,\"Dask\"],[0,[],0,\", \"],[0,[14],1,\"Ray\"],[0,[],0,\", etc.):\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"Python... is the fastest growing language and very popular, but \"],[0,[1],1,\"Python has no distributed functionality\"],[0,[],0,\".\\\" â€” Founder, Application Infrastructure Startup\"]]],[1,\"p\",[[0,[],0,\"Have no fear though, \"],[0,[15],1,\"Spark\"],[0,[],0,\" is here!\"]]],[1,\"p\",[[0,[],0,\"Spark bills itself as \\\"a unified analytics engine for large-scale data processing\\\", which in layman's terms mean it's very, very fast â€” fast enough to handle large datasets at high throughput. Spark is built from the ground up with distributed computing in mind, enabling it to take advantage of the advancements in cloud computing we discussed above. Spark also offers a number of high-level operators that enable interoperability with more popular languages like Python, SQL, Java and more.\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"Big data development cycles used to take forever, not fast enough for software developers. \"],[0,[1],1,\"Spark has meaningfully sped up the cycles\"],[0,[],0,\".\\\" â€” Founder, Data Science Startup\"]]],[1,\"h2\",[[0,[],0,\"Trend #6: Transfer learning from DevOps to data science and data engineering\"]]],[10,6],[1,\"p\",[[0,[],0,\"Historically, data science has not had the emphasis on fast iteration and development cycles that DevOps has had. When merged with traditional software engineering, this is less of a problem. But as data science as a practice gains clout, data science professionals are being carved out into their own teams. While this comes with certain benefits, it often comes at the cost of speed:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"Data science is now being carved out of development teams, and the data-related development cycles have elongated.\\\" â€” Founder, Data Science Startup\"]]],[1,\"p\",[[0,[],0,\"Additionally, data science is only becoming more complex. Data engineering has emerged as a key component of the overall data science lifecycle and, while less sexy than building and training the latest deep learning models, is often the phase that takes the longest in any given project. Many consider it to be an entirely different skill set from core data science. ETL (Extract, Transform, Load) tooling is just one example:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"Let's look at the problem of managing ETL pipelines. There are actually two pieces â€” the ETL pipeline that transforms the data, and the pipeline that manages the ETL pipeline itself.\\\" â€” Executive, Data Science Startup\"]]],[1,\"p\",[[0,[],0,\"DataOps and MLOps are the response to these complexities and speed bumps, bringing best practices from DevOps to the realm of data science and machine learning:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"DataOps and MLOps bring DevOps principles such as agile development to data and machine learning.\\\" â€” Founder, Data Science Startup\"]]],[1,\"p\",[[0,[],0,\"Instead of being crushed under the weight of increasingly intractable datasets and data engineering puzzles, DataOps and MLOps help data scientists and engineers better wrangle the data development process itself and achieve business outcomes with the same agility as traditional software development:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"We're big on DevOps and the empowerment of the data scientist and data engineer. \"],[0,[1],1,\"They should have control over the end-to-end process.\"],[0,[],0,\" Whoever is the creator is also the person whoâ€™s responsible for the ongoing success of the artifact.\\\" â€” Executive, Data Science Startup\"]]],[1,\"p\",[[0,[],0,\"DataOps and MLOps are opening new possibilities for data and model version control, machine learning feature engineering and storage, and more. Think unit or regression tests, except for datasets and machine learning models:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"In GitOps, the continuous integration / continuous delivery / continuous deployment pipeline checks the code and deploys the application to a staging environment, eventually ending up in production. Most tech-forward companies have adopted that now. \"],[0,[1],1,\"We want to bring that to the data scientist\"],[0,[],0,\".\\\" â€” Founder, Data Science Startup\"]]],[1,\"p\",[[0,[],0,\"The grand vision? Driving efficiencies that will enable teams and organizations to keep up with the growth of Big Data:\"]]],[1,\"blockquote\",[[0,[],0,\"\\\"\"],[0,[1],1,\"The trend toward DataOps will be big.\"],[0,[],0,\" It'll make organizations more efficient.\\\" â€” Executive, Data Science Startup\"]]],[1,\"h2\",[[0,[],0,\"Conclusion\"]]],[1,\"p\",[[0,[],0,\"Developers are increasingly considered one of the most important constituencies within organizations. Organizations both old and young are generating and consuming greater amounts of software, and developers remain the basic economic unit of software production.\"]]],[1,\"p\",[[0,[],0,\"As the scarce input of the software production function, software engineers don't come cheap, and it's therefore critical to maximize their productivity and output. As software grows only more powerful, valuable, and essential, anything that makes software engineers more productive will be similarly potent and relevant.\"]]],[1,\"p\",[[0,[],0,\"Be informed of our next publication in this series, the \"],[0,[1],1,\"top strategic priorities of developer productivity companies\"],[0,[],0,\", by entering your email below:\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p>Developer productivity is undergoing a tectonic shift. New software development paradigms and tooling have accelerated the pace and productivity of modern software teams, quickening the \"shipping speed\" of new software.</p><p>To dissect these trends, my good friend and colleague, <a href=\"https://www.linkedin.com/in/clio-smurro-31967b9/\">Clio Smurro</a>, and I interviewed founders and executives at next-generation software and infrastructure startups pushing the developer productivity frontier to get their thoughts and insights. They shared their views on:</p><ul><li><strong>major industry trends (you are here)</strong>,</li><li><a href=\"__GHOST_URL__/developer-productivity-strategic-priorities/\">top strategic priorities</a>, and</li><li><a href=\"__GHOST_URL__/developer-productivity-challenges/\">biggest challenges and pain points</a></li></ul><p>In this first chapter, we share our findings on the important trends shaping developer productivity, including:</p><ul><li>Trend #1: <a href=\"__GHOST_URL__/developer-productivity-trends/#trend-1-developers-have-the-power-and-the-purse\">Developers have the power... and the purse</a></li><li>Trend #2: <a href=\"__GHOST_URL__/developer-productivity-trends/#trend-2-application-security-is-shifting-left\">Application security is \"shifting left\"</a></li><li>Trend #3: <a href=\"__GHOST_URL__/developer-productivity-trends/#trend-3-the-distributed-cloud-is-having-its-covid-moment\">The distributed cloud is having its COVID moment</a></li><li>Trend #4: <a href=\"__GHOST_URL__/developer-productivity-trends/#trend-4-remote-software-development-is-here-to-stay\">Remote software development is here to stay</a></li><li>Trend #5: <a href=\"__GHOST_URL__/developer-productivity-trends/#trend-5-the-growth-of-python-spark-and-big-data\">The growth of Python, Spark, and Big Data</a></li><li>Trend #6: <a href=\"__GHOST_URL__/developer-productivity-trends/#trend-6-transfer-learning-from-devops-to-data-science-and-data-engineering\">Transfer learning from DevOps to data science and data engineering</a></li></ul><p>Want to be notified when we publish part two of our findings? Subscribe below, and we'll also send you a nicely formatted PDF of our research!</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive a report with the full results</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Your Email Address\" id=\"mce-EMAIL\" required>\n<input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Six Trends Shaping Developer Productivity\">\n<input type=\"checkbox\" value=\"4\" name=\"group[78549][4]\" id=\"mce-group[78549]-78549-0\" style=\"display:none\" checked>\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Send Report âš¡</span></button>\n</form>\n            </section><!--kg-card-end: html--><h2 id=\"trend-1-developers-have-the-power-and-the-purse\">Trend #1: Developers have the power... and the purse</h2><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/07/dev-power.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><blockquote>\"<strong>Buying products that save developer time is no longer an argument you need to explain</strong>. People get it.\" â€” Executive, Developer Tools Startup</blockquote><p>Software engineers continue to be a scarce resource in most organizations. Companies are increasingly focused on enhancing the productivity of developers. In doing so, power and autonomy flow to developers, and the dollars are quick to follow.</p><p>Vendors are reflecting this new reality in their go-to-market positioning and sales efforts:</p><blockquote>\"In our sales conversation, <strong>we frame things in terms of productivity and developer time saved</strong>... You're comparing the cost of the product against engineering time saved.\" â€” Executive, Developer Tools Startup</blockquote><p>Even before sales gets involved, developers are adopting software they need to get their work done on their own, often without the involvement or permission of procurement or upper management. Developers know what they want, the tools they love, and the technologies that enable their ideal architectures and designs.</p><blockquote>\"<strong>We're seeing lots of self-serve.</strong> Developers are getting more autonomy as buyers. <strong>Most of our sign-ups are via bottoms-up</strong> â€” people signing themselves up, after which our sales team eventually reaches out to them.\" â€” Executive, Developer Tools Startup</blockquote><p>Unlike many other domains of enterprise software, where features are built to appease higher and higher levels of management rather than end users themselves, the core developer experience remains hugely important. If anything, analogous trends in observability and monitoring are developing in a symbiotic rather than antagonistic fashion with developer productivity.</p><p>As engineering teams scale, the need for agile workflows becomes apparent, drawing many toward the burgeoning DevOps paradigm and its associated ecosystem of tools. DevOps enables ongoing operation of and rapid iteration on software via Git-based version control, continuous integration, continuous deployment, security testing, and more.</p><blockquote>\"DevOps hasnâ€™t been around for long, but more companies are realizing the need/value for it.\" â€” Developer Advocate, Application Infrastructure Startup</blockquote><p>To the extent that vendors are attempting to appease management, they are doing so by building unified product ecosystems. These enable customers to purchase multiple component tools of the overall software development lifecycle in a single package. While these do carry some benefits for end users, most still prefer to purchase the best solution for each task, again reflecting in influence and clout of individual software developers:</p><blockquote>\"GitHub, Atlassian, Microsoft... <strong>Theyâ€™re trying to get everyone to adopt a unified tool system.</strong> But most people still go with best-of-breed, as far as tools go. The idea though is that some people will eventually go with more of a â€œyou canâ€™t get fired for buying IBMâ€ approach, where you buy everything from a single vendor.\" â€” Executive, Application Security Startup</blockquote><h2 id=\"trend-2-application-security-is-shifting-left\">Trend #2: Application security is \"shifting left\"</h2><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/07/app-sec-left.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>In past eras, application security was oftentimes dealt with after the fact. Software would be largely complete by the time security analysts had a chance to examine and poke holes in its defenses. In main cases, this might not even happen until after code is already running in production, where any vulnerabilities may have already been exploited by nefarious actors:</p><blockquote>\"Once the code is built, the artifact goes into a registry. The security team wants to know...<strong>what are the risks? Is this meeting my policies?</strong>\" â€” Executive, Application Security Startup</blockquote><p>No longer. Application security is now a tier one priority in many organizations:</p><blockquote>\"Security used to be an afterthought. In the past, someone would write code, someone would deploy code, and then someone else would handle security. <strong>That boundary doesnâ€™t exist anymore.</strong>\" â€” Executive, Developer Tools Startup</blockquote><p>Spurred by the rash of high-profile security incidents and gaffes at major corporations around the world, organizations are challenging their development teams to take on more of the security burden upfront, well before software is even ready for production or artifacts have been built. \"DevSecOps\" is born:</p><blockquote>\"<strong>Shifting left means move everything towards the developer.</strong> It doesn't have to be a security person's responsibility to ensure secrets are secure â€” the developer can do this now too. The more tooling you give, earlier on in the process of writing the application, the easier this is.\" â€” Director, Developer Tools Startup</blockquote><p>Security vendors continue to sell mostly to security teams but realize their tools are increasingly landing directly in the hands of developers themselves:</p><blockquote>\"We don't sell to developers, we sell to security teams...but at the end of the day, <strong>itâ€™s the developers who need to take more upfront responsibility for security.</strong>\" â€” Executive, Application Security Startup</blockquote><p>It's easy to think these new tools are only valuable to large enterprises paranoid about breaches, hacks, and other threats to application security. Not true, say some of the security leaders we spoke to, who emphasized that the heightened focus on security is reverberating through the software development industry, at both large organization and small:</p><blockquote>\"These security initiatives are not just for big companies...<strong>every company needs them</strong>.\" â€” Executive, Developer Tools Startup</blockquote><p>Then there's the concept of \"low trust\" or even \"no trust\", where applications do not give each other the benefit of the doubt and every app must prove its credentials in order to send and receive requests and data from other apps and microservices. This adds new complexity to software development, heightening the important of thinking through security implications early on in development:</p><blockquote>\"In low trust or no trust environments, how do you make sure applications can talk to each other?\" â€” Executive, Developer Tools Startup</blockquote><p>These complexities are inevitable, but vendors also know there are limits to developer patience. They are keen to insert security tooling into workflows as seamlessly as possible. Usability drives usage â€” if a tool is to difficult to use or increases cycle times too dramatically, developers won't use it, defeating the purpose entirely:</p><blockquote>\"DevOps folks are often not security experts. <strong>Theyâ€™re looking for usability.</strong> How easy is this to access? Does it fit in our existing workflows? Can it plug into <a href=\"https://www.jenkins.io/\">Jenkins</a>? I don't want my developers having to use a new tool.\" â€” Executive, Application Security Startup</blockquote><p>As development and security increasingly merge, buying patterns and processes will incorporate the needs of both stakeholders, and vendors will need to adjust their tactics appropriately:</p><blockquote>\"<strong>DevOps needs to like it, SecOps needs to buy it</strong>. Both are involved in the purchase process.\" â€” Executive, Application Security Startup</blockquote><h2 id=\"trend-3-the-distributed-cloud-is-having-its-covid-moment\">Trend #3: The distributed cloud is having its COVID moment</h2><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/07/distributed-cloud.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Demand for distributed computing is growing and that demand has only surged in the COVID era.</p><blockquote>\"<strong>COVID has caused a 2-3 year acceleration in everyone's journey to the cloud.</strong> The companies who have survived and thrived are the ones which evolved sooner.\" â€” Executive, Developer Tools Startup</blockquote><p>Elastic scaling of compute, storage, and other resources is important in a divergent set of scenarios. Some businesses (Zoom, Fastly, Amazon, Instacart, etc.) have seen demand for their services surge, requiring rapid scale up of existing deployments, assisted by prescient decisions to factor applications into microservices.</p><p>On the other hand, certain companies have seen business dry up overnight. This makes the ability to scale down equally important, allowing costs to flex proportionately with revenue:</p><blockquote>\"Do only what's needed. That's key for dynamic shifts in needs. <strong>You need to design software for scaling up, but the infrastructure also needs to be able to scale down</strong>.\" â€” Executive, Developer Tools Startup</blockquote><p>But what if your business runs on legacy applications or infrastructure technologies? You're in a much tougher position, which is prompting many organizations to ask the question â€” can you accelerate developer productivity within legacy application development?</p><blockquote>There's a lot of legacy .NET applications from 10 years ago that weren't originally built with containers. Organizations want to get those into containers. A question people are asking â€” <strong>can you get developer productivity with legacy applications too?</strong> â€” Executive, Application Security Startup</blockquote><p>Increasingly, the answer is â€” yes. Legacy applications are being refactored from monolithic to microservices-based architectures, leveraging the power of containers and other associated advancements:</p><blockquote>\"We are seeing a movement from cloud \"greenfield\", only using the cloud for new applications, to \"lift and shift\", getting legacy applications into containers and into the cloud. We've started working with Windows-based containers.\" â€” Executive, Application Security Startup</blockquote><p>While old-school organizations and engineering teams play catch up, next-gen startups and technology companies aren't waiting around.</p><blockquote>\"<strong>The biggest trend right now is the move to serverless</strong> â€” functions as a service, hiding more complexity from developers. Serverless is a way for developers to just focus on stateless applications, to just focus on what they use most directly.\" â€” Executive, Application Infrastructure Startup</blockquote><p>Serverless has emerged as a major trend. Leveraging the \"infinite\" scalability of the major cloud providers, serverless promises to decompose applications into a series of function calls â€” without regard to the underlying infrastructure.</p><p>While the cloud providers have always had a clear incentive to push such a regime, it seems like development teams themselves are warming up to the idea, thought it's full realization is still years away:</p><blockquote>\"At our company, we talk about nodes and clusters today. We think of elastic pools of storage and compute that you can just use. But, <strong>a few years from now, we won't even be worried about literal nodes and clusters</strong>.\" â€” Executive, Application Infrastructure Startup</blockquote><h2 id=\"trend-4-remote-software-development-is-here-to-stay\">Trend #4: Remote software development is here to stay</h2><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/07/remote-development.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>In conducting our interviews, we were struck at how little COVID had affected the productivity of most software development teams. Perhaps we had a biased sample (we mostly spoke with startups), but the near-universal response was that the move to mandatory remote work had been relatively smooth. Many already had significant portions of their development teams working remotely, which helped to ease the transition.</p><p>Further, many had seen little disruption in their go-to-market efforts, given their focus on selling to developers who had themselves seen little interruption in their work.</p><p>If it is true that at least some teams and organizations can be nearly as productive working remotely as in-person, we may see some aspects of this new work paradigm stick around long after COVID subsides.</p><blockquote>\"The shift to working remote is happening... It's month three of the new normal, and I think <strong>there will be long-term changes as a result of this</strong>.\" â€” Executive, Developer Tools Startup</blockquote><p>Software developers who enjoy this new style of work may have other reasons to rejoice too. <a href=\"__GHOST_URL__/remote-software-developers-earn-more/\">As I've previously written about</a>, developers who work remotely earn up to 22% more than developers who don't. Of course, as with many aspects of a <em>forced</em> transition to remote work, it's not clear whether this result applies when organizations had no choice about the move.</p><h2 id=\"trend-5-the-growth-of-python-spark-and-big-data\">Trend #5: The growth of Python, Spark, and Big Data</h2><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/07/python-spark-big-data-growth.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><blockquote>\"From our perspective, <strong>Python is winning</strong>, and we see that trend continuing.\" â€” Executive, Data Science Startup</blockquote><p>Teams love Python for its ease-of-use and rapid time-to-value even for relatively non-technical individuals, who can quickly get up to speed with the language and generate value output:</p><blockquote>\"<strong>Itâ€™s easy to learnâ€¦.people can learn it in 8 weeks and then be useful in a Fortune 1000 company</strong>.\" â€” Executive, Data Science Startup</blockquote><p>In addition to its user-friendliness, Python is revered for its ecosystem of packages for tackling difficult data science challenges and processing large data sets.</p><p>Speaking of large data sets, after much hype and suspense, Big Data has finally arrived and is a major driver of Python's massive popularity:</p><blockquote>\"Big Data is not just trendy anymore, but <strong>itâ€™s actually happening now</strong>. Not like 5 years ago when it was first hyped.\" â€” Executive, Data Science Startup</blockquote><p>These large datasets are increasingly shifting to the cloud, where various storage offerings from S3 to Snowflake and more have proliferated, offering no shortage of options at competitive prices for various performance levels and data access frequencies. Leaders agree that Python is the preeminent language for handling data in the cloud:</p><blockquote>\"We are seeing a shift to the cloud, and <strong>Python is dominant for data in the cloud</strong>.\" â€” Executive, Data Science Startup</blockquote><p>However, having been conceived well before the microservices revolution or the cloud generally, Python out-of-the-box does not come with much distributed computing functionality, though multiple vendors and technologies have arisen in recent years to cover this gap (<a href=\"https://dask.org/\">Dask</a>, <a href=\"https://ray.io/\">Ray</a>, etc.):</p><blockquote>\"Python... is the fastest growing language and very popular, but <strong>Python has no distributed functionality</strong>.\" â€” Founder, Application Infrastructure Startup</blockquote><p>Have no fear though, <a href=\"https://spark.apache.org/\">Spark</a> is here!</p><p>Spark bills itself as \"a unified analytics engine for large-scale data processing\", which in layman's terms mean it's very, very fast â€” fast enough to handle large datasets at high throughput. Spark is built from the ground up with distributed computing in mind, enabling it to take advantage of the advancements in cloud computing we discussed above. Spark also offers a number of high-level operators that enable interoperability with more popular languages like Python, SQL, Java and more.</p><blockquote>\"Big data development cycles used to take forever, not fast enough for software developers. <strong>Spark has meaningfully sped up the cycles</strong>.\" â€” Founder, Data Science Startup</blockquote><h2 id=\"trend-6-transfer-learning-from-devops-to-data-science-and-data-engineering\">Trend #6: Transfer learning from DevOps to data science and data engineering</h2><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2020/07/devops-dataops-mlops.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Historically, data science has not had the emphasis on fast iteration and development cycles that DevOps has had. When merged with traditional software engineering, this is less of a problem. But as data science as a practice gains clout, data science professionals are being carved out into their own teams. While this comes with certain benefits, it often comes at the cost of speed:</p><blockquote>\"Data science is now being carved out of development teams, and the data-related development cycles have elongated.\" â€” Founder, Data Science Startup</blockquote><p>Additionally, data science is only becoming more complex. Data engineering has emerged as a key component of the overall data science lifecycle and, while less sexy than building and training the latest deep learning models, is often the phase that takes the longest in any given project. Many consider it to be an entirely different skill set from core data science. ETL (Extract, Transform, Load) tooling is just one example:</p><blockquote>\"Let's look at the problem of managing ETL pipelines. There are actually two pieces â€” the ETL pipeline that transforms the data, and the pipeline that manages the ETL pipeline itself.\" â€” Executive, Data Science Startup</blockquote><p>DataOps and MLOps are the response to these complexities and speed bumps, bringing best practices from DevOps to the realm of data science and machine learning:</p><blockquote>\"DataOps and MLOps bring DevOps principles such as agile development to data and machine learning.\" â€” Founder, Data Science Startup</blockquote><p>Instead of being crushed under the weight of increasingly intractable datasets and data engineering puzzles, DataOps and MLOps help data scientists and engineers better wrangle the data development process itself and achieve business outcomes with the same agility as traditional software development:</p><blockquote>\"We're big on DevOps and the empowerment of the data scientist and data engineer. <strong>They should have control over the end-to-end process.</strong> Whoever is the creator is also the person whoâ€™s responsible for the ongoing success of the artifact.\" â€” Executive, Data Science Startup</blockquote><p>DataOps and MLOps are opening new possibilities for data and model version control, machine learning feature engineering and storage, and more. Think unit or regression tests, except for datasets and machine learning models:</p><blockquote>\"In GitOps, the continuous integration / continuous delivery / continuous deployment pipeline checks the code and deploys the application to a staging environment, eventually ending up in production. Most tech-forward companies have adopted that now. <strong>We want to bring that to the data scientist</strong>.\" â€” Founder, Data Science Startup</blockquote><p>The grand vision? Driving efficiencies that will enable teams and organizations to keep up with the growth of Big Data:</p><blockquote>\"<strong>The trend toward DataOps will be big.</strong> It'll make organizations more efficient.\" â€” Executive, Data Science Startup</blockquote><h2 id=\"conclusion\">Conclusion</h2><p>Developers are increasingly considered one of the most important constituencies within organizations. Organizations both old and young are generating and consuming greater amounts of software, and developers remain the basic economic unit of software production.</p><p>As the scarce input of the software production function, software engineers don't come cheap, and it's therefore critical to maximize their productivity and output. As software grows only more powerful, valuable, and essential, anything that makes software engineers more productive will be similarly potent and relevant.</p><p>Be informed of our next publication in this series, the <strong>top strategic priorities of developer productivity companies</strong>, by entering your email below:</p>","comment_id":"5f0d75ab2fc931237d113877","plaintext":"Developer productivity is undergoing a tectonic shift. New software development\nparadigms and tooling have accelerated the pace and productivity of modern\nsoftware teams, quickening the \"shipping speed\" of new software.\n\nTo dissect these trends, my good friend and colleague, Clio Smurro\n[https://www.linkedin.com/in/clio-smurro-31967b9/], and I interviewed founders\nand executives at next-generation software and infrastructure startups pushing\nthe developer productivity frontier to get their thoughts and insights. They\nshared their views on:\n\n * major industry trends (you are here),\n * top strategic priorities\n   [__GHOST_URL__/developer-productivity-strategic-priorities/], and\n * biggest challenges and pain points\n   [__GHOST_URL__/developer-productivity-challenges/]\n\nIn this first chapter, we share our findings on the important trends shaping\ndeveloper productivity, including:\n\n * Trend #1: Developers have the power... and the purse\n   [__GHOST_URL__/developer-productivity-trends/#trend-1-developers-have-the-power-and-the-purse]\n * Trend #2: Application security is \"shifting left\"\n   [__GHOST_URL__/developer-productivity-trends/#trend-2-application-security-is-shifting-left]\n * Trend #3: The distributed cloud is having its COVID moment\n   [__GHOST_URL__/developer-productivity-trends/#trend-3-the-distributed-cloud-is-having-its-covid-moment]\n * Trend #4: Remote software development is here to stay\n   [__GHOST_URL__/developer-productivity-trends/#trend-4-remote-software-development-is-here-to-stay]\n * Trend #5: The growth of Python, Spark, and Big Data\n   [__GHOST_URL__/developer-productivity-trends/#trend-5-the-growth-of-python-spark-and-big-data]\n * Trend #6: Transfer learning from DevOps to data science and data engineering\n   [__GHOST_URL__/developer-productivity-trends/#trend-6-transfer-learning-from-devops-to-data-science-and-data-engineering]\n\nWant to be notified when we publish part two of our findings? Subscribe below,\nand we'll also send you a nicely formatted PDF of our research!\n\nReceive a report with the full results\n\n\nSend Report âš¡ Trend #1: Developers have the power... and the purse\n> \"Buying products that save developer time is no longer an argument you need to\nexplain. People get it.\" â€” Executive, Developer Tools Startup\nSoftware engineers continue to be a scarce resource in most organizations.\nCompanies are increasingly focused on enhancing the productivity of developers.\nIn doing so, power and autonomy flow to developers, and the dollars are quick to\nfollow.\n\nVendors are reflecting this new reality in their go-to-market positioning and\nsales efforts:\n\n> \"In our sales conversation, we frame things in terms of productivity and\ndeveloper time saved... You're comparing the cost of the product against\nengineering time saved.\" â€” Executive, Developer Tools Startup\nEven before sales gets involved, developers are adopting software they need to\nget their work done on their own, often without the involvement or permission of\nprocurement or upper management. Developers know what they want, the tools they\nlove, and the technologies that enable their ideal architectures and designs.\n\n> \"We're seeing lots of self-serve. Developers are getting more autonomy as\nbuyers. Most of our sign-ups are via bottoms-up â€” people signing themselves up,\nafter which our sales team eventually reaches out to them.\" â€” Executive,\nDeveloper Tools Startup\nUnlike many other domains of enterprise software, where features are built to\nappease higher and higher levels of management rather than end users themselves,\nthe core developer experience remains hugely important. If anything, analogous\ntrends in observability and monitoring are developing in a symbiotic rather than\nantagonistic fashion with developer productivity.\n\nAs engineering teams scale, the need for agile workflows becomes apparent,\ndrawing many toward the burgeoning DevOps paradigm and its associated ecosystem\nof tools. DevOps enables ongoing operation of and rapid iteration on software\nvia Git-based version control, continuous integration, continuous deployment,\nsecurity testing, and more.\n\n> \"DevOps hasnâ€™t been around for long, but more companies are realizing the\nneed/value for it.\" â€” Developer Advocate, Application Infrastructure Startup\nTo the extent that vendors are attempting to appease management, they are doing\nso by building unified product ecosystems. These enable customers to purchase\nmultiple component tools of the overall software development lifecycle in a\nsingle package. While these do carry some benefits for end users, most still\nprefer to purchase the best solution for each task, again reflecting in\ninfluence and clout of individual software developers:\n\n> \"GitHub, Atlassian, Microsoft... Theyâ€™re trying to get everyone to adopt a\nunified tool system. But most people still go with best-of-breed, as far as\ntools go. The idea though is that some people will eventually go with more of a\nâ€œyou canâ€™t get fired for buying IBMâ€ approach, where you buy everything from a\nsingle vendor.\" â€” Executive, Application Security Startup\nTrend #2: Application security is \"shifting left\"\nIn past eras, application security was oftentimes dealt with after the fact.\nSoftware would be largely complete by the time security analysts had a chance to\nexamine and poke holes in its defenses. In main cases, this might not even\nhappen until after code is already running in production, where any\nvulnerabilities may have already been exploited by nefarious actors:\n\n> \"Once the code is built, the artifact goes into a registry. The security team\nwants to know...what are the risks? Is this meeting my policies?\" â€” Executive,\nApplication Security Startup\nNo longer. Application security is now a tier one priority in many\norganizations:\n\n> \"Security used to be an afterthought. In the past, someone would write code,\nsomeone would deploy code, and then someone else would handle security. That\nboundary doesnâ€™t exist anymore.\" â€” Executive, Developer Tools Startup\nSpurred by the rash of high-profile security incidents and gaffes at major\ncorporations around the world, organizations are challenging their development\nteams to take on more of the security burden upfront, well before software is\neven ready for production or artifacts have been built. \"DevSecOps\" is born:\n\n> \"Shifting left means move everything towards the developer. It doesn't have to\nbe a security person's responsibility to ensure secrets are secure â€” the\ndeveloper can do this now too. The more tooling you give, earlier on in the\nprocess of writing the application, the easier this is.\" â€” Director, Developer\nTools Startup\nSecurity vendors continue to sell mostly to security teams but realize their\ntools are increasingly landing directly in the hands of developers themselves:\n\n> \"We don't sell to developers, we sell to security teams...but at the end of the\nday, itâ€™s the developers who need to take more upfront responsibility for\nsecurity.\" â€” Executive, Application Security Startup\nIt's easy to think these new tools are only valuable to large enterprises\nparanoid about breaches, hacks, and other threats to application security. Not\ntrue, say some of the security leaders we spoke to, who emphasized that the\nheightened focus on security is reverberating through the software development\nindustry, at both large organization and small:\n\n> \"These security initiatives are not just for big companies...every company needs\nthem.\" â€” Executive, Developer Tools Startup\nThen there's the concept of \"low trust\" or even \"no trust\", where applications\ndo not give each other the benefit of the doubt and every app must prove its\ncredentials in order to send and receive requests and data from other apps and\nmicroservices. This adds new complexity to software development, heightening the\nimportant of thinking through security implications early on in development:\n\n> \"In low trust or no trust environments, how do you make sure applications can\ntalk to each other?\" â€” Executive, Developer Tools Startup\nThese complexities are inevitable, but vendors also know there are limits to\ndeveloper patience. They are keen to insert security tooling into workflows as\nseamlessly as possible. Usability drives usage â€” if a tool is to difficult to\nuse or increases cycle times too dramatically, developers won't use it,\ndefeating the purpose entirely:\n\n> \"DevOps folks are often not security experts. Theyâ€™re looking for usability. How\neasy is this to access? Does it fit in our existing workflows? Can it plug into \nJenkins [https://www.jenkins.io/]? I don't want my developers having to use a\nnew tool.\" â€” Executive, Application Security Startup\nAs development and security increasingly merge, buying patterns and processes\nwill incorporate the needs of both stakeholders, and vendors will need to adjust\ntheir tactics appropriately:\n\n> \"DevOps needs to like it, SecOps needs to buy it. Both are involved in the\npurchase process.\" â€” Executive, Application Security Startup\nTrend #3: The distributed cloud is having its COVID moment\nDemand for distributed computing is growing and that demand has only surged in\nthe COVID era.\n\n> \"COVID has caused a 2-3 year acceleration in everyone's journey to the cloud. \nThe companies who have survived and thrived are the ones which evolved sooner.\"\nâ€” Executive, Developer Tools Startup\nElastic scaling of compute, storage, and other resources is important in a\ndivergent set of scenarios. Some businesses (Zoom, Fastly, Amazon, Instacart,\netc.) have seen demand for their services surge, requiring rapid scale up of\nexisting deployments, assisted by prescient decisions to factor applications\ninto microservices.\n\nOn the other hand, certain companies have seen business dry up overnight. This\nmakes the ability to scale down equally important, allowing costs to flex\nproportionately with revenue:\n\n> \"Do only what's needed. That's key for dynamic shifts in needs. You need to\ndesign software for scaling up, but the infrastructure also needs to be able to\nscale down.\" â€” Executive, Developer Tools Startup\nBut what if your business runs on legacy applications or infrastructure\ntechnologies? You're in a much tougher position, which is prompting many\norganizations to ask the question â€” can you accelerate developer productivity\nwithin legacy application development?\n\n> There's a lot of legacy .NET applications from 10 years ago that weren't\noriginally built with containers. Organizations want to get those into\ncontainers. A question people are asking â€” can you get developer productivity\nwith legacy applications too? â€” Executive, Application Security Startup\nIncreasingly, the answer is â€” yes. Legacy applications are being refactored from\nmonolithic to microservices-based architectures, leveraging the power of\ncontainers and other associated advancements:\n\n> \"We are seeing a movement from cloud \"greenfield\", only using the cloud for new\napplications, to \"lift and shift\", getting legacy applications into containers\nand into the cloud. We've started working with Windows-based containers.\" â€”\nExecutive, Application Security Startup\nWhile old-school organizations and engineering teams play catch up, next-gen\nstartups and technology companies aren't waiting around.\n\n> \"The biggest trend right now is the move to serverless â€” functions as a service,\nhiding more complexity from developers. Serverless is a way for developers to\njust focus on stateless applications, to just focus on what they use most\ndirectly.\" â€” Executive, Application Infrastructure Startup\nServerless has emerged as a major trend. Leveraging the \"infinite\" scalability\nof the major cloud providers, serverless promises to decompose applications into\na series of function calls â€” without regard to the underlying infrastructure.\n\nWhile the cloud providers have always had a clear incentive to push such a\nregime, it seems like development teams themselves are warming up to the idea,\nthought it's full realization is still years away:\n\n> \"At our company, we talk about nodes and clusters today. We think of elastic\npools of storage and compute that you can just use. But, a few years from now,\nwe won't even be worried about literal nodes and clusters.\" â€” Executive,\nApplication Infrastructure Startup\nTrend #4: Remote software development is here to stay\nIn conducting our interviews, we were struck at how little COVID had affected\nthe productivity of most software development teams. Perhaps we had a biased\nsample (we mostly spoke with startups), but the near-universal response was that\nthe move to mandatory remote work had been relatively smooth. Many already had\nsignificant portions of their development teams working remotely, which helped\nto ease the transition.\n\nFurther, many had seen little disruption in their go-to-market efforts, given\ntheir focus on selling to developers who had themselves seen little interruption\nin their work.\n\nIf it is true that at least some teams and organizations can be nearly as\nproductive working remotely as in-person, we may see some aspects of this new\nwork paradigm stick around long after COVID subsides.\n\n> \"The shift to working remote is happening... It's month three of the new normal,\nand I think there will be long-term changes as a result of this.\" â€” Executive,\nDeveloper Tools Startup\nSoftware developers who enjoy this new style of work may have other reasons to\nrejoice too. As I've previously written about\n[__GHOST_URL__/remote-software-developers-earn-more/], developers who work\nremotely earn up to 22% more than developers who don't. Of course, as with many\naspects of a forced transition to remote work, it's not clear whether this\nresult applies when organizations had no choice about the move.\n\nTrend #5: The growth of Python, Spark, and Big Data\n> \"From our perspective, Python is winning, and we see that trend continuing.\" â€”\nExecutive, Data Science Startup\nTeams love Python for its ease-of-use and rapid time-to-value even for\nrelatively non-technical individuals, who can quickly get up to speed with the\nlanguage and generate value output:\n\n> \"Itâ€™s easy to learnâ€¦.people can learn it in 8 weeks and then be useful in a\nFortune 1000 company.\" â€” Executive, Data Science Startup\nIn addition to its user-friendliness, Python is revered for its ecosystem of\npackages for tackling difficult data science challenges and processing large\ndata sets.\n\nSpeaking of large data sets, after much hype and suspense, Big Data has finally\narrived and is a major driver of Python's massive popularity:\n\n> \"Big Data is not just trendy anymore, but itâ€™s actually happening now. Not like\n5 years ago when it was first hyped.\" â€” Executive, Data Science Startup\nThese large datasets are increasingly shifting to the cloud, where various\nstorage offerings from S3 to Snowflake and more have proliferated, offering no\nshortage of options at competitive prices for various performance levels and\ndata access frequencies. Leaders agree that Python is the preeminent language\nfor handling data in the cloud:\n\n> \"We are seeing a shift to the cloud, and Python is dominant for data in the\ncloud.\" â€” Executive, Data Science Startup\nHowever, having been conceived well before the microservices revolution or the\ncloud generally, Python out-of-the-box does not come with much distributed\ncomputing functionality, though multiple vendors and technologies have arisen in\nrecent years to cover this gap (Dask [https://dask.org/], Ray [https://ray.io/],\netc.):\n\n> \"Python... is the fastest growing language and very popular, but Python has no\ndistributed functionality.\" â€” Founder, Application Infrastructure Startup\nHave no fear though, Spark [https://spark.apache.org/] is here!\n\nSpark bills itself as \"a unified analytics engine for large-scale data\nprocessing\", which in layman's terms mean it's very, very fast â€” fast enough to\nhandle large datasets at high throughput. Spark is built from the ground up with\ndistributed computing in mind, enabling it to take advantage of the advancements\nin cloud computing we discussed above. Spark also offers a number of high-level\noperators that enable interoperability with more popular languages like Python,\nSQL, Java and more.\n\n> \"Big data development cycles used to take forever, not fast enough for software\ndevelopers. Spark has meaningfully sped up the cycles.\" â€” Founder, Data Science\nStartup\nTrend #6: Transfer learning from DevOps to data science and data engineering\nHistorically, data science has not had the emphasis on fast iteration and\ndevelopment cycles that DevOps has had. When merged with traditional software\nengineering, this is less of a problem. But as data science as a practice gains\nclout, data science professionals are being carved out into their own teams.\nWhile this comes with certain benefits, it often comes at the cost of speed:\n\n> \"Data science is now being carved out of development teams, and the data-related\ndevelopment cycles have elongated.\" â€” Founder, Data Science Startup\nAdditionally, data science is only becoming more complex. Data engineering has\nemerged as a key component of the overall data science lifecycle and, while less\nsexy than building and training the latest deep learning models, is often the\nphase that takes the longest in any given project. Many consider it to be an\nentirely different skill set from core data science. ETL (Extract, Transform,\nLoad) tooling is just one example:\n\n> \"Let's look at the problem of managing ETL pipelines. There are actually two\npieces â€” the ETL pipeline that transforms the data, and the pipeline that\nmanages the ETL pipeline itself.\" â€” Executive, Data Science Startup\nDataOps and MLOps are the response to these complexities and speed bumps,\nbringing best practices from DevOps to the realm of data science and machine\nlearning:\n\n> \"DataOps and MLOps bring DevOps principles such as agile development to data and\nmachine learning.\" â€” Founder, Data Science Startup\nInstead of being crushed under the weight of increasingly intractable datasets\nand data engineering puzzles, DataOps and MLOps help data scientists and\nengineers better wrangle the data development process itself and achieve\nbusiness outcomes with the same agility as traditional software development:\n\n> \"We're big on DevOps and the empowerment of the data scientist and data\nengineer. They should have control over the end-to-end process. Whoever is the\ncreator is also the person whoâ€™s responsible for the ongoing success of the\nartifact.\" â€” Executive, Data Science Startup\nDataOps and MLOps are opening new possibilities for data and model version\ncontrol, machine learning feature engineering and storage, and more. Think unit\nor regression tests, except for datasets and machine learning models:\n\n> \"In GitOps, the continuous integration / continuous delivery / continuous\ndeployment pipeline checks the code and deploys the application to a staging\nenvironment, eventually ending up in production. Most tech-forward companies\nhave adopted that now. We want to bring that to the data scientist.\" â€” Founder,\nData Science Startup\nThe grand vision? Driving efficiencies that will enable teams and organizations\nto keep up with the growth of Big Data:\n\n> \"The trend toward DataOps will be big. It'll make organizations more efficient.\"\nâ€” Executive, Data Science Startup\nConclusion\nDevelopers are increasingly considered one of the most important constituencies\nwithin organizations. Organizations both old and young are generating and\nconsuming greater amounts of software, and developers remain the basic economic\nunit of software production.\n\nAs the scarce input of the software production function, software engineers\ndon't come cheap, and it's therefore critical to maximize their productivity and\noutput. As software grows only more powerful, valuable, and essential, anything\nthat makes software engineers more productive will be similarly potent and\nrelevant.\n\nBe informed of our next publication in this series, the top strategic priorities\nof developer productivity companies, by entering your email below:","feature_image":"__GHOST_URL__/content/images/2020/07/image-20200714021923342.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-07-14T09:06:51.000Z","updated_at":"2021-03-11T08:43:05.000Z","published_at":"2020-07-14T19:20:44.000Z","custom_excerpt":"We interviewed developer productivity leaders. Here's what they said.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5f3bec2d17b26d3ef80d621b","uuid":"663a4e09-d4e2-43f8-8cab-d9852e030107","title":"Top Three Strategic Priorities of Developer Productivity Startups","slug":"developer-productivity-strategic-priorities","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive a report with the full results</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Your Email Address\\\" id=\\\"mce-EMAIL\\\" required>\\n<input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Top Three Strategic Priorities of Developer Productivity Startups\\\">\\n<input type=\\\"checkbox\\\" value=\\\"8\\\" name=\\\"group[78589][8]\\\" id=\\\"mce-group[78589]-78589-0\\\" style=\\\"display:none\\\" checked>\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Send Report âš¡</span></button>\\n</form>\\n            </section>\"}]],\"markups\":[[\"a\",[\"href\",\"https://www.linkedin.com/in/clio-smurro-31967b9/\"]],[\"a\",[\"href\",\"__GHOST_URL__/developer-productivity-trends/\"]],[\"strong\"],[\"a\",[\"href\",\"__GHOST_URL__/developer-productivity-challenges/\"]],[\"a\",[\"href\",\"#priority-1-product-go-to-market-fit\"]],[\"a\",[\"href\",\"#priority-2-sow-first-reap-later\"]],[\"a\",[\"href\",\"#priority-3-customers-must-succeed-or-we-will-fail\"]],[\"em\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Developer productivity is undergoing a tectonic shift. New software development paradigms and tooling have accelerated the pace and productivity of modern software teams, quickening the \\\"shipping speed\\\" of new software.\"]]],[1,\"p\",[[0,[],0,\"To better understand the strategic landscape, my good friend and colleague, \"],[0,[0],1,\"Clio Smurro\"],[0,[],0,\", and I interviewed founders and executives at next-generation software and infrastructure startups pushing the developer productivity frontier to get their thoughts and insights. They shared their views on:\"]]],[3,\"ul\",[[[0,[1],1,\"major industry trends\"],[0,[],0,\",\"]],[[0,[2],1,\"top strategic priorities (you are here)\"],[0,[],0,\", and\"]],[[0,[3],1,\"biggest challenges and pain points\"]]]],[1,\"p\",[[0,[],0,\"In this second chapter, we share our findings on the \"],[0,[2],1,\"top strategic priorities\"],[0,[],0,\" of developer productivity startups, including:\"]]],[3,\"ul\",[[[0,[4],1,\"Priority #1: Product-(go-to-)market fit\"],[0,[],0,\"\"]],[[0,[5],1,\"Priority #2: Sow first, reap later\"],[0,[],0,\"\"]],[[0,[6],1,\"Priority #3: Customers must succeed... or we will fail\"]]]],[1,\"p\",[[0,[],0,\"Want to be notified when we publish part three of our findings? Subscribe below, and we'll also send you a nicely formatted PDF of our research!\"]]],[10,0],[1,\"h2\",[[0,[],0,\"Priority #1: Product-(go-to-)market fit\"]]],[1,\"p\",[[0,[],0,\"Developer productivity companies work extremely hard on the initial V1 of the product. As developers themselves, these founders are targeting difficult technical problems where elegant solutions do not yet exist, hoping to bring a product to market that is fundamentally innovative. While in \\\"heads down\\\" mode, however, it's easy to ignore market sizing. Many developer productivity founders do not sit down to make initial estimates of their addressable market until after the technology has already been built:\"]]],[1,\"blockquote\",[[0,[2],1,\"2020 is all about product-market fit.\"],[0,[],0,\" The last year and a half, we built a platform that solves a hard technical problem. Now we've come out of stealth. The question is â€” \"],[0,[2],1,\"is this a market for 5 or 5,000? Is it 5 or 10 years out?\"],[0,[],0,\" â€” Founder, Data Science Startup\"]]],[1,\"blockquote\",[[0,[2],1,\"We are doubling down on product-market fit.\"],[0,[],0,\" We need to figure out who buys our tool, what their characteristics are, and how to find more of them. â€” Executive, Developer Tools Startup\"]]],[1,\"p\",[[0,[],0,\"Successfully growing a developer productivity startup from the seed stage onward involves more than simply \\\"knowing\\\" what your market is. More than that, it requires forging a path from the laptops of your engineering team to the credit cards of potential users, teams, and organizations. \\\"How to distribute\\\" is not necessarily the same question as \\\"how to sell,\\\" a question which confounds many developer productivity companies. This slight variation of product-market fit, which we call \"],[0,[2],1,\"product-go-to-market fit\"],[0,[],0,\", is tricky for developer productivity startups, who often achieve significant adoption of their tools well before revenue catches up, similar to many consumer startups.\"]]],[1,\"p\",[[0,[],0,\"As technically-oriented companies founded by technically-oriented people, developer productivity companies struggle with marketing, positioning, and sales, which are rarely their strong suits. For example, early teams often lack someone with product marketing or sales expertise, leading to ambiguity and uncertainty around how to initially frame the product or company:\"]]],[1,\"blockquote\",[[0,[],0,\"We need to nail down our positioning from a marketing standpoint. \"],[0,[2],1,\"We were founded by 2 ex-engineers, and we haven't had a marketing person this whole time.\"],[0,[],0,\" What is our positioning? How do we present that in an effective way? â€” Developer Advocate, Application Infrastructure Startup\"]]],[1,\"p\",[[0,[],0,\"Many companies have aligned themselves to burgeoning trends they've presciently identified, but invariably they arrive at a solution in advance of most market demand. This puts many in the difficult spot of deciding both how to bridge the gap to where real flesh-and-blood customers are today and how much bridge is worth building. Oftentimes there's a significant distance between next-gen startups on the bleeding edge and old-school organizations where most of the revenue lies:\"]]],[1,\"blockquote\",[[0,[],0,\"How many people actually need real-time prediction vs just batch prediction? If they aren't yet ready for real-time, \"],[0,[2],1,\"do we need to start by providing them stepping stones to meet them where theyâ€™re at?\"],[0,[],0,\" â€” Founder, Data Science Startup\"]]],[1,\"p\",[[0,[],0,\"Part of that bridge comes in the form of product improvements that enhance the applicability of the product to real customer use cases. One founder framed this as \\\"product geometry\\\":\"]]],[1,\"blockquote\",[[0,[],0,\"What we've built is a relatively new concept for people. \"],[0,[2],1,\"But we have to make sure that the product geometry maps well to actual customers needs for enough people.\"],[0,[],0,\" â€” Founder, Data Science Startup\"]]],[1,\"p\",[[0,[],0,\"On the other hand, sometimes the product is fine as-is but education is required to both generate awareness and understanding of the potential value of the product or service. This doesn't always work, naturally leading to the question â€” \"],[0,[7],1,\"is it them or us?\"],[0,[],0,\":\"]]],[1,\"blockquote\",[[0,[2],1,\"If you talk to potential customers, thereâ€™s a lot of customer education required.\"],[0,[],0,\" If youâ€™re trying to explain it and theyâ€™re not getting it, is that their problem or yours for not explaining it right? â€” Founder, Data Science Startup\"]]],[1,\"p\",[[0,[],0,\"Another vector upon which to achieve product-go-to-market fit is in the business model itself. Pricing can be a meaningful barrier to adoption. If it's too expensive to get started with the product, most developers and small organizations will never bother to try it out, which can be a missed a opportunity:\"]]],[1,\"blockquote\",[[0,[2],1,\"We want to bring down the cost of using our technology to the point where we can give it to developers for free\"],[0,[],0,\", especially since Amazon and others provide a free version. â€” Executive, Application Infrastructure Startup\"]]],[1,\"p\",[[0,[],0,\"This is not simply a matter of changing the pricing on your website. For example, if your distributed database requires a node of at least a certain size to avoid performance issues, lowering the barrier to entry for prospective customers requires modifying the product. Certain technologies, especially infrastructure running clusters or nodes in the cloud may require significant architectural changes to run on smaller instances:\"]]],[1,\"blockquote\",[[0,[2],1,\"Our technology is expensive to run.\"],[0,[],0,\" Our cheapest cluster is still $50+/month. We'd love to get it down to $10/month so \"],[0,[2],1,\"more people can get a small slice of it instead of fewer people getting a big slice of it.\"],[0,[],0,\" â€” Executive, Application Infrastructure Startup\"]]],[1,\"h2\",[[0,[],0,\"Priority #2: Sow first, reap later\"]]],[1,\"p\",[[0,[],0,\"Developer productivity startups execute a very clear one-two punch â€” plant and nurture the seeds of grassroots adoption first, harvest revenue second. In other words, if they use it, they will (eventually) pay for it (or so the theory goes):\"]]],[1,\"blockquote\",[[0,[],0,\"Our number one goal is to increase end user adoption. Our second goal is revenue. \"],[0,[2],1,\"We believe that if they try our product, they will spend for it eventually\"],[0,[],0,\". â€” Executive, Developer Tools Startup\"]]],[1,\"p\",[[0,[],0,\"Oftentimes, the first step is achieved via an organic open core model where core functionality is made available in the open source edition of the product, with extra team and enterprise-focused features available as closed source or open source activated via license key. Broadening open source adoption becomes a singular goal for many:\"]]],[1,\"blockquote\",[[0,[],0,\"Our mission is straightforward â€” \"],[0,[2],1,\"we want to 10x our open source community\"],[0,[],0,\". â€” Founder, Data Science Startup\"]]],[1,\"blockquote\",[[0,[2],1,\"We want to make [our open source technology] a huge success\"],[0,[],0,\". We want to grow the open source community. â€” Founder, Application Infrastructure Startup\"]]],[1,\"p\",[[0,[],0,\"Self-service is the key to bottoms-up adoption. Developers want to get up to speed as quickly as possible with minimal friction. They need to see value immediately and feel like they are in control. Typically, this means having the ability to spin up a small instance or process on their laptop via command-line interface (CLI) or other tool:\"]]],[1,\"blockquote\",[[0,[2],1,\"We need more bottoms-up adoption from developers.\"],[0,[],0,\" Building capabilities for developers to spin up their own instances is key. â€” Executive, Application Infrastructure Startup\"]]],[1,\"p\",[[0,[],0,\"But the \\\"\"],[0,[7],1,\"if they use it, they will pay for it\"],[0,[],0,\"\\\" logic does not always play out. Sometimes, bottoms-up adoption works well for the free version of a tool but \"],[0,[7],1,\"doesn't\"],[0,[],0,\" work so well for the paid version. It's not uncommon to see technologies, especially those that are open source, struggle to convert adoption into paid usage. And when users do want to pay for more features, developer productivity startups quickly find out its much harder to onboard paid clients who now have higher expectations, need more hand-holding, and require service-level agreements (SLAs). This makes paying customers much more difficult to adequately serve than open source users who can simply download and go:\"]]],[1,\"blockquote\",[[0,[],0,\"We have tons of interest in our beta. We want to move them from beta users to paid customers. \"],[0,[2],1,\"We need to figure out a better way to onboard clients to make us more efficient and scalable\"],[0,[],0,\". â€” Developer Advocate, Application Infrastructure Startup\"]]],[1,\"blockquote\",[[0,[2],1,\"Every account is very manual right now.\"],[0,[],0,\" We're very much a \\\"white glove\\\" service. â€” Manager, Application Infrastructure Startup\"]]],[1,\"p\",[[0,[],0,\"One might expect ambitious growth plans to temper in the face of the COVID-19 pandemic. Interestingly, most of the startups we spoke with have seen little measurable impact from COVID-19. Most are beginning from a small starting point with little to lose, meaning that everything is effectively upside. Yes, the pandemic is certainly generated waves, but these early-stage vendors manage to stay largely under the surf:\"]]],[1,\"blockquote\",[[0,[2],1,\"Weâ€™re not big enough for COVID to affect us.\"],[0,[],0,\" We're starting from zero, so all growth is significant. All clients are growth for us. â€” Executive, Data Science Startup\"]]],[1,\"blockquote\",[[0,[2],1,\"We havenâ€™t really been affected by COVID at all.\"],[0,[],0,\" Some consumer and travel customers have had to pull out or pause. Otherwise, no issues from COVID. â€” Developer Advocate, Application Infrastructure Startup\"]]],[1,\"p\",[[0,[],0,\"As companies targeting developers, who are more accustomed to working remote, developer productivity companies have not seen much disruption in buying or usage patterns. In some cases, COVID-19 has actually served as a tailwind, with work from home generating a need for better, more robust tools that individuals and small teams can use independently to get productive work done:\"]]],[1,\"blockquote\",[[0,[2],1,\"If anything itâ€™s helped us.\"],[0,[],0,\" People are home doing data science and they need right tools. â€” Executive, Data Science Startup\"]]],[1,\"h2\",[[0,[],0,\"Priority #3: Customers must succeed... or we will fail\"]]],[1,\"blockquote\",[[0,[],0,\"Weâ€™re starting to move to a phase of our business where customer success is increasingly important. â€” Executive, Application Infrastructure Startup\"]]],[1,\"p\",[[0,[],0,\"Moving fast and breaking things makes sense in the earliest phases of development when shipping product out the door takes precedence, but early design decisions eventually catch up with you. The best things move quickly in the early days to achieve a minimum viable product that serves the more obvious use cases but pivot at some point to cleaning up the mess they made:\"]]],[1,\"blockquote\",[[0,[2],1,\"We started by shipping a lot of things really quickly, but what we shipped was buggy and broke a lot of design conventions\"],[0,[],0,\". Weâ€™re working on re-skinning it, improving accessibility, etc. \"],[0,[2],1,\"Fit and finish. Polish\"],[0,[],0,\". â€” Manager, Developer Tools Startup\"]]],[1,\"p\",[[0,[],0,\"Here again, education comes up as important process getting users up to speed and reducing time-to-value. Ironically, developer productivity tools, especially on the infrastructure side, can be complex and difficult to learn, emphasizing the importance of high-quality documentation and customer support.\"]]],[1,\"blockquote\",[[0,[2],1,\"Improving the user experience is a priority.\"],[0,[],0,\" The process of signing up, using the product, all the different use cases. Our product is difficult and complex to learn. \"],[0,[2],1,\"We need to make it easier.\"],[0,[],0,\" â€” Executive, Developer Tools Startup\"]]],[1,\"p\",[[0,[],0,\"Eventually, once the product is in good shape and serving initial use cases well, the focus shifts to customer success and retention. This often involves solving for issues that do not necessarily arise in casual usage but do crop up in large-scale production environments or other serious use cases. Sophisticated customers have little patience for a tool that fails when it counts most:\"]]],[1,\"blockquote\",[[0,[],0,\"For the first few years, it was about getting our first use cases. Does it demo well? Can it survive contrived failure scenarios? \"],[0,[2],1,\"Now that we have a lot of customers, we focus on retention.\"],[0,[],0,\" â€” Executive, Application Infrastructure Startup\"]]],[1,\"p\",[[0,[],0,\"Customer success means serving all stakeholders well. This means both individual contributors and managers, the front office and back office, and so on. For example, infrastructure companies must appease not only the principal architect tasked with conceiving the target architecture that will then be implemented, but the individual developers themselves who will either implementing or maintaining the technology on an ongoing basis:\"]]],[1,\"blockquote\",[[0,[2],1,\"We need to make our technology more developer friendly.\"],[0,[],0,\" Infrastructure architects love us, but once the architects make that decision, \"],[0,[2],1,\"they need people to build that vision\"],[0,[],0,\". â€” Executive, Application Infrastructure Startup\"]]],[1,\"p\",[[0,[],0,\"As developer productivity startups move up-market, customers demand more enterprise-grade features. Developer productivity becomes \"],[0,[7],1,\"organizational productivity\"],[0,[],0,\". In this sense, customer success becomes a source of product development feedback, informing the roadmap and guiding vendors toward new revenue opportunities and larger deals:\"]]],[1,\"blockquote\",[[0,[2],1,\"Our customers need to be able to plug our technology into the rest of their enterprise stack.\"],[0,[],0,\" Single sign on, lightweight directory protocol (LDAP), etc. We call this enterprise \\\"ruggedization.\\\" â€” Executive, Application Infrastructure Startup\"]]],[1,\"p\",[[0,[],0,\"In addition to enterprise features, developer productivity startups must plug into a number of popular developer and collaboration tools already in place in many of the organizations they wish to penetrate. Integrations to Slack, Atlassian, Git, and other tools becomes \\\"table stakes\\\" â€” practically required to see wide adoption given how embedded these other tools are in the workflows of most developers:\"]]],[1,\"blockquote\",[[0,[],0,\"We want to deepen our integrations. Jenkins, GitHub, Atlassian, GitLab, Microsoft. \"],[0,[2],1,\"We want first-class plugins.\"],[0,[],0,\" â€” Executive, Application Security Startup\"]]],[1,\"h2\",[[0,[],0,\"Conclusion\"]]],[1,\"p\",[[0,[],0,\"As with most startups, developer productivity companies must adapt to an evolving strategic context as they scale and mature. What worked in stealth might not work after public launch; what passed muster as a scraggly startup selling to other startups might not cut it for buttoned-down enterprise clients.\"]]],[1,\"p\",[[0,[],0,\"This strategic evolution comes in three broad phases:\"]]],[3,\"ul\",[[[0,[2],1,\"First\"],[0,[],0,\", developer productivity startups map out and blaze a trail from the source code to the credit card numbers of user and buyers at target organizations\"]],[[0,[2],1,\"Second\"],[0,[],0,\", having identified fertile soil, they seed the market via organic adoption, making bets that will hopefully bear fruit the form of revenue in the coming month and years\"]],[[0,[2],1,\"Third\"],[0,[],0,\" and last, the best developer productivity companies ensure their fledgling customers do not die on the vine but rather grow their usage and expand their contracts over time\"]]]],[1,\"p\",[[0,[],0,\"Successful execution of this three part plan lays a strong foundation for developer productivity companies to thrive and survive in the face of strategic threats (the public cloud casts a long shadow) or economic disruption.\"]]],[1,\"p\",[[0,[],0,\"Be informed of our next and final publication in this series, the \"],[0,[2],1,\"biggest challenges and pain points of developer productivity companies\"],[0,[],0,\", by entering your email below:\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p>Developer productivity is undergoing a tectonic shift. New software development paradigms and tooling have accelerated the pace and productivity of modern software teams, quickening the \"shipping speed\" of new software.</p><p>To better understand the strategic landscape, my good friend and colleague, <a href=\"https://www.linkedin.com/in/clio-smurro-31967b9/\">Clio Smurro</a>, and I interviewed founders and executives at next-generation software and infrastructure startups pushing the developer productivity frontier to get their thoughts and insights. They shared their views on:</p><ul><li><a href=\"__GHOST_URL__/developer-productivity-trends/\">major industry trends</a>,</li><li><strong>top strategic priorities (you are here)</strong>, and</li><li><a href=\"__GHOST_URL__/developer-productivity-challenges/\">biggest challenges and pain points</a></li></ul><p>In this second chapter, we share our findings on the <strong>top strategic priorities</strong> of developer productivity startups, including:</p><ul><li><a href=\"#priority-1-product-go-to-market-fit\">Priority #1: Product-(go-to-)market fit</a></li><li><a href=\"#priority-2-sow-first-reap-later\">Priority #2: Sow first, reap later</a></li><li><a href=\"#priority-3-customers-must-succeed-or-we-will-fail\">Priority #3: Customers must succeed... or we will fail</a></li></ul><p>Want to be notified when we publish part three of our findings? Subscribe below, and we'll also send you a nicely formatted PDF of our research!</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive a report with the full results</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Your Email Address\" id=\"mce-EMAIL\" required>\n<input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Top Three Strategic Priorities of Developer Productivity Startups\">\n<input type=\"checkbox\" value=\"8\" name=\"group[78589][8]\" id=\"mce-group[78589]-78589-0\" style=\"display:none\" checked>\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Send Report âš¡</span></button>\n</form>\n            </section><!--kg-card-end: html--><h2 id=\"priority-1-product-go-to-market-fit\">Priority #1: Product-(go-to-)market fit</h2><p>Developer productivity companies work extremely hard on the initial V1 of the product. As developers themselves, these founders are targeting difficult technical problems where elegant solutions do not yet exist, hoping to bring a product to market that is fundamentally innovative. While in \"heads down\" mode, however, it's easy to ignore market sizing. Many developer productivity founders do not sit down to make initial estimates of their addressable market until after the technology has already been built:</p><blockquote><strong>2020 is all about product-market fit.</strong> The last year and a half, we built a platform that solves a hard technical problem. Now we've come out of stealth. The question is â€” <strong>is this a market for 5 or 5,000? Is it 5 or 10 years out?</strong> â€” Founder, Data Science Startup</blockquote><blockquote><strong>We are doubling down on product-market fit.</strong> We need to figure out who buys our tool, what their characteristics are, and how to find more of them. â€” Executive, Developer Tools Startup</blockquote><p>Successfully growing a developer productivity startup from the seed stage onward involves more than simply \"knowing\" what your market is. More than that, it requires forging a path from the laptops of your engineering team to the credit cards of potential users, teams, and organizations. \"How to distribute\" is not necessarily the same question as \"how to sell,\" a question which confounds many developer productivity companies. This slight variation of product-market fit, which we call <strong>product-go-to-market fit</strong>, is tricky for developer productivity startups, who often achieve significant adoption of their tools well before revenue catches up, similar to many consumer startups.</p><p>As technically-oriented companies founded by technically-oriented people, developer productivity companies struggle with marketing, positioning, and sales, which are rarely their strong suits. For example, early teams often lack someone with product marketing or sales expertise, leading to ambiguity and uncertainty around how to initially frame the product or company:</p><blockquote>We need to nail down our positioning from a marketing standpoint. <strong>We were founded by 2 ex-engineers, and we haven't had a marketing person this whole time.</strong> What is our positioning? How do we present that in an effective way? â€” Developer Advocate, Application Infrastructure Startup</blockquote><p>Many companies have aligned themselves to burgeoning trends they've presciently identified, but invariably they arrive at a solution in advance of most market demand. This puts many in the difficult spot of deciding both how to bridge the gap to where real flesh-and-blood customers are today and how much bridge is worth building. Oftentimes there's a significant distance between next-gen startups on the bleeding edge and old-school organizations where most of the revenue lies:</p><blockquote>How many people actually need real-time prediction vs just batch prediction? If they aren't yet ready for real-time, <strong>do we need to start by providing them stepping stones to meet them where theyâ€™re at?</strong> â€” Founder, Data Science Startup</blockquote><p>Part of that bridge comes in the form of product improvements that enhance the applicability of the product to real customer use cases. One founder framed this as \"product geometry\":</p><blockquote>What we've built is a relatively new concept for people. <strong>But we have to make sure that the product geometry maps well to actual customers needs for enough people.</strong> â€” Founder, Data Science Startup</blockquote><p>On the other hand, sometimes the product is fine as-is but education is required to both generate awareness and understanding of the potential value of the product or service. This doesn't always work, naturally leading to the question â€” <em>is it them or us?</em>:</p><blockquote><strong>If you talk to potential customers, thereâ€™s a lot of customer education required.</strong> If youâ€™re trying to explain it and theyâ€™re not getting it, is that their problem or yours for not explaining it right? â€” Founder, Data Science Startup</blockquote><p>Another vector upon which to achieve product-go-to-market fit is in the business model itself. Pricing can be a meaningful barrier to adoption. If it's too expensive to get started with the product, most developers and small organizations will never bother to try it out, which can be a missed a opportunity:</p><blockquote><strong>We want to bring down the cost of using our technology to the point where we can give it to developers for free</strong>, especially since Amazon and others provide a free version. â€” Executive, Application Infrastructure Startup</blockquote><p>This is not simply a matter of changing the pricing on your website. For example, if your distributed database requires a node of at least a certain size to avoid performance issues, lowering the barrier to entry for prospective customers requires modifying the product. Certain technologies, especially infrastructure running clusters or nodes in the cloud may require significant architectural changes to run on smaller instances:</p><blockquote><strong>Our technology is expensive to run.</strong> Our cheapest cluster is still $50+/month. We'd love to get it down to $10/month so <strong>more people can get a small slice of it instead of fewer people getting a big slice of it.</strong> â€” Executive, Application Infrastructure Startup</blockquote><h2 id=\"priority-2-sow-first-reap-later\">Priority #2: Sow first, reap later</h2><p>Developer productivity startups execute a very clear one-two punch â€” plant and nurture the seeds of grassroots adoption first, harvest revenue second. In other words, if they use it, they will (eventually) pay for it (or so the theory goes):</p><blockquote>Our number one goal is to increase end user adoption. Our second goal is revenue. <strong>We believe that if they try our product, they will spend for it eventually</strong>. â€” Executive, Developer Tools Startup</blockquote><p>Oftentimes, the first step is achieved via an organic open core model where core functionality is made available in the open source edition of the product, with extra team and enterprise-focused features available as closed source or open source activated via license key. Broadening open source adoption becomes a singular goal for many:</p><blockquote>Our mission is straightforward â€” <strong>we want to 10x our open source community</strong>. â€” Founder, Data Science Startup</blockquote><blockquote><strong>We want to make [our open source technology] a huge success</strong>. We want to grow the open source community. â€” Founder, Application Infrastructure Startup</blockquote><p>Self-service is the key to bottoms-up adoption. Developers want to get up to speed as quickly as possible with minimal friction. They need to see value immediately and feel like they are in control. Typically, this means having the ability to spin up a small instance or process on their laptop via command-line interface (CLI) or other tool:</p><blockquote><strong>We need more bottoms-up adoption from developers.</strong> Building capabilities for developers to spin up their own instances is key. â€” Executive, Application Infrastructure Startup</blockquote><p>But the \"<em>if they use it, they will pay for it</em>\" logic does not always play out. Sometimes, bottoms-up adoption works well for the free version of a tool but <em>doesn't</em> work so well for the paid version. It's not uncommon to see technologies, especially those that are open source, struggle to convert adoption into paid usage. And when users do want to pay for more features, developer productivity startups quickly find out its much harder to onboard paid clients who now have higher expectations, need more hand-holding, and require service-level agreements (SLAs). This makes paying customers much more difficult to adequately serve than open source users who can simply download and go:</p><blockquote>We have tons of interest in our beta. We want to move them from beta users to paid customers. <strong>We need to figure out a better way to onboard clients to make us more efficient and scalable</strong>. â€” Developer Advocate, Application Infrastructure Startup</blockquote><blockquote><strong>Every account is very manual right now.</strong> We're very much a \"white glove\" service. â€” Manager, Application Infrastructure Startup</blockquote><p>One might expect ambitious growth plans to temper in the face of the COVID-19 pandemic. Interestingly, most of the startups we spoke with have seen little measurable impact from COVID-19. Most are beginning from a small starting point with little to lose, meaning that everything is effectively upside. Yes, the pandemic is certainly generated waves, but these early-stage vendors manage to stay largely under the surf:</p><blockquote><strong>Weâ€™re not big enough for COVID to affect us.</strong> We're starting from zero, so all growth is significant. All clients are growth for us. â€” Executive, Data Science Startup</blockquote><blockquote><strong>We havenâ€™t really been affected by COVID at all.</strong> Some consumer and travel customers have had to pull out or pause. Otherwise, no issues from COVID. â€” Developer Advocate, Application Infrastructure Startup</blockquote><p>As companies targeting developers, who are more accustomed to working remote, developer productivity companies have not seen much disruption in buying or usage patterns. In some cases, COVID-19 has actually served as a tailwind, with work from home generating a need for better, more robust tools that individuals and small teams can use independently to get productive work done:</p><blockquote><strong>If anything itâ€™s helped us.</strong> People are home doing data science and they need right tools. â€” Executive, Data Science Startup</blockquote><h2 id=\"priority-3-customers-must-succeed-or-we-will-fail\">Priority #3: Customers must succeed... or we will fail</h2><blockquote>Weâ€™re starting to move to a phase of our business where customer success is increasingly important. â€” Executive, Application Infrastructure Startup</blockquote><p>Moving fast and breaking things makes sense in the earliest phases of development when shipping product out the door takes precedence, but early design decisions eventually catch up with you. The best things move quickly in the early days to achieve a minimum viable product that serves the more obvious use cases but pivot at some point to cleaning up the mess they made:</p><blockquote><strong>We started by shipping a lot of things really quickly, but what we shipped was buggy and broke a lot of design conventions</strong>. Weâ€™re working on re-skinning it, improving accessibility, etc. <strong>Fit and finish. Polish</strong>. â€” Manager, Developer Tools Startup</blockquote><p>Here again, education comes up as important process getting users up to speed and reducing time-to-value. Ironically, developer productivity tools, especially on the infrastructure side, can be complex and difficult to learn, emphasizing the importance of high-quality documentation and customer support.</p><blockquote><strong>Improving the user experience is a priority.</strong> The process of signing up, using the product, all the different use cases. Our product is difficult and complex to learn. <strong>We need to make it easier.</strong> â€” Executive, Developer Tools Startup</blockquote><p>Eventually, once the product is in good shape and serving initial use cases well, the focus shifts to customer success and retention. This often involves solving for issues that do not necessarily arise in casual usage but do crop up in large-scale production environments or other serious use cases. Sophisticated customers have little patience for a tool that fails when it counts most:</p><blockquote>For the first few years, it was about getting our first use cases. Does it demo well? Can it survive contrived failure scenarios? <strong>Now that we have a lot of customers, we focus on retention.</strong> â€” Executive, Application Infrastructure Startup</blockquote><p>Customer success means serving all stakeholders well. This means both individual contributors and managers, the front office and back office, and so on. For example, infrastructure companies must appease not only the principal architect tasked with conceiving the target architecture that will then be implemented, but the individual developers themselves who will either implementing or maintaining the technology on an ongoing basis:</p><blockquote><strong>We need to make our technology more developer friendly.</strong> Infrastructure architects love us, but once the architects make that decision, <strong>they need people to build that vision</strong>. â€” Executive, Application Infrastructure Startup</blockquote><p>As developer productivity startups move up-market, customers demand more enterprise-grade features. Developer productivity becomes <em>organizational productivity</em>. In this sense, customer success becomes a source of product development feedback, informing the roadmap and guiding vendors toward new revenue opportunities and larger deals:</p><blockquote><strong>Our customers need to be able to plug our technology into the rest of their enterprise stack.</strong> Single sign on, lightweight directory protocol (LDAP), etc. We call this enterprise \"ruggedization.\" â€” Executive, Application Infrastructure Startup</blockquote><p>In addition to enterprise features, developer productivity startups must plug into a number of popular developer and collaboration tools already in place in many of the organizations they wish to penetrate. Integrations to Slack, Atlassian, Git, and other tools becomes \"table stakes\" â€” practically required to see wide adoption given how embedded these other tools are in the workflows of most developers:</p><blockquote>We want to deepen our integrations. Jenkins, GitHub, Atlassian, GitLab, Microsoft. <strong>We want first-class plugins.</strong> â€” Executive, Application Security Startup</blockquote><h2 id=\"conclusion\">Conclusion</h2><p>As with most startups, developer productivity companies must adapt to an evolving strategic context as they scale and mature. What worked in stealth might not work after public launch; what passed muster as a scraggly startup selling to other startups might not cut it for buttoned-down enterprise clients.</p><p>This strategic evolution comes in three broad phases:</p><ul><li><strong>First</strong>, developer productivity startups map out and blaze a trail from the source code to the credit card numbers of user and buyers at target organizations</li><li><strong>Second</strong>, having identified fertile soil, they seed the market via organic adoption, making bets that will hopefully bear fruit the form of revenue in the coming month and years</li><li><strong>Third</strong> and last, the best developer productivity companies ensure their fledgling customers do not die on the vine but rather grow their usage and expand their contracts over time</li></ul><p>Successful execution of this three part plan lays a strong foundation for developer productivity companies to thrive and survive in the face of strategic threats (the public cloud casts a long shadow) or economic disruption.</p><p>Be informed of our next and final publication in this series, the <strong>biggest challenges and pain points of developer productivity companies</strong>, by entering your email below:</p>","comment_id":"5f3bec2d17b26d3ef80d621b","plaintext":"Developer productivity is undergoing a tectonic shift. New software development\nparadigms and tooling have accelerated the pace and productivity of modern\nsoftware teams, quickening the \"shipping speed\" of new software.\n\nTo better understand the strategic landscape, my good friend and colleague, \nClio\nSmurro [https://www.linkedin.com/in/clio-smurro-31967b9/], and I interviewed\nfounders and executives at next-generation software and infrastructure startups\npushing the developer productivity frontier to get their thoughts and insights.\nThey shared their views on:\n\n * major industry trends [__GHOST_URL__/developer-productivity-trends/],\n * top strategic priorities (you are here), and\n * biggest challenges and pain points\n   [__GHOST_URL__/developer-productivity-challenges/]\n\nIn this second chapter, we share our findings on the top strategic priorities of\ndeveloper productivity startups, including:\n\n * Priority #1: Product-(go-to-)market fit\n * Priority #2: Sow first, reap later\n * Priority #3: Customers must succeed... or we will fail\n\nWant to be notified when we publish part three of our findings? Subscribe below,\nand we'll also send you a nicely formatted PDF of our research!\n\nReceive a report with the full results\n\n\nSend Report âš¡ Priority #1: Product-(go-to-)market fit\nDeveloper productivity companies work extremely hard on the initial V1 of the\nproduct. As developers themselves, these founders are targeting difficult\ntechnical problems where elegant solutions do not yet exist, hoping to bring a\nproduct to market that is fundamentally innovative. While in \"heads down\" mode,\nhowever, it's easy to ignore market sizing. Many developer productivity founders\ndo not sit down to make initial estimates of their addressable market until\nafter the technology has already been built:\n\n> 2020 is all about product-market fit. The last year and a half, we built a\nplatform that solves a hard technical problem. Now we've come out of stealth.\nThe question is â€” is this a market for 5 or 5,000? Is it 5 or 10 years out? â€”\nFounder, Data Science Startup\n> We are doubling down on product-market fit. We need to figure out who buys our\ntool, what their characteristics are, and how to find more of them. â€” Executive,\nDeveloper Tools Startup\nSuccessfully growing a developer productivity startup from the seed stage onward\ninvolves more than simply \"knowing\" what your market is. More than that, it\nrequires forging a path from the laptops of your engineering team to the credit\ncards of potential users, teams, and organizations. \"How to distribute\" is not\nnecessarily the same question as \"how to sell,\" a question which confounds many\ndeveloper productivity companies. This slight variation of product-market fit,\nwhich we call product-go-to-market fit, is tricky for developer productivity\nstartups, who often achieve significant adoption of their tools well before\nrevenue catches up, similar to many consumer startups.\n\nAs technically-oriented companies founded by technically-oriented people,\ndeveloper productivity companies struggle with marketing, positioning, and\nsales, which are rarely their strong suits. For example, early teams often lack\nsomeone with product marketing or sales expertise, leading to ambiguity and\nuncertainty around how to initially frame the product or company:\n\n> We need to nail down our positioning from a marketing standpoint. We were\nfounded by 2 ex-engineers, and we haven't had a marketing person this whole\ntime. What is our positioning? How do we present that in an effective way? â€”\nDeveloper Advocate, Application Infrastructure Startup\nMany companies have aligned themselves to burgeoning trends they've presciently\nidentified, but invariably they arrive at a solution in advance of most market\ndemand. This puts many in the difficult spot of deciding both how to bridge the\ngap to where real flesh-and-blood customers are today and how much bridge is\nworth building. Oftentimes there's a significant distance between next-gen\nstartups on the bleeding edge and old-school organizations where most of the\nrevenue lies:\n\n> How many people actually need real-time prediction vs just batch prediction? If\nthey aren't yet ready for real-time, do we need to start by providing them\nstepping stones to meet them where theyâ€™re at? â€” Founder, Data Science Startup\nPart of that bridge comes in the form of product improvements that enhance the\napplicability of the product to real customer use cases. One founder framed this\nas \"product geometry\":\n\n> What we've built is a relatively new concept for people. But we have to make\nsure that the product geometry maps well to actual customers needs for enough\npeople. â€” Founder, Data Science Startup\nOn the other hand, sometimes the product is fine as-is but education is required\nto both generate awareness and understanding of the potential value of the\nproduct or service. This doesn't always work, naturally leading to the question\nâ€” is it them or us?:\n\n> If you talk to potential customers, thereâ€™s a lot of customer education\nrequired. If youâ€™re trying to explain it and theyâ€™re not getting it, is that\ntheir problem or yours for not explaining it right? â€” Founder, Data Science\nStartup\nAnother vector upon which to achieve product-go-to-market fit is in the business\nmodel itself. Pricing can be a meaningful barrier to adoption. If it's too\nexpensive to get started with the product, most developers and small\norganizations will never bother to try it out, which can be a missed a\nopportunity:\n\n> We want to bring down the cost of using our technology to the point where we can\ngive it to developers for free, especially since Amazon and others provide a\nfree version. â€” Executive, Application Infrastructure Startup\nThis is not simply a matter of changing the pricing on your website. For\nexample, if your distributed database requires a node of at least a certain size\nto avoid performance issues, lowering the barrier to entry for prospective\ncustomers requires modifying the product. Certain technologies, especially\ninfrastructure running clusters or nodes in the cloud may require significant\narchitectural changes to run on smaller instances:\n\n> Our technology is expensive to run. Our cheapest cluster is still $50+/month.\nWe'd love to get it down to $10/month so more people can get a small slice of it\ninstead of fewer people getting a big slice of it. â€” Executive, Application\nInfrastructure Startup\nPriority #2: Sow first, reap later\nDeveloper productivity startups execute a very clear one-two punch â€” plant and\nnurture the seeds of grassroots adoption first, harvest revenue second. In other\nwords, if they use it, they will (eventually) pay for it (or so the theory\ngoes):\n\n> Our number one goal is to increase end user adoption. Our second goal is\nrevenue. We believe that if they try our product, they will spend for it\neventually. â€” Executive, Developer Tools Startup\nOftentimes, the first step is achieved via an organic open core model where core\nfunctionality is made available in the open source edition of the product, with\nextra team and enterprise-focused features available as closed source or open\nsource activated via license key. Broadening open source adoption becomes a\nsingular goal for many:\n\n> Our mission is straightforward â€” we want to 10x our open source community. â€”\nFounder, Data Science Startup\n> We want to make [our open source technology] a huge success. We want to grow the\nopen source community. â€” Founder, Application Infrastructure Startup\nSelf-service is the key to bottoms-up adoption. Developers want to get up to\nspeed as quickly as possible with minimal friction. They need to see value\nimmediately and feel like they are in control. Typically, this means having the\nability to spin up a small instance or process on their laptop via command-line\ninterface (CLI) or other tool:\n\n> We need more bottoms-up adoption from developers. Building capabilities for\ndevelopers to spin up their own instances is key. â€” Executive, Application\nInfrastructure Startup\nBut the \"if they use it, they will pay for it\" logic does not always play out.\nSometimes, bottoms-up adoption works well for the free version of a tool but \ndoesn't work so well for the paid version. It's not uncommon to see\ntechnologies, especially those that are open source, struggle to convert\nadoption into paid usage. And when users do want to pay for more features,\ndeveloper productivity startups quickly find out its much harder to onboard paid\nclients who now have higher expectations, need more hand-holding, and require\nservice-level agreements (SLAs). This makes paying customers much more difficult\nto adequately serve than open source users who can simply download and go:\n\n> We have tons of interest in our beta. We want to move them from beta users to\npaid customers. We need to figure out a better way to onboard clients to make us\nmore efficient and scalable. â€” Developer Advocate, Application Infrastructure\nStartup\n> Every account is very manual right now. We're very much a \"white glove\" service.\nâ€” Manager, Application Infrastructure Startup\nOne might expect ambitious growth plans to temper in the face of the COVID-19\npandemic. Interestingly, most of the startups we spoke with have seen little\nmeasurable impact from COVID-19. Most are beginning from a small starting point\nwith little to lose, meaning that everything is effectively upside. Yes, the\npandemic is certainly generated waves, but these early-stage vendors manage to\nstay largely under the surf:\n\n> Weâ€™re not big enough for COVID to affect us. We're starting from zero, so all\ngrowth is significant. All clients are growth for us. â€” Executive, Data Science\nStartup\n> We havenâ€™t really been affected by COVID at all. Some consumer and travel\ncustomers have had to pull out or pause. Otherwise, no issues from COVID. â€”\nDeveloper Advocate, Application Infrastructure Startup\nAs companies targeting developers, who are more accustomed to working remote,\ndeveloper productivity companies have not seen much disruption in buying or\nusage patterns. In some cases, COVID-19 has actually served as a tailwind, with\nwork from home generating a need for better, more robust tools that individuals\nand small teams can use independently to get productive work done:\n\n> If anything itâ€™s helped us. People are home doing data science and they need\nright tools. â€” Executive, Data Science Startup\nPriority #3: Customers must succeed... or we will fail\n> Weâ€™re starting to move to a phase of our business where customer success is\nincreasingly important. â€” Executive, Application Infrastructure Startup\nMoving fast and breaking things makes sense in the earliest phases of\ndevelopment when shipping product out the door takes precedence, but early\ndesign decisions eventually catch up with you. The best things move quickly in\nthe early days to achieve a minimum viable product that serves the more obvious\nuse cases but pivot at some point to cleaning up the mess they made:\n\n> We started by shipping a lot of things really quickly, but what we shipped was\nbuggy and broke a lot of design conventions. Weâ€™re working on re-skinning it,\nimproving accessibility, etc. Fit and finish. Polish. â€” Manager, Developer Tools\nStartup\nHere again, education comes up as important process getting users up to speed\nand reducing time-to-value. Ironically, developer productivity tools, especially\non the infrastructure side, can be complex and difficult to learn, emphasizing\nthe importance of high-quality documentation and customer support.\n\n> Improving the user experience is a priority. The process of signing up, using\nthe product, all the different use cases. Our product is difficult and complex\nto learn. We need to make it easier. â€” Executive, Developer Tools Startup\nEventually, once the product is in good shape and serving initial use cases\nwell, the focus shifts to customer success and retention. This often involves\nsolving for issues that do not necessarily arise in casual usage but do crop up\nin large-scale production environments or other serious use cases. Sophisticated\ncustomers have little patience for a tool that fails when it counts most:\n\n> For the first few years, it was about getting our first use cases. Does it demo\nwell? Can it survive contrived failure scenarios? Now that we have a lot of\ncustomers, we focus on retention. â€” Executive, Application Infrastructure\nStartup\nCustomer success means serving all stakeholders well. This means both individual\ncontributors and managers, the front office and back office, and so on. For\nexample, infrastructure companies must appease not only the principal architect\ntasked with conceiving the target architecture that will then be implemented,\nbut the individual developers themselves who will either implementing or\nmaintaining the technology on an ongoing basis:\n\n> We need to make our technology more developer friendly. Infrastructure\narchitects love us, but once the architects make that decision, they need people\nto build that vision. â€” Executive, Application Infrastructure Startup\nAs developer productivity startups move up-market, customers demand more\nenterprise-grade features. Developer productivity becomes organizational\nproductivity. In this sense, customer success becomes a source of product\ndevelopment feedback, informing the roadmap and guiding vendors toward new\nrevenue opportunities and larger deals:\n\n> Our customers need to be able to plug our technology into the rest of their\nenterprise stack. Single sign on, lightweight directory protocol (LDAP), etc. We\ncall this enterprise \"ruggedization.\" â€” Executive, Application Infrastructure\nStartup\nIn addition to enterprise features, developer productivity startups must plug\ninto a number of popular developer and collaboration tools already in place in\nmany of the organizations they wish to penetrate. Integrations to Slack,\nAtlassian, Git, and other tools becomes \"table stakes\" â€” practically required to\nsee wide adoption given how embedded these other tools are in the workflows of\nmost developers:\n\n> We want to deepen our integrations. Jenkins, GitHub, Atlassian, GitLab,\nMicrosoft. We want first-class plugins. â€” Executive, Application Security\nStartup\nConclusion\nAs with most startups, developer productivity companies must adapt to an\nevolving strategic context as they scale and mature. What worked in stealth\nmight not work after public launch; what passed muster as a scraggly startup\nselling to other startups might not cut it for buttoned-down enterprise clients.\n\nThis strategic evolution comes in three broad phases:\n\n * First, developer productivity startups map out and blaze a trail from the\n   source code to the credit card numbers of user and buyers at target\n   organizations\n * Second, having identified fertile soil, they seed the market via organic\n   adoption, making bets that will hopefully bear fruit the form of revenue in\n   the coming month and years\n * Third and last, the best developer productivity companies ensure their\n   fledgling customers do not die on the vine but rather grow their usage and\n   expand their contracts over time\n\nSuccessful execution of this three part plan lays a strong foundation for\ndeveloper productivity companies to thrive and survive in the face of strategic\nthreats (the public cloud casts a long shadow) or economic disruption.\n\nBe informed of our next and final publication in this series, the biggest\nchallenges and pain points of developer productivity companies, by entering your\nemail below:","feature_image":"__GHOST_URL__/content/images/2020/08/strategic-priorities-1.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-08-18T14:56:45.000Z","updated_at":"2021-03-11T08:43:18.000Z","published_at":"2020-08-18T15:30:32.000Z","custom_excerpt":"What's top of mind for developer productivity leaders","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5f6d214f17b26d3ef80d624c","uuid":"2cf0d94c-8507-4da7-8b1b-19c08567e9ad","title":"Portfolio","slug":"portfolio","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/10/ExaLogo.jpg\",\"width\":200,\"height\":105}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2024/08/logo-horizontal-copy-1.png\",\"width\":382,\"height\":117}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2023/10/image.png\",\"width\":648,\"height\":115}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/05/Redpanda_horizontal.png\",\"width\":1348,\"height\":228}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/image.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/09/materialize-1.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/10/Observo_AI_Logo-1.jpg\",\"width\":1024,\"height\":512}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/10/PolarSignalsLogo.jpg\",\"width\":1024,\"height\":512}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/03/Ponder_LogoWordmark_H1_Color.png\",\"width\":8000,\"height\":2710}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/01/matillion_logo.png\",\"width\":1024,\"height\":94}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/03/VoltronData_Logo-green_vertical-copy-2-2048x1032-1.jpeg\",\"width\":2048,\"height\":1032}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2024/05/image.png\",\"width\":132,\"height\":40}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/03/astro-full-logo.png\",\"width\":3200,\"height\":1280}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2023/02/image-1.png\",\"width\":2294,\"height\":272}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2024/05/image-6.png\",\"width\":1612,\"height\":580}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2024/07/image.png\",\"width\":200,\"height\":44}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/10/NuanceLabs.png\",\"width\":213,\"height\":73}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/10/contextual-ai-wordmark-gray.jpg\",\"width\":480,\"height\":57}],[\"image\",{\"fileName\":\"gitlab.png\",\"src\":\"__GHOST_URL__/content/images/2020/09/gitlab.png\",\"row\":0,\"width\":2308,\"height\":765}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/fastly.png\",\"width\":2374,\"height\":939}],[\"image\",{\"fileName\":\"alteryx.png\",\"src\":\"__GHOST_URL__/content/images/2020/09/alteryx.png\",\"row\":0,\"width\":195,\"height\":76}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/surveymonkey.png\",\"width\":689,\"height\":140}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/relativity.png\",\"width\":731,\"height\":174}],[\"image\",{\"fileName\":\"brightwheel.png\",\"src\":\"__GHOST_URL__/content/images/2020/09/brightwheel.png\",\"row\":0,\"width\":1050,\"height\":208}],[\"image\",{\"fileName\":\"heptagon.png\",\"src\":\"__GHOST_URL__/content/images/2020/09/heptagon-1.png\",\"row\":0,\"width\":960,\"height\":250}],[\"image\",{\"fileName\":\"viv.png\",\"src\":\"__GHOST_URL__/content/images/2020/09/viv.png\",\"row\":0,\"width\":358,\"height\":122}],[\"gallery\",{\"images\":[{\"fileName\":\"epicgames.png\",\"row\":0,\"width\":1032,\"height\":1198,\"src\":\"__GHOST_URL__/content/images/2020/09/epicgames-2.png\"}]}],[\"image\",{\"fileName\":\"ageoflearning.png\",\"src\":\"__GHOST_URL__/content/images/2020/09/ageoflearning-1.png\",\"row\":0,\"width\":1269,\"height\":155}],[\"image\",{\"fileName\":\"ezcater.png\",\"src\":\"__GHOST_URL__/content/images/2020/09/ezcater-2.png\",\"row\":0,\"width\":340,\"height\":80}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/07/uber.png\",\"width\":753,\"height\":274}]],\"markups\":[],\"sections\":[[1,\"h2\",[[0,[],0,\"Current:\"]]],[10,0],[10,1],[10,2],[10,3],[10,4],[10,5],[10,6],[10,7],[10,8],[10,9],[10,10],[10,11],[10,12],[10,13],[10,14],[10,15],[10,16],[10,17],[1,\"h2\",[[0,[],0,\"Previous: Enterprise / Software\"]]],[10,18],[10,19],[10,20],[10,21],[10,22],[10,23],[10,24],[10,25],[1,\"h2\",[[0,[],0,\"Previous: Consumer / Internet\"]]],[10,26],[10,27],[10,28],[10,29]],\"ghostVersion\":\"3.0\"}","html":"<h2 id=\"current-\">Current:</h2><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2025/10/ExaLogo.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"200\" height=\"105\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2024/08/logo-horizontal-copy-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"382\" height=\"117\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2023/10/image.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"648\" height=\"115\" srcset=\"__GHOST_URL__/content/images/size/w600/2023/10/image.png 600w, __GHOST_URL__/content/images/2023/10/image.png 648w\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/05/Redpanda_horizontal.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1348\" height=\"228\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/05/Redpanda_horizontal.png 600w, __GHOST_URL__/content/images/size/w1000/2022/05/Redpanda_horizontal.png 1000w, __GHOST_URL__/content/images/2022/05/Redpanda_horizontal.png 1348w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/image.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/09/materialize-1.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2025/10/Observo_AI_Logo-1.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"1024\" height=\"512\" srcset=\"__GHOST_URL__/content/images/size/w600/2025/10/Observo_AI_Logo-1.jpg 600w, __GHOST_URL__/content/images/size/w1000/2025/10/Observo_AI_Logo-1.jpg 1000w, __GHOST_URL__/content/images/2025/10/Observo_AI_Logo-1.jpg 1024w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2025/10/PolarSignalsLogo.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"1024\" height=\"512\" srcset=\"__GHOST_URL__/content/images/size/w600/2025/10/PolarSignalsLogo.jpg 600w, __GHOST_URL__/content/images/size/w1000/2025/10/PolarSignalsLogo.jpg 1000w, __GHOST_URL__/content/images/2025/10/PolarSignalsLogo.jpg 1024w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/03/Ponder_LogoWordmark_H1_Color.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"678\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/03/Ponder_LogoWordmark_H1_Color.png 600w, __GHOST_URL__/content/images/size/w1000/2022/03/Ponder_LogoWordmark_H1_Color.png 1000w, __GHOST_URL__/content/images/size/w1600/2022/03/Ponder_LogoWordmark_H1_Color.png 1600w, __GHOST_URL__/content/images/size/w2400/2022/03/Ponder_LogoWordmark_H1_Color.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/01/matillion_logo.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1024\" height=\"94\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/01/matillion_logo.png 600w, __GHOST_URL__/content/images/size/w1000/2022/01/matillion_logo.png 1000w, __GHOST_URL__/content/images/2022/01/matillion_logo.png 1024w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/03/VoltronData_Logo-green_vertical-copy-2-2048x1032-1.jpeg\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1008\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/03/VoltronData_Logo-green_vertical-copy-2-2048x1032-1.jpeg 600w, __GHOST_URL__/content/images/size/w1000/2022/03/VoltronData_Logo-green_vertical-copy-2-2048x1032-1.jpeg 1000w, __GHOST_URL__/content/images/size/w1600/2022/03/VoltronData_Logo-green_vertical-copy-2-2048x1032-1.jpeg 1600w, __GHOST_URL__/content/images/2022/03/VoltronData_Logo-green_vertical-copy-2-2048x1032-1.jpeg 2048w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2024/05/image.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"132\" height=\"40\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/03/astro-full-logo.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"800\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/03/astro-full-logo.png 600w, __GHOST_URL__/content/images/size/w1000/2022/03/astro-full-logo.png 1000w, __GHOST_URL__/content/images/size/w1600/2022/03/astro-full-logo.png 1600w, __GHOST_URL__/content/images/size/w2400/2022/03/astro-full-logo.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2023/02/image-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"237\" srcset=\"__GHOST_URL__/content/images/size/w600/2023/02/image-1.png 600w, __GHOST_URL__/content/images/size/w1000/2023/02/image-1.png 1000w, __GHOST_URL__/content/images/size/w1600/2023/02/image-1.png 1600w, __GHOST_URL__/content/images/2023/02/image-1.png 2294w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2024/05/image-6.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1612\" height=\"580\" srcset=\"__GHOST_URL__/content/images/size/w600/2024/05/image-6.png 600w, __GHOST_URL__/content/images/size/w1000/2024/05/image-6.png 1000w, __GHOST_URL__/content/images/size/w1600/2024/05/image-6.png 1600w, __GHOST_URL__/content/images/2024/05/image-6.png 1612w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2024/07/image.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"200\" height=\"44\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2025/10/NuanceLabs.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"213\" height=\"73\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2025/10/contextual-ai-wordmark-gray.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"480\" height=\"57\"></figure><h2 id=\"previous-enterprise-software\">Previous: Enterprise / Software</h2><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/09/gitlab.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"663\" srcset=\"__GHOST_URL__/content/images/size/w600/2020/09/gitlab.png 600w, __GHOST_URL__/content/images/size/w1000/2020/09/gitlab.png 1000w, __GHOST_URL__/content/images/size/w1600/2020/09/gitlab.png 1600w, __GHOST_URL__/content/images/2020/09/gitlab.png 2308w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/fastly.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"791\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/fastly.png 600w, __GHOST_URL__/content/images/size/w1000/2021/07/fastly.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/07/fastly.png 1600w, __GHOST_URL__/content/images/2021/07/fastly.png 2374w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/09/alteryx.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"195\" height=\"76\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/surveymonkey.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"689\" height=\"140\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/surveymonkey.png 600w, __GHOST_URL__/content/images/2021/07/surveymonkey.png 689w\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/relativity.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"731\" height=\"174\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/relativity.png 600w, __GHOST_URL__/content/images/2021/07/relativity.png 731w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/09/brightwheel.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1050\" height=\"208\" srcset=\"__GHOST_URL__/content/images/size/w600/2020/09/brightwheel.png 600w, __GHOST_URL__/content/images/size/w1000/2020/09/brightwheel.png 1000w, __GHOST_URL__/content/images/2020/09/brightwheel.png 1050w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/09/heptagon-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"960\" height=\"250\" srcset=\"__GHOST_URL__/content/images/size/w600/2020/09/heptagon-1.png 600w, __GHOST_URL__/content/images/2020/09/heptagon-1.png 960w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/09/viv.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"358\" height=\"122\"></figure><h2 id=\"previous-consumer-internet\">Previous: Consumer / Internet</h2><figure class=\"kg-card kg-gallery-card kg-width-wide\"><div class=\"kg-gallery-container\"><div class=\"kg-gallery-row\"><div class=\"kg-gallery-image\"><img src=\"__GHOST_URL__/content/images/2020/09/epicgames-2.png\" width=\"1032\" height=\"1198\" loading=\"lazy\" alt srcset=\"__GHOST_URL__/content/images/size/w600/2020/09/epicgames-2.png 600w, __GHOST_URL__/content/images/size/w1000/2020/09/epicgames-2.png 1000w, __GHOST_URL__/content/images/2020/09/epicgames-2.png 1032w\" sizes=\"(min-width: 720px) 720px\"></div></div></div></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/09/ageoflearning-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1269\" height=\"155\" srcset=\"__GHOST_URL__/content/images/size/w600/2020/09/ageoflearning-1.png 600w, __GHOST_URL__/content/images/size/w1000/2020/09/ageoflearning-1.png 1000w, __GHOST_URL__/content/images/2020/09/ageoflearning-1.png 1269w\" sizes=\"(min-width: 720px) 720px\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/09/ezcater-2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"340\" height=\"80\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/07/uber.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"753\" height=\"274\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/07/uber.png 600w, __GHOST_URL__/content/images/2021/07/uber.png 753w\" sizes=\"(min-width: 720px) 720px\"></figure>","comment_id":"5f6d214f17b26d3ef80d624c","plaintext":"Current:\nPrevious: Enterprise / Software\nPrevious: Consumer / Internet","feature_image":null,"featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-09-24T22:44:31.000Z","updated_at":"2025-10-16T08:06:59.000Z","published_at":"2020-12-03T04:40:25.000Z","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"page","email_recipient_filter":"none"},{"id":"5f6ffd0617b26d3ef80d62bb","uuid":"6fcea71e-34cd-4ea2-8849-2636ad510dc1","title":"Thank You for Subscribing!","slug":"thank-you-subscribe","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"You'll receive a welcome email from me shortly.\"]]],[1,\"p\",[[0,[],0,\"Check your spam folder if you don't see it (and whitelist me)!\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p>You'll receive a welcome email from me shortly.</p><p>Check your spam folder if you don't see it (and whitelist me)!</p>","comment_id":"5f6ffd0617b26d3ef80d62bb","plaintext":"You'll receive a welcome email from me shortly.\n\nCheck your spam folder if you don't see it (and whitelist me)!","feature_image":null,"featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-09-27T02:46:30.000Z","updated_at":"2022-07-03T21:01:59.000Z","published_at":"2020-09-27T02:48:26.000Z","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"page","email_recipient_filter":"none"},{"id":"5f73972a17b26d3ef80d62cb","uuid":"5d063b9e-e85d-4d67-9ebd-64f6e11ced03","title":"Pre-training via Paraphrasing (Paper Explained)","slug":"pre-training-paraphrasing","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}]],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/09/image-20200927144908141.png\",\"alt\":\"image-20200927144908141\",\"title\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/09/image-20200927144848658.png\",\"alt\":\"image-20200927144848658\",\"title\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/09/image-20200927145026936.png\",\"alt\":\"image-20200927145026936\",\"title\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/09/image-20200927144959013.png\",\"alt\":\"image-20200927144959013\",\"title\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/09/image-20200927145105128.png\",\"alt\":\"image-20200927145105128\",\"title\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/09/image-20200927145133850.png\",\"alt\":\"image-20200927145133850\",\"title\":\"\"}]],\"markups\":[[\"em\"],[\"strong\"],[\"a\",[\"href\",\"https://ai.facebook.com/people/mike-lewis/\"]],[\"a\",[\"href\",\"https://www.linkedin.com/in/marjan-ghazvininejad/\"]],[\"a\",[\"href\",\"https://www.linkedin.com/in/gargi-ghosh-5b1087b/\"]],[\"a\",[\"href\",\"https://www.linkedin.com/in/armenag/\"]],[\"a\",[\"href\",\"https://www.linkedin.com/in/sidaw/\"]],[\"a\",[\"href\",\"https://twitter.com/lukezettlemoyer\"]],[\"a\",[\"href\",\"http://arxiv.org/abs/2006.15020\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/1706.03762\"]],[\"a\",[\"href\",\"http://jalammar.github.io/illustrated-transformer/\"]],[\"a\",[\"href\",\"https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html\"]],[\"a\",[\"href\",\"https://commoncrawl.org/2016/10/news-dataset-available/\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/1810.04805?source=post_page\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/1901.07291\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/1911.02116\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/1909.00437\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/2001.08210\"]],[\"a\",[\"href\",\"http://www.statmt.org/wmt19/\"]],[\"a\",[\"href\",\"https://comparable.limsi.fr/bucc2018/bucc2018-task.html\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/2004.14900\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/ROUGE_(metric)\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/1910.07475\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/1908.11828\"]]],\"sections\":[[1,\"p\",[]],[1,\"p\",[[0,[0],1,\"(I'm trying something new: summarizing and explaining technical research papers I come across. I spend a ton of free time reading these so I figure why not put some of that time spent to good use? Hoping this benefits others who are knee-deep in machine learning and econometric research.)\"]]],[1,\"p\",[[0,[1],1,\"Title:\"],[0,[],0,\" Pre-training via Paraphrasing\"]]],[1,\"p\",[[0,[1],1,\"Authors:\"],[0,[],0,\" \"],[0,[2],1,\"Mike Lewis\"],[0,[],0,\", \"],[0,[3],1,\"Marjan Ghazvininejad\"],[0,[],0,\", \"],[0,[4],1,\"Gargi Ghosh\"],[0,[],0,\", \"],[0,[5],1,\"Armen Aghajanyan\"],[0,[],0,\", \"],[0,[6],1,\"Sida Wang\"],[0,[],0,\", \"],[0,[7],1,\"Luke Zettlemoyer\"],[0,[],0,\" (all of Facebook AI)\"]]],[1,\"p\",[[0,[1],1,\"One sentence summary:\"],[0,[],0,\" Transformer model pre-trained on document retrieval and reconstruction performs surprisingly well on wide range of fine-tuned and zero-shot / unsupervised downstream tasks\"]]],[1,\"p\",[[0,[1],1,\"Source:\"],[0,[],0,\" \"],[0,[8],1,\"http://arxiv.org/abs/2006.15020\"]]],[1,\"p\",[[0,[1],1,\"Compression:\"],[0,[],0,\" 10 pages (original ex. references and appendix) -> 3.5 pages (this article)\"]]],[1,\"h2\",[[0,[],0,\"Summary\"]]],[1,\"p\",[[0,[],0,\"\\\"\"],[0,[8],1,\"Pre-training via Paraphrasing\"],[0,[],0,\"\\\" introduces \"],[0,[1],1,\"MARGE\"],[0,[],0,\", a \"],[0,[1],1,\"Multilingual Autoencoder that Retrieves and Generates\"],[0,[],0,\". In this architecture, a \"],[0,[0],1,\"retrieval model\"],[0,[],0,\" is trained to score the relevancy of batches of \\\"evidence\\\" documents \\\\(z_{1...M}\\\\) based on their similarity to a \\\"target\\\" document \\\\(x\\\\). Simultaneously, a \"],[0,[0],1,\"reconstruction model\"],[0,[],0,\" is trained to reconstruct the original target document conditioning on the evidence documents and their relevance scores from the retrieval model. This back-and-forth emulates the behavior of an autoencoder (or even a denoising autoencoder) whereby the mapping of target document to evidence documents serves as an \"],[0,[0],1,\"information bottleneck\"],[0,[],0,\" forcing the model to learn document representations that will best enable the reconstruction of the input document.\"]]],[1,\"p\",[[0,[],0,\"Once pre-trained on this \\\"paraphrasing\\\" task, MARGE can then be leveraged for downstream tasks like sentence retrieval, machine translation, summarization, paraphrasing, and question answering. Even with no fine-tuning (i.e. \\\"zero-shot\\\"), the model demonstrates impressive performance on these tasks. Performance improves meaningfully with task-specific fine-tuning.\"]]],[1,\"h2\",[[0,[],0,\"Key results and takeaways\"]]],[3,\"ul\",[[[0,[],0,\"Transformer-based model pre-trained on retrieval / reconstruction performs admirably across multiple downstream generative and discriminative tasks, \"],[0,[1],1,\"including state of the art (SOTA) results on some tasks\"]],[[0,[1],1,\"Achieves BLEU scores of up to 35.8\"],[0,[],0,\" on zero-shot unsupervised document translation with no task-specific fine-tuning\"]],[[0,[],0,\"Outperforms other unsupervised models on unsupervised cross-lingual sentence retrieval by large margin\"]],[[0,[],0,\"Impressively, \"],[0,[1],1,\"model is trainable from random initialization\"],[0,[],0,\" despite \\\"chicken-and-egg\\\" problem of retrieval and reconstruction models being co-dependent\"]]]],[1,\"h2\",[[0,[],0,\"Methodology\"]]],[1,\"p\",[[0,[],0,\"Retrieval and reconstruction together act as an \"],[0,[0],1,\"autoencoder\"],[0,[],0,\". The retrieved documents act as a noisy representation of the input, and this process serves as an information bottleneck for the algorithm (an encoder). The meaning of the original input is therefore encoded in these documents via the choice of which documents to retrieve along with the relevance score assigned to each. This mapping of input to retrieved documents is the \\\"encoder\\\" of the autoencoder. The reconstruction of the input via the retrieved documents is effectively the decoder.\"]]],[1,\"p\",[[0,[],0,\"Both the encoder and decoder here have a \"],[0,[9],1,\"Transformer\"],[0,[],0,\"-like architecture with \"],[0,[10],1,\"multi-headed attention\"],[0,[],0,\" calculated across multiple layers.\"]]],[1,\"h3\",[[0,[],0,\"Retrieval model\"]]],[1,\"p\",[[0,[],0,\"The input to the MARGE model is a batch of \\\"evidence\\\" (the documents to be retrieved) and a \\\"target\\\" (the document to be reconstructed). Batches are created by:\"]]],[3,\"ul\",[[[0,[],0,\"sharding the document dataset into groups of potentially documents using heuristics like publication date\"]],[[0,[],0,\"taking the \\\\(k\\\\) evidence documents within the shard most similar to the target document (according to \\\\(f(x,z)\\\\) below)\"]],[[0,[],0,\"including a subset of these \\\\(k\\\\) documents in the batch, weighting documents in other languages more than same-language documents\"]]]],[1,\"p\",[[0,[],0,\"Batches are dropped and regenerated offline every 10K training steps by re-computing the pairwise relevance scores across documents.\"]]],[1,\"p\",[[0,[],0,\"The retrieval model compares candidate documents by computing a pairwise relevance score \\\\(f(x, z)\\\\) between a target document \\\\(x\\\\) and evidence document \\\\(z\\\\) from the corpus. This takes the form of the cosine similarity of the documents, encoded by a function \\\\(g(\\\\cdot)\\\\), which takes the form of the first token of a 4-layer Transformer network:\"]]],[1,\"p\",[[0,[],0,\"$$\"],[1,[],0,0],[0,[],0,\"f(x,z) = \\\\frac{g(x) \\\\cdot g(z)}{|g(x)| |g(z)|}\"],[1,[],0,1],[0,[],0,\"$$\"]]],[1,\"p\",[[0,[],0,\"These relevance scores are used both to select documents to be included in each batch as well as push the model to pay more attention to more similar documents when reconstructing the input, as I'll cover later on.\"]]],[1,\"p\",[[0,[],0,\"Using the same function for both targets and evidence ensures documents with similar words are more likely to be mapped to similar representations, even if the encoding function is largely random (which it will be at initialization).\"]]],[1,\"h3\",[[0,[],0,\"Reconstruction model\"]]],[1,\"p\",[[0,[],0,\"The reconstruction model computes the likelihood of the target document tokens, conditioned on the evidence documents within the batch and associated relevance scores. The vector representations for all evidence documents within each batch are concatenated together into a single vector \\\\(z_{1...M}\\\\) before being used for reconstruction:\"]]],[1,\"p\",[[0,[],0,\"$$\"],[1,[],0,2],[0,[],0,\"L_\\\\theta = - \\\\sum_i \\\\log{p_\\\\theta(x_i|z_{1...M}, f(x_i,z_1), ..., f(x_i,z_M))}\"],[1,[],0,3],[0,[],0,\"$$\"]]],[1,\"p\",[[0,[],0,\"During decoding, attention weights are calculated for each token of the target across the set of concatenated evidence documents, meaning that the weights correspond to the attention the decoder should pay to each token of each evidence document at each time-step, capturing token-wise similarity as in standard \"],[0,[11],1,\"dot-product attention\"],[0,[],0,\". Here however, the relevance scores for each document are added to the attention scores for the tokens from that document, multiplied by a trainable scalar parameter \\\\(\\\\beta\\\\). These biased scores are then softmaxed, yielding the attention weights for each time-step, layer \\\\(l\\\\), and attention head \\\\(h\\\\):\"]]],[1,\"p\",[[0,[],0,\"$$\"],[1,[],0,4],[0,[],0,\"\\\\alpha = softmax_{z_{1...M}}(Q^{lh}(x_i)K^{lh}(z_{1...M}) + \\\\beta f(x_i,z_j)) \\\\in \\\\mathbb{R}^{|x_i| \\\\times \\\\sum_j |z_j|}\"],[1,[],0,5],[0,[],0,\"$$\"]]],[1,\"p\",[[0,[],0,\"Backpropagating the reconstruction loss improves both the reconstruction model and the relevance model via this attention mechanism.\"]]],[1,\"h3\",[[0,[],0,\"Architecture and training\"]]],[1,\"p\",[[0,[],0,\"The model encoder (distinct from the encoder \\\\(g(\\\\cdot)\\\\) used to encode individual documents) is a 12-layer Transformer network with dimension 1024 and feedforward layers of size 4096. The decoder is similar in structure but the feedforward layers there are size 16536 and 4 additional Transformer layers are added to the base with only self-attention (i.e. attention only to other words within the same document) and feedforward layers of size 4096. These supplemental layers allow the words in the target to contextualize locally before doing so across documents. The first four layers of the encoder are used in the relevance model (this is the \\\\(g(\\\\cdot)\\\\) referred to above).\"]]],[1,\"p\",[[0,[],0,\"The model is initially pre-trained on the \"],[0,[12],1,\"CC-NEWS corpus\"],[0,[],0,\" for 1M total steps. At this point, the checkpointed model is referred to as MARGE-NEWS. Then, the authors further pre-train for an additional 100K steps on Wikipedia, referring to the resulting model as MARGE.\"]]],[1,\"p\",[[0,[],0,\"For fine-tuning, a different procedure is used for generation and classification problems. For generation (translation, summarization), the task input is fed into the encoder and the final output is generated by the decoder. For classification, the task input is fed into both the encoder and decoder\"]]],[1,\"p\",[[0,[],0,\"The MARGE model ends up with 963M parameters, more than most of its comparison set of \\\"the strongest available multi-lingual pre-trained models\\\" (\"],[0,[13],1,\"mBERT\"],[0,[],0,\", \"],[0,[14],1,\"XLM\"],[0,[],0,\", \"],[0,[15],1,\"XLM-R\"],[0,[],0,\", \"],[0,[16],1,\"MMTE\"],[0,[],0,\", \"],[0,[17],1,\"mBART\"],[0,[],0,\"), but is trained on fewer languages and a medium-sized dataset and a medium amount of GPU pre-training days:\"]]],[10,0],[1,\"h2\",[[0,[],0,\"Experiments and results\"]]],[1,\"p\",[[0,[],0,\"The papers show the wide applicability of MARGE and its paraphrasing pre-training technique by evaluating its performance across wide array of NLP tasks. MARGE performs well across many tasks, wider than any previous pre-trained model. This includes zero-shot document translation, and performance improves further with fine-tuning. The strong results of MARGE establish retrieval / reconstruction as a viable alternative to MLM for pre-training. The success of the method is partly driven by the higher relatedness of the pre-training task to downstream tasks.\"]]],[1,\"h3\",[[0,[],0,\"Document-Level Machine Translation\"]]],[1,\"p\",[[0,[],0,\"The authors demonstrate the models strong translation performance across a number of language pairs and within both zero-shot and fine-tuned settings, achieving 35.8 BLEU in the case of unsupervised translation from German into English on the \"],[0,[18],1,\"WMT19 dataset\"],[0,[],0,\", the highest score ever achieved by a system trained with no bitext (as in iterative back-translation). Performance does vary significantly by language:\"]]],[10,1],[1,\"p\",[[0,[],0,\"Supervised translation with labeled bitext improves performance further, achieving competitive results against mBART:\"]]],[10,2],[1,\"h3\",[[0,[],0,\"Cross-lingual Sentence Retrieval\"]]],[1,\"p\",[[0,[],0,\"It would make sense that a model trained retrieve similar documents, sometimes in a different language, would perform well on a sentence retrieval task. Confirming this intuition, MARGE outperforms other unsupervised models by almost 10 points on the \"],[0,[19],1,\"BUCC2018 benchmark\"],[0,[],0,\", though the embeddings are tuned somewhat on BUCC development data:\"]]],[10,3],[1,\"h3\",[[0,[],0,\"Summarization\"]]],[1,\"p\",[[0,[],0,\"The authors evaluate the model's performance on monolingual sequence-to-sequence generation via text summarization tasks sourced from the \"],[0,[20],1,\"MLSum\"],[0,[],0,\" dataset. Performance is compared across multiple languages, and the extractive oracle performance level is shown for comparison-sake. What's impressive here is that MARGE's summaries are inherent abstractive - the model is generating summaries in its own words, not simply extracting words from the input text - and yet it manage to outperform an extractive mBERT model on a fundamentally extractive performance metric (\"],[0,[21],1,\"ROUGE-L\"],[0,[],0,\"). This is not trivial to do:\"]]],[10,4],[1,\"h3\",[[0,[],0,\"Question answering and paraphrasing\"]]],[1,\"p\",[[0,[],0,\"The \"],[0,[22],1,\"MLQA dataset\"],[0,[],0,\" is used to test MARGE's performance on question answering. MARGE what over or underperforms XLM-R depending on the language, on average underperforming by a small margin (as measured by F1 score). Paraphrasing is tested on the \"],[0,[23],1,\"PAWS-X paraphrase detection dataset\"],[0,[],0,\", where the model is trained on English and zero-shot transfer is tested on other languages. MARGE demonstrates SOTA performance relative to XLM-R:\"]]],[10,5],[1,\"h2\",[[0,[],0,\"Conclusion\"]]],[1,\"p\",[[0,[],0,\"I think this is an interesting paper mainly due to its demonstration of a new pre-training methodology that appears to work as well as masked language modeling for NLP-related tasks. The literature around pre-training grows daily, but I think we've only really scratched the surface of potential pre-training methods. That's why I'm excited to see some new blood in NLP pre-training, which has been dominated by masked language modeling a la BERT.\"]]],[1,\"p\",[[0,[],0,\"That said, the paper involves \"],[0,[0],1,\"some\"],[0,[],0,\" hackery that seems necessary to get the model to train. This includes the heuristics that are used to group documents into relevant batches to retrieve from (which is inherently non-differentiable) as well as others tricks like encouraging cross-lingual behavior via hardcoded overweighting of cross-lingual documents in the collected batches. These tricks act as a sort of \\\"intelligent design\\\" mechanism which is not uncommon in deep learning but does mean that the model is not entirely trainable end-to-end via gradient descent (though it mostly is).\"]]],[1,\"p\",[[0,[],0,\"Additionally, these steps are outlined in the paper but due to limitations of the human language are not easily replicable solely via the paper's explanation. The authors would need to open source the underlying model code for others to replicate and verify these results.\"]]],[1,\"p\",[[0,[],0,\"Model-specific training and architectural hacks aside, MARGE's performance is quite impressive and adds a new feather in the pre-training quiver for NLP models.\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p></p><p><em>(I'm trying something new: summarizing and explaining technical research papers I come across. I spend a ton of free time reading these so I figure why not put some of that time spent to good use? Hoping this benefits others who are knee-deep in machine learning and econometric research.)</em></p><p><strong>Title:</strong> Pre-training via Paraphrasing</p><p><strong>Authors:</strong> <a href=\"https://ai.facebook.com/people/mike-lewis/\">Mike Lewis</a>, <a href=\"https://www.linkedin.com/in/marjan-ghazvininejad/\">Marjan Ghazvininejad</a>, <a href=\"https://www.linkedin.com/in/gargi-ghosh-5b1087b/\">Gargi Ghosh</a>, <a href=\"https://www.linkedin.com/in/armenag/\">Armen Aghajanyan</a>, <a href=\"https://www.linkedin.com/in/sidaw/\">Sida Wang</a>, <a href=\"https://twitter.com/lukezettlemoyer\">Luke Zettlemoyer</a> (all of Facebook AI)</p><p><strong>One sentence summary:</strong> Transformer model pre-trained on document retrieval and reconstruction performs surprisingly well on wide range of fine-tuned and zero-shot / unsupervised downstream tasks</p><p><strong>Source:</strong> <a href=\"http://arxiv.org/abs/2006.15020\">http://arxiv.org/abs/2006.15020</a></p><p><strong>Compression:</strong> 10 pages (original ex. references and appendix) -&gt; 3.5 pages (this article)</p><h2 id=\"summary\">Summary</h2><p>\"<a href=\"http://arxiv.org/abs/2006.15020\">Pre-training via Paraphrasing</a>\" introduces <strong>MARGE</strong>, a <strong>Multilingual Autoencoder that Retrieves and Generates</strong>. In this architecture, a <em>retrieval model</em> is trained to score the relevancy of batches of \"evidence\" documents \\(z_{1...M}\\) based on their similarity to a \"target\" document \\(x\\). Simultaneously, a <em>reconstruction model</em> is trained to reconstruct the original target document conditioning on the evidence documents and their relevance scores from the retrieval model. This back-and-forth emulates the behavior of an autoencoder (or even a denoising autoencoder) whereby the mapping of target document to evidence documents serves as an <em>information bottleneck</em> forcing the model to learn document representations that will best enable the reconstruction of the input document.</p><p>Once pre-trained on this \"paraphrasing\" task, MARGE can then be leveraged for downstream tasks like sentence retrieval, machine translation, summarization, paraphrasing, and question answering. Even with no fine-tuning (i.e. \"zero-shot\"), the model demonstrates impressive performance on these tasks. Performance improves meaningfully with task-specific fine-tuning.</p><h2 id=\"key-results-and-takeaways\">Key results and takeaways</h2><ul><li>Transformer-based model pre-trained on retrieval / reconstruction performs admirably across multiple downstream generative and discriminative tasks, <strong>including state of the art (SOTA) results on some tasks</strong></li><li><strong>Achieves BLEU scores of up to 35.8</strong> on zero-shot unsupervised document translation with no task-specific fine-tuning</li><li>Outperforms other unsupervised models on unsupervised cross-lingual sentence retrieval by large margin</li><li>Impressively, <strong>model is trainable from random initialization</strong> despite \"chicken-and-egg\" problem of retrieval and reconstruction models being co-dependent</li></ul><h2 id=\"methodology\">Methodology</h2><p>Retrieval and reconstruction together act as an <em>autoencoder</em>. The retrieved documents act as a noisy representation of the input, and this process serves as an information bottleneck for the algorithm (an encoder). The meaning of the original input is therefore encoded in these documents via the choice of which documents to retrieve along with the relevance score assigned to each. This mapping of input to retrieved documents is the \"encoder\" of the autoencoder. The reconstruction of the input via the retrieved documents is effectively the decoder.</p><p>Both the encoder and decoder here have a <a href=\"https://arxiv.org/abs/1706.03762\">Transformer</a>-like architecture with <a href=\"http://jalammar.github.io/illustrated-transformer/\">multi-headed attention</a> calculated across multiple layers.</p><h3 id=\"retrieval-model\">Retrieval model</h3><p>The input to the MARGE model is a batch of \"evidence\" (the documents to be retrieved) and a \"target\" (the document to be reconstructed). Batches are created by:</p><ul><li>sharding the document dataset into groups of potentially documents using heuristics like publication date</li><li>taking the \\(k\\) evidence documents within the shard most similar to the target document (according to \\(f(x,z)\\) below)</li><li>including a subset of these \\(k\\) documents in the batch, weighting documents in other languages more than same-language documents</li></ul><p>Batches are dropped and regenerated offline every 10K training steps by re-computing the pairwise relevance scores across documents.</p><p>The retrieval model compares candidate documents by computing a pairwise relevance score \\(f(x, z)\\) between a target document \\(x\\) and evidence document \\(z\\) from the corpus. This takes the form of the cosine similarity of the documents, encoded by a function \\(g(\\cdot)\\), which takes the form of the first token of a 4-layer Transformer network:</p><p>$$<br>f(x,z) = \\frac{g(x) \\cdot g(z)}{|g(x)| |g(z)|}<br>$$</p><p>These relevance scores are used both to select documents to be included in each batch as well as push the model to pay more attention to more similar documents when reconstructing the input, as I'll cover later on.</p><p>Using the same function for both targets and evidence ensures documents with similar words are more likely to be mapped to similar representations, even if the encoding function is largely random (which it will be at initialization).</p><h3 id=\"reconstruction-model\">Reconstruction model</h3><p>The reconstruction model computes the likelihood of the target document tokens, conditioned on the evidence documents within the batch and associated relevance scores. The vector representations for all evidence documents within each batch are concatenated together into a single vector \\(z_{1...M}\\) before being used for reconstruction:</p><p>$$<br>L_\\theta = - \\sum_i \\log{p_\\theta(x_i|z_{1...M}, f(x_i,z_1), ..., f(x_i,z_M))}<br>$$</p><p>During decoding, attention weights are calculated for each token of the target across the set of concatenated evidence documents, meaning that the weights correspond to the attention the decoder should pay to each token of each evidence document at each time-step, capturing token-wise similarity as in standard <a href=\"https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html\">dot-product attention</a>. Here however, the relevance scores for each document are added to the attention scores for the tokens from that document, multiplied by a trainable scalar parameter \\(\\beta\\). These biased scores are then softmaxed, yielding the attention weights for each time-step, layer \\(l\\), and attention head \\(h\\):</p><p>$$<br>\\alpha = softmax_{z_{1...M}}(Q^{lh}(x_i)K^{lh}(z_{1...M}) + \\beta f(x_i,z_j)) \\in \\mathbb{R}^{|x_i| \\times \\sum_j |z_j|}<br>$$</p><p>Backpropagating the reconstruction loss improves both the reconstruction model and the relevance model via this attention mechanism.</p><h3 id=\"architecture-and-training\">Architecture and training</h3><p>The model encoder (distinct from the encoder \\(g(\\cdot)\\) used to encode individual documents) is a 12-layer Transformer network with dimension 1024 and feedforward layers of size 4096. The decoder is similar in structure but the feedforward layers there are size 16536 and 4 additional Transformer layers are added to the base with only self-attention (i.e. attention only to other words within the same document) and feedforward layers of size 4096. These supplemental layers allow the words in the target to contextualize locally before doing so across documents. The first four layers of the encoder are used in the relevance model (this is the \\(g(\\cdot)\\) referred to above).</p><p>The model is initially pre-trained on the <a href=\"https://commoncrawl.org/2016/10/news-dataset-available/\">CC-NEWS corpus</a> for 1M total steps. At this point, the checkpointed model is referred to as MARGE-NEWS. Then, the authors further pre-train for an additional 100K steps on Wikipedia, referring to the resulting model as MARGE.</p><p>For fine-tuning, a different procedure is used for generation and classification problems. For generation (translation, summarization), the task input is fed into the encoder and the final output is generated by the decoder. For classification, the task input is fed into both the encoder and decoder</p><p>The MARGE model ends up with 963M parameters, more than most of its comparison set of \"the strongest available multi-lingual pre-trained models\" (<a href=\"https://arxiv.org/abs/1810.04805?source=post_page\">mBERT</a>, <a href=\"https://arxiv.org/abs/1901.07291\">XLM</a>, <a href=\"https://arxiv.org/abs/1911.02116\">XLM-R</a>, <a href=\"https://arxiv.org/abs/1909.00437\">MMTE</a>, <a href=\"https://arxiv.org/abs/2001.08210\">mBART</a>), but is trained on fewer languages and a medium-sized dataset and a medium amount of GPU pre-training days:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/09/image-20200927144908141.png\" class=\"kg-image\" alt=\"image-20200927144908141\" loading=\"lazy\"></figure><h2 id=\"experiments-and-results\">Experiments and results</h2><p>The papers show the wide applicability of MARGE and its paraphrasing pre-training technique by evaluating its performance across wide array of NLP tasks. MARGE performs well across many tasks, wider than any previous pre-trained model. This includes zero-shot document translation, and performance improves further with fine-tuning. The strong results of MARGE establish retrieval / reconstruction as a viable alternative to MLM for pre-training. The success of the method is partly driven by the higher relatedness of the pre-training task to downstream tasks.</p><h3 id=\"document-level-machine-translation\">Document-Level Machine Translation</h3><p>The authors demonstrate the models strong translation performance across a number of language pairs and within both zero-shot and fine-tuned settings, achieving 35.8 BLEU in the case of unsupervised translation from German into English on the <a href=\"http://www.statmt.org/wmt19/\">WMT19 dataset</a>, the highest score ever achieved by a system trained with no bitext (as in iterative back-translation). Performance does vary significantly by language:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/09/image-20200927144848658.png\" class=\"kg-image\" alt=\"image-20200927144848658\" loading=\"lazy\"></figure><p>Supervised translation with labeled bitext improves performance further, achieving competitive results against mBART:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/09/image-20200927145026936.png\" class=\"kg-image\" alt=\"image-20200927145026936\" loading=\"lazy\"></figure><h3 id=\"cross-lingual-sentence-retrieval\">Cross-lingual Sentence Retrieval</h3><p>It would make sense that a model trained retrieve similar documents, sometimes in a different language, would perform well on a sentence retrieval task. Confirming this intuition, MARGE outperforms other unsupervised models by almost 10 points on the <a href=\"https://comparable.limsi.fr/bucc2018/bucc2018-task.html\">BUCC2018 benchmark</a>, though the embeddings are tuned somewhat on BUCC development data:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/09/image-20200927144959013.png\" class=\"kg-image\" alt=\"image-20200927144959013\" loading=\"lazy\"></figure><h3 id=\"summarization\">Summarization</h3><p>The authors evaluate the model's performance on monolingual sequence-to-sequence generation via text summarization tasks sourced from the <a href=\"https://arxiv.org/abs/2004.14900\">MLSum</a> dataset. Performance is compared across multiple languages, and the extractive oracle performance level is shown for comparison-sake. What's impressive here is that MARGE's summaries are inherent abstractive - the model is generating summaries in its own words, not simply extracting words from the input text - and yet it manage to outperform an extractive mBERT model on a fundamentally extractive performance metric (<a href=\"https://en.wikipedia.org/wiki/ROUGE_(metric)\">ROUGE-L</a>). This is not trivial to do:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/09/image-20200927145105128.png\" class=\"kg-image\" alt=\"image-20200927145105128\" loading=\"lazy\"></figure><h3 id=\"question-answering-and-paraphrasing\">Question answering and paraphrasing</h3><p>The <a href=\"https://arxiv.org/abs/1910.07475\">MLQA dataset</a> is used to test MARGE's performance on question answering. MARGE what over or underperforms XLM-R depending on the language, on average underperforming by a small margin (as measured by F1 score). Paraphrasing is tested on the <a href=\"https://arxiv.org/abs/1908.11828\">PAWS-X paraphrase detection dataset</a>, where the model is trained on English and zero-shot transfer is tested on other languages. MARGE demonstrates SOTA performance relative to XLM-R:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/09/image-20200927145133850.png\" class=\"kg-image\" alt=\"image-20200927145133850\" loading=\"lazy\"></figure><h2 id=\"conclusion\">Conclusion</h2><p>I think this is an interesting paper mainly due to its demonstration of a new pre-training methodology that appears to work as well as masked language modeling for NLP-related tasks. The literature around pre-training grows daily, but I think we've only really scratched the surface of potential pre-training methods. That's why I'm excited to see some new blood in NLP pre-training, which has been dominated by masked language modeling a la BERT.</p><p>That said, the paper involves <em>some</em> hackery that seems necessary to get the model to train. This includes the heuristics that are used to group documents into relevant batches to retrieve from (which is inherently non-differentiable) as well as others tricks like encouraging cross-lingual behavior via hardcoded overweighting of cross-lingual documents in the collected batches. These tricks act as a sort of \"intelligent design\" mechanism which is not uncommon in deep learning but does mean that the model is not entirely trainable end-to-end via gradient descent (though it mostly is).</p><p>Additionally, these steps are outlined in the paper but due to limitations of the human language are not easily replicable solely via the paper's explanation. The authors would need to open source the underlying model code for others to replicate and verify these results.</p><p>Model-specific training and architectural hacks aside, MARGE's performance is quite impressive and adds a new feather in the pre-training quiver for NLP models.</p>","comment_id":"5f73972a17b26d3ef80d62cb","plaintext":"\n\n(I'm trying something new: summarizing and explaining technical research papers\nI come across. I spend a ton of free time reading these so I figure why not put\nsome of that time spent to good use? Hoping this benefits others who are\nknee-deep in machine learning and econometric research.)\n\nTitle: Pre-training via Paraphrasing\n\nAuthors: Mike Lewis [https://ai.facebook.com/people/mike-lewis/], Marjan\nGhazvininejad [https://www.linkedin.com/in/marjan-ghazvininejad/], Gargi Ghosh\n[https://www.linkedin.com/in/gargi-ghosh-5b1087b/], Armen Aghajanyan\n[https://www.linkedin.com/in/armenag/], Sida Wang\n[https://www.linkedin.com/in/sidaw/], Luke Zettlemoyer\n[https://twitter.com/lukezettlemoyer] (all of Facebook AI)\n\nOne sentence summary: Transformer model pre-trained on document retrieval and\nreconstruction performs surprisingly well on wide range of fine-tuned and\nzero-shot / unsupervised downstream tasks\n\nSource: http://arxiv.org/abs/2006.15020\n\nCompression: 10 pages (original ex. references and appendix) -> 3.5 pages (this\narticle)\n\nSummary\n\"Pre-training via Paraphrasing [http://arxiv.org/abs/2006.15020]\" introduces \nMARGE, a Multilingual Autoencoder that Retrieves and Generates. In this\narchitecture, a retrieval model is trained to score the relevancy of batches of\n\"evidence\" documents \\(z_{1...M}\\) based on their similarity to a \"target\"\ndocument \\(x\\). Simultaneously, a reconstruction model is trained to reconstruct\nthe original target document conditioning on the evidence documents and their\nrelevance scores from the retrieval model. This back-and-forth emulates the\nbehavior of an autoencoder (or even a denoising autoencoder) whereby the mapping\nof target document to evidence documents serves as an information bottleneck \nforcing the model to learn document representations that will best enable the\nreconstruction of the input document.\n\nOnce pre-trained on this \"paraphrasing\" task, MARGE can then be leveraged for\ndownstream tasks like sentence retrieval, machine translation, summarization,\nparaphrasing, and question answering. Even with no fine-tuning (i.e.\n\"zero-shot\"), the model demonstrates impressive performance on these tasks.\nPerformance improves meaningfully with task-specific fine-tuning.\n\nKey results and takeaways\n * Transformer-based model pre-trained on retrieval / reconstruction performs\n   admirably across multiple downstream generative and discriminative tasks, \n   including state of the art (SOTA) results on some tasks\n * Achieves BLEU scores of up to 35.8 on zero-shot unsupervised document\n   translation with no task-specific fine-tuning\n * Outperforms other unsupervised models on unsupervised cross-lingual sentence\n   retrieval by large margin\n * Impressively, model is trainable from random initialization despite\n   \"chicken-and-egg\" problem of retrieval and reconstruction models being\n   co-dependent\n\nMethodology\nRetrieval and reconstruction together act as an autoencoder. The retrieved\ndocuments act as a noisy representation of the input, and this process serves as\nan information bottleneck for the algorithm (an encoder). The meaning of the\noriginal input is therefore encoded in these documents via the choice of which\ndocuments to retrieve along with the relevance score assigned to each. This\nmapping of input to retrieved documents is the \"encoder\" of the autoencoder. The\nreconstruction of the input via the retrieved documents is effectively the\ndecoder.\n\nBoth the encoder and decoder here have a Transformer\n[https://arxiv.org/abs/1706.03762]-like architecture with multi-headed attention\n[http://jalammar.github.io/illustrated-transformer/] calculated across multiple\nlayers.\n\nRetrieval model\nThe input to the MARGE model is a batch of \"evidence\" (the documents to be\nretrieved) and a \"target\" (the document to be reconstructed). Batches are\ncreated by:\n\n * sharding the document dataset into groups of potentially documents using\n   heuristics like publication date\n * taking the \\(k\\) evidence documents within the shard most similar to the\n   target document (according to \\(f(x,z)\\) below)\n * including a subset of these \\(k\\) documents in the batch, weighting documents\n   in other languages more than same-language documents\n\nBatches are dropped and regenerated offline every 10K training steps by\nre-computing the pairwise relevance scores across documents.\n\nThe retrieval model compares candidate documents by computing a pairwise\nrelevance score \\(f(x, z)\\) between a target document \\(x\\) and evidence\ndocument \\(z\\) from the corpus. This takes the form of the cosine similarity of\nthe documents, encoded by a function \\(g(\\cdot)\\), which takes the form of the\nfirst token of a 4-layer Transformer network:\n\n$$\nf(x,z) = \\frac{g(x) \\cdot g(z)}{|g(x)| |g(z)|}\n$$\n\nThese relevance scores are used both to select documents to be included in each\nbatch as well as push the model to pay more attention to more similar documents\nwhen reconstructing the input, as I'll cover later on.\n\nUsing the same function for both targets and evidence ensures documents with\nsimilar words are more likely to be mapped to similar representations, even if\nthe encoding function is largely random (which it will be at initialization).\n\nReconstruction model\nThe reconstruction model computes the likelihood of the target document tokens,\nconditioned on the evidence documents within the batch and associated relevance\nscores. The vector representations for all evidence documents within each batch\nare concatenated together into a single vector \\(z_{1...M}\\) before being used\nfor reconstruction:\n\n$$\nL_\\theta = - \\sum_i \\log{p_\\theta(x_i|z_{1...M}, f(x_i,z_1), ..., f(x_i,z_M))}\n$$\n\nDuring decoding, attention weights are calculated for each token of the target\nacross the set of concatenated evidence documents, meaning that the weights\ncorrespond to the attention the decoder should pay to each token of each\nevidence document at each time-step, capturing token-wise similarity as in\nstandard dot-product attention\n[https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html]. Here\nhowever, the relevance scores for each document are added to the attention\nscores for the tokens from that document, multiplied by a trainable scalar\nparameter \\(\\beta\\). These biased scores are then softmaxed, yielding the\nattention weights for each time-step, layer \\(l\\), and attention head \\(h\\):\n\n$$\n\\alpha = softmax_{z_{1...M}}(Q^{lh}(x_i)K^{lh}(z_{1...M}) + \\beta f(x_i,z_j))\n\\in \\mathbb{R}^{|x_i| \\times \\sum_j |z_j|}\n$$\n\nBackpropagating the reconstruction loss improves both the reconstruction model\nand the relevance model via this attention mechanism.\n\nArchitecture and training\nThe model encoder (distinct from the encoder \\(g(\\cdot)\\) used to encode\nindividual documents) is a 12-layer Transformer network with dimension 1024 and\nfeedforward layers of size 4096. The decoder is similar in structure but the\nfeedforward layers there are size 16536 and 4 additional Transformer layers are\nadded to the base with only self-attention (i.e. attention only to other words\nwithin the same document) and feedforward layers of size 4096. These\nsupplemental layers allow the words in the target to contextualize locally\nbefore doing so across documents. The first four layers of the encoder are used\nin the relevance model (this is the \\(g(\\cdot)\\) referred to above).\n\nThe model is initially pre-trained on the CC-NEWS corpus\n[https://commoncrawl.org/2016/10/news-dataset-available/] for 1M total steps. At\nthis point, the checkpointed model is referred to as MARGE-NEWS. Then, the\nauthors further pre-train for an additional 100K steps on Wikipedia, referring\nto the resulting model as MARGE.\n\nFor fine-tuning, a different procedure is used for generation and classification\nproblems. For generation (translation, summarization), the task input is fed\ninto the encoder and the final output is generated by the decoder. For\nclassification, the task input is fed into both the encoder and decoder\n\nThe MARGE model ends up with 963M parameters, more than most of its comparison\nset of \"the strongest available multi-lingual pre-trained models\" (mBERT\n[https://arxiv.org/abs/1810.04805?source=post_page], XLM\n[https://arxiv.org/abs/1901.07291], XLM-R [https://arxiv.org/abs/1911.02116], \nMMTE [https://arxiv.org/abs/1909.00437], mBART\n[https://arxiv.org/abs/2001.08210]), but is trained on fewer languages and a\nmedium-sized dataset and a medium amount of GPU pre-training days:\n\nExperiments and results\nThe papers show the wide applicability of MARGE and its paraphrasing\npre-training technique by evaluating its performance across wide array of NLP\ntasks. MARGE performs well across many tasks, wider than any previous\npre-trained model. This includes zero-shot document translation, and performance\nimproves further with fine-tuning. The strong results of MARGE establish\nretrieval / reconstruction as a viable alternative to MLM for pre-training. The\nsuccess of the method is partly driven by the higher relatedness of the\npre-training task to downstream tasks.\n\nDocument-Level Machine Translation\nThe authors demonstrate the models strong translation performance across a\nnumber of language pairs and within both zero-shot and fine-tuned settings,\nachieving 35.8 BLEU in the case of unsupervised translation from German into\nEnglish on the WMT19 dataset [http://www.statmt.org/wmt19/], the highest score\never achieved by a system trained with no bitext (as in iterative\nback-translation). Performance does vary significantly by language:\n\nSupervised translation with labeled bitext improves performance further,\nachieving competitive results against mBART:\n\nCross-lingual Sentence Retrieval\nIt would make sense that a model trained retrieve similar documents, sometimes\nin a different language, would perform well on a sentence retrieval task.\nConfirming this intuition, MARGE outperforms other unsupervised models by almost\n10 points on the BUCC2018 benchmark\n[https://comparable.limsi.fr/bucc2018/bucc2018-task.html], though the embeddings\nare tuned somewhat on BUCC development data:\n\nSummarization\nThe authors evaluate the model's performance on monolingual sequence-to-sequence\ngeneration via text summarization tasks sourced from the MLSum\n[https://arxiv.org/abs/2004.14900] dataset. Performance is compared across\nmultiple languages, and the extractive oracle performance level is shown for\ncomparison-sake. What's impressive here is that MARGE's summaries are inherent\nabstractive - the model is generating summaries in its own words, not simply\nextracting words from the input text - and yet it manage to outperform an\nextractive mBERT model on a fundamentally extractive performance metric (ROUGE-L\n[https://en.wikipedia.org/wiki/ROUGE_(metric)]). This is not trivial to do:\n\nQuestion answering and paraphrasing\nThe MLQA dataset [https://arxiv.org/abs/1910.07475] is used to test MARGE's\nperformance on question answering. MARGE what over or underperforms XLM-R\ndepending on the language, on average underperforming by a small margin (as\nmeasured by F1 score). Paraphrasing is tested on the PAWS-X paraphrase\ndetection\ndataset [https://arxiv.org/abs/1908.11828], where the model is trained on\nEnglish and zero-shot transfer is tested on other languages. MARGE demonstrates\nSOTA performance relative to XLM-R:\n\nConclusion\nI think this is an interesting paper mainly due to its demonstration of a new\npre-training methodology that appears to work as well as masked language\nmodeling for NLP-related tasks. The literature around pre-training grows daily,\nbut I think we've only really scratched the surface of potential pre-training\nmethods. That's why I'm excited to see some new blood in NLP pre-training, which\nhas been dominated by masked language modeling a la BERT.\n\nThat said, the paper involves some hackery that seems necessary to get the model\nto train. This includes the heuristics that are used to group documents into\nrelevant batches to retrieve from (which is inherently non-differentiable) as\nwell as others tricks like encouraging cross-lingual behavior via hardcoded\noverweighting of cross-lingual documents in the collected batches. These tricks\nact as a sort of \"intelligent design\" mechanism which is not uncommon in deep\nlearning but does mean that the model is not entirely trainable end-to-end via\ngradient descent (though it mostly is).\n\nAdditionally, these steps are outlined in the paper but due to limitations of\nthe human language are not easily replicable solely via the paper's explanation.\nThe authors would need to open source the underlying model code for others to\nreplicate and verify these results.\n\nModel-specific training and architectural hacks aside, MARGE's performance is\nquite impressive and adds a new feather in the pre-training quiver for NLP\nmodels.","feature_image":"__GHOST_URL__/content/images/2021/07/image-20200927143543270.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-09-29T20:20:58.000Z","updated_at":"2021-07-20T03:10:15.000Z","published_at":"2020-09-29T21:03:16.000Z","custom_excerpt":"Transformer model pre-trained on document retrieval and reconstruction performs well on both fine-tuned and zero-shot downstream tasks","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5f7a463517b26d3ef80d635a","uuid":"6525f28f-e1c3-4029-8ff7-cec5d2b0fa07","title":"An Image is Worth 16x16 Words: Transformers for Image Recognition (Paper Explained)","slug":"transformers-image-recognition","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}]],\"cards\":[[\"embed\",{\"url\":\"https://twitter.com/karpathy/status/1312279279741276161\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale <a href=\\\"https://t.co/r5a0RuWyZE\\\">https://t.co/r5a0RuWyZE</a> v cool. Further steps towards deprecating ConvNets with Transformers. Loving the increasing convergence of Vision/NLP and the much more efficient/flexible class of architectures. <a href=\\\"https://t.co/muj3cR6uGA\\\">pic.twitter.com/muj3cR6uGA</a></p>&mdash; Andrej Karpathy (@karpathy) <a href=\\\"https://twitter.com/karpathy/status/1312279279741276161?ref_src=twsrc%5Etfw\\\">October 3, 2020</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\"}],[\"image\",{\"src\":\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2F2OSKlMdMu4.png?alt=media&token=96665b64-59c0-49e6-9620-4e2ed5c194a9\",\"alt\":\"img\",\"title\":\"\"}],[\"image\",{\"src\":\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2F48LEQrPHie.png?alt=media&token=ea615283-6f31-4f55-adfd-c56daed993cf\",\"alt\":\"img\",\"title\":\"\"}],[\"image\",{\"src\":\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2FGRzsbFb6vJ.png?alt=media&token=1aec9a71-1329-4340-92ca-de961f4e0f2c\",\"alt\":\"img\",\"title\":\"\"}],[\"image\",{\"src\":\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2FXwJwDr5hc7.png?alt=media&token=e301e7d6-acfd-4720-adc3-41756e4d92c1\",\"alt\":\"img\",\"title\":\"\"}],[\"image\",{\"src\":\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2FNTp0HNzd1y.png?alt=media&token=fc2114ab-293b-46b5-9865-173e36146697\",\"alt\":\"img\",\"title\":\"\"}],[\"image\",{\"src\":\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2F3WDSyMFDSj.png?alt=media&token=0df75f5f-c3bd-4f74-92a8-d6d1398bbd2b\",\"alt\":\"img\",\"title\":\"\"}],[\"image\",{\"src\":\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2FdUY64eIB3n.png?alt=media&token=6ce00cb5-cf21-43ae-a904-6e69ac2854d4\",\"alt\":\"img\",\"title\":\"\"}]],\"markups\":[[\"strong\"],[\"a\",[\"href\",\"https://openreview.net/forum?id=YicbFdNTTy\"]],[\"a\",[\"href\",\"https://iclr.cc/\"]],[\"a\",[\"href\",\"https://openreview.net/forum?id=YicbFdNTT\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/1706.03762\"]],[\"a\",[\"href\",\"http://www.image-net.org/\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/1707.02968\"]],[\"a\",[\"href\",\"https://twitter.com/karpathy\"]],[\"em\"],[\"a\",[\"href\",\"https://arxiv.org/abs/1810.04805\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/1912.11370\"]]],\"sections\":[[1,\"p\",[]],[3,\"ul\",[[[0,[0],1,\"Title:\"],[0,[],0,\" \"],[0,[1],1,\"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\"]],[[0,[0],1,\"Authors:\"],[0,[],0,\" Anonymous (Paper currently in blind review for \"],[0,[2],1,\"ICLR 2021\"],[0,[],0,\")\"]],[[0,[0],1,\"One sentence summary:\"],[0,[],0,\" Large Transformer trained on large datasets outperform CNN-based architectures and achieve state of the art results on image recognition tasks\"]],[[0,[0],1,\"Source:\"],[0,[],0,\" \"],[0,[1],1,\"https://openreview.net/forum?id=YicbFdNTTy\"]],[[0,[0],1,\"Compression:\"],[0,[],0,\" 8 pages (original ex. references and appendix) -> 3.75 pages (this article)\"]]]],[1,\"h2\",[[0,[0],1,\"Summary\"]]],[1,\"p\",[[0,[],0,\"\\\"\"],[0,[3],1,\"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\"],[0,[],0,\"\\\" introduces the Visual Transformer, an architecture which leverages mostly standard Transformer components from the original NLP-focused \\\"\"],[0,[4],1,\"Attention is All You Need\"],[0,[],0,\"\\\" paper but instead applies them to computer vision, specifically image recognition. Images are transformed into sequences of image patches representing \\\"tokens,\\\" similar to word tokens in NLP. The model is trained in supervised fashion on image classification using these patch sequences as input.\"]]],[1,\"p\",[[0,[],0,\"The image-based Transformer does not outperform CNNs when trained on mid-sized datasets such as \"],[0,[5],1,\"ImageNet\"],[0,[],0,\", underperforming similar-sized ResNet models. This is likely due to an inability overcome the inherent advantage of CNNs (inductive biases like translational equivariance and locality). However, when the Transformer model is pre-trained on large image datasets (specifically, \"],[0,[6],1,\"JFT\"],[0,[],0,\") and transferred to other tasks, the model achieves SOTA results.\"]]],[1,\"p\",[[0,[],0,\"The strong results suggest the long hoped-for convergence of architectures across NLP and computer vision may finally be here in the form of Transformers. Per \"],[0,[7],1,\"Andrej Karpathy\"],[0,[],0,\", Director of AI at Tesla:\"]]],[10,0],[1,\"h2\",[[0,[0],1,\"Key results and takeaways\"]]],[3,\"ul\",[[[0,[0],1,\"Large Vision Transformer model mapping patches of image to classification labels outperforms CNN-based architectures and achieves state of the art results\"],[0,[],0,\" when trained on large (100M+ images) datasets\"]],[[0,[],0,\"Transformer model \"],[0,[0],1,\"underperforms CNNs when only trained on mid-sized datasets\"]],[[0,[0],1,\"Early layers of the Vision Transformer are able to attend to large chunks of the image\"],[0,[],0,\", unlike traditional convolutional layers with are constrained to a local window\"]],[[0,[],0,\"Self-supervised pre-training with \\\"\"],[0,[8],1,\"masked patch prediction\"],[0,[],0,\"\\\" achieves decent results but \"],[0,[0],1,\"underperforms supervised pre-training\"]]]],[1,\"h2\",[[0,[0],1,\"Methodology\"]]],[1,\"h3\",[[0,[0],1,\"Architecture\"]]],[1,\"p\",[[0,[],0,\"The model effectively analogizes between words as tokens of larger sentences and groups of pixels as \\\"tokens\\\" of larger images. Like a sequence of word tokens makes a sentence, a sequence of pixel patches makes an image. Thus, the input image is broken up into multiple patches of \\\\(P^2 \\\\cdot C\\\\) dimensions representing square subsections of the original image (including all color channels \\\\(C\\\\)), forming a sequence of image patches of length \\\\(N\\\\).\"]]],[1,\"p\",[[0,[],0,\"Image patches \\\\(\\\\mathbf{x}_{p}^{n}\\\\), typically 16x16 pixels, are embedded into \\\\(D\\\\) dimension vectors using an embedding matrix \\\\(\\\\textbf{E}\\\\). The sequence of \\\"patch embeddings\\\" is prepended with a learnable \\\\(\\\\texttt{[class]}\\\\) token, similar to \"],[0,[9],1,\"BERT\"],[0,[],0,\", telling the model to classify the image, leaving us  with a \\\\((N+1) \\\\times D\\\\) dimension vector, \\\\(\\\\textbf{z}\\\\).\"]]],[1,\"p\",[[0,[],0,\"The representation of the first token in the output of the final Transformer encoder layer serves as the image representation. The classification head is attached to only this token. Position embeddings are added to the patch embeddings, and these vectors serve as input to the encoder.\"]]],[1,\"p\",[[0,[],0,\"The Transformer architecture is constructed as follows:\"]]],[1,\"p\",[[0,[],0,\"$$\"],[1,[],0,0],[0,[],0,\"\\\\begin{aligned} \"],[1,[],0,1],[0,[],0,\"\\\\mathbf{z}_{0} &=\\\\left[\\\\mathbf{x}_{\\\\text {class }} ; \\\\mathbf{x}_{p}^{1} \\\\mathbf{E} ; \\\\mathbf{x}_{p}^{2} \\\\mathbf{E} ; \\\\cdots ; \\\\mathbf{x}_{p}^{N} \\\\mathbf{E}\\\\right]+\\\\mathbf{E}_{p o s}, & \\\\mathbf{E} \\\\in \\\\mathbb{R}^{\\\\left(P^{2} \\\\cdot C\\\\right) \\\\times D}, \\\\mathbf{E}_{p o s} \\\\in \\\\mathbb{R}^{(N+1) \\\\times D} \"],[1,[],0,2],[0,[],0,\"\\\\\\\\ \\\\mathbf{z}_{\\\\ell}^{\\\\prime} &=\\\\operatorname{MSA}\\\\left(\\\\mathrm{LN}\\\\left(\\\\mathbf{z}_{\\\\ell-1}\\\\right)\\\\right)+\\\\mathbf{z}_{\\\\ell-1}, & \\\\ell =1 \\\\ldots L \"],[1,[],0,3],[0,[],0,\"\\\\\\\\ \\\\mathbf{z}_{\\\\ell} &=\\\\operatorname{MLP}\\\\left(\\\\mathrm{LN}\\\\left(\\\\mathbf{z}_{\\\\ell}^{\\\\prime}\\\\right)\\\\right)+\\\\mathbf{z}_{\\\\ell}^{\\\\prime}, & \\\\ell =1 \\\\ldots L \"],[1,[],0,4],[0,[],0,\"\\\\\\\\ \\\\mathbf{y} &=\\\\operatorname{LN}\\\\left(\\\\mathbf{z}_{L}^{0}\\\\right) \"],[1,[],0,5],[0,[],0,\"\\\\end{aligned}\"],[1,[],0,6],[0,[],0,\"$$\"]]],[1,\"p\",[[0,[],0,\"where \\\\(\\\\mathbf{z}_{\\\\ell}\\\\) represents the patch sequence representation output at each layer \\\\(\\\\ell\\\\) of the network and \\\\(\\\\mathbf{z}_{L}^{0}\\\\) is the first token of the final layer output, which is fed into the classification head with Layer Norm \\\\((\\\\mathrm{LN})\\\\) applied.\"]]],[1,\"p\",[[0,[],0,\"Layer representations \\\\(\\\\mathbf{z}_{\\\\ell}\\\\) are passed through each Transformer block, where Layer Norm and multi-headed self-attention is applied \\\\((\\\\operatorname{MSA})\\\\), a residual skip connection to the previous layer's representation \\\\(\\\\mathbf{z}_{\\\\ell-1}\\\\) added, followed by Layer Norm, and a feed forward layer \\\\((\\\\mathrm{MLP})\\\\) with a residual connection to the intermediate representation, \\\\(\\\\mathbf{z}_{\\\\ell}^{\\\\prime}\\\\).\"]]],[1,\"p\",[[0,[],0,\"The authors construct multiple versions of the model at various scales to compare results across model size, similar to BERT. Base = \\\"B\\\", Large = \\\"L\\\", Huge = \\\"H\\\".\"]]],[10,1],[1,\"p\",[[0,[],0,\"The authors also experiment with a \"],[0,[8],1,\"hybrid\"],[0,[],0,\" architecture, where instead of using patches as the input sequence, the intermediate representation of a ResNet model is used, replacing the patch embedding. The rest of the architecture remains unchanged.\"]]],[1,\"h3\",[[0,[0],1,\"Training\"]]],[1,\"p\",[[0,[],0,\"Models are (pre-)trained on multiple image datasets, including ImageNet (1K classes / 1.3M images), ImageNet-21K (21K classes / 14M images), and JFT (18K classes / 303M images). As the largest dataset, JFT-300M is the main focus of the paper, which we will see enables big performance improvements when used in the largest versions of the architecture. Here, the model is pre-trained for 1M steps. The remaining training hyperparameters can found be found in the paper.\"]]],[1,\"p\",[[0,[],0,\"The Vision Transformer is fine-tuned at higher resolution than pre-training, which helps performance. However, higher resolution images have more pixels, so the patch sequences are longer. Rather than create extra positional embeddings for these additional tokens, the existing embeddings are interpolated such that multiple higher resolution patches correspond to each lower resolution positional embedding. This is necessary as the additional positional embeddings would not have been seen during pre-training and hence would be meaningless if applied directly. This is the only point in which inductive bias about the structure of images enters into the Vision Transformer.\"]]],[1,\"h2\",[[0,[0],1,\"Experiments and results\"]]],[1,\"p\",[[0,[],0,\"The authors choose a number of benchmark tasks for performance evaluation: ImageNet, ImageNet ReaL, CIFAR-10/100, Oxford-IIIT Pets, Oxford Flowers-102, and the 19-task VTAB classification suite.\"]]],[1,\"h3\",[[0,[0],1,\"Performance\"]]],[1,\"p\",[[0,[],0,\"ViT-L/16 matches or outperforms \"],[0,[10],1,\"BiT-L\"],[0,[],0,\" (large ResNet that supports supervised transfer learning) on all datasets with 4-10x fewer computational resources used during pre-training (as measured by TPUv3-days):\"]]],[10,2],[1,\"p\",[[0,[],0,\"This performance advantage disappears if ViT is trained on a smallest dataset, such as ImageNet. Only with the largest dataset, JFT-300M, do larger models outperform all others:\"]]],[10,3],[1,\"p\",[[0,[],0,\"ViT-B/16 and ViT-B/32 do not gain as much from being trained on larger datasets. This alludes to the intuition that the convolutional inductive bias is most useful for smaller datasets. On larger datasets however, learning the patterns directly is better:\"]]],[10,4],[1,\"h3\",[[0,[0],1,\"Performance vs. compute cost\"]]],[1,\"p\",[[0,[],0,\"The Vision Transformer outperforms ResNets in terms of the performance / compute ratio. ViT uses half as much compute to attain the same performance level (x-axis is pre-training exaFLOPs on log scale):\"]]],[10,5],[1,\"p\",[[0,[],0,\"Interestingly, hybrids slightly outperform the Vision Transformer with small computational budgets but not for larger ones. The authors note their surprise at this result, as it might be expected that convolutional feature maps coming from ResNet would be helpful at any scale\"]]],[1,\"h3\",[[0,[0],1,\"Global self-attention\"]]],[1,\"p\",[[0,[],0,\"Self-attention allows the Vision Transformer to integrate information across the entire image, even in the lower Transformer layers. This is unlike CNNs, where only the later layers are able to aggregate information from different parts of the image. Experiments show that the \\\"attention distance\\\" of the attended area is large in the later layers, as expected, but also large in some portion of the earlier layers, demonstrating the ability to learn long-range dependencies. For example, some of the earlier layers heads attend to patches 100 pixels away from on another (right chart below):\"]]],[10,6],[1,\"p\",[[0,[],0,\"The model clearly attends to image regions that are most relevant for classification:\"]]],[10,7],[1,\"h3\",[[0,[0],1,\"Self-supervised pre-training\"]]],[1,\"p\",[[0,[],0,\"The authors experiment with self-supervised pre-training using \\\"\"],[0,[8],1,\"masked patch prediction\"],[0,[],0,\",\\\" mimicking masked language modeling in the NLP context. With this training regimen, ViT-B/16 achieves 79.9% accuracy on ImageNet, a 2% improvement relative to training from scratch, but 4% lower than supervised pre-training used in the rest of the paper.\"]]],[1,\"h2\",[[0,[],0,\"Reflection\"]]],[1,\"p\",[[0,[],0,\"OK, so this is exciting stuff. Personally, I've never liked convolutions, for similar reasons that I've never liked recurrent neural networks. There just something \"],[0,[8],1,\"complicated\"],[0,[],0,\" about them. Something inelegant. I've always loved more linear architectures, largely composed of feedforward layers with various augmentations like normalization or residual skip connections, i.e. Transformers and attention-based networks in general (and yes I know it's possible to rewrite convolutions as affine transforms). So I think it's very cool to finally see this applied to computer vision with strong results.\"]]],[1,\"p\",[[0,[],0,\"I don't know if there were enough ablations to totally prove this, but it seems like insufficient data was the core blocker preventing linear transformations from achieving similar results to CNNs. The inductive biases of CNNs have always been their key advantage, but that advantage seems to wither under the weight of massive global self-attention learned on massive image datasets, at least for image recognition / classification.\"]]],[1,\"p\",[[0,[],0,\"The authors also note that, given performance does not yet appear to saturate with increasing model size, the Vision Transformer could potentially be scaled up even further. Nice.\"]]],[1,\"p\",[[0,[],0,\"A couple wrinkles to point out.\"]]],[1,\"p\",[[0,[],0,\"The paper is currently under double-blind review for conference submission at ICLR 2021, so the authors remain anonymous for now. That said, I'd be shocked if it wasn't Google behind this paper. There are a few tells, like the fact that they use TPUs (Google-specific hardware) for training and the JFT-300M dataset (a Google maintained dataset). As of right now, it doesn't appear the JFT-300M is publicly available -- only Google researchers have access. Therefore, even if the code was made publicly available (which I'm guessing it won't), the results are not replicable. As readers, we have no idea what architectural tricks may have been used that are not made clear by the text of the paper itself, so reproducibility is not guaranteed.\"]]],[1,\"p\",[[0,[],0,\"Second, as some folks on Twitter have noted, using these 16x16 patches as input to the model is likely suboptimal. It's at best a first step and the strong performance of the hybrid version of the model (which uses intermediate ResNet representations as input) suggests as much.\"]]],[1,\"p\",[[0,[],0,\"As noted before, convolutions seems to help most in low-data / compute regimes, helping the model perform better with less training time for all but the largest model and dataset. Future research may reveal better ways to represent the input image while still avoiding the use of convolutions. If I had to guess, as in NLP, self-supervised pre-training will be key.\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p></p><ul><li><strong>Title:</strong> <a href=\"https://openreview.net/forum?id=YicbFdNTTy\">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a></li><li><strong>Authors:</strong> Anonymous (Paper currently in blind review for <a href=\"https://iclr.cc/\">ICLR 2021</a>)</li><li><strong>One sentence summary:</strong> Large Transformer trained on large datasets outperform CNN-based architectures and achieve state of the art results on image recognition tasks</li><li><strong>Source:</strong> <a href=\"https://openreview.net/forum?id=YicbFdNTTy\">https://openreview.net/forum?id=YicbFdNTTy</a></li><li><strong>Compression:</strong> 8 pages (original ex. references and appendix) -&gt; 3.75 pages (this article)</li></ul><h2 id=\"summary\"><strong>Summary</strong></h2><p>\"<a href=\"https://openreview.net/forum?id=YicbFdNTT\">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a>\" introduces the Visual Transformer, an architecture which leverages mostly standard Transformer components from the original NLP-focused \"<a href=\"https://arxiv.org/abs/1706.03762\">Attention is All You Need</a>\" paper but instead applies them to computer vision, specifically image recognition. Images are transformed into sequences of image patches representing \"tokens,\" similar to word tokens in NLP. The model is trained in supervised fashion on image classification using these patch sequences as input.</p><p>The image-based Transformer does not outperform CNNs when trained on mid-sized datasets such as <a href=\"http://www.image-net.org/\">ImageNet</a>, underperforming similar-sized ResNet models. This is likely due to an inability overcome the inherent advantage of CNNs (inductive biases like translational equivariance and locality). However, when the Transformer model is pre-trained on large image datasets (specifically, <a href=\"https://arxiv.org/abs/1707.02968\">JFT</a>) and transferred to other tasks, the model achieves SOTA results.</p><p>The strong results suggest the long hoped-for convergence of architectures across NLP and computer vision may finally be here in the form of Transformers. Per <a href=\"https://twitter.com/karpathy\">Andrej Karpathy</a>, Director of AI at Tesla:</p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale <a href=\"https://t.co/r5a0RuWyZE\">https://t.co/r5a0RuWyZE</a> v cool. Further steps towards deprecating ConvNets with Transformers. Loving the increasing convergence of Vision/NLP and the much more efficient/flexible class of architectures. <a href=\"https://t.co/muj3cR6uGA\">pic.twitter.com/muj3cR6uGA</a></p>&mdash; Andrej Karpathy (@karpathy) <a href=\"https://twitter.com/karpathy/status/1312279279741276161?ref_src=twsrc%5Etfw\">October 3, 2020</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><h2 id=\"key-results-and-takeaways\"><strong>Key results and takeaways</strong></h2><ul><li><strong>Large Vision Transformer model mapping patches of image to classification labels outperforms CNN-based architectures and achieves state of the art results</strong> when trained on large (100M+ images) datasets</li><li>Transformer model <strong>underperforms CNNs when only trained on mid-sized datasets</strong></li><li><strong>Early layers of the Vision Transformer are able to attend to large chunks of the image</strong>, unlike traditional convolutional layers with are constrained to a local window</li><li>Self-supervised pre-training with \"<em>masked patch prediction</em>\" achieves decent results but <strong>underperforms supervised pre-training</strong></li></ul><h2 id=\"methodology\"><strong>Methodology</strong></h2><h3 id=\"architecture\"><strong>Architecture</strong></h3><p>The model effectively analogizes between words as tokens of larger sentences and groups of pixels as \"tokens\" of larger images. Like a sequence of word tokens makes a sentence, a sequence of pixel patches makes an image. Thus, the input image is broken up into multiple patches of \\(P^2 \\cdot C\\) dimensions representing square subsections of the original image (including all color channels \\(C\\)), forming a sequence of image patches of length \\(N\\).</p><p>Image patches \\(\\mathbf{x}_{p}^{n}\\), typically 16x16 pixels, are embedded into \\(D\\) dimension vectors using an embedding matrix \\(\\textbf{E}\\). The sequence of \"patch embeddings\" is prepended with a learnable \\(\\texttt{[class]}\\) token, similar to <a href=\"https://arxiv.org/abs/1810.04805\">BERT</a>, telling the model to classify the image, leaving us Â with a \\((N+1) \\times D\\) dimension vector, \\(\\textbf{z}\\).</p><p>The representation of the first token in the output of the final Transformer encoder layer serves as the image representation. The classification head is attached to only this token. Position embeddings are added to the patch embeddings, and these vectors serve as input to the encoder.</p><p>The Transformer architecture is constructed as follows:</p><p>$$<br>\\begin{aligned} <br>\\mathbf{z}_{0} &amp;=\\left[\\mathbf{x}_{\\text {class }} ; \\mathbf{x}_{p}^{1} \\mathbf{E} ; \\mathbf{x}_{p}^{2} \\mathbf{E} ; \\cdots ; \\mathbf{x}_{p}^{N} \\mathbf{E}\\right]+\\mathbf{E}_{p o s}, &amp; \\mathbf{E} \\in \\mathbb{R}^{\\left(P^{2} \\cdot C\\right) \\times D}, \\mathbf{E}_{p o s} \\in \\mathbb{R}^{(N+1) \\times D} <br>\\\\ \\mathbf{z}_{\\ell}^{\\prime} &amp;=\\operatorname{MSA}\\left(\\mathrm{LN}\\left(\\mathbf{z}_{\\ell-1}\\right)\\right)+\\mathbf{z}_{\\ell-1}, &amp; \\ell =1 \\ldots L <br>\\\\ \\mathbf{z}_{\\ell} &amp;=\\operatorname{MLP}\\left(\\mathrm{LN}\\left(\\mathbf{z}_{\\ell}^{\\prime}\\right)\\right)+\\mathbf{z}_{\\ell}^{\\prime}, &amp; \\ell =1 \\ldots L <br>\\\\ \\mathbf{y} &amp;=\\operatorname{LN}\\left(\\mathbf{z}_{L}^{0}\\right) <br>\\end{aligned}<br>$$</p><p>where \\(\\mathbf{z}_{\\ell}\\) represents the patch sequence representation output at each layer \\(\\ell\\) of the network and \\(\\mathbf{z}_{L}^{0}\\) is the first token of the final layer output, which is fed into the classification head with Layer Norm \\((\\mathrm{LN})\\) applied.</p><p>Layer representations \\(\\mathbf{z}_{\\ell}\\) are passed through each Transformer block, where Layer Norm and multi-headed self-attention is applied \\((\\operatorname{MSA})\\), a residual skip connection to the previous layer's representation \\(\\mathbf{z}_{\\ell-1}\\) added, followed by Layer Norm, and a feed forward layer \\((\\mathrm{MLP})\\) with a residual connection to the intermediate representation, \\(\\mathbf{z}_{\\ell}^{\\prime}\\).</p><p>The authors construct multiple versions of the model at various scales to compare results across model size, similar to BERT. Base = \"B\", Large = \"L\", Huge = \"H\".</p><figure class=\"kg-card kg-image-card\"><img src=\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2F2OSKlMdMu4.png?alt=media&amp;token=96665b64-59c0-49e6-9620-4e2ed5c194a9\" class=\"kg-image\" alt=\"img\" loading=\"lazy\"></figure><p>The authors also experiment with a <em>hybrid</em> architecture, where instead of using patches as the input sequence, the intermediate representation of a ResNet model is used, replacing the patch embedding. The rest of the architecture remains unchanged.</p><h3 id=\"training\"><strong>Training</strong></h3><p>Models are (pre-)trained on multiple image datasets, including ImageNet (1K classes / 1.3M images), ImageNet-21K (21K classes / 14M images), and JFT (18K classes / 303M images). As the largest dataset, JFT-300M is the main focus of the paper, which we will see enables big performance improvements when used in the largest versions of the architecture. Here, the model is pre-trained for 1M steps. The remaining training hyperparameters can found be found in the paper.</p><p>The Vision Transformer is fine-tuned at higher resolution than pre-training, which helps performance. However, higher resolution images have more pixels, so the patch sequences are longer. Rather than create extra positional embeddings for these additional tokens, the existing embeddings are interpolated such that multiple higher resolution patches correspond to each lower resolution positional embedding. This is necessary as the additional positional embeddings would not have been seen during pre-training and hence would be meaningless if applied directly. This is the only point in which inductive bias about the structure of images enters into the Vision Transformer.</p><h2 id=\"experiments-and-results\"><strong>Experiments and results</strong></h2><p>The authors choose a number of benchmark tasks for performance evaluation: ImageNet, ImageNet ReaL, CIFAR-10/100, Oxford-IIIT Pets, Oxford Flowers-102, and the 19-task VTAB classification suite.</p><h3 id=\"performance\"><strong>Performance</strong></h3><p>ViT-L/16 matches or outperforms <a href=\"https://arxiv.org/abs/1912.11370\">BiT-L</a> (large ResNet that supports supervised transfer learning) on all datasets with 4-10x fewer computational resources used during pre-training (as measured by TPUv3-days):</p><figure class=\"kg-card kg-image-card\"><img src=\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2F48LEQrPHie.png?alt=media&amp;token=ea615283-6f31-4f55-adfd-c56daed993cf\" class=\"kg-image\" alt=\"img\" loading=\"lazy\"></figure><p>This performance advantage disappears if ViT is trained on a smallest dataset, such as ImageNet. Only with the largest dataset, JFT-300M, do larger models outperform all others:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2FGRzsbFb6vJ.png?alt=media&amp;token=1aec9a71-1329-4340-92ca-de961f4e0f2c\" class=\"kg-image\" alt=\"img\" loading=\"lazy\"></figure><p>ViT-B/16 and ViT-B/32 do not gain as much from being trained on larger datasets. This alludes to the intuition that the convolutional inductive bias is most useful for smaller datasets. On larger datasets however, learning the patterns directly is better:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2FXwJwDr5hc7.png?alt=media&amp;token=e301e7d6-acfd-4720-adc3-41756e4d92c1\" class=\"kg-image\" alt=\"img\" loading=\"lazy\"></figure><h3 id=\"performance-vs-compute-cost\"><strong>Performance vs. compute cost</strong></h3><p>The Vision Transformer outperforms ResNets in terms of the performance / compute ratio. ViT uses half as much compute to attain the same performance level (x-axis is pre-training exaFLOPs on log scale):</p><figure class=\"kg-card kg-image-card\"><img src=\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2FNTp0HNzd1y.png?alt=media&amp;token=fc2114ab-293b-46b5-9865-173e36146697\" class=\"kg-image\" alt=\"img\" loading=\"lazy\"></figure><p>Interestingly, hybrids slightly outperform the Vision Transformer with small computational budgets but not for larger ones. The authors note their surprise at this result, as it might be expected that convolutional feature maps coming from ResNet would be helpful at any scale</p><h3 id=\"global-self-attention\"><strong>Global self-attention</strong></h3><p>Self-attention allows the Vision Transformer to integrate information across the entire image, even in the lower Transformer layers. This is unlike CNNs, where only the later layers are able to aggregate information from different parts of the image. Experiments show that the \"attention distance\" of the attended area is large in the later layers, as expected, but also large in some portion of the earlier layers, demonstrating the ability to learn long-range dependencies. For example, some of the earlier layers heads attend to patches 100 pixels away from on another (right chart below):</p><figure class=\"kg-card kg-image-card\"><img src=\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2F3WDSyMFDSj.png?alt=media&amp;token=0df75f5f-c3bd-4f74-92a8-d6d1398bbd2b\" class=\"kg-image\" alt=\"img\" loading=\"lazy\"></figure><p>The model clearly attends to image regions that are most relevant for classification:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2FdUY64eIB3n.png?alt=media&amp;token=6ce00cb5-cf21-43ae-a904-6e69ac2854d4\" class=\"kg-image\" alt=\"img\" loading=\"lazy\"></figure><h3 id=\"self-supervised-pre-training\"><strong>Self-supervised pre-training</strong></h3><p>The authors experiment with self-supervised pre-training using \"<em>masked patch prediction</em>,\" mimicking masked language modeling in the NLP context. With this training regimen, ViT-B/16 achieves 79.9% accuracy on ImageNet, a 2% improvement relative to training from scratch, but 4% lower than supervised pre-training used in the rest of the paper.</p><h2 id=\"reflection\">Reflection</h2><p>OK, so this is exciting stuff. Personally, I've never liked convolutions, for similar reasons that I've never liked recurrent neural networks. There just something <em>complicated</em> about them. Something inelegant. I've always loved more linear architectures, largely composed of feedforward layers with various augmentations like normalization or residual skip connections, i.e. Transformers and attention-based networks in general (and yes I know it's possible to rewrite convolutions as affine transforms). So I think it's very cool to finally see this applied to computer vision with strong results.</p><p>I don't know if there were enough ablations to totally prove this, but it seems like insufficient data was the core blocker preventing linear transformations from achieving similar results to CNNs. The inductive biases of CNNs have always been their key advantage, but that advantage seems to wither under the weight of massive global self-attention learned on massive image datasets, at least for image recognition / classification.</p><p>The authors also note that, given performance does not yet appear to saturate with increasing model size, the Vision Transformer could potentially be scaled up even further. Nice.</p><p>A couple wrinkles to point out.</p><p>The paper is currently under double-blind review for conference submission at ICLR 2021, so the authors remain anonymous for now. That said, I'd be shocked if it wasn't Google behind this paper. There are a few tells, like the fact that they use TPUs (Google-specific hardware) for training and the JFT-300M dataset (a Google maintained dataset). As of right now, it doesn't appear the JFT-300M is publicly available -- only Google researchers have access. Therefore, even if the code was made publicly available (which I'm guessing it won't), the results are not replicable. As readers, we have no idea what architectural tricks may have been used that are not made clear by the text of the paper itself, so reproducibility is not guaranteed.</p><p>Second, as some folks on Twitter have noted, using these 16x16 patches as input to the model is likely suboptimal. It's at best a first step and the strong performance of the hybrid version of the model (which uses intermediate ResNet representations as input) suggests as much.</p><p>As noted before, convolutions seems to help most in low-data / compute regimes, helping the model perform better with less training time for all but the largest model and dataset. Future research may reveal better ways to represent the input image while still avoiding the use of convolutions. If I had to guess, as in NLP, self-supervised pre-training will be key.</p>","comment_id":"5f7a463517b26d3ef80d635a","plaintext":"\n\n * Title: An Image is Worth 16x16 Words: Transformers for Image Recognition at\n   Scale [https://openreview.net/forum?id=YicbFdNTTy]\n * Authors: Anonymous (Paper currently in blind review for ICLR 2021\n   [https://iclr.cc/])\n * One sentence summary: Large Transformer trained on large datasets outperform\n   CNN-based architectures and achieve state of the art results on image\n   recognition tasks\n * Source: https://openreview.net/forum?id=YicbFdNTTy\n * Compression: 8 pages (original ex. references and appendix) -> 3.75 pages\n   (this article)\n\nSummary\n\"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\n[https://openreview.net/forum?id=YicbFdNTT]\" introduces the Visual Transformer,\nan architecture which leverages mostly standard Transformer components from the\noriginal NLP-focused \"Attention is All You Need\n[https://arxiv.org/abs/1706.03762]\" paper but instead applies them to computer\nvision, specifically image recognition. Images are transformed into sequences of\nimage patches representing \"tokens,\" similar to word tokens in NLP. The model is\ntrained in supervised fashion on image classification using these patch\nsequences as input.\n\nThe image-based Transformer does not outperform CNNs when trained on mid-sized\ndatasets such as ImageNet [http://www.image-net.org/], underperforming\nsimilar-sized ResNet models. This is likely due to an inability overcome the\ninherent advantage of CNNs (inductive biases like translational equivariance and\nlocality). However, when the Transformer model is pre-trained on large image\ndatasets (specifically, JFT [https://arxiv.org/abs/1707.02968]) and transferred\nto other tasks, the model achieves SOTA results.\n\nThe strong results suggest the long hoped-for convergence of architectures\nacross NLP and computer vision may finally be here in the form of Transformers.\nPer Andrej Karpathy [https://twitter.com/karpathy], Director of AI at Tesla:\n\n> An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale \nhttps://t.co/r5a0RuWyZE v cool. Further steps towards deprecating ConvNets with\nTransformers. Loving the increasing convergence of Vision/NLP and the much more\nefficient/flexible class of architectures. pic.twitter.com/muj3cR6uGA\n[https://t.co/muj3cR6uGA]\n\nâ€” Andrej Karpathy (@karpathy) October 3, 2020\n[https://twitter.com/karpathy/status/1312279279741276161?ref_src=twsrc%5Etfw]\nKey results and takeaways\n * Large Vision Transformer model mapping patches of image to classification\n   labels outperforms CNN-based architectures and achieves state of the art\n   results when trained on large (100M+ images) datasets\n * Transformer model underperforms CNNs when only trained on mid-sized datasets\n * Early layers of the Vision Transformer are able to attend to large chunks of\n   the image, unlike traditional convolutional layers with are constrained to a\n   local window\n * Self-supervised pre-training with \"masked patch prediction\" achieves decent\n   results but underperforms supervised pre-training\n\nMethodology\nArchitecture\nThe model effectively analogizes between words as tokens of larger sentences and\ngroups of pixels as \"tokens\" of larger images. Like a sequence of word tokens\nmakes a sentence, a sequence of pixel patches makes an image. Thus, the input\nimage is broken up into multiple patches of \\(P^2 \\cdot C\\) dimensions\nrepresenting square subsections of the original image (including all color\nchannels \\(C\\)), forming a sequence of image patches of length \\(N\\).\n\nImage patches \\(\\mathbf{x}_{p}^{n}\\), typically 16x16 pixels, are embedded into\n\\(D\\) dimension vectors using an embedding matrix \\(\\textbf{E}\\). The sequence\nof \"patch embeddings\" is prepended with a learnable \\(\\texttt{[class]}\\) token,\nsimilar to BERT [https://arxiv.org/abs/1810.04805], telling the model to\nclassify the image, leaving us Â with a \\((N+1) \\times D\\) dimension vector,\n\\(\\textbf{z}\\).\n\nThe representation of the first token in the output of the final Transformer\nencoder layer serves as the image representation. The classification head is\nattached to only this token. Position embeddings are added to the patch\nembeddings, and these vectors serve as input to the encoder.\n\nThe Transformer architecture is constructed as follows:\n\n$$\n\\begin{aligned} \n\\mathbf{z}_{0} &=\\left[\\mathbf{x}_{\\text {class }} ; \\mathbf{x}_{p}^{1}\n\\mathbf{E} ; \\mathbf{x}_{p}^{2} \\mathbf{E} ; \\cdots ; \\mathbf{x}_{p}^{N}\n\\mathbf{E}\\right]+\\mathbf{E}_{p o s}, & \\mathbf{E} \\in \\mathbb{R}^{\\left(P^{2}\n\\cdot C\\right) \\times D}, \\mathbf{E}_{p o s} \\in \\mathbb{R}^{(N+1) \\times D} \n\\\\ \\mathbf{z}_{\\ell}^{\\prime}\n&=\\operatorname{MSA}\\left(\\mathrm{LN}\\left(\\mathbf{z}_{\\ell-1}\\right)\\right)+\\mathbf{z}_{\\ell-1},\n& \\ell =1 \\ldots L \n\\\\ \\mathbf{z}_{\\ell}\n&=\\operatorname{MLP}\\left(\\mathrm{LN}\\left(\\mathbf{z}_{\\ell}^{\\prime}\\right)\\right)+\\mathbf{z}_{\\ell}^{\\prime},\n& \\ell =1 \\ldots L \n\\\\ \\mathbf{y} &=\\operatorname{LN}\\left(\\mathbf{z}_{L}^{0}\\right) \n\\end{aligned}\n$$\n\nwhere \\(\\mathbf{z}_{\\ell}\\) represents the patch sequence representation output\nat each layer \\(\\ell\\) of the network and \\(\\mathbf{z}_{L}^{0}\\) is the first\ntoken of the final layer output, which is fed into the classification head with\nLayer Norm \\((\\mathrm{LN})\\) applied.\n\nLayer representations \\(\\mathbf{z}_{\\ell}\\) are passed through each Transformer\nblock, where Layer Norm and multi-headed self-attention is applied\n\\((\\operatorname{MSA})\\), a residual skip connection to the previous layer's\nrepresentation \\(\\mathbf{z}_{\\ell-1}\\) added, followed by Layer Norm, and a feed\nforward layer \\((\\mathrm{MLP})\\) with a residual connection to the intermediate\nrepresentation, \\(\\mathbf{z}_{\\ell}^{\\prime}\\).\n\nThe authors construct multiple versions of the model at various scales to\ncompare results across model size, similar to BERT. Base = \"B\", Large = \"L\",\nHuge = \"H\".\n\nThe authors also experiment with a hybrid architecture, where instead of using\npatches as the input sequence, the intermediate representation of a ResNet model\nis used, replacing the patch embedding. The rest of the architecture remains\nunchanged.\n\nTraining\nModels are (pre-)trained on multiple image datasets, including ImageNet (1K\nclasses / 1.3M images), ImageNet-21K (21K classes / 14M images), and JFT (18K\nclasses / 303M images). As the largest dataset, JFT-300M is the main focus of\nthe paper, which we will see enables big performance improvements when used in\nthe largest versions of the architecture. Here, the model is pre-trained for 1M\nsteps. The remaining training hyperparameters can found be found in the paper.\n\nThe Vision Transformer is fine-tuned at higher resolution than pre-training,\nwhich helps performance. However, higher resolution images have more pixels, so\nthe patch sequences are longer. Rather than create extra positional embeddings\nfor these additional tokens, the existing embeddings are interpolated such that\nmultiple higher resolution patches correspond to each lower resolution\npositional embedding. This is necessary as the additional positional embeddings\nwould not have been seen during pre-training and hence would be meaningless if\napplied directly. This is the only point in which inductive bias about the\nstructure of images enters into the Vision Transformer.\n\nExperiments and results\nThe authors choose a number of benchmark tasks for performance evaluation:\nImageNet, ImageNet ReaL, CIFAR-10/100, Oxford-IIIT Pets, Oxford Flowers-102, and\nthe 19-task VTAB classification suite.\n\nPerformance\nViT-L/16 matches or outperforms BiT-L [https://arxiv.org/abs/1912.11370] (large\nResNet that supports supervised transfer learning) on all datasets with 4-10x\nfewer computational resources used during pre-training (as measured by\nTPUv3-days):\n\nThis performance advantage disappears if ViT is trained on a smallest dataset,\nsuch as ImageNet. Only with the largest dataset, JFT-300M, do larger models\noutperform all others:\n\nViT-B/16 and ViT-B/32 do not gain as much from being trained on larger datasets.\nThis alludes to the intuition that the convolutional inductive bias is most\nuseful for smaller datasets. On larger datasets however, learning the patterns\ndirectly is better:\n\nPerformance vs. compute cost\nThe Vision Transformer outperforms ResNets in terms of the performance / compute\nratio. ViT uses half as much compute to attain the same performance level\n(x-axis is pre-training exaFLOPs on log scale):\n\nInterestingly, hybrids slightly outperform the Vision Transformer with small\ncomputational budgets but not for larger ones. The authors note their surprise\nat this result, as it might be expected that convolutional feature maps coming\nfrom ResNet would be helpful at any scale\n\nGlobal self-attention\nSelf-attention allows the Vision Transformer to integrate information across the\nentire image, even in the lower Transformer layers. This is unlike CNNs, where\nonly the later layers are able to aggregate information from different parts of\nthe image. Experiments show that the \"attention distance\" of the attended area\nis large in the later layers, as expected, but also large in some portion of the\nearlier layers, demonstrating the ability to learn long-range dependencies. For\nexample, some of the earlier layers heads attend to patches 100 pixels away from\non another (right chart below):\n\nThe model clearly attends to image regions that are most relevant for\nclassification:\n\nSelf-supervised pre-training\nThe authors experiment with self-supervised pre-training using \"masked patch\nprediction,\" mimicking masked language modeling in the NLP context. With this\ntraining regimen, ViT-B/16 achieves 79.9% accuracy on ImageNet, a 2% improvement\nrelative to training from scratch, but 4% lower than supervised pre-training\nused in the rest of the paper.\n\nReflection\nOK, so this is exciting stuff. Personally, I've never liked convolutions, for\nsimilar reasons that I've never liked recurrent neural networks. There just\nsomething complicated about them. Something inelegant. I've always loved more\nlinear architectures, largely composed of feedforward layers with various\naugmentations like normalization or residual skip connections, i.e. Transformers\nand attention-based networks in general (and yes I know it's possible to rewrite\nconvolutions as affine transforms). So I think it's very cool to finally see\nthis applied to computer vision with strong results.\n\nI don't know if there were enough ablations to totally prove this, but it seems\nlike insufficient data was the core blocker preventing linear transformations\nfrom achieving similar results to CNNs. The inductive biases of CNNs have always\nbeen their key advantage, but that advantage seems to wither under the weight of\nmassive global self-attention learned on massive image datasets, at least for\nimage recognition / classification.\n\nThe authors also note that, given performance does not yet appear to saturate\nwith increasing model size, the Vision Transformer could potentially be scaled\nup even further. Nice.\n\nA couple wrinkles to point out.\n\nThe paper is currently under double-blind review for conference submission at\nICLR 2021, so the authors remain anonymous for now. That said, I'd be shocked if\nit wasn't Google behind this paper. There are a few tells, like the fact that\nthey use TPUs (Google-specific hardware) for training and the JFT-300M dataset\n(a Google maintained dataset). As of right now, it doesn't appear the JFT-300M\nis publicly available -- only Google researchers have access. Therefore, even if\nthe code was made publicly available (which I'm guessing it won't), the results\nare not replicable. As readers, we have no idea what architectural tricks may\nhave been used that are not made clear by the text of the paper itself, so\nreproducibility is not guaranteed.\n\nSecond, as some folks on Twitter have noted, using these 16x16 patches as input\nto the model is likely suboptimal. It's at best a first step and the strong\nperformance of the hybrid version of the model (which uses intermediate ResNet\nrepresentations as input) suggests as much.\n\nAs noted before, convolutions seems to help most in low-data / compute regimes,\nhelping the model perform better with less training time for all but the largest\nmodel and dataset. Future research may reveal better ways to represent the input\nimage while still avoiding the use of convolutions. If I had to guess, as in\nNLP, self-supervised pre-training will be key.","feature_image":"__GHOST_URL__/content/images/2021/07/M_MKtM3ruT.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-10-04T22:01:25.000Z","updated_at":"2021-07-20T03:11:30.000Z","published_at":"2020-10-04T23:17:13.000Z","custom_excerpt":"Large Transformer trained on large datasets outperform CNN-based architectures and achieve state of the art results on image recognition tasks","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5f7c16ab17b26d3ef80d63ea","uuid":"deaeecd0-b56e-43ab-8a47-6dfc50e49430","title":"Enterprise Software Monetization is Fat-Tailed","slug":"software-fat-tailed","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}]],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/image-20200824082909012.png\",\"alt\":\"image-20200824082909012\",\"title\":\"\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Enterprise Software Monetization is Fat-Tailed\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Subscribe</span></button>\\n</form>\\n</section>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/qNmFsndFgJ.png\",\"alt\":\"img\",\"title\":\"\",\"caption\":\"Source: <a href=\\\"https://david-salazar.github.io/2020/05/19/understanding-the-tail-exponent/\\\">David Salazar</a>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/image-20200905234041096.png\",\"alt\":\"image-20200905234041096\",\"title\":\"\",\"caption\":\"Source: <a href=\\\"https://www.sec.gov/Archives/edgar/data/1764925/000162828019004786/slacks-1.htm\\\">Slack's S-1</a>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/image-20200905234326829.png\",\"alt\":\"image-20200905234326829\",\"title\":\"\",\"caption\":\"<a href=\\\"https://docs.google.com/spreadsheets/d/163g-Tn9AdjF4bb4v7j8VidqeqMJvAHvb7EHUR2ctYsk/edit?usp=sharing\\\">Source</a>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/alpha.png\",\"alt\":\"alpha\",\"title\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/share.png\",\"alt\":\"share\",\"title\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/zxdn9Kwr6j.png\",\"alt\":\"img\",\"title\":\"\",\"caption\":\"Source: <a href=\\\"http://reactionwheel.net/2015/06/power-laws-in-venture.html\\\" rel=\\\"noopener\\\">Reaction Wheel</a>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/image-20200907200713719.png\",\"alt\":\"image-20200907200713719\",\"title\":\"\",\"caption\":\"Source: <a href=\\\"http://reactionwheel.net/2015/06/power-laws-in-venture.html\\\" rel=\\\"noopener\\\">Reaction Wheel</a>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/H5qNMNZPFO.png\",\"alt\":\"H5qNMNZPFO\",\"title\":\"\",\"caption\":\"Source: <a href=\\\"https://angel.co/pdf/lp-performance.pdf\\\" rel=\\\"noopener\\\">AngelList</a>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/image-20200909125015490.png\",\"alt\":\"image-20200909125015490\",\"title\":\"\",\"caption\":\"Source: <a href=\\\"https://arxiv.org/abs/2001.10488\\\">Statistical Consequences of Fat Tails</a>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/image-20200909124000940.png\",\"alt\":\"image-20200909124000940\",\"title\":\"\",\"caption\":\"Source: <a href=\\\"https://arxiv.org/abs/2001.10488\\\">Statistical Consequences of Fat Tails</a>\"}]],\"markups\":[[\"strong\"],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Fat-tailed_distribution\"]],[\"a\",[\"href\",\"http://reactionwheel.net/2015/06/power-laws-in-venture.html\"]],[\"a\",[\"href\",\"__GHOST_URL__/vcs-index-invest/\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=XhTHG3QmVwM\"]],[\"a\",[\"href\",\"https://www.investopedia.com/terms/1/80-20-rule.asp\"]],[\"a\",[\"href\",\"https://www.sec.gov/Archives/edgar/data/1764925/000162828019004786/slacks-1.htm\"]],[\"a\",[\"href\",\"https://docs.google.com/spreadsheets/d/163g-Tn9AdjF4bb4v7j8VidqeqMJvAHvb7EHUR2ctYsk/edit?usp=sharing\"]],[\"a\",[\"href\",\"https://www.thetaequity.com/slack-ipo\"]],[\"a\",[\"href\",\"https://aip.scitation.org/doi/10.1063/1.5141837\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Personal_record\"]],[\"em\"],[\"a\",[\"href\",\"https://www.institutionalinvestor.com/article/b1nlj1gb3g3bbd/The-Pervasive-Head-Scratching-Risk-Exploding-Problem-With-Venture-Capital\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/2001.10488\"]],[\"a\",[\"href\",\"https://saasx.com/2018/09/13/how-to-execute-a-saas-land-and-expand-strategy/\"]],[\"a\",[\"href\",\"__GHOST_URL__/magical-magic-number/\"]],[\"a\",[\"href\",\"http://www.edge.org/conversation/nassim_nicholas_taleb-the-fourth-quadrant-a-map-of-the-limits-of-statistics\"]],[\"a\",[\"href\",\"https://whoisnnamdi.com/weighted-acv/\"]],[\"a\",[\"href\",\"__GHOST_URL__/product-market-fit-is-lindy/\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"In enterprise software, \"],[0,[0],1,\"the \\\"average\\\" customer is a meaningless concept.\"]]],[1,\"p\",[[0,[],0,\"Paying too much attention to the \\\"average\\\" customer leads many founders and investors astray.\"]]],[1,\"p\",[[0,[],0,\"Instead, \"],[0,[0],1,\"focus on the tails.\"]]],[1,\"p\",[[0,[],0,\"Here's why.\"]]],[1,\"h2\",[[0,[],0,\"The basics\"]]],[1,\"p\",[[0,[],0,\"Define \\\"monetization\\\" as the average revenue a software vendor extracts from its customers:\"],[1,[],0,0],[0,[],0,\"$$\"],[1,[],0,1],[0,[],0,\"\\\\text {monetization} = \\\\text {total revenue / total customers}\"],[1,[],0,2],[0,[],0,\"$$\"],[1,[],0,3],[0,[],0,\"Wild variation in monetization across customers means most enterprise software customers contribute little to overall revenue.\"]]],[1,\"p\",[[0,[],0,\"For example, a late-stage software company with $50M+ in ARR and ~2,000 customers might have a small number of customers with enormous contracts, possibly greater than $500K or even $1M in ARR each, and a large number with tiny contracts in the ~$10K range.\"]]],[1,\"p\",[[0,[],0,\"The extreme, non-negative variation around the average produces a right or positively skewed monetization distribution:\"]]],[10,0],[1,\"p\",[[0,[],0,\"Sufficiently skewed distributions are \\\"\"],[0,[1],1,\"fat-tailed\"],[0,[],0,\".\\\" Large customer contracts will determine the properties of the distribution, like its mean or variance. Similarly, large customers will account for an enormous proportion of overall revenue. In other words, software monetization is a \"],[0,[2],1,\"power law\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"In a \"],[0,[3],1,\"previous essay\"],[0,[],0,\", I introduced the notion of \\\\(\\\\alpha\\\\), or alpha, the shape or tail parameter, which characterizes the \\\"fat-tailedness\\\" of a power law distribution. The smaller \\\\(\\\\alpha\\\\), the more skewed the distribution, the fatter the tails, with \\\\(\\\\alpha < 2\\\\) indicating extreme skew and fat-tailedness. For software monetization, the fatter the tail, the more common and impactful are those \\\"whale\\\" customers.\"]]],[1,\"p\",[[0,[],0,\"Evidence for skewed monetization is tough to come by without access to a company's commercial contracts. However, we can infer the fat-tailedness from the SEC filings of public software companies with a simple trick.\"]]],[10,1],[1,\"h2\",[[0,[],0,\"The math\"]]],[1,\"p\",[[0,[],0,\"The trick? A \"],[0,[4],1,\"formula\"],[0,[],0,\" exists that calculates the concentration in the top percentiles of a power law distribution based on the \\\\(\\\\alpha\\\\) of the distribution:\"],[1,[],0,4],[1,[],0,5],[0,[],0,\"$$\"],[1,[],0,6],[0,[],0,\"\\\\text{s} = p^{\\\\frac{\\\\alpha-1}{\\\\alpha}}\"],[1,[],0,7],[0,[],0,\"$$\"],[1,[],0,8],[0,[],0,\"where \\\\(s\\\\) is the share of the total and \\\\(p\\\\) is the percentile.\"]]],[1,\"p\",[[0,[],0,\"Plug in the \\\\(\\\\alpha\\\\) and the percentile \\\\(p\\\\) you are interested in to get the share of the total that the top-p% of customers represent.\"]]],[1,\"p\",[[0,[],0,\"Invert the formula to yield the \\\\(\\\\alpha\\\\) of a power law distribution given a certain percentile and share:\"],[1,[],0,9],[0,[],0,\"$$\"],[1,[],0,10],[0,[],0,\"\\\\alpha = \\\\frac{\\\\log{p}}{\\\\log{p}-\\\\log{\\\\text{s}}}\"],[1,[],0,11],[0,[],0,\"$$\"],[1,[],0,12],[0,[],0,\"This means we can infer \\\\(\\\\alpha\\\\)â€‹ and therefore how fat-tailed the revenue distribution is if we know the share of revenue represented by the largest customers of a given software vendor.\"]]],[1,\"p\",[[0,[],0,\"We can estimate the shape of the customer distribution by plugging \\\\(\\\\alpha\\\\) back into the first equation along with some other percentile X in order to estimate the share of revenue earned from the top-X% of customers, which we can repeat for other percentiles. For example, the relationship between \\\\(\\\\alpha\\\\) and the revenue concentrated in the top-20% of customer looks like this:\"]]],[10,2],[1,\"p\",[[0,[],0,\"An \\\\(\\\\alpha = 1.16\\\\) yields the classic \"],[0,[5],1,\"Pareto 80/20 distribution\"],[0,[],0,\", where 20% of customers account for 80% of revenue.\"]]],[1,\"p\",[[0,[],0,\"Before we proceed, know that this method only works if we assume upfront that the distribution is in fact power law distributed, at least in the tails. We never proved this, so don't interpolate/extrapolate too far with this method.\"]]],[1,\"p\",[[0,[],0,\"With that caveat acknowledged, let's throw caution to the wind!\"]]],[1,\"h2\",[[0,[],0,\"The evidence\"]]],[1,\"p\",[[0,[],0,\"Public companies do their best to hide customer concentration. But at a certain point fiduciary duty requires that they disclose revenue concentration, especially if a few customers account for a large enough chunk of revenue.\"]]],[1,\"p\",[[0,[],0,\"Commonly, companies will state that \\\"no customer represents more than X% of revenue.\\\" Less frequently, companies will go further, disclosing the number of customers that exceed some revenue threshold, typically $100,000, and the proportion of revenue they represent. This gets framed as a point of strength â€” \\\"look how many large customers we have\\\" â€” but it also indicates customer concentration since the X customers with greater than $100K contracts are by definition the X largest customers.\"]]],[1,\"p\",[[0,[],0,\"Here's an example from \"],[0,[6],1,\"Slack's S-1\"],[0,[],0,\":\"]]],[10,3],[1,\"p\",[[0,[],0,\"From this sort of disclosure we can calculate the \\\\(\\\\alpha\\\\) and fat-tailedness of customer monetization for public software vendors via the procedure outlined above, plugging in the share of total revenue and total customers represented by these large customers. \"],[0,[7],1,\"I've done the hard work for you\"],[0,[],0,\" for a subset of public software companies:\"]]],[10,4],[1,\"p\",[[0,[0],1,\"The alphas are universally below 2\"],[0,[],0,\", implying a high level of skew.\"]]],[1,\"p\",[[0,[],0,\"A more visual representation of the alphas (with the average in black):\"]]],[10,5],[1,\"p\",[[0,[],0,\"The implied top-20% and top-1% revenue concentration are quite large for most companies (blue = top 20%, red = top 1%):\"]]],[10,6],[1,\"p\",[[0,[],0,\"So, \"],[0,[0],1,\"the top 20% typically represent ~70% of revenue\"],[0,[],0,\", while \"],[0,[0],1,\"the top 1% represent ~40%\"],[0,[],0,\". Not quite Pareto 80/20, but pretty close! Interestingly, many companies tied to infrastructure in some way like Datadog, Fastly, and Twilio do have 80/20 monetization distributions, at least in some years.\"]]],[1,\"p\",[[0,[],0,\"As I caveated, these figures will be off to some degree. I'd guess they overestimate revenue concentration somewhat.\"]]],[1,\"p\",[[0,[],0,\"However, I'm comforted by corroboration from a \"],[0,[8],1,\"report by Theta Equity Partners\"],[0,[],0,\" that uses a completely different methodology to estimate the monetization distribution of Slack's customer base. Based on the \"],[0,[6],1,\"S-1 filing\"],[0,[],0,\", they found that \"],[0,[0],1,\"Slack's top 1% of customers account for 40% of total revenue in 2019\"],[0,[],0,\":\"]]],[1,\"blockquote\",[[0,[],0,\"As we mentioned previously, the data and the model imply a high level of variability in the â€œgoodnessâ€ of Slackâ€™s customers â€“ \"],[0,[0],1,\"a small (<1%) segment of â€œheavyâ€ customers accounts for 40% of companyâ€™s revenues\"],[0,[],0,\" and generates revenue per customer which is more than 100 times larger than everyone else.\"]]],[1,\"p\",[[0,[],0,\"Using my methodology, I find that \"],[0,[0],1,\"the top 1% of Slack's customers in 2019 represented 43% of revenue\"],[0,[],0,\", which is quite similar.\"]]],[1,\"h2\",[[0,[],0,\"The implications\"]]],[1,\"p\",[[0,[],0,\"It's easy to see these results and think \\\"Yes, sure, customer concentration is a thing. So what?\\\" But the implications of a fat-tailed monetization distribution are profound.\"]]],[1,\"h3\",[[0,[],0,\"Why don't software companies index invest?\"]]],[1,\"p\",[[0,[],0,\"First, as I discussed previously in \"],[0,[3],1,\"Why Don't VCs Index Invest\"],[0,[],0,\", when facing a sufficiently fat-tailed distribution of returns, it doesn't make sense to be picky or overly concentrated in one's investments. Index investing is the optimal allocation strategy.\"]]],[1,\"p\",[[0,[],0,\"Here, returns are synonymous with revenue and investment is synonymous with customer acquisition costs, or CAC. If the distribution of revenue is fat-tailed, vendors should be trying to insert their software into as many customers as possible, as cheaply as possible. Don't try to land large upfront, as this requires investing in a heavy and expensive enterprise sales motion that may not yield results. Instead, spend small and land small, with each customer contract acting as a potential \\\"lottery ticket\\\" that may unlock a much larger contract later on, similar to an early-stage startup investment.\"]]],[1,\"p\",[[0,[],0,\"There's some merit to this analogy between venture capital and software go-to-market strategies. One only has to look at estimates of \\\\(\\\\alpha\\\\) for venture capital investments to see that we are dealing with similar phenomena here (ignore the orange footnotes):\"]]],[10,7],[1,\"h3\",[[0,[],0,\"Whale hunting\"]]],[1,\"p\",[[0,[],0,\"Second, as I allude to in the \"],[0,[3],1,\"aforementioned essay\"],[0,[],0,\", finite samples of a positively skewed, fat-tailed distribution tend to underestimate the average, or mean, of the distribution. Large values are rare, so small samples will tend to miss them. Unless you have an extremely large dataset, the \\\"true\\\" mean is typically larger than the mean you measure from the data. So the calculated sample mean tends to increase as the sample size grows, reflecting those large, infrequent outcomes.\"]]],[1,\"p\",[[0,[],0,\"Said more precisely:\"]]],[1,\"blockquote\",[[0,[],0,\"An additional difficulty in the numerical estimation of momentsâ€”and, therefore, of riskâ€”is due to the very slow convergence of estimated values to the exact values of the process, even if the associated moments are finite. This â€œslow Law of Large Numbersâ€ is caused by the large weight of rare events (black swans), which take a lot of data to show up, and prevent a proper estimation of the moments of such processes through the moments of a sample. â€” \"],[0,[9],1,\"Fat tails and black swans: Exact results for multiplicative processes with resets\"]]],[1,\"p\",[[0,[],0,\"Further, the largest value you are likely to see in a sample of power law distribution (the expected value of the maximum value) is proportional to the sample size \\\\(n\\\\) and inversely proportional to \\\\(\\\\alpha\\\\):\"],[1,[],0,13],[0,[],0,\"$$\"],[1,[],0,14],[0,[],0,\"\\\\mathbb{E} [x_{max}] \\\\sim n^{1/(\\\\alpha-1)}\"],[1,[],0,15],[0,[],0,\"$$\"],[1,[],0,16],[0,[],0,\"In plain English â€” your \"],[0,[10],1,\"personal best\"],[0,[],0,\" can only get better with more attempts. In the realm of venture, that looks like this:\"]]],[10,8],[1,\"p\",[[0,[],0,\"This is why returns in venture capital tend to increase with portfolio size:\"]]],[10,9],[1,\"p\",[[0,[],0,\"In the context of software monetization, the \\\"true distribution\\\" is the set of \"],[0,[0],1,\"all\"],[0,[],0,\" potential customers while the \\\"sample\\\" is the set of \"],[0,[11],1,\"current\"],[0,[],0,\" customers. Each customer is like a draw from a random variable representing all potential customers, just like a venture capital investment is like a random draw from a fat-tailed distribution of potential returns.\"]]],[1,\"p\",[[0,[0],1,\"My claim is that the average monetization across your customer base â€” ARR/customer, revenue/customer, etc. â€” is an underestimate of the \\\"true\\\" or \\\"potential\\\" monetization.\"],[0,[],0,\" As you land more customers, so the logic goes, the revenue you extract will tend to rise due to this fat-tailed phenomenon, with no change in pricing model or customer targeting.\"]]],[1,\"p\",[[0,[],0,\"More \"],[0,[11],1,\"is\"],[0,[],0,\" more, or specifically, more customers is more monetization, for the same reason that \"],[0,[12],1,\"larger venture portfolios yield higher returns\"],[0,[],0,\". Your wins get bigger the more broadly you penetrate the market.\"]]],[1,\"p\",[[0,[],0,\"It's natural to ask â€” \\\"\"],[0,[0],1,\"how much does current monetization underestimate potential monetization?\"],[0,[],0,\"\\\"\"]]],[1,\"p\",[[0,[13],1,\"Nassim Taleb\"],[0,[],0,\" has already done the math for us. Imagine that true average monetization is the sum of the monetization of customers smaller than the largest customer we've acquired thus far, which he calls \\\\(K\\\\), and the contribution of potential customers larger than our largest:\"],[1,[],0,17],[0,[],0,\"$$\"],[1,[],0,18],[0,[],0,\"\\\\text{true mean} = \\\\text{mean of existing customers}_{<K} + \\\\text{contribution of potential customers}_{>K}\"],[1,[],0,19],[0,[],0,\"$$\"],[1,[],0,20],[0,[],0,\"In the chart below, the shaded region represents larger customers yet to be acquired:\"]]],[10,10],[1,\"p\",[[0,[],0,\"What proportion of the total does this extra bit represent? That depends both on \\\\(\\\\alpha\\\\), or how fat-tailed the distribution is, and on the sample size. The smaller \\\\(\\\\alpha\\\\) and the smaller our sample, the more we underestimate the true mean:\"]]],[10,11],[1,\"p\",[[0,[],0,\"So for an enterprise software company with \\\\(\\\\alpha = 1.3\\\\), which is typical in my data set, and 1000 customers, these not yet acquired customers will account for 20% of the true mean. This means the \"],[0,[0],1,\"true monetization is about 1 / 0.8 = 25% higher than current monetization\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[11],1,\"That number is conservative\"],[0,[],0,\" â€” it assumes that we've already acquired every customer up to a certain size, thereby maximizing monetization of customers equal to or below that size. We haven't really done this though, so even current monetization underestimates how well we could monetize, even without acquiring larger customers. Factor that in, and the degree to which we underestimate true monetization only increases.\"]]],[1,\"h3\",[[0,[],0,\"The math behind land and expand\"]]],[1,\"p\",[[0,[],0,\"Combined, the above insights form a mathematical justification for \\\"\"],[0,[14],1,\"land and expand\"],[0,[],0,\"\\\"-style go-to-market strategies.\"]]],[1,\"p\",[[0,[],0,\"Here, land and expand is effectively an \"],[0,[3],1,\"indexing strategy\"],[0,[],0,\" â€” land at as many organizations with as little investment as possible. Every once in a while you'll land a Google, a Facebook, or an Amazon (both figuratively and literally) which will drive a disproportionate share of revenue.\"]]],[1,\"p\",[[0,[],0,\"Even if those customers start off small, any given customer could potentially become quite large.\"]]],[1,\"p\",[[0,[],0,\"Further, it can make sense to overspend somewhat on establishing those small beachheads, as they likely underestimate the true average contract value. For this reason, common metrics for evaluating the efficiency of software sales like the \\\"\"],[0,[15],1,\"magic number\"],[0,[],0,\"\\\" may underestimate the efficiency of land and expand models, especially during the land phase.\"]]],[1,\"blockquote\",[[0,[],0,\"If we suspect right-skewness, the true mean is more likely to be underestimated by measurement of past realizations, and the total potential is likewise poorly gauged. â€” \"],[0,[16],1,\"The Fourth Quadrant: A Map of the Limits of Statistics\"]]],[1,\"p\",[[0,[],0,\"In fact, one of the best software investments I ever made (that shall remain nameless) was in a company that on its face seemed quite inefficient, with a magic number well below 1. The leadership team preached the virtues of its land and expand model, but our static analysis of its sales metrics was doomed to underestimate its true efficiency, even after many hours spent (by yours truly) wrangling and analyzing the data.\"]]],[1,\"p\",[[0,[],0,\"Luckily, we got over our concerns and made what turned out to be a great investment.\"]]],[1,\"p\",[[0,[],0,\"With more mathematical context, the story is a visceral personal reminder to properly grapple with the implications and dynamics of fat-tailed software monetization.\"]]],[1,\"h2\",[[0,[],0,\"The end\"]]],[1,\"p\",[[0,[],0,\"This is just a small taste of fat tails, and I plan to write more in the coming months on their broader implications for high-growth startups. Much ink has been spilled on this topic within the context of venture investing, but not so much for operating the underlying businesses themselves.\"]]],[1,\"p\",[[0,[],0,\"Here's a preview of the topics:\"]]],[3,\"ul\",[[[0,[],0,\"Why software markets are always larger than we think\"]],[[0,[17],1,\"Why \\\"Weighted ACV\\\" beats the traditional ACV metric\"]],[[0,[],0,\"Why investors consistently undervalue enterprise software and overvalue consumer startups\"]],[[0,[],0,\"Why open source is built by individuals rather than communities\"]],[[0,[18],1,\"Why product-market fit gets harder to achieve the longer you search for it\"]]]],[1,\"p\",[[0,[],0,\"I've been thinking about some of these essays for the better part of a year, so I'm excited to \"],[0,[11],1,\"finally\"],[0,[],0,\" share these ideas.\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p>In enterprise software, <strong>the \"average\" customer is a meaningless concept.</strong></p><p>Paying too much attention to the \"average\" customer leads many founders and investors astray.</p><p>Instead, <strong>focus on the tails.</strong></p><p>Here's why.</p><h2 id=\"the-basics\">The basics</h2><p>Define \"monetization\" as the average revenue a software vendor extracts from its customers:<br>$$<br>\\text {monetization} = \\text {total revenue / total customers}<br>$$<br>Wild variation in monetization across customers means most enterprise software customers contribute little to overall revenue.</p><p>For example, a late-stage software company with $50M+ in ARR and ~2,000 customers might have a small number of customers with enormous contracts, possibly greater than $500K or even $1M in ARR each, and a large number with tiny contracts in the ~$10K range.</p><p>The extreme, non-negative variation around the average produces a right or positively skewed monetization distribution:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/image-20200824082909012.png\" class=\"kg-image\" alt=\"image-20200824082909012\" loading=\"lazy\"></figure><p>Sufficiently skewed distributions are \"<a href=\"https://en.wikipedia.org/wiki/Fat-tailed_distribution\">fat-tailed</a>.\" Large customer contracts will determine the properties of the distribution, like its mean or variance. Similarly, large customers will account for an enormous proportion of overall revenue. In other words, software monetization is a <a href=\"http://reactionwheel.net/2015/06/power-laws-in-venture.html\">power law</a>.</p><p>In a <a href=\"__GHOST_URL__/vcs-index-invest/\">previous essay</a>, I introduced the notion of \\(\\alpha\\), or alpha, the shape or tail parameter, which characterizes the \"fat-tailedness\" of a power law distribution. The smaller \\(\\alpha\\), the more skewed the distribution, the fatter the tails, with \\(\\alpha &lt; 2\\) indicating extreme skew and fat-tailedness. For software monetization, the fatter the tail, the more common and impactful are those \"whale\" customers.</p><p>Evidence for skewed monetization is tough to come by without access to a company's commercial contracts. However, we can infer the fat-tailedness from the SEC filings of public software companies with a simple trick.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Enterprise Software Monetization is Fat-Tailed\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Subscribe</span></button>\n</form>\n</section><!--kg-card-end: html--><h2 id=\"the-math\">The math</h2><p>The trick? A <a href=\"https://www.youtube.com/watch?v=XhTHG3QmVwM\">formula</a> exists that calculates the concentration in the top percentiles of a power law distribution based on the \\(\\alpha\\) of the distribution:<br><br>$$<br>\\text{s} = p^{\\frac{\\alpha-1}{\\alpha}}<br>$$<br>where \\(s\\) is the share of the total and \\(p\\) is the percentile.</p><p>Plug in the \\(\\alpha\\) and the percentile \\(p\\) you are interested in to get the share of the total that the top-p% of customers represent.</p><p>Invert the formula to yield the \\(\\alpha\\) of a power law distribution given a certain percentile and share:<br>$$<br>\\alpha = \\frac{\\log{p}}{\\log{p}-\\log{\\text{s}}}<br>$$<br>This means we can infer \\(\\alpha\\)â€‹ and therefore how fat-tailed the revenue distribution is if we know the share of revenue represented by the largest customers of a given software vendor.</p><p>We can estimate the shape of the customer distribution by plugging \\(\\alpha\\) back into the first equation along with some other percentile X in order to estimate the share of revenue earned from the top-X% of customers, which we can repeat for other percentiles. For example, the relationship between \\(\\alpha\\) and the revenue concentrated in the top-20% of customer looks like this:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2020/10/qNmFsndFgJ.png\" class=\"kg-image\" alt=\"img\" loading=\"lazy\"><figcaption>Source: <a href=\"https://david-salazar.github.io/2020/05/19/understanding-the-tail-exponent/\">David Salazar</a></figcaption></figure><p>An \\(\\alpha = 1.16\\) yields the classic <a href=\"https://www.investopedia.com/terms/1/80-20-rule.asp\">Pareto 80/20 distribution</a>, where 20% of customers account for 80% of revenue.</p><p>Before we proceed, know that this method only works if we assume upfront that the distribution is in fact power law distributed, at least in the tails. We never proved this, so don't interpolate/extrapolate too far with this method.</p><p>With that caveat acknowledged, let's throw caution to the wind!</p><h2 id=\"the-evidence\">The evidence</h2><p>Public companies do their best to hide customer concentration. But at a certain point fiduciary duty requires that they disclose revenue concentration, especially if a few customers account for a large enough chunk of revenue.</p><p>Commonly, companies will state that \"no customer represents more than X% of revenue.\" Less frequently, companies will go further, disclosing the number of customers that exceed some revenue threshold, typically $100,000, and the proportion of revenue they represent. This gets framed as a point of strength â€” \"look how many large customers we have\" â€” but it also indicates customer concentration since the X customers with greater than $100K contracts are by definition the X largest customers.</p><p>Here's an example from <a href=\"https://www.sec.gov/Archives/edgar/data/1764925/000162828019004786/slacks-1.htm\">Slack's S-1</a>:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2020/10/image-20200905234041096.png\" class=\"kg-image\" alt=\"image-20200905234041096\" loading=\"lazy\"><figcaption>Source: <a href=\"https://www.sec.gov/Archives/edgar/data/1764925/000162828019004786/slacks-1.htm\">Slack's S-1</a></figcaption></figure><p>From this sort of disclosure we can calculate the \\(\\alpha\\) and fat-tailedness of customer monetization for public software vendors via the procedure outlined above, plugging in the share of total revenue and total customers represented by these large customers. <a href=\"https://docs.google.com/spreadsheets/d/163g-Tn9AdjF4bb4v7j8VidqeqMJvAHvb7EHUR2ctYsk/edit?usp=sharing\">I've done the hard work for you</a> for a subset of public software companies:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2020/10/image-20200905234326829.png\" class=\"kg-image\" alt=\"image-20200905234326829\" loading=\"lazy\"><figcaption><a href=\"https://docs.google.com/spreadsheets/d/163g-Tn9AdjF4bb4v7j8VidqeqMJvAHvb7EHUR2ctYsk/edit?usp=sharing\">Source</a></figcaption></figure><p><strong>The alphas are universally below 2</strong>, implying a high level of skew.</p><p>A more visual representation of the alphas (with the average in black):</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/alpha.png\" class=\"kg-image\" alt=\"alpha\" loading=\"lazy\"></figure><p>The implied top-20% and top-1% revenue concentration are quite large for most companies (blue = top 20%, red = top 1%):</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/share.png\" class=\"kg-image\" alt=\"share\" loading=\"lazy\"></figure><p>So, <strong>the top 20% typically represent ~70% of revenue</strong>, while <strong>the top 1% represent ~40%</strong>. Not quite Pareto 80/20, but pretty close! Interestingly, many companies tied to infrastructure in some way like Datadog, Fastly, and Twilio do have 80/20 monetization distributions, at least in some years.</p><p>As I caveated, these figures will be off to some degree. I'd guess they overestimate revenue concentration somewhat.</p><p>However, I'm comforted by corroboration from a <a href=\"https://www.thetaequity.com/slack-ipo\">report by Theta Equity Partners</a> that uses a completely different methodology to estimate the monetization distribution of Slack's customer base. Based on the <a href=\"https://www.sec.gov/Archives/edgar/data/1764925/000162828019004786/slacks-1.htm\">S-1 filing</a>, they found that <strong>Slack's top 1% of customers account for 40% of total revenue in 2019</strong>:</p><blockquote>As we mentioned previously, the data and the model imply a high level of variability in the â€œgoodnessâ€ of Slackâ€™s customers â€“ <strong>a small (&lt;1%) segment of â€œheavyâ€ customers accounts for 40% of companyâ€™s revenues</strong> and generates revenue per customer which is more than 100 times larger than everyone else.</blockquote><p>Using my methodology, I find that <strong>the top 1% of Slack's customers in 2019 represented 43% of revenue</strong>, which is quite similar.</p><h2 id=\"the-implications\">The implications</h2><p>It's easy to see these results and think \"Yes, sure, customer concentration is a thing. So what?\" But the implications of a fat-tailed monetization distribution are profound.</p><h3 id=\"why-don-t-software-companies-index-invest\">Why don't software companies index invest?</h3><p>First, as I discussed previously in <a href=\"__GHOST_URL__/vcs-index-invest/\">Why Don't VCs Index Invest</a>, when facing a sufficiently fat-tailed distribution of returns, it doesn't make sense to be picky or overly concentrated in one's investments. Index investing is the optimal allocation strategy.</p><p>Here, returns are synonymous with revenue and investment is synonymous with customer acquisition costs, or CAC. If the distribution of revenue is fat-tailed, vendors should be trying to insert their software into as many customers as possible, as cheaply as possible. Don't try to land large upfront, as this requires investing in a heavy and expensive enterprise sales motion that may not yield results. Instead, spend small and land small, with each customer contract acting as a potential \"lottery ticket\" that may unlock a much larger contract later on, similar to an early-stage startup investment.</p><p>There's some merit to this analogy between venture capital and software go-to-market strategies. One only has to look at estimates of \\(\\alpha\\) for venture capital investments to see that we are dealing with similar phenomena here (ignore the orange footnotes):</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2020/10/zxdn9Kwr6j.png\" class=\"kg-image\" alt=\"img\" loading=\"lazy\"><figcaption>Source: <a href=\"http://reactionwheel.net/2015/06/power-laws-in-venture.html\" rel=\"noopener\">Reaction Wheel</a></figcaption></figure><h3 id=\"whale-hunting\">Whale hunting</h3><p>Second, as I allude to in the <a href=\"__GHOST_URL__/vcs-index-invest/\">aforementioned essay</a>, finite samples of a positively skewed, fat-tailed distribution tend to underestimate the average, or mean, of the distribution. Large values are rare, so small samples will tend to miss them. Unless you have an extremely large dataset, the \"true\" mean is typically larger than the mean you measure from the data. So the calculated sample mean tends to increase as the sample size grows, reflecting those large, infrequent outcomes.</p><p>Said more precisely:</p><blockquote>An additional difficulty in the numerical estimation of momentsâ€”and, therefore, of riskâ€”is due to the very slow convergence of estimated values to the exact values of the process, even if the associated moments are finite. This â€œslow Law of Large Numbersâ€ is caused by the large weight of rare events (black swans), which take a lot of data to show up, and prevent a proper estimation of the moments of such processes through the moments of a sample. â€” <a href=\"https://aip.scitation.org/doi/10.1063/1.5141837\">Fat tails and black swans: Exact results for multiplicative processes with resets</a></blockquote><p>Further, the largest value you are likely to see in a sample of power law distribution (the expected value of the maximum value) is proportional to the sample size \\(n\\) and inversely proportional to \\(\\alpha\\):<br>$$<br>\\mathbb{E} [x_{max}] \\sim n^{1/(\\alpha-1)}<br>$$<br>In plain English â€” your <a href=\"https://en.wikipedia.org/wiki/Personal_record\">personal best</a> can only get better with more attempts. In the realm of venture, that looks like this:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2020/10/image-20200907200713719.png\" class=\"kg-image\" alt=\"image-20200907200713719\" loading=\"lazy\"><figcaption>Source: <a href=\"http://reactionwheel.net/2015/06/power-laws-in-venture.html\" rel=\"noopener\">Reaction Wheel</a></figcaption></figure><p>This is why returns in venture capital tend to increase with portfolio size:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2020/10/H5qNMNZPFO.png\" class=\"kg-image\" alt=\"H5qNMNZPFO\" loading=\"lazy\"><figcaption>Source: <a href=\"https://angel.co/pdf/lp-performance.pdf\" rel=\"noopener\">AngelList</a></figcaption></figure><p>In the context of software monetization, the \"true distribution\" is the set of <strong>all</strong> potential customers while the \"sample\" is the set of <em>current</em> customers. Each customer is like a draw from a random variable representing all potential customers, just like a venture capital investment is like a random draw from a fat-tailed distribution of potential returns.</p><p><strong>My claim is that the average monetization across your customer base â€” ARR/customer, revenue/customer, etc. â€” is an underestimate of the \"true\" or \"potential\" monetization.</strong> As you land more customers, so the logic goes, the revenue you extract will tend to rise due to this fat-tailed phenomenon, with no change in pricing model or customer targeting.</p><p>More <em>is</em> more, or specifically, more customers is more monetization, for the same reason that <a href=\"https://www.institutionalinvestor.com/article/b1nlj1gb3g3bbd/The-Pervasive-Head-Scratching-Risk-Exploding-Problem-With-Venture-Capital\">larger venture portfolios yield higher returns</a>. Your wins get bigger the more broadly you penetrate the market.</p><p>It's natural to ask â€” \"<strong>how much does current monetization underestimate potential monetization?</strong>\"</p><p><a href=\"https://arxiv.org/abs/2001.10488\">Nassim Taleb</a> has already done the math for us. Imagine that true average monetization is the sum of the monetization of customers smaller than the largest customer we've acquired thus far, which he calls \\(K\\), and the contribution of potential customers larger than our largest:<br>$$<br>\\text{true mean} = \\text{mean of existing customers}_{&lt;K} + \\text{contribution of potential customers}_{&gt;K}<br>$$<br>In the chart below, the shaded region represents larger customers yet to be acquired:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2020/10/image-20200909125015490.png\" class=\"kg-image\" alt=\"image-20200909125015490\" loading=\"lazy\"><figcaption>Source: <a href=\"https://arxiv.org/abs/2001.10488\">Statistical Consequences of Fat Tails</a></figcaption></figure><p>What proportion of the total does this extra bit represent? That depends both on \\(\\alpha\\), or how fat-tailed the distribution is, and on the sample size. The smaller \\(\\alpha\\) and the smaller our sample, the more we underestimate the true mean:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2020/10/image-20200909124000940.png\" class=\"kg-image\" alt=\"image-20200909124000940\" loading=\"lazy\"><figcaption>Source: <a href=\"https://arxiv.org/abs/2001.10488\">Statistical Consequences of Fat Tails</a></figcaption></figure><p>So for an enterprise software company with \\(\\alpha = 1.3\\), which is typical in my data set, and 1000 customers, these not yet acquired customers will account for 20% of the true mean. This means the <strong>true monetization is about 1 / 0.8 = 25% higher than current monetization</strong>.</p><p><em>That number is conservative</em> â€” it assumes that we've already acquired every customer up to a certain size, thereby maximizing monetization of customers equal to or below that size. We haven't really done this though, so even current monetization underestimates how well we could monetize, even without acquiring larger customers. Factor that in, and the degree to which we underestimate true monetization only increases.</p><h3 id=\"the-math-behind-land-and-expand\">The math behind land and expand</h3><p>Combined, the above insights form a mathematical justification for \"<a href=\"https://saasx.com/2018/09/13/how-to-execute-a-saas-land-and-expand-strategy/\">land and expand</a>\"-style go-to-market strategies.</p><p>Here, land and expand is effectively an <a href=\"__GHOST_URL__/vcs-index-invest/\">indexing strategy</a> â€” land at as many organizations with as little investment as possible. Every once in a while you'll land a Google, a Facebook, or an Amazon (both figuratively and literally) which will drive a disproportionate share of revenue.</p><p>Even if those customers start off small, any given customer could potentially become quite large.</p><p>Further, it can make sense to overspend somewhat on establishing those small beachheads, as they likely underestimate the true average contract value. For this reason, common metrics for evaluating the efficiency of software sales like the \"<a href=\"__GHOST_URL__/magical-magic-number/\">magic number</a>\" may underestimate the efficiency of land and expand models, especially during the land phase.</p><blockquote>If we suspect right-skewness, the true mean is more likely to be underestimated by measurement of past realizations, and the total potential is likewise poorly gauged. â€” <a href=\"http://www.edge.org/conversation/nassim_nicholas_taleb-the-fourth-quadrant-a-map-of-the-limits-of-statistics\">The Fourth Quadrant: A Map of the Limits of Statistics</a></blockquote><p>In fact, one of the best software investments I ever made (that shall remain nameless) was in a company that on its face seemed quite inefficient, with a magic number well below 1. The leadership team preached the virtues of its land and expand model, but our static analysis of its sales metrics was doomed to underestimate its true efficiency, even after many hours spent (by yours truly) wrangling and analyzing the data.</p><p>Luckily, we got over our concerns and made what turned out to be a great investment.</p><p>With more mathematical context, the story is a visceral personal reminder to properly grapple with the implications and dynamics of fat-tailed software monetization.</p><h2 id=\"the-end\">The end</h2><p>This is just a small taste of fat tails, and I plan to write more in the coming months on their broader implications for high-growth startups. Much ink has been spilled on this topic within the context of venture investing, but not so much for operating the underlying businesses themselves.</p><p>Here's a preview of the topics:</p><ul><li>Why software markets are always larger than we think</li><li><a href=\"https://whoisnnamdi.com/weighted-acv/\">Why \"Weighted ACV\" beats the traditional ACV metric</a></li><li>Why investors consistently undervalue enterprise software and overvalue consumer startups</li><li>Why open source is built by individuals rather than communities</li><li><a href=\"__GHOST_URL__/product-market-fit-is-lindy/\">Why product-market fit gets harder to achieve the longer you search for it</a></li></ul><p>I've been thinking about some of these essays for the better part of a year, so I'm excited to <em>finally</em> share these ideas.</p>","comment_id":"5f7c16ab17b26d3ef80d63ea","plaintext":"In enterprise software, the \"average\" customer is a meaningless concept.\n\nPaying too much attention to the \"average\" customer leads many founders and\ninvestors astray.\n\nInstead, focus on the tails.\n\nHere's why.\n\nThe basics\nDefine \"monetization\" as the average revenue a software vendor extracts from its\ncustomers:\n$$\n\\text {monetization} = \\text {total revenue / total customers}\n$$\nWild variation in monetization across customers means most enterprise software\ncustomers contribute little to overall revenue.\n\nFor example, a late-stage software company with $50M+ in ARR and ~2,000\ncustomers might have a small number of customers with enormous contracts,\npossibly greater than $500K or even $1M in ARR each, and a large number with\ntiny contracts in the ~$10K range.\n\nThe extreme, non-negative variation around the average produces a right or\npositively skewed monetization distribution:\n\nSufficiently skewed distributions are \"fat-tailed\n[https://en.wikipedia.org/wiki/Fat-tailed_distribution].\" Large customer\ncontracts will determine the properties of the distribution, like its mean or\nvariance. Similarly, large customers will account for an enormous proportion of\noverall revenue. In other words, software monetization is a power law\n[http://reactionwheel.net/2015/06/power-laws-in-venture.html].\n\nIn a previous essay [__GHOST_URL__/vcs-index-invest/], I introduced the\nnotion of \\(\\alpha\\), or alpha, the shape or tail parameter, which characterizes\nthe \"fat-tailedness\" of a power law distribution. The smaller \\(\\alpha\\), the\nmore skewed the distribution, the fatter the tails, with \\(\\alpha < 2\\)\nindicating extreme skew and fat-tailedness. For software monetization, the\nfatter the tail, the more common and impactful are those \"whale\" customers.\n\nEvidence for skewed monetization is tough to come by without access to a\ncompany's commercial contracts. However, we can infer the fat-tailedness from\nthe SEC filings of public software companies with a simple trick.\n\nReceive my next long-form post\nThoughtful analysis of the business and economics of tech\n\n\n\nSubscribeThe math\nThe trick? A formula [https://www.youtube.com/watch?v=XhTHG3QmVwM] exists that\ncalculates the concentration in the top percentiles of a power law distribution\nbased on the \\(\\alpha\\) of the distribution:\n\n$$\n\\text{s} = p^{\\frac{\\alpha-1}{\\alpha}}\n$$\nwhere \\(s\\) is the share of the total and \\(p\\) is the percentile.\n\nPlug in the \\(\\alpha\\) and the percentile \\(p\\) you are interested in to get the\nshare of the total that the top-p% of customers represent.\n\nInvert the formula to yield the \\(\\alpha\\) of a power law distribution given a\ncertain percentile and share:\n$$\n\\alpha = \\frac{\\log{p}}{\\log{p}-\\log{\\text{s}}}\n$$\nThis means we can infer \\(\\alpha\\)â€‹ and therefore how fat-tailed the revenue\ndistribution is if we know the share of revenue represented by the largest\ncustomers of a given software vendor.\n\nWe can estimate the shape of the customer distribution by plugging \\(\\alpha\\)\nback into the first equation along with some other percentile X in order to\nestimate the share of revenue earned from the top-X% of customers, which we can\nrepeat for other percentiles. For example, the relationship between \\(\\alpha\\)\nand the revenue concentrated in the top-20% of customer looks like this:\n\nSource: David Salazar\n[https://david-salazar.github.io/2020/05/19/understanding-the-tail-exponent/]An\n\\(\\alpha = 1.16\\) yields the classic Pareto 80/20 distribution\n[https://www.investopedia.com/terms/1/80-20-rule.asp], where 20% of customers\naccount for 80% of revenue.\n\nBefore we proceed, know that this method only works if we assume upfront that\nthe distribution is in fact power law distributed, at least in the tails. We\nnever proved this, so don't interpolate/extrapolate too far with this method.\n\nWith that caveat acknowledged, let's throw caution to the wind!\n\nThe evidence\nPublic companies do their best to hide customer concentration. But at a certain\npoint fiduciary duty requires that they disclose revenue concentration,\nespecially if a few customers account for a large enough chunk of revenue.\n\nCommonly, companies will state that \"no customer represents more than X% of\nrevenue.\" Less frequently, companies will go further, disclosing the number of\ncustomers that exceed some revenue threshold, typically $100,000, and the\nproportion of revenue they represent. This gets framed as a point of strength â€”\n\"look how many large customers we have\" â€” but it also indicates customer\nconcentration since the X customers with greater than $100K contracts are by\ndefinition the X largest customers.\n\nHere's an example from Slack's S-1\n[https://www.sec.gov/Archives/edgar/data/1764925/000162828019004786/slacks-1.htm]\n:\n\nSource: Slack's S-1\n[https://www.sec.gov/Archives/edgar/data/1764925/000162828019004786/slacks-1.htm]\nFrom this sort of disclosure we can calculate the \\(\\alpha\\) and fat-tailedness\nof customer monetization for public software vendors via the procedure outlined\nabove, plugging in the share of total revenue and total customers represented by\nthese large customers. I've done the hard work for you\n[https://docs.google.com/spreadsheets/d/163g-Tn9AdjF4bb4v7j8VidqeqMJvAHvb7EHUR2ctYsk/edit?usp=sharing] \nfor a subset of public software companies:\n\nSource\n[https://docs.google.com/spreadsheets/d/163g-Tn9AdjF4bb4v7j8VidqeqMJvAHvb7EHUR2ctYsk/edit?usp=sharing]\nThe alphas are universally below 2, implying a high level of skew.\n\nA more visual representation of the alphas (with the average in black):\n\nThe implied top-20% and top-1% revenue concentration are quite large for most\ncompanies (blue = top 20%, red = top 1%):\n\nSo, the top 20% typically represent ~70% of revenue, while the top 1% represent\n~40%. Not quite Pareto 80/20, but pretty close! Interestingly, many companies\ntied to infrastructure in some way like Datadog, Fastly, and Twilio do have\n80/20 monetization distributions, at least in some years.\n\nAs I caveated, these figures will be off to some degree. I'd guess they\noverestimate revenue concentration somewhat.\n\nHowever, I'm comforted by corroboration from a report by Theta Equity Partners\n[https://www.thetaequity.com/slack-ipo] that uses a completely different\nmethodology to estimate the monetization distribution of Slack's customer base.\nBased on the S-1 filing\n[https://www.sec.gov/Archives/edgar/data/1764925/000162828019004786/slacks-1.htm]\n, they found that Slack's top 1% of customers account for 40% of total revenue\nin 2019:\n\n> As we mentioned previously, the data and the model imply a high level of\nvariability in the â€œgoodnessâ€ of Slackâ€™s customers â€“ a small (<1%) segment of\nâ€œheavyâ€ customers accounts for 40% of companyâ€™s revenues and generates revenue\nper customer which is more than 100 times larger than everyone else.\nUsing my methodology, I find that the top 1% of Slack's customers in 2019\nrepresented 43% of revenue, which is quite similar.\n\nThe implications\nIt's easy to see these results and think \"Yes, sure, customer concentration is a\nthing. So what?\" But the implications of a fat-tailed monetization distribution\nare profound.\n\nWhy don't software companies index invest?\nFirst, as I discussed previously in Why Don't VCs Index Invest\n[https://nnamdi.net/vcs-index-invest/], when facing a sufficiently fat-tailed\ndistribution of returns, it doesn't make sense to be picky or overly\nconcentrated in one's investments. Index investing is the optimal allocation\nstrategy.\n\nHere, returns are synonymous with revenue and investment is synonymous with\ncustomer acquisition costs, or CAC. If the distribution of revenue is\nfat-tailed, vendors should be trying to insert their software into as many\ncustomers as possible, as cheaply as possible. Don't try to land large upfront,\nas this requires investing in a heavy and expensive enterprise sales motion that\nmay not yield results. Instead, spend small and land small, with each customer\ncontract acting as a potential \"lottery ticket\" that may unlock a much larger\ncontract later on, similar to an early-stage startup investment.\n\nThere's some merit to this analogy between venture capital and software\ngo-to-market strategies. One only has to look at estimates of \\(\\alpha\\) for\nventure capital investments to see that we are dealing with similar phenomena\nhere (ignore the orange footnotes):\n\nSource: Reaction Wheel\n[http://reactionwheel.net/2015/06/power-laws-in-venture.html]Whale hunting\nSecond, as I allude to in the aforementioned essay\n[https://nnamdi.net/vcs-index-invest/], finite samples of a positively skewed,\nfat-tailed distribution tend to underestimate the average, or mean, of the\ndistribution. Large values are rare, so small samples will tend to miss them.\nUnless you have an extremely large dataset, the \"true\" mean is typically larger\nthan the mean you measure from the data. So the calculated sample mean tends to\nincrease as the sample size grows, reflecting those large, infrequent outcomes.\n\nSaid more precisely:\n\n> An additional difficulty in the numerical estimation of momentsâ€”and, therefore,\nof riskâ€”is due to the very slow convergence of estimated values to the exact\nvalues of the process, even if the associated moments are finite. This â€œslow Law\nof Large Numbersâ€ is caused by the large weight of rare events (black swans),\nwhich take a lot of data to show up, and prevent a proper estimation of the\nmoments of such processes through the moments of a sample. â€” Fat tails and\nblack\nswans: Exact results for multiplicative processes with resets\n[https://aip.scitation.org/doi/10.1063/1.5141837]\nFurther, the largest value you are likely to see in a sample of power law\ndistribution (the expected value of the maximum value) is proportional to the\nsample size \\(n\\) and inversely proportional to \\(\\alpha\\):\n$$\n\\mathbb{E} [x_{max}] \\sim n^{1/(\\alpha-1)}\n$$\nIn plain English â€” your personal best\n[https://en.wikipedia.org/wiki/Personal_record] can only get better with more\nattempts. In the realm of venture, that looks like this:\n\nSource: Reaction Wheel\n[http://reactionwheel.net/2015/06/power-laws-in-venture.html]This is why returns\nin venture capital tend to increase with portfolio size:\n\nSource: AngelList [https://angel.co/pdf/lp-performance.pdf]In the context of\nsoftware monetization, the \"true distribution\" is the set of all potential\ncustomers while the \"sample\" is the set of current customers. Each customer is\nlike a draw from a random variable representing all potential customers, just\nlike a venture capital investment is like a random draw from a fat-tailed\ndistribution of potential returns.\n\nMy claim is that the average monetization across your customer base â€”\nARR/customer, revenue/customer, etc. â€” is an underestimate of the \"true\" or\n\"potential\" monetization. As you land more customers, so the logic goes, the\nrevenue you extract will tend to rise due to this fat-tailed phenomenon, with no\nchange in pricing model or customer targeting.\n\nMore is more, or specifically, more customers is more monetization, for the same\nreason that larger venture portfolios yield higher returns\n[https://www.institutionalinvestor.com/article/b1nlj1gb3g3bbd/The-Pervasive-Head-Scratching-Risk-Exploding-Problem-With-Venture-Capital]\n. Your wins get bigger the more broadly you penetrate the market.\n\nIt's natural to ask â€” \"how much does current monetization underestimate\npotential monetization?\"\n\nNassim Taleb [https://arxiv.org/abs/2001.10488] has already done the math for\nus. Imagine that true average monetization is the sum of the monetization of\ncustomers smaller than the largest customer we've acquired thus far, which he\ncalls \\(K\\), and the contribution of potential customers larger than our\nlargest:\n$$\n\\text{true mean} = \\text{mean of existing customers}_{<K} + \\text{contribution\nof potential customers}_{>K}\n$$\nIn the chart below, the shaded region represents larger customers yet to be\nacquired:\n\nSource: Statistical Consequences of Fat Tails [https://arxiv.org/abs/2001.10488]\nWhat proportion of the total does this extra bit represent? That depends both on\n\\(\\alpha\\), or how fat-tailed the distribution is, and on the sample size. The\nsmaller \\(\\alpha\\) and the smaller our sample, the more we underestimate the\ntrue mean:\n\nSource: Statistical Consequences of Fat Tails [https://arxiv.org/abs/2001.10488]\nSo for an enterprise software company with \\(\\alpha = 1.3\\), which is typical in\nmy data set, and 1000 customers, these not yet acquired customers will account\nfor 20% of the true mean. This means the true monetization is about 1 / 0.8 =\n25% higher than current monetization.\n\nThat number is conservative â€” it assumes that we've already acquired every\ncustomer up to a certain size, thereby maximizing monetization of customers\nequal to or below that size. We haven't really done this though, so even current\nmonetization underestimates how well we could monetize, even without acquiring\nlarger customers. Factor that in, and the degree to which we underestimate true\nmonetization only increases.\n\nThe math behind land and expand\nCombined, the above insights form a mathematical justification for \"land and\nexpand\n[https://saasx.com/2018/09/13/how-to-execute-a-saas-land-and-expand-strategy/]\n\"-style go-to-market strategies.\n\nHere, land and expand is effectively an indexing strategy\n[https://nnamdi.net/vcs-index-invest/] â€” land at as many organizations with as\nlittle investment as possible. Every once in a while you'll land a Google, a\nFacebook, or an Amazon (both figuratively and literally) which will drive a\ndisproportionate share of revenue.\n\nEven if those customers start off small, any given customer could potentially\nbecome quite large.\n\nFurther, it can make sense to overspend somewhat on establishing those small\nbeachheads, as they likely underestimate the true average contract value. For\nthis reason, common metrics for evaluating the efficiency of software sales like\nthe \"magic number [__GHOST_URL__/magical-magic-number/]\" may underestimate\nthe efficiency of land and expand models, especially during the land phase.\n\n> If we suspect right-skewness, the true mean is more likely to be underestimated\nby measurement of past realizations, and the total potential is likewise poorly\ngauged. â€” The Fourth Quadrant: A Map of the Limits of Statistics\n[http://www.edge.org/conversation/nassim_nicholas_taleb-the-fourth-quadrant-a-map-of-the-limits-of-statistics]\nIn fact, one of the best software investments I ever made (that shall remain\nnameless) was in a company that on its face seemed quite inefficient, with a\nmagic number well below 1. The leadership team preached the virtues of its land\nand expand model, but our static analysis of its sales metrics was doomed to\nunderestimate its true efficiency, even after many hours spent (by yours truly)\nwrangling and analyzing the data.\n\nLuckily, we got over our concerns and made what turned out to be a great\ninvestment.\n\nWith more mathematical context, the story is a visceral personal reminder to\nproperly grapple with the implications and dynamics of fat-tailed software\nmonetization.\n\nThe end\nThis is just a small taste of fat tails, and I plan to write more in the coming\nmonths on their broader implications for high-growth startups. Much ink has been\nspilled on this topic within the context of venture investing, but not so much\nfor operating the underlying businesses themselves.\n\nHere's a preview of the topics:\n\n * Why software markets are always larger than we think\n * Why \"Weighted ACV\" beats the traditional ACV metric\n   [https://whoisnnamdi.com/weighted-acv/]\n * Why investors consistently undervalue enterprise software and overvalue\n   consumer startups\n * Why open source is built by individuals rather than communities\n * Why product-market fit gets harder to achieve the longer you search for it\n   [__GHOST_URL__/product-market-fit-is-lindy/]\n\nI've been thinking about some of these essays for the better part of a year, so\nI'm excited to finally share these ideas.","feature_image":"__GHOST_URL__/content/images/2020/10/header-resized.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-10-06T07:03:07.000Z","updated_at":"2022-09-24T22:19:10.000Z","published_at":"2020-10-06T15:59:16.000Z","custom_excerpt":"In enterprise software, averages are meaningless. Instead, focus on the tails.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5f90896a17b26d3ef80d6490","uuid":"b8a0c3d4-52e4-4bef-afee-8569257f4540","title":"Talks","slug":"talks","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}]],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/10/gensf.png\",\"width\":336,\"height\":188}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/10/benedikt.png\",\"width\":586,\"height\":539}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/07/SCR-20250708-keig.png\",\"width\":534,\"height\":430}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/07/SCR-20250708-kdmv.png\",\"width\":600,\"height\":434}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/07/SCR-20250708-kcrg.png\",\"width\":602,\"height\":450}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/04/image-4.png\",\"width\":596,\"height\":655}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/04/image.png\",\"width\":442,\"height\":437}],[\"embed\",{\"url\":\"https://open.spotify.com/episode/6VSpSl0g528jWUzDLpf0vL\",\"html\":\"<iframe style=\\\"border-radius: 12px\\\" width=\\\"100%\\\" height=\\\"152\\\" title=\\\"Spotify Embed: Episode 109: Developer Productivity, Real-Time Data Infrastructure, and The Fat-Tailed Nature of Enterprise Software with Nnamdi Iregbulem\\\" frameborder=\\\"0\\\" allowfullscreen allow=\\\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\\\" loading=\\\"lazy\\\" src=\\\"https://open.spotify.com/embed/episode/6VSpSl0g528jWUzDLpf0vL?utm_source=oembed\\\"></iframe>\",\"type\":\"rich\",\"metadata\":{\"width\":456,\"height\":152,\"version\":\"1.0\",\"provider_name\":\"Spotify\",\"provider_url\":\"https://spotify.com/\",\"title\":\"Episode 109: Developer Productivity, Real-Time Data Infrastructure, and The Fat-Tailed Nature of Enterprise Software with Nnamdi Iregbulem\",\"thumbnail_url\":\"https://i.scdn.co/image/ab67656300005f1f0975bca27ba2472355b445bb\",\"thumbnail_width\":300,\"thumbnail_height\":300}}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/04/image-1.png\",\"width\":600,\"height\":600}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2023/03/image.png\",\"width\":1024,\"height\":1024}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/12/image.png\",\"width\":1786,\"height\":712}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/10/image.png\",\"width\":1199,\"height\":675}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/10/image-1.png\",\"width\":1200,\"height\":628}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/08/Nnamdi-I-Traction.png\",\"width\":1600,\"height\":900}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/08/image.png\",\"width\":1092,\"height\":466}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/image-1.png\",\"width\":800,\"height\":800}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/06/image.png\",\"width\":840,\"height\":672}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/05/image-3.png\",\"width\":960,\"height\":540}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/05/image-1.png\",\"width\":1650,\"height\":822}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/04/12---Nnamdi-Iregbulem.png\",\"width\":1080,\"height\":1080}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/05/image.png\",\"width\":900,\"height\":506}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/04/image.png\",\"width\":1245,\"height\":700}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2022/02/image.png\",\"width\":1071,\"height\":344}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/08/Nnamdi-Iregbulem.png\",\"width\":1920,\"height\":1080}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/05/image.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/03/image.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/12/image.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/11/119985712_667820227170903_4758538190186304063_n.jpg\"}],[\"embed\",{\"url\":\"https://www.youtube.com/watch?v=C8juMZGuSvk\",\"html\":\"<iframe width=\\\"480\\\" height=\\\"270\\\" src=\\\"https://www.youtube.com/embed/C8juMZGuSvk?feature=oembed\\\" frameborder=\\\"0\\\" allow=\\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\\" allowfullscreen></iframe>\",\"type\":\"video\"}],[\"markdown\",{\"markdown\":\"[![chart](__GHOST_URL__/content/images/2019/01/years_coding.png)](https://docs.google.com/presentation/d/14v-eLdpu2il8AMXU2a8rC4Nc4qaB2OyKTt6dALDhgJA/edit?usp=sharing)\"}]],\"markups\":[[\"a\",[\"href\",\"https://www.youtube.com/watch?v=azoBSxpkv7Y\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=Id7ebjEqAW8\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=jMzHuLzmpog\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=NVd_FmEDzis\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=5U_c_IHWK6I\"]],[\"a\",[\"href\",\"https://www.linkedin.com/in/andy-zhou-679376206/\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=sr1n4Swgk8k\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=4xT_6NtC3oo\"]],[\"a\",[\"href\",\"http://datacast.substack.com/\",\"rel\",\"nofollow ugc noopener\"]],[\"a\",[\"href\",\"https://open.substack.com/users/6557034-nnamdi-iregbulem?utm_source=mentions\",\"rel\",\"noreferrer\"]],[\"a\",[\"href\",\"https://lsvp.com/team/nnamdi-iregbulem/\",\"rel\",\"nofollow ugc noopener\"]],[\"a\",[\"href\",\"https://lsvp.com/\",\"rel\",\"nofollow ugc noopener\"]],[\"a\",[\"href\",\"https://open.spotify.com/episode/6VSpSl0g528jWUzDLpf0vL\"]],[\"a\",[\"href\",\"https://jameskle.com/writes/nnamdi-iregbulem\"]],[\"a\",[\"href\",\"https://podcasts.apple.com/us/podcast/seed-stage-valuation-insights-from-lightspeeds-nnamdi/id1719488387?i=1000680395270\"]],[\"strong\"],[\"a\",[\"href\",\"https://lsvp.com/?ref=terra-nova\"]],[\"a\",[\"href\",\"https://www.terranova.co/nnamdi-iregbulem-lightspeed-venture-partners-boosting-software-productivity/\"]],[\"a\",[\"href\",\"https://saasnorth.com/events/breakout-11/\"]],[\"a\",[\"href\",\"https://www.moderndatastack.xyz/podcast/s01-e05-streaming-data-and-the-modern-real-time-data-stack-lightspeed-ventures-74te\"]],[\"a\",[\"href\",\"https://podcasts.apple.com/us/podcast/the-developer-productivity-manifesto-with/id1539945251?i=1000581913746\"]],[\"a\",[\"href\",\"https://www.tractionconf.io/agenda\"]],[\"a\",[\"href\",\"https://youtube.com/watch?v=O94U-N26dbU\"]],[\"a\",[\"href\",\"https://embed.emamo.com/event/worldfestival-2022/s/the-developer-productivity-manifesto-NPYkva\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=_8oZYEtjNWQ\"]],[\"a\",[\"href\",\"https://blog.postman.com/breaking-changes-with-lightspeed-venture-partners-nnamdi-iregbulem-real-time-api-infrastructure-investments/\"]],[\"a\",[\"href\",\"https://fullratchet.net/337-navigating-macro-headwinds-balancing-growth-v-profitability-and-how-to-get-in-front-of-the-top-1-of-founders-nnamdi-iregbulem/\"]],[\"a\",[\"href\",\"https://open.spotify.com/episode/0EmEAuxMxb41hSx7P4nAOU?si=xBjhBnMNQse-DbtISdGzow\"]],[\"a\",[\"href\",\"https://deepdives.devrelcon.dev/workshops/aligning-devrel-with-your-business-stakeholders/\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=b3gBxsdCyw0\"]],[\"a\",[\"href\",\"https://www.klipfolio.com/blog/what-is-weighted-acv\"]],[\"a\",[\"href\",\"https://news.crunchbase.com/news/real-time-modern-data-stack/\"]],[\"a\",[\"href\",\"https://www.protocol.com/enterprise/lightspeed-vc-saas-revenue\"]],[\"a\",[\"href\",\"https://dataopsunleashed.com/2022-2/buildvsbuy/\"]],[\"a\",[\"href\",\"https://www.klipfolio.com/metrics/saas/weighted-acv\"]],[\"a\",[\"href\",\"https://gitlabcommitvirtual2021.com/\"]],[\"a\",[\"href\",\"https://docs.google.com/presentation/d/1i0ttzn6u7pgZ0Y8DUhmSFinyfjgjLqJoSUn4BO63ad8/edit?usp=sharing\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=_Q7i0ZKeTz8\"]],[\"a\",[\"href\",\"https://foundersnetwork.com/blog/pitching-your-enterprise-software-startup-with-lightspeeds-nnamdi-iregbulem/\"]],[\"a\",[\"href\",\"https://www.industryconference.com/virtual\"]],[\"a\",[\"href\",\"https://open.spotify.com/episode/2p9OMbLE4RRDvCFrq2wldm?si=UiFhbhiARjSeJE_FcHBnlw\"]],[\"a\",[\"href\",\"https://views.substack.com/p/nnamdiiregbulem\"]],[\"a\",[\"href\",\"https://open.spotify.com/episode/4gl2cUBR4MdWFzKYaHgb3D\"]],[\"a\",[\"href\",\"https://www.instagram.com/p/CFd4Gx6JvWf/\"]],[\"a\",[\"href\",\"https://gitlabcommitvirtual2020.sched.com/event/dUYa\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=C8juMZGuSvk\"]],[\"a\",[\"href\",\"https://docs.google.com/presentation/d/1U3G5-nZZoySkIashsrQbd4BAEqJGwDq-cF_xnPRZiNQ/edit?usp=sharing\"]],[\"a\",[\"href\",\"https://gitlab.com/whoisnnamdi/black-dev-2020\"]],[\"a\",[\"href\",\"https://github.com/whoisnnamdi/black-dev-2020/\"]],[\"a\",[\"href\",\"__GHOST_URL__/highest-paid-software-developer/\"]],[\"a\",[\"href\",\"https://docs.google.com/presentation/d/14v-eLdpu2il8AMXU2a8rC4Nc4qaB2OyKTt6dALDhgJA/edit?usp=sharing\"]]],\"sections\":[[1,\"h2\",[[0,[],0,\"Inside the Black Box: The Urgency of AI Interpretability\"]]],[1,\"blockquote\",[[0,[],0,\"Recorded live at Lightspeedâ€™s offices in San Francisco, this special episode of Generative Now dives into the urgency and promise of AI interpretability. Lightspeed partner Nnamdi Iregbulem spoke with Anthropic researcher Jack Lindsey and Goodfire co-founder and Chief Scientist Tom McGrath, who previously co-founded Google DeepMindâ€™s interpretability team. They discuss opening the black box of modern AI models in order to understand their reliability and spot real-world safety concerns, in order to build AI systems of the future that we can trust.\"]]],[3,\"ul\",[[[0,[0],1,\"Video\"]]]],[10,0],[1,\"h2\",[[0,[],0,\"Benedikt Stroebl: With Imperfect Verifiers, Scale Fails\"]]],[1,\"blockquote\",[[0,[],0,\"Verifiers are a hot topic in AI these days, where they play a role in both post-training and inference time scaling. But what if more compute at inference time doesn't always improve AI performance? I discuss with Benedikt Stroebl his research on the challenges presented by the inference time scaling paradigm, along with a particular application of agentic techniques to the world of cybersecurity.\"]]],[3,\"ul\",[[[0,[1],1,\"Video\"]]]],[10,1],[1,\"h2\",[[0,[],0,\"Satish Chandra: Google's AI Coding Agents That Fix Bugs Automatically\"]]],[1,\"blockquote\",[[0,[],0,\"Can AI agents soon eliminate the tedious task of debugging code? Google's Satish Chandra reveals groundbreaking research on how AI is changing the way teams fix and maintain production code.\"]]],[3,\"ul\",[[[0,[2],1,\"Video\"]]]],[10,2],[1,\"h2\",[[0,[],0,\"Jonas HÃ¼botter: 1000 Expert Models, 100x Faster, For Free\"]]],[1,\"blockquote\",[[0,[],0,\"What if you could get all the benefits of test-time adaptation of AI models for a particular task, but 100 times faster and essentially for free? Jonas HÃ¼botter shows how pre-training 1000 expert models and merging them at test-time achieves exactly that, with nearly zero overhead.\"]]],[3,\"ul\",[[[0,[3],1,\"Video\"]]]],[10,3],[1,\"h2\",[[0,[],0,\"Daniel Kang: AI Hackers Are Coming Sooner Than You Think\"]]],[1,\"blockquote\",[[0,[],0,\"AI systems that can autonomously hack applications are no longer science fiction. In this revealing conversation, Daniel Kang breaks down his team's research showing that AI systems can now find and exploit security vulnerabilities using agentic approaches.\"]]],[3,\"ul\",[[[0,[4],1,\"Video\"]]]],[10,4],[1,\"h2\",[[0,[],0,\"Andy Zhou: Language Agent Tree Search & Autonomous Red Teaming\"]]],[1,\"blockquote\",[[0,[],0,\"In this conversation I chat with \"],[0,[5],1,\"Andy Zhou\"],[0,[],0,\", where we discuss his ICML-accepted work on Language Agent Tree Search, which unifies reasoning, acting, and planning in LLMs via an innovative search algorithm, and AutoRed Teamer, an autonomous system for end-to-end red teaming LLMs.\"]]],[3,\"ul\",[[[0,[6],1,\"Video\"]]]],[10,5],[1,\"h2\",[[0,[],0,\"Charlie Snell: Optimally Scaling Test-Time Compute & Predicting Emergence\"]]],[1,\"blockquote\",[[0,[],0,\"In this conversation, I sit down with AI researcher Charlie Snell from UC Berkeley to discuss his groundbreaking work on optimally scaling test-time compute and predicting emergent capabilities in large language models. Charlie unpacks multiple dimensions of his work that could reshape how we approach AI development and inference strategies.\"]]],[3,\"ul\",[[[0,[7],1,\"Video\"]]]],[10,6],[1,\"h2\",[[0,[],0,\"Developer Productivity, Real-Time Data Infrastructure, and The Fat-Tailed Nature of Enterprise Software â€“ Datacast\"]]],[1,\"blockquote\",[[0,[],0,\"The 109th episode of \"],[0,[8],1,\"Datacast\"],[0,[],0,\" is my conversation with \"],[0,[9],1,\"Nnamdi Iregbulem\"],[0,[],0,\", a \"],[0,[10],1,\"Partner\"],[0,[],0,\" at \"],[0,[11],1,\"Lightspeed Venture Partners\"],[0,[],0,\". His mission is to increase total software output by supporting entrepreneurs building technical tools for technical people. He focuses on investments in technical enterprise software such as developer tools, application infrastructure, and machine learning.\"]]],[3,\"ul\",[[[0,[12],1,\"Podcast\"]],[[0,[13],1,\"Highlights\"]]]],[10,7],[1,\"h2\",[[0,[],0,\"Seed-stage Valuation Insights - Fund/Build/Scale\"]]],[1,\"blockquote\",[[0,[],0,\"If a team hasnâ€™t built a minimum viable product, secured paying customers, or demonstrated strong unit economics, what exactly are seed-stage investors betting on?\"],[1,[],0,0],[1,[],0,1],[0,[],0,\"To get some answers, I sat down with Nnamdi Iregbulem, a partner at Lightspeed Venture Partners, to discuss what drives seed valuations, the traits of successful founders, and his perspective on AI startups.\"],[1,[],0,2],[1,[],0,3],[0,[],0,\"Nnamdi shared his journey from coding as a kid to investment banking at JP Morgan, growth-stage investing at Iconiq Capital, and now helping early-stage founders at Lightspeed. He explains why seed valuations often reflect the opportunity cost of the founding team more than traditional factors like interest rates or public market comps, and highlights the rising costs of GPUs and AI talent as critical considerations.\"],[1,[],0,4],[1,[],0,5],[0,[],0,\"We also explored the traits that set exceptional founders apart â€” like strong domain expertise, adaptability, and demonstrated excellence â€” and why inference-based AI startups may have an edge over those focused on training new models.\"]]],[3,\"ul\",[[[0,[14],1,\"Podcast\"]]]],[10,8],[1,\"h2\",[[0,[],0,\"Lightspeedâ€™s Nnamdi Iregbulem: Boosting Total Software Output\"]]],[1,\"blockquote\",[[0,[],0,\"In a software-driven world, attracting and retaining top tech talent â€” from software engineers to data scientists â€” is becoming table stakes for teams looking to gain a competitive edge. But amid labor shortages, companies are now turning to software developer tools to help their teams do more with less. \"],[0,[15,15],2,\"Nnamdi Iregbulem\"],[0,[],0,\", partner at \"],[0,[16],1,\"Lightspeed Venture Partners\"],[0,[],0,\", explores how democratizing software development and investing in productivity tools can make teams more efficient.\"]]],[3,\"ul\",[[[0,[17],1,\"Interview\"]]]],[10,9],[1,\"h2\",[[0,[],0,\"SaaS Metrics 2.0 â€“ A Field Guide to the Metrics that Matter Today\"]]],[1,\"blockquote\",[[0,[],0,\"10 years ago, the hottest metrics for any SaaS company were revenue growth, customer retention, and LTV:CAC ratio. It was growth at all costs, chasing the magical T2D3 curve. While these metrics are still core, todayâ€™s entrepreneurs and investors are more sophisticated, and todayâ€™s world is very different. An expert panel â€“ a SaaS researcher, a leading VC, and a top SaaS CFO â€“ will give you practical, take-home guidance on the key metrics that are needed to understand and optimize your SaaS business today\"]]],[3,\"ul\",[[[0,[18],1,\"Event page\"]]]],[10,10],[1,\"h2\",[[0,[],0,\"Streaming Data and the Modern Real-Time Data Stack â€“ The Modern Data Show\"]]],[1,\"blockquote\",[[0,[],0,\"With the modern data stack evolving constantly, the next thing to look forward to is a real-time data stack, where companies are not just producing data in real-time but also consuming it on a real-time basis. In this latest episode of the Modern Data Show, we discuss the same with our guest Nnamdi Iregbulem, who has invested in a lot of modern real-time data stack tools.\"]]],[3,\"ul\",[[[0,[19],1,\"Podcast\"]]]],[10,11],[1,\"h2\",[[0,[],0,\"The Developer Productivity Manifesto with Nnamdi Iregbulem\"]]],[1,\"blockquote\",[[0,[],0,\"We welcome Nnamdi Iregbulem, Partner at Lightspeed, self-taught programmer, investor, and more, to talk about his latest conference talk, â€œThe Developer Productivity Manifesto,â€ in his venture to help developers understand both the technical and economic impact of their own productivity.\"]]],[3,\"ul\",[[[0,[20],1,\"Podcast\"]]]],[10,12],[1,\"h2\",[[0,[],0,\"The Next Trillion Dollar Market - 5 Lessons from Selling to Millions of Developers\"]]],[1,\"blockquote\",[[0,[],0,\"Think marketing to developers is all about hoodies and hackathons?  Think again. As the developer-led economy, now worth $50B USD is poised to grow to a trillion dollars, companies that offer products for developers must refocus to a business-to-developer (B2D) model as developers become not only users of products, but key purchasing influencers.\"]]],[3,\"ul\",[[[0,[21],1,\"Event page\"]],[[0,[22],1,\"Video\"]]]],[10,13],[1,\"h2\",[[0,[],0,\"The Developer Productivity Manifesto | Dev Innovation Summit\"]]],[1,\"blockquote\",[[0,[],0,\"With the explosion of various developer tools and services in recent years, it's tempting to think that we've entered a golden age for software development productivity. However, contrary to popular belief, developer productivity is in fact declining, and this phenomenon risks bringing modern software development to a grinding halt in many organizations. In this talk, Nnamdi Iregbulem reveals a framework for thinking about developer productivity and charts a path toward reversing this dire trend. \"]]],[3,\"ul\",[[[0,[23],1,\"Event page\"]]]],[10,14],[1,\"h2\",[[0,[],0,\"Breaking Changes Podcast | Postman\"]]],[1,\"blockquote\",[[0,[],0,\"In this Breaking Changes, Postman Chief Evangelist Kin Lane welcomes Nnamdi Iregbulem of Lightspeed Venture Partner to talk about the importance of developer tools, streaming API technology,  and how data and machine learning is continuing to shape the API landscape.\"]]],[3,\"ul\",[[[0,[24],1,\"Podcast\"]],[[0,[25],1,\"Recap\"]]]],[10,15],[1,\"h2\",[[0,[],0,\"The Full Ratchet: Venture Capital Demystified\"]]],[1,\"blockquote\",[[0,[],0,\"Nnamdi Iregbulem of Lightspeed Venture Partners joins Nate to discuss Navigating Macro Headwinds, Balancing Growth v. Profitability, and How to Get in Front of the Top 1% of Founders. In this episode we cover: (1) Tips for Founders When Capital Gets Expensive, (2) Where Software is Still Eating the World, (3) The Uncapped Upside of Writing in VC, (4) How to Get in Front of the Top Founders\"]]],[3,\"ul\",[[[0,[26],1,\"Podcast\"]]]],[10,16],[1,\"h2\",[[0,[],0,\"The Scaling Developer Success Podcast\"]]],[1,\"blockquote\",[[0,[],0,\"The world of DevRel had evolved over the last few years. This podcast dives into dev success with some of the world's top leaders in the industry.\"]]],[3,\"ul\",[[[0,[27],1,\"Spotify\"]]]],[10,17],[1,\"h2\",[[0,[],0,\"Aligning DevRel with Your Business Stakeholders\"]]],[1,\"blockquote\",[[0,[],0,\"Practical discussion of how to make sure your DevRel program meets your companyâ€™s needs.\"]]],[3,\"ul\",[[[0,[28],1,\"Event page\"]]]],[10,18],[1,\"h2\",[[0,[],0,\"What is Weighted ACV? â€“ Metric Stack\"]]],[1,\"blockquote\",[[0,[],0,\"Nnamdi Iregbulem, Partner at Lightspeed Venture Partners is our guest on the podcast this week. Nnamdi walks through this new metric: What is it? How do you calculate it? When should a company start tracking weighted ACV?\"]]],[3,\"ul\",[[[0,[29],1,\"Podcast\"]],[[0,[30],1,\"Summary\"]]]],[10,19],[1,\"h2\",[[0,[],0,\"How The Modern Data Stack Is Going Real-Time\"]]],[1,\"blockquote\",[[0,[],0,\"Times have changed. Organizations are increasingly fed up with traditional data infrastructure, which is slow to yield answers to key business intelligence questions and often out of date and out of sync with current business realities, typically by a day or more.\"]]],[3,\"ul\",[[[0,[31],1,\"Guest Blog\"]]]],[10,20],[1,\"h2\",[[0,[],0,\"What VCs miss about SaaS revenue\"]]],[1,\"blockquote\",[[0,[],0,\"Protocol caught up with Lightspeed Venture Partnersâ€™ Nnamdi Iregbulem to talk about revenue concentration in SaaS and why todayâ€™s metrics donâ€™t give investors the full picture.\"]]],[3,\"ul\",[[[0,[32],1,\"Interview\"]]]],[10,21],[1,\"h2\",[[0,[],0,\"Build vs Buy | DataOps Unleashed 2022\"]]],[1,\"blockquote\",[[0,[],0,\"Join Nnamdi, Andrei, Aaron, and Gokul as they discuss their decision-making methods and strategies for evaluating whether to build or buy components for their data stacks.\"]]],[3,\"ul\",[[[0,[33],1,\"Video\"]]]],[10,22],[1,\"h2\",[[0,[],0,\"Weighted ACV | MetricHQ\"]]],[1,\"blockquote\",[[0,[],0,\"Weighted Annual Contract Value (WACV) calculates the average contract dollar value with a weighted average proportional to the value of the contract. Essentially, higher value contracts are assigned more importance when calculating the total average contract value of a business. This approach is helpful to companies that have widely varying customer concentration by accurately calculating an ACV that is not skewed by contracts with low dollar value.\"]]],[3,\"ul\",[[[0,[34],1,\"Article\"]]]],[1,\"h2\",[[0,[],0,\"The Developer Productivity Manifesto (GitLab Commit 2021)\"]]],[1,\"blockquote\",[[0,[],0,\"With the explosion of various developer tools and services in recent years, it's tempting to think that we've entered a golden age for software development productivity. However, contrary to popular belief, developer productivity is in fact declining, and this phenomenon risks bringing modern software development to a grinding halt in many organizations. In this talk, Nnamdi Iregbulem reveals a framework for thinking about developer productivity and charts a path toward reversing this dire trend.\"]]],[3,\"ul\",[[[0,[35],1,\"Event page\"]],[[0,[36],1,\"Slides\"]],[[0,[37],1,\"Video\"]]]],[10,23],[1,\"h2\",[[0,[],0,\"Pitching Your Enterprise Software Startup with Lightspeedâ€™s Nnamdi Iregbulem\"]]],[1,\"blockquote\",[[0,[],0,\"A partner at Lightspeed Venture Partners whoâ€™s backed names like Fastly, GitLab and Epic Games, Iregbulem offers advice and feedback at a Founders Network pitch practice.\"]]],[3,\"ul\",[[[0,[38],1,\"Interview\"]]]],[1,\"h2\",[[0,[],0,\"The Developer Productivity Manifesto (INDUSTRY Virtual 2021)\"]]],[1,\"blockquote\",[[0,[],0,\"As product people, we're always thinking about the performance of the teams actually developing the products -- including our software developers. With the explosion of various developer tools and services in recent years, it's tempting to think that we've entered a golden age for software development productivity. However, contrary to popular belief, developer productivity is in fact declining, and this phenomenon risks bringing modern software development to a grinding halt in many organizations. In this talk, Nnamdi Iregbulem reveals a framework for thinking about developer productivity and charts a path toward reversing this dire trend.\"]]],[3,\"ul\",[[[0,[39],1,\"Event page\"]]]],[10,24],[1,\"h2\",[[0,[],0,\"Venture Games Podcast by Chris Quaidoo\"]]],[1,\"blockquote\",[[0,[],0,\"In Episode 4 of Venture Games, my guest Nnamdi Iregbulem, Partner at Lightspeed Venture Partners, talks about being a lifelong gamer and self-proclaimed tech nerd, investing in Epic Games, the company behind Fortnite, his blog, whoisnnamdi.com, and being selected as one of Forbes 30 Under 30 in Venture.\"]]],[3,\"ul\",[[[0,[40],1,\"Podcast\"]]]],[10,25],[1,\"h2\",[[0,[],0,\"Views by Pol FaÃ±anÃ¡s & Gerard Garcia\"]]],[3,\"ul\",[[[0,[41],1,\"Interview\"]]]],[10,26],[1,\"h2\",[[0,[],0,\"Igbopedia Podcast\"]]],[1,\"blockquote\",[[0,[],0,\"My guest is Nnamdi Iregbulem. He is a Partner at Lightspeed Venture Partners, a US-headquartered venture capital firm. On this episode, Nnamdi joins me in conversation from Silicon Valley where he invests in and advises start-ups that build next-generation technology. We talk about his early life, his work and what he is passionate about. Check out his personal website: whoisnnamdi.com\"]]],[3,\"ul\",[[[0,[42],1,\"Podcast\"]],[[0,[43],1,\"Igbopedia Instagram\"]]]],[10,27],[1,\"h2\",[[0,[],0,\"The State of Black Software Development\"]]],[1,\"blockquote\",[[0,[],0,\"Recent events have raised awareness of pervasive issues facing blacks in America. Further, blacks have historically been underrepresented in software development, accounting for approximately 2% of software  developers despite making up approximately 13% of the American  population. Many companies claim to be committed to diversifying their  software engineering workforce, and these promises have only accelerated  in recent months. However, aside from data revealing their prevalence  among software developers, little publicly available data or analysis  exists on the professional experience of black software developers. In  this presentation, I analyze pay gaps, paths to promotion, job and  career satisfaction, and other aspects of black software development to  better understand the career journeys of black software engineers.\"]]],[3,\"ul\",[[[0,[44],1,\"Event page\"]],[[0,[45],1,\"Video\"]],[[0,[46],1,\"Slides\"]],[[0,[47],1,\"GitLab\"],[0,[],0,\"/ \"],[0,[48],1,\"GitHub\"],[0,[],0,\" Repo\"]]]],[10,28],[1,\"h2\",[[0,[],0,\"What I Learned Analyzing the Earnings of 11,037 Software Developers\"]]],[3,\"ul\",[[[0,[49],1,\"Write-up\"]],[[0,[50],1,\"Slides\"]]]],[10,29],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}","html":"<h2 id=\"inside-the-black-box-the-urgency-of-ai-interpretability\">Inside the Black Box: The Urgency of AI Interpretability</h2><blockquote>Recorded live at Lightspeedâ€™s offices in San Francisco, this special episode of Generative Now dives into the urgency and promise of AI interpretability. Lightspeed partner Nnamdi Iregbulem spoke with Anthropic researcher Jack Lindsey and Goodfire co-founder and Chief Scientist Tom McGrath, who previously co-founded Google DeepMindâ€™s interpretability team. They discuss opening the black box of modern AI models in order to understand their reliability and spot real-world safety concerns, in order to build AI systems of the future that we can trust.</blockquote><ul><li><a href=\"https://www.youtube.com/watch?v=azoBSxpkv7Y\">Video</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2025/10/gensf.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"336\" height=\"188\"></figure><h2 id=\"benedikt-stroebl-with-imperfect-verifiers-scale-fails\">Benedikt Stroebl: With Imperfect Verifiers, Scale Fails</h2><blockquote>Verifiers are a hot topic in AI these days, where they play a role in both post-training and inference time scaling. But what if more compute at inference time doesn't always improve AI performance? I discuss with Benedikt Stroebl his research on the challenges presented by the inference time scaling paradigm, along with a particular application of agentic techniques to the world of cybersecurity.</blockquote><ul><li><a href=\"https://www.youtube.com/watch?v=Id7ebjEqAW8\">Video</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2025/10/benedikt.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"586\" height=\"539\"></figure><h2 id=\"satish-chandra-google-s-ai-coding-agents-that-fix-bugs-automatically\">Satish Chandra: Google's AI Coding Agents That Fix Bugs Automatically</h2><blockquote>Can AI agents soon eliminate the tedious task of debugging code? Google's Satish Chandra reveals groundbreaking research on how AI is changing the way teams fix and maintain production code.</blockquote><ul><li><a href=\"https://www.youtube.com/watch?v=jMzHuLzmpog\">Video</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2025/07/SCR-20250708-keig.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"534\" height=\"430\"></figure><h2 id=\"jonas-h-botter-1000-expert-models-100x-faster-for-free\">Jonas HÃ¼botter: 1000 Expert Models, 100x Faster, For Free</h2><blockquote>What if you could get all the benefits of test-time adaptation of AI models for a particular task, but 100 times faster and essentially for free? Jonas HÃ¼botter shows how pre-training 1000 expert models and merging them at test-time achieves exactly that, with nearly zero overhead.</blockquote><ul><li><a href=\"https://www.youtube.com/watch?v=NVd_FmEDzis\">Video</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2025/07/SCR-20250708-kdmv.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"600\" height=\"434\" srcset=\"__GHOST_URL__/content/images/2025/07/SCR-20250708-kdmv.png 600w\"></figure><h2 id=\"daniel-kang-ai-hackers-are-coming-sooner-than-you-think\">Daniel Kang: AI Hackers Are Coming Sooner Than You Think</h2><blockquote>AI systems that can autonomously hack applications are no longer science fiction. In this revealing conversation, Daniel Kang breaks down his team's research showing that AI systems can now find and exploit security vulnerabilities using agentic approaches.</blockquote><ul><li><a href=\"https://www.youtube.com/watch?v=5U_c_IHWK6I\">Video</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2025/07/SCR-20250708-kcrg.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"602\" height=\"450\" srcset=\"__GHOST_URL__/content/images/size/w600/2025/07/SCR-20250708-kcrg.png 600w, __GHOST_URL__/content/images/2025/07/SCR-20250708-kcrg.png 602w\"></figure><h2 id=\"andy-zhou-language-agent-tree-search-autonomous-red-teaming\">Andy Zhou: Language Agent Tree Search &amp; Autonomous Red Teaming</h2><blockquote>In this conversation I chat with <a href=\"https://www.linkedin.com/in/andy-zhou-679376206/\">Andy Zhou</a>, where we discuss his ICML-accepted work on Language Agent Tree Search, which unifies reasoning, acting, and planning in LLMs via an innovative search algorithm, and AutoRed Teamer, an autonomous system for end-to-end red teaming LLMs.</blockquote><ul><li><a href=\"https://www.youtube.com/watch?v=sr1n4Swgk8k\">Video</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2025/04/image-4.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"596\" height=\"655\"></figure><h2 id=\"charlie-snell-optimally-scaling-test-time-compute-predicting-emergence\">Charlie Snell: Optimally Scaling Test-Time Compute &amp; Predicting Emergence</h2><blockquote>In this conversation, I sit down with AI researcher Charlie Snell from UC Berkeley to discuss his groundbreaking work on optimally scaling test-time compute and predicting emergent capabilities in large language models. Charlie unpacks multiple dimensions of his work that could reshape how we approach AI development and inference strategies.</blockquote><ul><li><a href=\"https://www.youtube.com/watch?v=4xT_6NtC3oo\">Video</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2025/04/image.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"442\" height=\"437\"></figure><h2 id=\"developer-productivity-real-time-data-infrastructure-and-the-fat-tailed-nature-of-enterprise-software-datacast\">Developer Productivity, Real-Time Data Infrastructure, and The Fat-Tailed Nature of Enterprise Software â€“ Datacast</h2><blockquote>The 109th episode of <a href=\"http://datacast.substack.com/\" rel=\"nofollow ugc noopener\">Datacast</a> is my conversation with <a href=\"https://open.substack.com/users/6557034-nnamdi-iregbulem?utm_source=mentions\" rel=\"noreferrer\">Nnamdi Iregbulem</a>, a <a href=\"https://lsvp.com/team/nnamdi-iregbulem/\" rel=\"nofollow ugc noopener\">Partner</a> at <a href=\"https://lsvp.com/\" rel=\"nofollow ugc noopener\">Lightspeed Venture Partners</a>. His mission is to increase total software output by supporting entrepreneurs building technical tools for technical people. He focuses on investments in technical enterprise software such as developer tools, application infrastructure, and machine learning.</blockquote><ul><li><a href=\"https://open.spotify.com/episode/6VSpSl0g528jWUzDLpf0vL\">Podcast</a></li><li><a href=\"https://jameskle.com/writes/nnamdi-iregbulem\">Highlights</a></li></ul><figure class=\"kg-card kg-embed-card\"><iframe style=\"border-radius: 12px\" width=\"100%\" height=\"152\" title=\"Spotify Embed: Episode 109: Developer Productivity, Real-Time Data Infrastructure, and The Fat-Tailed Nature of Enterprise Software with Nnamdi Iregbulem\" frameborder=\"0\" allowfullscreen allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\" src=\"https://open.spotify.com/embed/episode/6VSpSl0g528jWUzDLpf0vL?utm_source=oembed\"></iframe></figure><h2 id=\"seed-stage-valuation-insights-fund-build-scale\">Seed-stage Valuation Insights - Fund/Build/Scale</h2><blockquote>If a team hasnâ€™t built a minimum viable product, secured paying customers, or demonstrated strong unit economics, what exactly are seed-stage investors betting on?<br><br>To get some answers, I sat down with Nnamdi Iregbulem, a partner at Lightspeed Venture Partners, to discuss what drives seed valuations, the traits of successful founders, and his perspective on AI startups.<br><br>Nnamdi shared his journey from coding as a kid to investment banking at JP Morgan, growth-stage investing at Iconiq Capital, and now helping early-stage founders at Lightspeed. He explains why seed valuations often reflect the opportunity cost of the founding team more than traditional factors like interest rates or public market comps, and highlights the rising costs of GPUs and AI talent as critical considerations.<br><br>We also explored the traits that set exceptional founders apart â€” like strong domain expertise, adaptability, and demonstrated excellence â€” and why inference-based AI startups may have an edge over those focused on training new models.</blockquote><ul><li><a href=\"https://podcasts.apple.com/us/podcast/seed-stage-valuation-insights-from-lightspeeds-nnamdi/id1719488387?i=1000680395270\">Podcast</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2025/04/image-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"600\" height=\"600\" srcset=\"__GHOST_URL__/content/images/2025/04/image-1.png 600w\"></figure><h2 id=\"lightspeed-s-nnamdi-iregbulem-boosting-total-software-output\">Lightspeedâ€™s Nnamdi Iregbulem: Boosting Total Software Output</h2><blockquote>In a software-driven world, attracting and retaining top tech talent â€” from software engineers to data scientists â€” is becoming table stakes for teams looking to gain a competitive edge. But amid labor shortages, companies are now turning to software developer tools to help their teams do more with less. <strong><strong>Nnamdi Iregbulem</strong></strong>, partner at <a href=\"https://lsvp.com/?ref=terra-nova\">Lightspeed Venture Partners</a>, explores how democratizing software development and investing in productivity tools can make teams more efficient.</blockquote><ul><li><a href=\"https://www.terranova.co/nnamdi-iregbulem-lightspeed-venture-partners-boosting-software-productivity/\">Interview</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2023/03/image.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1024\" height=\"1024\" srcset=\"__GHOST_URL__/content/images/size/w600/2023/03/image.png 600w, __GHOST_URL__/content/images/size/w1000/2023/03/image.png 1000w, __GHOST_URL__/content/images/2023/03/image.png 1024w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"saas-metrics-2-0-a-field-guide-to-the-metrics-that-matter-today\">SaaS Metrics 2.0 â€“ A Field Guide to the Metrics that Matter Today</h2><blockquote>10 years ago, the hottest metrics for any SaaS company were revenue growth, customer retention, and LTV:CAC ratio. It was growth at all costs, chasing the magical T2D3 curve. While these metrics are still core, todayâ€™s entrepreneurs and investors are more sophisticated, and todayâ€™s world is very different. An expert panel â€“ a SaaS researcher, a leading VC, and a top SaaS CFO â€“ will give you practical, take-home guidance on the key metrics that are needed to understand and optimize your SaaS business today</blockquote><ul><li><a href=\"https://saasnorth.com/events/breakout-11/\">Event page</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/12/image.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1786\" height=\"712\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/12/image.png 600w, __GHOST_URL__/content/images/size/w1000/2022/12/image.png 1000w, __GHOST_URL__/content/images/size/w1600/2022/12/image.png 1600w, __GHOST_URL__/content/images/2022/12/image.png 1786w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"streaming-data-and-the-modern-real-time-data-stack-the-modern-data-show\">Streaming Data and the Modern Real-Time Data Stack â€“ The Modern Data Show</h2><blockquote>With the modern data stack evolving constantly, the next thing to look forward to is a real-time data stack, where companies are not just producing data in real-time but also consuming it on a real-time basis. In this latest episode of the Modern Data Show, we discuss the same with our guest Nnamdi Iregbulem, who has invested in a lot of modern real-time data stack tools.</blockquote><ul><li><a href=\"https://www.moderndatastack.xyz/podcast/s01-e05-streaming-data-and-the-modern-real-time-data-stack-lightspeed-ventures-74te\">Podcast</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/10/image.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1199\" height=\"675\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/10/image.png 600w, __GHOST_URL__/content/images/size/w1000/2022/10/image.png 1000w, __GHOST_URL__/content/images/2022/10/image.png 1199w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"the-developer-productivity-manifesto-with-nnamdi-iregbulem\">The Developer Productivity Manifesto with Nnamdi Iregbulem</h2><blockquote>We welcome Nnamdi Iregbulem, Partner at Lightspeed, self-taught programmer, investor, and more, to talk about his latest conference talk, â€œThe Developer Productivity Manifesto,â€ in his venture to help developers understand both the technical and economic impact of their own productivity.</blockquote><ul><li><a href=\"https://podcasts.apple.com/us/podcast/the-developer-productivity-manifesto-with/id1539945251?i=1000581913746\">Podcast</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/10/image-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1200\" height=\"628\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/10/image-1.png 600w, __GHOST_URL__/content/images/size/w1000/2022/10/image-1.png 1000w, __GHOST_URL__/content/images/2022/10/image-1.png 1200w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"the-next-trillion-dollar-market-5-lessons-from-selling-to-millions-of-developers\">The Next Trillion Dollar Market - 5 Lessons from Selling to Millions of Developers</h2><blockquote>Think marketing to developers is all about hoodies and hackathons? Â Think again. As the developer-led economy, now worth $50B USD is poised to grow to a trillion dollars, companies that offer products for developers must refocus to a business-to-developer (B2D) model as developers become not only users of products, but key purchasing influencers.</blockquote><ul><li><a href=\"https://www.tractionconf.io/agenda\">Event page</a></li><li><a href=\"https://youtube.com/watch?v=O94U-N26dbU\">Video</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/08/Nnamdi-I-Traction.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1600\" height=\"900\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/08/Nnamdi-I-Traction.png 600w, __GHOST_URL__/content/images/size/w1000/2022/08/Nnamdi-I-Traction.png 1000w, __GHOST_URL__/content/images/2022/08/Nnamdi-I-Traction.png 1600w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"the-developer-productivity-manifesto-dev-innovation-summit\">The Developer Productivity Manifesto | Dev Innovation Summit</h2><blockquote>With the explosion of various developer tools and services in recent years, it's tempting to think that we've entered a golden age for software development productivity. However, contrary to popular belief, developer productivity is in fact declining, and this phenomenon risks bringing modern software development to a grinding halt in many organizations. In this talk, Nnamdi Iregbulem reveals a framework for thinking about developer productivity and charts a path toward reversing this dire trend. </blockquote><ul><li><a href=\"https://embed.emamo.com/event/worldfestival-2022/s/the-developer-productivity-manifesto-NPYkva\">Event page</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/08/image.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1092\" height=\"466\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/08/image.png 600w, __GHOST_URL__/content/images/size/w1000/2022/08/image.png 1000w, __GHOST_URL__/content/images/2022/08/image.png 1092w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"breaking-changes-podcast-postman\">Breaking Changes Podcast | Postman</h2><blockquote>In this Breaking Changes, Postman Chief Evangelist Kin Lane welcomes Nnamdi Iregbulem of Lightspeed Venture Partner to talk about the importance of developer tools, streaming API technology, Â and how data and machine learning is continuing to shape the API landscape.</blockquote><ul><li><a href=\"https://www.youtube.com/watch?v=_8oZYEtjNWQ\">Podcast</a></li><li><a href=\"https://blog.postman.com/breaking-changes-with-lightspeed-venture-partners-nnamdi-iregbulem-real-time-api-infrastructure-investments/\">Recap</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/image-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"800\" height=\"800\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/06/image-1.png 600w, __GHOST_URL__/content/images/2022/06/image-1.png 800w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"the-full-ratchet-venture-capital-demystified\">The Full Ratchet: Venture Capital Demystified</h2><blockquote>Nnamdi Iregbulem of Lightspeed Venture Partners joins Nate to discuss Navigating Macro Headwinds, Balancing Growth v. Profitability, and How to Get in Front of the Top 1% of Founders. In this episode we cover: (1) Tips for Founders When Capital Gets Expensive, (2) Where Software is Still Eating the World, (3) The Uncapped Upside of Writing in VC, (4) How to Get in Front of the Top Founders</blockquote><ul><li><a href=\"https://fullratchet.net/337-navigating-macro-headwinds-balancing-growth-v-profitability-and-how-to-get-in-front-of-the-top-1-of-founders-nnamdi-iregbulem/\">Podcast</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/06/image.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"840\" height=\"672\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/06/image.png 600w, __GHOST_URL__/content/images/2022/06/image.png 840w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"the-scaling-developer-success-podcast\">The Scaling Developer Success Podcast</h2><blockquote>The world of DevRel had evolved over the last few years. This podcast dives into dev success with some of the world's top leaders in the industry.</blockquote><ul><li><a href=\"https://open.spotify.com/episode/0EmEAuxMxb41hSx7P4nAOU?si=xBjhBnMNQse-DbtISdGzow\">Spotify</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/05/image-3.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"960\" height=\"540\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/05/image-3.png 600w, __GHOST_URL__/content/images/2022/05/image-3.png 960w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"aligning-devrel-with-your-business-stakeholders\">Aligning DevRel with Your Business Stakeholders</h2><blockquote>Practical discussion of how to make sure your DevRel program meets your companyâ€™s needs.</blockquote><ul><li><a href=\"https://deepdives.devrelcon.dev/workshops/aligning-devrel-with-your-business-stakeholders/\">Event page</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/05/image-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1650\" height=\"822\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/05/image-1.png 600w, __GHOST_URL__/content/images/size/w1000/2022/05/image-1.png 1000w, __GHOST_URL__/content/images/size/w1600/2022/05/image-1.png 1600w, __GHOST_URL__/content/images/2022/05/image-1.png 1650w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"what-is-weighted-acv-metric-stack\">What is Weighted ACV? â€“ Metric Stack</h2><blockquote>Nnamdi Iregbulem, Partner at Lightspeed Venture Partners is our guest on the podcast this week. Nnamdi walks through this new metric: What is it? How do you calculate it? When should a company start tracking weighted ACV?</blockquote><ul><li><a href=\"https://www.youtube.com/watch?v=b3gBxsdCyw0\">Podcast</a></li><li><a href=\"https://www.klipfolio.com/blog/what-is-weighted-acv\">Summary</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/04/12---Nnamdi-Iregbulem.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1080\" height=\"1080\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/04/12---Nnamdi-Iregbulem.png 600w, __GHOST_URL__/content/images/size/w1000/2022/04/12---Nnamdi-Iregbulem.png 1000w, __GHOST_URL__/content/images/2022/04/12---Nnamdi-Iregbulem.png 1080w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"how-the-modern-data-stack-is-going-real-time\">How The Modern Data Stack Is Going Real-Time</h2><blockquote>Times have changed. Organizations are increasingly fed up with traditional data infrastructure, which is slow to yield answers to key business intelligence questions and often out of date and out of sync with current business realities, typically by a day or more.</blockquote><ul><li><a href=\"https://news.crunchbase.com/news/real-time-modern-data-stack/\">Guest Blog</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/05/image.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"900\" height=\"506\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/05/image.png 600w, __GHOST_URL__/content/images/2022/05/image.png 900w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"what-vcs-miss-about-saas-revenue\">What VCs miss about SaaS revenue</h2><blockquote>Protocol caught up with Lightspeed Venture Partnersâ€™ Nnamdi Iregbulem to talk about revenue concentration in SaaS and why todayâ€™s metrics donâ€™t give investors the full picture.</blockquote><ul><li><a href=\"https://www.protocol.com/enterprise/lightspeed-vc-saas-revenue\">Interview</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/04/image.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1245\" height=\"700\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/04/image.png 600w, __GHOST_URL__/content/images/size/w1000/2022/04/image.png 1000w, __GHOST_URL__/content/images/2022/04/image.png 1245w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"build-vs-buy-dataops-unleashed-2022\">Build vs Buy | DataOps Unleashed 2022</h2><blockquote>Join Nnamdi, Andrei, Aaron, and Gokul as they discuss their decision-making methods and strategies for evaluating whether to build or buy components for their data stacks.</blockquote><ul><li><a href=\"https://dataopsunleashed.com/2022-2/buildvsbuy/\">Video</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2022/02/image.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1071\" height=\"344\" srcset=\"__GHOST_URL__/content/images/size/w600/2022/02/image.png 600w, __GHOST_URL__/content/images/size/w1000/2022/02/image.png 1000w, __GHOST_URL__/content/images/2022/02/image.png 1071w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"weighted-acv-metrichq\">Weighted ACV | MetricHQ</h2><blockquote>Weighted Annual Contract Value (WACV) calculates the average contract dollar value with a weighted average proportional to the value of the contract. Essentially, higher value contracts are assigned more importance when calculating the total average contract value of a business. This approach is helpful to companies that have widely varying customer concentration by accurately calculating an ACV that is not skewed by contracts with low dollar value.</blockquote><ul><li><a href=\"https://www.klipfolio.com/metrics/saas/weighted-acv\">Article</a></li></ul><h2 id=\"the-developer-productivity-manifesto-gitlab-commit-2021-\">The Developer Productivity Manifesto (GitLab Commit 2021)</h2><blockquote>With the explosion of various developer tools and services in recent years, it's tempting to think that we've entered a golden age for software development productivity. However, contrary to popular belief, developer productivity is in fact declining, and this phenomenon risks bringing modern software development to a grinding halt in many organizations. In this talk, Nnamdi Iregbulem reveals a framework for thinking about developer productivity and charts a path toward reversing this dire trend.</blockquote><ul><li><a href=\"https://gitlabcommitvirtual2021.com/\">Event page</a></li><li><a href=\"https://docs.google.com/presentation/d/1i0ttzn6u7pgZ0Y8DUhmSFinyfjgjLqJoSUn4BO63ad8/edit?usp=sharing\">Slides</a></li><li><a href=\"https://www.youtube.com/watch?v=_Q7i0ZKeTz8\">Video</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/08/Nnamdi-Iregbulem.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1920\" height=\"1080\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/08/Nnamdi-Iregbulem.png 600w, __GHOST_URL__/content/images/size/w1000/2021/08/Nnamdi-Iregbulem.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/08/Nnamdi-Iregbulem.png 1600w, __GHOST_URL__/content/images/2021/08/Nnamdi-Iregbulem.png 1920w\" sizes=\"(min-width: 720px) 720px\"></figure><h2 id=\"pitching-your-enterprise-software-startup-with-lightspeed-s-nnamdi-iregbulem\">Pitching Your Enterprise Software Startup with Lightspeedâ€™s Nnamdi Iregbulem</h2><blockquote>A partner at Lightspeed Venture Partners whoâ€™s backed names like Fastly, GitLab and Epic Games, Iregbulem offers advice and feedback at a Founders Network pitch practice.</blockquote><ul><li><a href=\"https://foundersnetwork.com/blog/pitching-your-enterprise-software-startup-with-lightspeeds-nnamdi-iregbulem/\">Interview</a></li></ul><h2 id=\"the-developer-productivity-manifesto-industry-virtual-2021-\">The Developer Productivity Manifesto (INDUSTRY Virtual 2021)</h2><blockquote>As product people, we're always thinking about the performance of the teams actually developing the products -- including our software developers. With the explosion of various developer tools and services in recent years, it's tempting to think that we've entered a golden age for software development productivity. However, contrary to popular belief, developer productivity is in fact declining, and this phenomenon risks bringing modern software development to a grinding halt in many organizations. In this talk, Nnamdi Iregbulem reveals a framework for thinking about developer productivity and charts a path toward reversing this dire trend.</blockquote><ul><li><a href=\"https://www.industryconference.com/virtual\">Event page</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/05/image.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><h2 id=\"venture-games-podcast-by-chris-quaidoo\">Venture Games Podcast by Chris Quaidoo</h2><blockquote>In Episode 4 of Venture Games, my guest Nnamdi Iregbulem, Partner at Lightspeed Venture Partners, talks about being a lifelong gamer and self-proclaimed tech nerd, investing in Epic Games, the company behind Fortnite, his blog, whoisnnamdi.com, and being selected as one of Forbes 30 Under 30 in Venture.</blockquote><ul><li><a href=\"https://open.spotify.com/episode/2p9OMbLE4RRDvCFrq2wldm?si=UiFhbhiARjSeJE_FcHBnlw\">Podcast</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/03/image.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><h2 id=\"views-by-pol-fa-an-s-gerard-garcia\">Views by Pol FaÃ±anÃ¡s &amp; Gerard Garcia</h2><ul><li><a href=\"https://views.substack.com/p/nnamdiiregbulem\">Interview</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/12/image.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><h2 id=\"igbopedia-podcast\">Igbopedia Podcast</h2><blockquote>My guest is Nnamdi Iregbulem. He is a Partner at Lightspeed Venture Partners, a US-headquartered venture capital firm. On this episode, Nnamdi joins me in conversation from Silicon Valley where he invests in and advises start-ups that build next-generation technology. We talk about his early life, his work and what he is passionate about. Check out his personal website: whoisnnamdi.com</blockquote><ul><li><a href=\"https://open.spotify.com/episode/4gl2cUBR4MdWFzKYaHgb3D\">Podcast</a></li><li><a href=\"https://www.instagram.com/p/CFd4Gx6JvWf/\">Igbopedia Instagram</a></li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/11/119985712_667820227170903_4758538190186304063_n.jpg\" class=\"kg-image\" alt loading=\"lazy\"></figure><h2 id=\"the-state-of-black-software-development\">The State of Black Software Development</h2><blockquote>Recent events have raised awareness of pervasive issues facing blacks in America. Further, blacks have historically been underrepresented in software development, accounting for approximately 2% of software Â developers despite making up approximately 13% of the American Â population. Many companies claim to be committed to diversifying their Â software engineering workforce, and these promises have only accelerated Â in recent months. However, aside from data revealing their prevalence Â among software developers, little publicly available data or analysis Â exists on the professional experience of black software developers. In Â this presentation, I analyze pay gaps, paths to promotion, job and Â career satisfaction, and other aspects of black software development to Â better understand the career journeys of black software engineers.</blockquote><ul><li><a href=\"https://gitlabcommitvirtual2020.sched.com/event/dUYa\">Event page</a></li><li><a href=\"https://www.youtube.com/watch?v=C8juMZGuSvk\">Video</a></li><li><a href=\"https://docs.google.com/presentation/d/1U3G5-nZZoySkIashsrQbd4BAEqJGwDq-cF_xnPRZiNQ/edit?usp=sharing\">Slides</a></li><li><a href=\"https://gitlab.com/whoisnnamdi/black-dev-2020\">GitLab</a>/ <a href=\"https://github.com/whoisnnamdi/black-dev-2020/\">GitHub</a> Repo</li></ul><figure class=\"kg-card kg-embed-card\"><iframe width=\"480\" height=\"270\" src=\"https://www.youtube.com/embed/C8juMZGuSvk?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></figure><h2 id=\"what-i-learned-analyzing-the-earnings-of-11-037-software-developers\">What I Learned Analyzing the Earnings of 11,037 Software Developers</h2><ul><li><a href=\"__GHOST_URL__/highest-paid-software-developer/\">Write-up</a></li><li><a href=\"https://docs.google.com/presentation/d/14v-eLdpu2il8AMXU2a8rC4Nc4qaB2OyKTt6dALDhgJA/edit?usp=sharing\">Slides</a></li></ul><!--kg-card-begin: markdown--><p><a href=\"https://docs.google.com/presentation/d/14v-eLdpu2il8AMXU2a8rC4Nc4qaB2OyKTt6dALDhgJA/edit?usp=sharing\"><img src=\"__GHOST_URL__/content/images/2019/01/years_coding.png\" alt=\"chart\" loading=\"lazy\"></a></p>\n<!--kg-card-end: markdown-->","comment_id":"5f90896a17b26d3ef80d6490","plaintext":"Inside the Black Box: The Urgency of AI Interpretability\n> Recorded live at Lightspeedâ€™s offices in San Francisco, this special episode of\nGenerative Now dives into the urgency and promise of AI interpretability.\nLightspeed partner Nnamdi Iregbulem spoke with Anthropic researcher Jack Lindsey\nand Goodfire co-founder and Chief Scientist Tom McGrath, who previously\nco-founded Google DeepMindâ€™s interpretability team. They discuss opening the\nblack box of modern AI models in order to understand their reliability and spot\nreal-world safety concerns, in order to build AI systems of the future that we\ncan trust.\n * Video [https://www.youtube.com/watch?v=azoBSxpkv7Y]\n\nBenedikt Stroebl: With Imperfect Verifiers, Scale Fails\n> Verifiers are a hot topic in AI these days, where they play a role in both\npost-training and inference time scaling. But what if more compute at inference\ntime doesn't always improve AI performance? I discuss with Benedikt Stroebl his\nresearch on the challenges presented by the inference time scaling paradigm,\nalong with a particular application of agentic techniques to the world of\ncybersecurity.\n * Video [https://www.youtube.com/watch?v=Id7ebjEqAW8]\n\nSatish Chandra: Google's AI Coding Agents That Fix Bugs Automatically\n> Can AI agents soon eliminate the tedious task of debugging code? Google's Satish\nChandra reveals groundbreaking research on how AI is changing the way teams fix\nand maintain production code.\n * Video [https://www.youtube.com/watch?v=jMzHuLzmpog]\n\nJonas HÃ¼botter: 1000 Expert Models, 100x Faster, For Free\n> What if you could get all the benefits of test-time adaptation of AI models for\na particular task, but 100 times faster and essentially for free? Jonas HÃ¼botter\nshows how pre-training 1000 expert models and merging them at test-time achieves\nexactly that, with nearly zero overhead.\n * Video [https://www.youtube.com/watch?v=NVd_FmEDzis]\n\nDaniel Kang: AI Hackers Are Coming Sooner Than You Think\n> AI systems that can autonomously hack applications are no longer science\nfiction. In this revealing conversation, Daniel Kang breaks down his team's\nresearch showing that AI systems can now find and exploit security\nvulnerabilities using agentic approaches.\n * Video [https://www.youtube.com/watch?v=5U_c_IHWK6I]\n\nAndy Zhou: Language Agent Tree Search & Autonomous Red Teaming\n> In this conversation I chat with Andy Zhou\n[https://www.linkedin.com/in/andy-zhou-679376206/], where we discuss his\nICML-accepted work on Language Agent Tree Search, which unifies reasoning,\nacting, and planning in LLMs via an innovative search algorithm, and AutoRed\nTeamer, an autonomous system for end-to-end red teaming LLMs.\n * Video [https://www.youtube.com/watch?v=sr1n4Swgk8k]\n\nCharlie Snell: Optimally Scaling Test-Time Compute & Predicting Emergence\n> In this conversation, I sit down with AI researcher Charlie Snell from UC\nBerkeley to discuss his groundbreaking work on optimally scaling test-time\ncompute and predicting emergent capabilities in large language models. Charlie\nunpacks multiple dimensions of his work that could reshape how we approach AI\ndevelopment and inference strategies.\n * Video [https://www.youtube.com/watch?v=4xT_6NtC3oo]\n\nDeveloper Productivity, Real-Time Data Infrastructure, and The Fat-Tailed Nature\nof Enterprise Software â€“ Datacast\n> The 109th episode of Datacast [http://datacast.substack.com/] is my conversation\nwith Nnamdi Iregbulem\n[https://open.substack.com/users/6557034-nnamdi-iregbulem?utm_source=mentions],\na Partner [https://lsvp.com/team/nnamdi-iregbulem/] at Lightspeed Venture\nPartners [https://lsvp.com/]. His mission is to increase total software output\nby supporting entrepreneurs building technical tools for technical people. He\nfocuses on investments in technical enterprise software such as developer tools,\napplication infrastructure, and machine learning.\n * Podcast [https://open.spotify.com/episode/6VSpSl0g528jWUzDLpf0vL]\n * Highlights [https://jameskle.com/writes/nnamdi-iregbulem]\n\nSeed-stage Valuation Insights - Fund/Build/Scale\n> If a team hasnâ€™t built a minimum viable product, secured paying customers, or\ndemonstrated strong unit economics, what exactly are seed-stage investors\nbetting on?\n\nTo get some answers, I sat down with Nnamdi Iregbulem, a partner at Lightspeed\nVenture Partners, to discuss what drives seed valuations, the traits of\nsuccessful founders, and his perspective on AI startups.\n\nNnamdi shared his journey from coding as a kid to investment banking at JP\nMorgan, growth-stage investing at Iconiq Capital, and now helping early-stage\nfounders at Lightspeed. He explains why seed valuations often reflect the\nopportunity cost of the founding team more than traditional factors like\ninterest rates or public market comps, and highlights the rising costs of GPUs\nand AI talent as critical considerations.\n\nWe also explored the traits that set exceptional founders apart â€” like strong\ndomain expertise, adaptability, and demonstrated excellence â€” and why\ninference-based AI startups may have an edge over those focused on training new\nmodels.\n * Podcast\n   [https://podcasts.apple.com/us/podcast/seed-stage-valuation-insights-from-lightspeeds-nnamdi/id1719488387?i=1000680395270]\n\nLightspeedâ€™s Nnamdi Iregbulem: Boosting Total Software Output\n> In a software-driven world, attracting and retaining top tech talent â€” from\nsoftware engineers to data scientists â€” is becoming table stakes for teams\nlooking to gain a competitive edge. But amid labor shortages, companies are now\nturning to software developer tools to help their teams do more with less. \nNnamdi Iregbulem, partner at Lightspeed Venture Partners\n[https://lsvp.com/?ref=terra-nova], explores how democratizing software\ndevelopment and investing in productivity tools can make teams more efficient.\n * Interview\n   [https://www.terranova.co/nnamdi-iregbulem-lightspeed-venture-partners-boosting-software-productivity/]\n\nSaaS Metrics 2.0 â€“ A Field Guide to the Metrics that Matter Today\n> 10 years ago, the hottest metrics for any SaaS company were revenue growth,\ncustomer retention, and LTV:CAC ratio. It was growth at all costs, chasing the\nmagical T2D3 curve. While these metrics are still core, todayâ€™s entrepreneurs\nand investors are more sophisticated, and todayâ€™s world is very different. An\nexpert panel â€“ a SaaS researcher, a leading VC, and a top SaaS CFO â€“ will give\nyou practical, take-home guidance on the key metrics that are needed to\nunderstand and optimize your SaaS business today\n * Event page [https://saasnorth.com/events/breakout-11/]\n\nStreaming Data and the Modern Real-Time Data Stack â€“ The Modern Data Show\n> With the modern data stack evolving constantly, the next thing to look forward\nto is a real-time data stack, where companies are not just producing data in\nreal-time but also consuming it on a real-time basis. In this latest episode of\nthe Modern Data Show, we discuss the same with our guest Nnamdi Iregbulem, who\nhas invested in a lot of modern real-time data stack tools.\n * Podcast\n   [https://www.moderndatastack.xyz/podcast/s01-e05-streaming-data-and-the-modern-real-time-data-stack-lightspeed-ventures-74te]\n\nThe Developer Productivity Manifesto with Nnamdi Iregbulem\n> We welcome Nnamdi Iregbulem, Partner at Lightspeed, self-taught programmer,\ninvestor, and more, to talk about his latest conference talk, â€œThe Developer\nProductivity Manifesto,â€ in his venture to help developers understand both the\ntechnical and economic impact of their own productivity.\n * Podcast\n   [https://podcasts.apple.com/us/podcast/the-developer-productivity-manifesto-with/id1539945251?i=1000581913746]\n\nThe Next Trillion Dollar Market - 5 Lessons from Selling to Millions of\nDevelopers\n> Think marketing to developers is all about hoodies and hackathons? Â Think again.\nAs the developer-led economy, now worth $50B USD is poised to grow to a trillion\ndollars, companies that offer products for developers must refocus to a\nbusiness-to-developer (B2D) model as developers become not only users of\nproducts, but key purchasing influencers.\n * Event page [https://www.tractionconf.io/agenda]\n * Video [https://youtube.com/watch?v=O94U-N26dbU]\n\nThe Developer Productivity Manifesto | Dev Innovation Summit\n> With the explosion of various developer tools and services in recent years, it's\ntempting to think that we've entered a golden age for software development\nproductivity. However, contrary to popular belief, developer productivity is in\nfact declining, and this phenomenon risks bringing modern software development\nto a grinding halt in many organizations. In this talk, Nnamdi Iregbulem reveals\na framework for thinking about developer productivity and charts a path toward\nreversing this dire trend. \n * Event page\n   [https://embed.emamo.com/event/worldfestival-2022/s/the-developer-productivity-manifesto-NPYkva]\n\nBreaking Changes Podcast | Postman\n> In this Breaking Changes, Postman Chief Evangelist Kin Lane welcomes Nnamdi\nIregbulem of Lightspeed Venture Partner to talk about the importance of\ndeveloper tools, streaming API technology, Â and how data and machine learning is\ncontinuing to shape the API landscape.\n * Podcast [https://www.youtube.com/watch?v=_8oZYEtjNWQ]\n * Recap\n   [https://blog.postman.com/breaking-changes-with-lightspeed-venture-partners-nnamdi-iregbulem-real-time-api-infrastructure-investments/]\n\nThe Full Ratchet: Venture Capital Demystified\n> Nnamdi Iregbulem of Lightspeed Venture Partners joins Nate to discuss Navigating\nMacro Headwinds, Balancing Growth v. Profitability, and How to Get in Front of\nthe Top 1% of Founders. In this episode we cover: (1) Tips for Founders When\nCapital Gets Expensive, (2) Where Software is Still Eating the World, (3) The\nUncapped Upside of Writing in VC, (4) How to Get in Front of the Top Founders\n * Podcast\n   [https://fullratchet.net/337-navigating-macro-headwinds-balancing-growth-v-profitability-and-how-to-get-in-front-of-the-top-1-of-founders-nnamdi-iregbulem/]\n\nThe Scaling Developer Success Podcast\n> The world of DevRel had evolved over the last few years. This podcast dives into\ndev success with some of the world's top leaders in the industry.\n * Spotify\n   [https://open.spotify.com/episode/0EmEAuxMxb41hSx7P4nAOU?si=xBjhBnMNQse-DbtISdGzow]\n\nAligning DevRel with Your Business Stakeholders\n> Practical discussion of how to make sure your DevRel program meets your\ncompanyâ€™s needs.\n * Event page\n   [https://deepdives.devrelcon.dev/workshops/aligning-devrel-with-your-business-stakeholders/]\n\nWhat is Weighted ACV? â€“ Metric Stack\n> Nnamdi Iregbulem, Partner at Lightspeed Venture Partners is our guest on the\npodcast this week. Nnamdi walks through this new metric: What is it? How do you\ncalculate it? When should a company start tracking weighted ACV?\n * Podcast [https://www.youtube.com/watch?v=b3gBxsdCyw0]\n * Summary [https://www.klipfolio.com/blog/what-is-weighted-acv]\n\nHow The Modern Data Stack Is Going Real-Time\n> Times have changed. Organizations are increasingly fed up with traditional data\ninfrastructure, which is slow to yield answers to key business intelligence\nquestions and often out of date and out of sync with current business realities,\ntypically by a day or more.\n * Guest Blog [https://news.crunchbase.com/news/real-time-modern-data-stack/]\n\nWhat VCs miss about SaaS revenue\n> Protocol caught up with Lightspeed Venture Partnersâ€™ Nnamdi Iregbulem to talk\nabout revenue concentration in SaaS and why todayâ€™s metrics donâ€™t give investors\nthe full picture.\n * Interview [https://www.protocol.com/enterprise/lightspeed-vc-saas-revenue]\n\nBuild vs Buy | DataOps Unleashed 2022\n> Join Nnamdi, Andrei, Aaron, and Gokul as they discuss their decision-making\nmethods and strategies for evaluating whether to build or buy components for\ntheir data stacks.\n * Video [https://dataopsunleashed.com/2022-2/buildvsbuy/]\n\nWeighted ACV | MetricHQ\n> Weighted Annual Contract Value (WACV) calculates the average contract dollar\nvalue with a weighted average proportional to the value of the contract.\nEssentially, higher value contracts are assigned more importance when\ncalculating the total average contract value of a business. This approach is\nhelpful to companies that have widely varying customer concentration by\naccurately calculating an ACV that is not skewed by contracts with low dollar\nvalue.\n * Article [https://www.klipfolio.com/metrics/saas/weighted-acv]\n\nThe Developer Productivity Manifesto (GitLab Commit 2021)\n> With the explosion of various developer tools and services in recent years, it's\ntempting to think that we've entered a golden age for software development\nproductivity. However, contrary to popular belief, developer productivity is in\nfact declining, and this phenomenon risks bringing modern software development\nto a grinding halt in many organizations. In this talk, Nnamdi Iregbulem reveals\na framework for thinking about developer productivity and charts a path toward\nreversing this dire trend.\n * Event page [https://gitlabcommitvirtual2021.com/]\n * Slides\n   [https://docs.google.com/presentation/d/1i0ttzn6u7pgZ0Y8DUhmSFinyfjgjLqJoSUn4BO63ad8/edit?usp=sharing]\n * Video [https://www.youtube.com/watch?v=_Q7i0ZKeTz8]\n\nPitching Your Enterprise Software Startup with Lightspeedâ€™s Nnamdi Iregbulem\n> A partner at Lightspeed Venture Partners whoâ€™s backed names like Fastly, GitLab\nand Epic Games, Iregbulem offers advice and feedback at a Founders Network pitch\npractice.\n * Interview\n   [https://foundersnetwork.com/blog/pitching-your-enterprise-software-startup-with-lightspeeds-nnamdi-iregbulem/]\n\nThe Developer Productivity Manifesto (INDUSTRY Virtual 2021)\n> As product people, we're always thinking about the performance of the teams\nactually developing the products -- including our software developers. With the\nexplosion of various developer tools and services in recent years, it's tempting\nto think that we've entered a golden age for software development productivity.\nHowever, contrary to popular belief, developer productivity is in fact\ndeclining, and this phenomenon risks bringing modern software development to a\ngrinding halt in many organizations. In this talk, Nnamdi Iregbulem reveals a\nframework for thinking about developer productivity and charts a path toward\nreversing this dire trend.\n * Event page [https://www.industryconference.com/virtual]\n\nVenture Games Podcast by Chris Quaidoo\n> In Episode 4 of Venture Games, my guest Nnamdi Iregbulem, Partner at Lightspeed\nVenture Partners, talks about being a lifelong gamer and self-proclaimed tech\nnerd, investing in Epic Games, the company behind Fortnite, his blog,\nwhoisnnamdi.com, and being selected as one of Forbes 30 Under 30 in Venture.\n * Podcast\n   [https://open.spotify.com/episode/2p9OMbLE4RRDvCFrq2wldm?si=UiFhbhiARjSeJE_FcHBnlw]\n\nViews by Pol FaÃ±anÃ¡s & Gerard Garcia\n * Interview [https://views.substack.com/p/nnamdiiregbulem]\n\nIgbopedia Podcast\n> My guest is Nnamdi Iregbulem. He is a Partner at Lightspeed Venture Partners, a\nUS-headquartered venture capital firm. On this episode, Nnamdi joins me in\nconversation from Silicon Valley where he invests in and advises start-ups that\nbuild next-generation technology. We talk about his early life, his work and\nwhat he is passionate about. Check out his personal website: whoisnnamdi.com\n * Podcast [https://open.spotify.com/episode/4gl2cUBR4MdWFzKYaHgb3D]\n * Igbopedia Instagram [https://www.instagram.com/p/CFd4Gx6JvWf/]\n\nThe State of Black Software Development\n> Recent events have raised awareness of pervasive issues facing blacks in\nAmerica. Further, blacks have historically been underrepresented in software\ndevelopment, accounting for approximately 2% of software Â developers despite\nmaking up approximately 13% of the American Â population. Many companies claim to\nbe committed to diversifying their Â software engineering workforce, and these\npromises have only accelerated Â in recent months. However, aside from data\nrevealing their prevalence Â among software developers, little publicly available\ndata or analysis Â exists on the professional experience of black software\ndevelopers. In Â this presentation, I analyze pay gaps, paths to promotion, job\nand Â career satisfaction, and other aspects of black software development to\nÂ better understand the career journeys of black software engineers.\n * Event page [https://gitlabcommitvirtual2020.sched.com/event/dUYa]\n * Video [https://www.youtube.com/watch?v=C8juMZGuSvk]\n * Slides\n   [https://docs.google.com/presentation/d/1U3G5-nZZoySkIashsrQbd4BAEqJGwDq-cF_xnPRZiNQ/edit?usp=sharing]\n * GitLab [https://gitlab.com/whoisnnamdi/black-dev-2020]/ GitHub\n   [https://github.com/whoisnnamdi/black-dev-2020/] Repo\n\nWhat I Learned Analyzing the Earnings of 11,037 Software Developers\n * Write-up [__GHOST_URL__/highest-paid-software-developer/]\n * Slides\n   [https://docs.google.com/presentation/d/14v-eLdpu2il8AMXU2a8rC4Nc4qaB2OyKTt6dALDhgJA/edit?usp=sharing]\n\n \n[https://docs.google.com/presentation/d/14v-eLdpu2il8AMXU2a8rC4Nc4qaB2OyKTt6dALDhgJA/edit?usp=sharing]","feature_image":null,"featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-10-21T19:18:02.000Z","updated_at":"2025-10-04T02:21:18.000Z","published_at":"2020-10-21T19:22:40.000Z","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"page","email_recipient_filter":"none"},{"id":"5f928e0717b26d3ef80d64b6","uuid":"4a3e57d8-3682-42c4-a4ba-fa9d0131c4b9","title":"Why We Will Never Have Enough Software Developers","slug":"never-enough-developers","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/W-kECKz1nw.png\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Why We Will Never Have Enough Software Developers\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Subscribe</span></button>\\n</form>\\n</section>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/azDsA9n3rx.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/Pc3AjVflhW.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/xfeKvOWxo-.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/OwoB5xsSdO.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/7ItjXMaTE-.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/heMo13OsG1.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/Lifecyle-Earnings-by-Degree-Category.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/Engineering-_-Computer-Science-Earnings-Premium.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/OFffH9kBKA.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/Human-Capital--w_o-Depreciation-.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/Software-Engineering-Human-Capital-Premium--w_o-Depreciation-.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/Human-Capital--w_-Depreciation-.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/Software-Engineering-Human-Capital-Premium--w_-Depreciation-.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/LFrqrUH7Kl.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/Relative-STEM-Probability-for-1-SD-Higher-Cognitive-Ability.png\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: Why We Will Never Have Enough Software Developers\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Subscribe</span></button>\\n</form>\\n</section>\"}]],\"markups\":[[\"em\"],[\"strong\"],[\"a\",[\"href\",\"https://academic.oup.com/qje/article/135/4/1965/5858010\"]],[\"a\",[\"href\",\"__GHOST_URL__/college-degrees-software-engineers/\"]],[\"a\",[\"href\",\"https://youtu.be/m1ERvlxgCD8?t=166\"]],[\"a\",[\"href\",\"__GHOST_URL__/you-dont-understand-compound-growth/\"]],[\"a\",[\"href\",\"https://www.military.com/join-armed-forces/asvab\"]],[\"a\",[\"href\",\"https://scholar.harvard.edu/ddeming/home\"]],[\"a\",[\"href\",\"https://scholar.harvard.edu/kadeem/home\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"We will never have enough software developers.\"]]],[1,\"p\",[[0,[],0,\"Developers are dropping out of the profession in large numbers despite efforts to grow the number of computer science graduates and software engineers.\"]]],[1,\"p\",[[0,[],0,\"Here's why.\"]]],[1,\"h2\",[[0,[],0,\"Developer dropout is real\"]]],[1,\"p\",[[0,[],0,\"Software development has a \"],[0,[0],1,\"serious\"],[0,[],0,\" retention problem:\"]]],[3,\"ul\",[[[0,[],0,\"At age 26, 59% of engineering and computer science grads work in occupations \"],[0,[0],1,\"related\"],[0,[],0,\" to their field of study. By age 50, only 41% work in the same domain, meaning a full \"],[0,[1],1,\"~30% drop out of the field by mid-career\"]],[[0,[],0,\"In contrast, engineering and computer science majors who join \"],[0,[0],1,\"unrelated\"],[0,[],0,\" fields upon graduation retain at much higher rates, with only 10-15% switching out after the age of 26:\"]]]],[10,0],[1,\"p\",[[0,[],0,\"Engineers often leave engineering for non-STEM management roles. Graduation into management is not surprising. What's surprising is that these are \"],[0,[1],1,\"non-STEM\"],[0,[],0,\" positions. Engineers swap technical roles for \"],[0,[0],1,\"non-technical\"],[0,[],0,\" roles over time.\"]]],[1,\"p\",[[0,[],0,\"This phenomenon, which I'll call \\\"\"],[0,[1],1,\"developer dropout\"],[0,[],0,\",\\\" is a real problem. What's behind it?\"]]],[10,1],[1,\"h2\",[[0,[],0,\"Out with the old skills, in with the new skills\"]]],[1,\"p\",[[0,[],0,\"Programming-related jobs have high rates of skill turnover. Over time, the types of skills required by companies hiring software developers change more rapidly than any other profession.\"]]],[1,\"p\",[[0,[],0,\"To demonstrate this, \"],[0,[2],1,\"researchers\"],[0,[],0,\" analyzed job postings on more than 40,000 online job boards and company websites between 2007 and 2019, controlling for employer, location, and occupation. They defined \\\"new\\\" skills as those that were rare or non-existent in 2007 but prevalent in 2019 and \\\"old\\\" skills as those that were prevalent in 2007 but rare or extinct in 2019.\"]]],[3,\"ul\",[[[0,[],0,\"While only 30% of all job vacancies required at least one new skill by 2019, \"],[0,[1],1,\"47% of computer and mathematical jobs required at least one new skill\"],[0,[],0,\" (i.e. a skill that was not common back in 2007)\"]],[[0,[],0,\"This compares to \"],[0,[0],1,\"less than 20%\"],[0,[],0,\" of jobs in fields like education, law, and community and social services\"]],[[0,[],0,\"In addition, \"],[0,[1],1,\"16% of jobs in computer and mathematical fields in 2007 required a skill that was obsolete by 2019\"],[0,[],0,\" (i.e. a skill that was common in 2007 but relatively rare in 2019), more than double any other job category:\"]]]],[10,2],[1,\"p\",[[0,[],0,\"About a third of the change in required skills in computer-related occupations is due to specific new software:\"]]],[3,\"ul\",[[[0,[],0,\"The fastest-growing software skills between 2007 and 2019 include \"],[0,[1],1,\"Python, R, and Apache Hadoop\"]],[[0,[],0,\"Software that was popular in 2007 but effectively obsolete by 2019 includes QuarkXpress, ActionScript, Solaris, IBM Websphere, and Adobe Flash (ah, finally a name I recognize)\"]]]],[1,\"p\",[[0,[],0,\"Data science, machine learning, and AI saw big increases among technology-intensive jobs as well. For example, the number of STEM-related jobs requiring skills in machine learning and AI grew more than 4x from 2007-2017, touching more than 15% of STEM jobs:\"]]],[10,3],[1,\"p\",[[0,[],0,\"To better compare rates of skill change across occupations, the researchers came up with a measure of skill change that tracks the absolute growth or decline of various skills within each profession from 2007 to 2019. Occupations whose required skills change rapidly in prevalence among job postings receive a high score, while jobs whose skills do not change much receive a lower score:\"]]],[10,4],[3,\"ul\",[[[0,[1],1,\"Computer-related occupations receive the highest score by far, 4.8\"],[0,[],0,\". Note that the mean and standard deviation of this measure are ~3 and ~1 respectively, so computer-related jobs are \"],[0,[1],1,\"nearly two standard deviations away from the typical job in America\"]],[[0,[],0,\"Meanwhile, jobs in education and and those involving manual labor have very low skill change scores, typically less than 2.\"]]]],[1,\"p\",[[0,[],0,\"We can get even more granular and look at specific job roles. This level of detail makes the difference even more stark (only showing the fastest changing roles):\"]]],[10,5],[1,\"p\",[[0,[],0,\"Web development has the highest rate of skill change \"],[0,[0],1,\"among all jobs in the country\"],[0,[],0,\". Next up are sales engineers, another often technical role. Database administrators, computer network architects, sysadmins, and application developers all make the top 10, and we see many other technical roles among the top 30. The mean and standard deviation are similar here, placing web development \"],[0,[1],1,\"more than 3 standard deviations away from the typical job in America\"],[0,[],0,\" in terms of skill change over time.\"]]],[1,\"p\",[[0,[],0,\"Suffice to say, \"],[0,[1],1,\"software development is a rapidly changing profession\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"You might think, however, that skill change would eventually settle down as one becomes more experienced.\"]]],[1,\"p\",[[0,[0],1,\"You'd be wrong.\"],[0,[],0,\" The skills for software engineering jobs change rapidly throughout the entire career lifecycle:\"]]],[10,6],[3,\"ul\",[[[0,[],0,\"In entry-level roles in computer and engineering occupations all the way through those requiring 12+ years of experience, \"],[0,[1],1,\"the proportion of job postings requiring at least one new skill in 2019 was effectively the same, 40-45%\"]],[[0,[],0,\"In contrast, \"],[0,[1],1,\"29% of entry-level non-computing and engineering roles in 2019 required at least one new skill, but this proportion declines to 24%\"],[0,[],0,\" for jobs requiring more than four years of experience\"]]]],[1,\"blockquote\",[[0,[],0,\"This means that experienced STEM workers seeking employment in 2019 are often required to possess skills that \"],[0,[1],1,\"were not required\"],[0,[],0,\" when they entered the labor market in 2007 or earlier.\"]]],[1,\"p\",[[0,[],0,\"Software engineers \"],[0,[1],1,\"never\"],[0,[],0,\" escape the skill-change vortex, even many years into their careers. Experienced engineers must learn and adopt technologies that didn't even exist when they started out. Developers must constantly retool themselves, even well after their \"],[0,[3],1,\"formal education\"],[0,[],0,\" ends.\"]]],[1,\"h2\",[[0,[4],1,\"Nothing's changed but my change\"]]],[1,\"p\",[[0,[1],1,\"College majors associated with faster changing jobs pay more early on.\"]]],[3,\"ul\",[[[0,[],0,\"In professions with one standard deviation increased skill change, pay is \"],[0,[1],1,\"~30%\"],[0,[],0,\" higher in the first few years of one's career\"]],[[0,[],0,\"If we exclude both the fastest and slowest-changing fields (Engineering/Computer Science at the high end, Health/Education at the low end), the early earnings premium for faster-changing roles increases to \"],[0,[1],1,\"~60%\"],[0,[],0,\":\"]]]],[10,7],[1,\"p\",[[0,[1],1,\"Fast-changing fields pay better.\"]]],[1,\"p\",[[0,[],0,\"Notice however that the pay advantage declines over time. By the time one approaches the age of 50, the pay premium for working in rapidly changing fields falls dramatically to only 20-30% vs slower changing professions.\"]]],[1,\"p\",[[0,[],0,\"Here's another way to see the eroding pay advantage. The below chart simulates the earnings of the average worker by category of college degree from ages 23 to 50 in 2016 dollars.\"]]],[3,\"ul\",[[[0,[],0,\"Computer science and engineering grads start off with sizable advantage vs any other major\"]],[[0,[],0,\"However, this premium \"],[0,[0],1,\"falls\"],[0,[],0,\" over time as the earnings of CS and engineering graduates plateau over time while the earnings of their peers grow \"],[0,[0],1,\"faster\"],[0,[],0,\" for \"],[0,[0],1,\"longer\"]],[[0,[],0,\"In fact, \"],[0,[1],1,\"life and physical science graduates' earnings surpass their computer and engineering classmates by the age of 40\"],[0,[],0,\":\"]]]],[10,8],[1,\"p\",[[0,[],0,\"Excluding business majors, the earnings premium of software engineering declines over time in both percentage \"],[0,[0],1,\"and\"],[0,[],0,\" absolute dollar terms, to the point where engineers barely out-earn social science majors:\"]]],[10,9],[1,\"p\",[[0,[],0,\"But the focus on college major is somewhat misleading. This phenomenon has less to do with one's field of study and more to do with \"],[0,[0],1,\"choice of occupation\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"To show this, researchers plotted the earnings premium of various categories workers relative to those with a non-Engineering/Computer Science major working in a non-Engineering/Computer Science job.\"]]],[3,\"ul\",[[[0,[],0,\"Workers who major in Engineering or Computer Science but work in unrelated fields actually see their earnings advantage \"],[0,[0],1,\"compound\"],[0,[],0,\" over time, rather than decline\"]],[[0,[],0,\"On the other hand, regardless of major, individuals who work in Engineering or Computer Science jobs see their earnings advantage erode over the years:\"]]]],[10,10],[1,\"blockquote\",[[0,[1],1,\"Declining relative returns is a feature of STEM jobs, not majors.\"],[0,[],0,\" The earnings premium for non-STEM majors in STEM occupations starts off near 40%, but declines to 20% within a decade. In contrast, the relative earnings advantage grows over time for computer science and engineering majors working in non-STEM occupations.\"]]],[1,\"p\",[[0,[],0,\"The \"],[0,[1],1,\"profession\"],[0,[],0,\" of software development drives the declining earnings premium, \"],[0,[1],1,\"not the college major\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"In fact, computer science majors who work in non-CS fields experience the \"],[0,[0],1,\"opposite\"],[0,[],0,\" dynamic of their non-developer peers â€” their relative earnings premium rises as they advance. A CS major who eschews the profession doesn't earn much more than otherwise similar non-CS majors early on, but eventually out-earns their peers by nearly 20%.\"]]],[1,\"p\",[[0,[],0,\"OK, that's enough about \"],[0,[0],1,\"what\"],[0,[],0,\" is happening. Now let's see \"],[0,[0],1,\"why\"],[0,[],0,\" it's happening.\"]]],[1,\"h2\",[[0,[0],1,\"Human\"],[0,[],0,\" capital depreciates too\"]]],[1,\"p\",[[0,[],0,\"Imagine a simple model where workers choose their profession in order to maximize income, which is a derivative of their own skill or human capital. Over time, workers gain new skills, while the value of their existing skills depreciates somewhat due to changing times.\"]]],[1,\"p\",[[0,[],0,\"Some workers, endowed with superior ability, learn faster than others, picking up skills at a quicker pace. Those workers will tend to sort into high-skilled, fast-changing professions initially, maximizing their early career earnings. Less impressive workers will sort into low-skilled, slower-changing professions.\"]]],[1,\"p\",[[0,[],0,\"In a world where human capital never depreciated, we could imagine that high-skilled individuals like software developers would maintain a relative human capital (and earnings) advantage over other professionals, leading to consistently increasing pay and a stable relative premium:\"]]],[10,11],[10,12],[1,\"p\",[[0,[],0,\"But, if human capital depreciates over time and that rate of depreciation is higher in rapidly-changing fields like software development, then developers' initial advantage would erode over time, narrowing the gap vs. non-developers:\"]]],[10,13],[10,14],[1,\"p\",[[0,[],0,\"This simple model helps explain what we see in the data â€” the software engineering earnings advantage disappears as the \"],[0,[0],1,\"effective\"],[0,[],0,\" human capital gap narrows.\"]]],[1,\"blockquote\",[[0,[],0,\"Applied majors such as computer science, engineering, and business teach vintage-specific skills that become less valuable as new skills are introduced to the workplace over time.\"]]],[1,\"p\",[[0,[],0,\"Specific skills in software development quickly become dated. Programming languages and development frameworks go out of style. Hadoop is hot one year, and it's old news the next. Like a fast, expensive car that quickly loses value as it's driven around town, the skills and human capital of software engineers fall apart without constant, expensive maintenance:\"]]],[1,\"blockquote\",[[0,[],0,\"Intuitively, careers with high rates of obsolescence require workers to learn many new tasks each year, which \"],[0,[1],1,\"diminishes learning gains and lowers the returns to experience\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"Quick learners are fast dropouts\"]]],[1,\"p\",[[0,[],0,\"The hits don't stop there. Ironically, \"],[0,[1],1,\"the quickest learners are also the quickest dropouts\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"To understand why, think back to the model we just outlined. Quick learners accumulate human capital faster than their slower peers, which means they have the most to lose when certain skills or abilities fall out of favor. In fact, \"],[0,[1],0,\"the return to being a fast learner is \"],[0,[0],1,\"higher\"],[0,[],0,\" in jobs with \"],[0,[0],1,\"low\"],[0,[],1,\" rates of skill change\"],[0,[],0,\" because the learnings can \"],[0,[5],1,\"compound\"],[0,[],0,\" over time instead of dwindle in relevance.\"]]],[1,\"blockquote\",[[0,[],0,\"High-ability workers are faster learners, in all jobs. However, \"],[0,[1],1,\"the relative return to ability is higher in careers that change less, because learning gains accumulate.\"]]],[1,\"p\",[[0,[],0,\"Said another way, \"],[0,[1],1,\"the opportunity cost of working in a rapidly-changing field is highest for the best learners\"],[0,[],0,\". This creates immense pressure to drop out of software engineering and other fast-changing careers into more stable roles and industries.\"]]],[1,\"p\",[[0,[],0,\"The researchers show this by regressing STEM job status on a number of other variables, including an interaction between age and score on the \"],[0,[6],1,\"Armed Forces Qualifying Test\"],[0,[],0,\" (AFQT), a common measure of cognitive ability. The coefficient comes out negative and statistically significant, implying that the relative probability of working in STEM at any given age \"],[0,[0],1,\"declines\"],[0,[],0,\" with cognitive ability (column 1 and 2 below):\"]]],[10,15],[1,\"blockquote\",[[0,[],0,\"The results imply that a worker with cognitive ability one standard deviation above average is 4.9 percentage points more likely to work in STEM at age 23, but \"],[0,[1],1,\"only 1.6 percentage points more likely to be working in a STEM job by age 34\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"In fact, by age 40, the regression predicts \"],[0,[1],0,\"workers with higher cognitive ability are \"],[0,[0],1,\"less\"],[0,[],1,\" likely to work in STEM than those with lower cognitive ability\"],[0,[],0,\".\"]]],[10,16],[1,\"p\",[[0,[],0,\"Simply put, \"],[0,[1],1,\"professionals with higher cognitive ability drop out of STEM careers earlier and faster\"],[0,[],0,\":\"]]],[1,\"blockquote\",[[0,[],0,\"... STEM majors with higher scores on the Armed Forces Qualifying Test (AFQT)â€”a widely used proxy for academic aptitudeâ€”\"],[0,[1],1,\"leave STEM careers more often and at younger ages\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"Implication: Growing the software engineering talent pool is harder than you think\"]]],[1,\"p\",[[0,[],0,\"Two points I want to drive home:\"]]],[1,\"p\",[[0,[1],1,\"First\"],[0,[],0,\" â€” software development has a \"],[0,[0],1,\"turnover\"],[0,[],0,\" problem.\"]]],[1,\"p\",[[0,[],0,\"Growing the supply of software developers is not trivial because the field already sees high levels of developer dropout and turnover, and this would only increase if the field were to grow larger. A larger software development labor pool would presumably drive down wages, encouraging even more developers to shift out of the profession, especially those past their career midpoints. On that flat part of the earnings curve, the incentive to remain a developer is weak at best.\"]]],[1,\"p\",[[0,[1],1,\"Second\"],[0,[],0,\" â€” software development also has a \"],[0,[0],1,\"selection\"],[0,[],0,\" problem.\"]]],[1,\"p\",[[0,[],0,\"The highest ability, fastest learners disproportionately leave the field over time. They have a multitude of other ways to profitably leverage their intellect and skills. \"],[0,[1],1,\"Software development carries serious opportunity cost.\"],[0,[],0,\" Again, this is ironic because one would normally expect the best to stay and worst to leave, but that's not what we see in the data. The software development talent pool mix shifts toward \"],[0,[0],1,\"lower cognitive ability\"],[0,[],0,\" as any given cohort matures.\"]]],[1,\"p\",[[0,[],0,\"Combined, these points suggest software development may be destined for perennial labor shortages unless the pace of change slows sufficiently.\"]]],[1,\"blockquote\",[[0,[],0,\"... \"],[0,[1],1,\"rapid technological change can lead to a short shelf life for technical skills\"],[0,[],0,\". This tradeoff between technology-specific and general skills is an important consideration for policymakers and colleges seeking to educate the workers of today, while also building the skills of the next generation.\"]]],[1,\"p\",[[0,[],0,\"To conclude, I emphasize: \"],[0,[1],1,\"highly skilled people prefer highly stable careers in the long-run\"],[0,[],0,\". This lets their relative ability and human capital advantage compound over time. Rapid deterioration of skills continuously levels the playing field, preventing the best from separating themselves from the pack. In such a situation, \"],[0,[1],1,\"it makes more sense to quit the race early than get caught in the pile up\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[0],0,\"Thanks to \"],[0,[7],1,\"David Deming\"],[0,[],0,\", \"],[0,[8],1,\"Kadeem Noray\"],[0,[],0,\", the authors of \"],[0,[2],1,\"the study\"],[0,[],1,\" from which much of this essay is derived.\"]]],[10,17],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}","html":"<p>We will never have enough software developers.</p><p>Developers are dropping out of the profession in large numbers despite efforts to grow the number of computer science graduates and software engineers.</p><p>Here's why.</p><h2 id=\"developer-dropout-is-real\">Developer dropout is real</h2><p>Software development has a <em>serious</em> retention problem:</p><ul><li>At age 26, 59% of engineering and computer science grads work in occupations <em>related</em> to their field of study. By age 50, only 41% work in the same domain, meaning a full <strong>~30% drop out of the field by mid-career</strong></li><li>In contrast, engineering and computer science majors who join <em>unrelated</em> fields upon graduation retain at much higher rates, with only 10-15% switching out after the age of 26:</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/W-kECKz1nw.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Engineers often leave engineering for non-STEM management roles. Graduation into management is not surprising. What's surprising is that these are <strong>non-STEM</strong> positions. Engineers swap technical roles for <em>non-technical</em> roles over time.</p><p>This phenomenon, which I'll call \"<strong>developer dropout</strong>,\" is a real problem. What's behind it?</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Why We Will Never Have Enough Software Developers\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Subscribe</span></button>\n</form>\n</section><!--kg-card-end: html--><h2 id=\"out-with-the-old-skills-in-with-the-new-skills\">Out with the old skills, in with the new skills</h2><p>Programming-related jobs have high rates of skill turnover. Over time, the types of skills required by companies hiring software developers change more rapidly than any other profession.</p><p>To demonstrate this, <a href=\"https://academic.oup.com/qje/article/135/4/1965/5858010\">researchers</a> analyzed job postings on more than 40,000 online job boards and company websites between 2007 and 2019, controlling for employer, location, and occupation. They defined \"new\" skills as those that were rare or non-existent in 2007 but prevalent in 2019 and \"old\" skills as those that were prevalent in 2007 but rare or extinct in 2019.</p><ul><li>While only 30% of all job vacancies required at least one new skill by 2019, <strong>47% of computer and mathematical jobs required at least one new skill</strong> (i.e. a skill that was not common back in 2007)</li><li>This compares to <em>less than 20%</em> of jobs in fields like education, law, and community and social services</li><li>In addition, <strong>16% of jobs in computer and mathematical fields in 2007 required a skill that was obsolete by 2019</strong> (i.e. a skill that was common in 2007 but relatively rare in 2019), more than double any other job category:</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/azDsA9n3rx.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>About a third of the change in required skills in computer-related occupations is due to specific new software:</p><ul><li>The fastest-growing software skills between 2007 and 2019 include <strong>Python, R, and Apache Hadoop</strong></li><li>Software that was popular in 2007 but effectively obsolete by 2019 includes QuarkXpress, ActionScript, Solaris, IBM Websphere, and Adobe Flash (ah, finally a name I recognize)</li></ul><p>Data science, machine learning, and AI saw big increases among technology-intensive jobs as well. For example, the number of STEM-related jobs requiring skills in machine learning and AI grew more than 4x from 2007-2017, touching more than 15% of STEM jobs:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/Pc3AjVflhW.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>To better compare rates of skill change across occupations, the researchers came up with a measure of skill change that tracks the absolute growth or decline of various skills within each profession from 2007 to 2019. Occupations whose required skills change rapidly in prevalence among job postings receive a high score, while jobs whose skills do not change much receive a lower score:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/xfeKvOWxo-.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><ul><li><strong>Computer-related occupations receive the highest score by far, 4.8</strong>. Note that the mean and standard deviation of this measure are ~3 and ~1 respectively, so computer-related jobs are <strong>nearly two standard deviations away from the typical job in America</strong></li><li>Meanwhile, jobs in education and and those involving manual labor have very low skill change scores, typically less than 2.</li></ul><p>We can get even more granular and look at specific job roles. This level of detail makes the difference even more stark (only showing the fastest changing roles):</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/OwoB5xsSdO.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Web development has the highest rate of skill change <em>among all jobs in the country</em>. Next up are sales engineers, another often technical role. Database administrators, computer network architects, sysadmins, and application developers all make the top 10, and we see many other technical roles among the top 30. The mean and standard deviation are similar here, placing web development <strong>more than 3 standard deviations away from the typical job in America</strong> in terms of skill change over time.</p><p>Suffice to say, <strong>software development is a rapidly changing profession</strong>.</p><p>You might think, however, that skill change would eventually settle down as one becomes more experienced.</p><p><em>You'd be wrong.</em> The skills for software engineering jobs change rapidly throughout the entire career lifecycle:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/7ItjXMaTE-.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><ul><li>In entry-level roles in computer and engineering occupations all the way through those requiring 12+ years of experience, <strong>the proportion of job postings requiring at least one new skill in 2019 was effectively the same, 40-45%</strong></li><li>In contrast, <strong>29% of entry-level non-computing and engineering roles in 2019 required at least one new skill, but this proportion declines to 24%</strong> for jobs requiring more than four years of experience</li></ul><blockquote>This means that experienced STEM workers seeking employment in 2019 are often required to possess skills that <strong>were not required</strong> when they entered the labor market in 2007 or earlier.</blockquote><p>Software engineers <strong>never</strong> escape the skill-change vortex, even many years into their careers. Experienced engineers must learn and adopt technologies that didn't even exist when they started out. Developers must constantly retool themselves, even well after their <a href=\"__GHOST_URL__/college-degrees-software-engineers/\">formal education</a> ends.</p><h2 id=\"nothing-s-changed-but-my-change\"><a href=\"https://youtu.be/m1ERvlxgCD8?t=166\">Nothing's changed but my change</a></h2><p><strong>College majors associated with faster changing jobs pay more early on.</strong></p><ul><li>In professions with one standard deviation increased skill change, pay is <strong>~30%</strong> higher in the first few years of one's career</li><li>If we exclude both the fastest and slowest-changing fields (Engineering/Computer Science at the high end, Health/Education at the low end), the early earnings premium for faster-changing roles increases to <strong>~60%</strong>:</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/heMo13OsG1.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p><strong>Fast-changing fields pay better.</strong></p><p>Notice however that the pay advantage declines over time. By the time one approaches the age of 50, the pay premium for working in rapidly changing fields falls dramatically to only 20-30% vs slower changing professions.</p><p>Here's another way to see the eroding pay advantage. The below chart simulates the earnings of the average worker by category of college degree from ages 23 to 50 in 2016 dollars.</p><ul><li>Computer science and engineering grads start off with sizable advantage vs any other major</li><li>However, this premium <em>falls</em> over time as the earnings of CS and engineering graduates plateau over time while the earnings of their peers grow <em>faster</em> for <em>longer</em></li><li>In fact, <strong>life and physical science graduates' earnings surpass their computer and engineering classmates by the age of 40</strong>:</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/Lifecyle-Earnings-by-Degree-Category.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Excluding business majors, the earnings premium of software engineering declines over time in both percentage <em>and</em> absolute dollar terms, to the point where engineers barely out-earn social science majors:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/Engineering-_-Computer-Science-Earnings-Premium.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>But the focus on college major is somewhat misleading. This phenomenon has less to do with one's field of study and more to do with <em>choice of occupation</em>.</p><p>To show this, researchers plotted the earnings premium of various categories workers relative to those with a non-Engineering/Computer Science major working in a non-Engineering/Computer Science job.</p><ul><li>Workers who major in Engineering or Computer Science but work in unrelated fields actually see their earnings advantage <em>compound</em> over time, rather than decline</li><li>On the other hand, regardless of major, individuals who work in Engineering or Computer Science jobs see their earnings advantage erode over the years:</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/OFffH9kBKA.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><blockquote><strong>Declining relative returns is a feature of STEM jobs, not majors.</strong> The earnings premium for non-STEM majors in STEM occupations starts off near 40%, but declines to 20% within a decade. In contrast, the relative earnings advantage grows over time for computer science and engineering majors working in non-STEM occupations.</blockquote><p>The <strong>profession</strong> of software development drives the declining earnings premium, <strong>not the college major</strong>.</p><p>In fact, computer science majors who work in non-CS fields experience the <em>opposite</em> dynamic of their non-developer peers â€” their relative earnings premium rises as they advance. A CS major who eschews the profession doesn't earn much more than otherwise similar non-CS majors early on, but eventually out-earns their peers by nearly 20%.</p><p>OK, that's enough about <em>what</em> is happening. Now let's see <em>why</em> it's happening.</p><h2 id=\"human-capital-depreciates-too\"><em>Human</em> capital depreciates too</h2><p>Imagine a simple model where workers choose their profession in order to maximize income, which is a derivative of their own skill or human capital. Over time, workers gain new skills, while the value of their existing skills depreciates somewhat due to changing times.</p><p>Some workers, endowed with superior ability, learn faster than others, picking up skills at a quicker pace. Those workers will tend to sort into high-skilled, fast-changing professions initially, maximizing their early career earnings. Less impressive workers will sort into low-skilled, slower-changing professions.</p><p>In a world where human capital never depreciated, we could imagine that high-skilled individuals like software developers would maintain a relative human capital (and earnings) advantage over other professionals, leading to consistently increasing pay and a stable relative premium:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/Human-Capital--w_o-Depreciation-.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/Software-Engineering-Human-Capital-Premium--w_o-Depreciation-.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>But, if human capital depreciates over time and that rate of depreciation is higher in rapidly-changing fields like software development, then developers' initial advantage would erode over time, narrowing the gap vs. non-developers:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/Human-Capital--w_-Depreciation-.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/Software-Engineering-Human-Capital-Premium--w_-Depreciation-.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>This simple model helps explain what we see in the data â€” the software engineering earnings advantage disappears as the <em>effective</em> human capital gap narrows.</p><blockquote>Applied majors such as computer science, engineering, and business teach vintage-specific skills that become less valuable as new skills are introduced to the workplace over time.</blockquote><p>Specific skills in software development quickly become dated. Programming languages and development frameworks go out of style. Hadoop is hot one year, and it's old news the next. Like a fast, expensive car that quickly loses value as it's driven around town, the skills and human capital of software engineers fall apart without constant, expensive maintenance:</p><blockquote>Intuitively, careers with high rates of obsolescence require workers to learn many new tasks each year, which <strong>diminishes learning gains and lowers the returns to experience</strong>.</blockquote><h2 id=\"quick-learners-are-fast-dropouts\">Quick learners are fast dropouts</h2><p>The hits don't stop there. Ironically, <strong>the quickest learners are also the quickest dropouts</strong>.</p><p>To understand why, think back to the model we just outlined. Quick learners accumulate human capital faster than their slower peers, which means they have the most to lose when certain skills or abilities fall out of favor. In fact, <strong>the return to being a fast learner is <em>higher</em> in jobs with <em>low</em> rates of skill change</strong> because the learnings can <a href=\"__GHOST_URL__/you-dont-understand-compound-growth/\">compound</a> over time instead of dwindle in relevance.</p><blockquote>High-ability workers are faster learners, in all jobs. However, <strong>the relative return to ability is higher in careers that change less, because learning gains accumulate.</strong></blockquote><p>Said another way, <strong>the opportunity cost of working in a rapidly-changing field is highest for the best learners</strong>. This creates immense pressure to drop out of software engineering and other fast-changing careers into more stable roles and industries.</p><p>The researchers show this by regressing STEM job status on a number of other variables, including an interaction between age and score on the <a href=\"https://www.military.com/join-armed-forces/asvab\">Armed Forces Qualifying Test</a> (AFQT), a common measure of cognitive ability. The coefficient comes out negative and statistically significant, implying that the relative probability of working in STEM at any given age <em>declines</em> with cognitive ability (column 1 and 2 below):</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/LFrqrUH7Kl.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><blockquote>The results imply that a worker with cognitive ability one standard deviation above average is 4.9 percentage points more likely to work in STEM at age 23, but <strong>only 1.6 percentage points more likely to be working in a STEM job by age 34</strong>.</blockquote><p>In fact, by age 40, the regression predicts <strong>workers with higher cognitive ability are <em>less</em> likely to work in STEM than those with lower cognitive ability</strong>.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/Relative-STEM-Probability-for-1-SD-Higher-Cognitive-Ability.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Simply put, <strong>professionals with higher cognitive ability drop out of STEM careers earlier and faster</strong>:</p><blockquote>... STEM majors with higher scores on the Armed Forces Qualifying Test (AFQT)â€”a widely used proxy for academic aptitudeâ€”<strong>leave STEM careers more often and at younger ages</strong>.</blockquote><h2 id=\"implication-growing-the-software-engineering-talent-pool-is-harder-than-you-think\">Implication: Growing the software engineering talent pool is harder than you think</h2><p>Two points I want to drive home:</p><p><strong>First</strong> â€” software development has a <em>turnover</em> problem.</p><p>Growing the supply of software developers is not trivial because the field already sees high levels of developer dropout and turnover, and this would only increase if the field were to grow larger. A larger software development labor pool would presumably drive down wages, encouraging even more developers to shift out of the profession, especially those past their career midpoints. On that flat part of the earnings curve, the incentive to remain a developer is weak at best.</p><p><strong>Second</strong> â€” software development also has a <em>selection</em> problem.</p><p>The highest ability, fastest learners disproportionately leave the field over time. They have a multitude of other ways to profitably leverage their intellect and skills. <strong>Software development carries serious opportunity cost.</strong> Again, this is ironic because one would normally expect the best to stay and worst to leave, but that's not what we see in the data. The software development talent pool mix shifts toward <em>lower cognitive ability</em> as any given cohort matures.</p><p>Combined, these points suggest software development may be destined for perennial labor shortages unless the pace of change slows sufficiently.</p><blockquote>... <strong>rapid technological change can lead to a short shelf life for technical skills</strong>. This tradeoff between technology-specific and general skills is an important consideration for policymakers and colleges seeking to educate the workers of today, while also building the skills of the next generation.</blockquote><p>To conclude, I emphasize: <strong>highly skilled people prefer highly stable careers in the long-run</strong>. This lets their relative ability and human capital advantage compound over time. Rapid deterioration of skills continuously levels the playing field, preventing the best from separating themselves from the pack. In such a situation, <strong>it makes more sense to quit the race early than get caught in the pile up</strong>.</p><p><em>Thanks to <a href=\"https://scholar.harvard.edu/ddeming/home\">David Deming</a>, <a href=\"https://scholar.harvard.edu/kadeem/home\">Kadeem Noray</a>, the authors of <a href=\"https://academic.oup.com/qje/article/135/4/1965/5858010\">the study</a> from which much of this essay is derived.</em></p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: Why We Will Never Have Enough Software Developers\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Subscribe</span></button>\n</form>\n</section><!--kg-card-end: html-->","comment_id":"5f928e0717b26d3ef80d64b6","plaintext":"We will never have enough software developers.\n\nDevelopers are dropping out of the profession in large numbers despite efforts\nto grow the number of computer science graduates and software engineers.\n\nHere's why.\n\nDeveloper dropout is real\nSoftware development has a serious retention problem:\n\n * At age 26, 59% of engineering and computer science grads work in occupations \n   related to their field of study. By age 50, only 41% work in the same domain,\n   meaning a full ~30% drop out of the field by mid-career\n * In contrast, engineering and computer science majors who join unrelated \n   fields upon graduation retain at much higher rates, with only 10-15%\n   switching out after the age of 26:\n\nEngineers often leave engineering for non-STEM management roles. Graduation into\nmanagement is not surprising. What's surprising is that these are non-STEM \npositions. Engineers swap technical roles for non-technical roles over time.\n\nThis phenomenon, which I'll call \"developer dropout,\" is a real problem. What's\nbehind it?\n\nReceive my next long-form post\nThoughtful analysis of the business and economics of tech\n\n\n\nSubscribeOut with the old skills, in with the new skills\nProgramming-related jobs have high rates of skill turnover. Over time, the types\nof skills required by companies hiring software developers change more rapidly\nthan any other profession.\n\nTo demonstrate this, researchers\n[https://academic.oup.com/qje/article/135/4/1965/5858010] analyzed job postings\non more than 40,000 online job boards and company websites between 2007 and\n2019, controlling for employer, location, and occupation. They defined \"new\"\nskills as those that were rare or non-existent in 2007 but prevalent in 2019 and\n\"old\" skills as those that were prevalent in 2007 but rare or extinct in 2019.\n\n * While only 30% of all job vacancies required at least one new skill by 2019, \n   47% of computer and mathematical jobs required at least one new skill (i.e. a\n   skill that was not common back in 2007)\n * This compares to less than 20% of jobs in fields like education, law, and\n   community and social services\n * In addition, 16% of jobs in computer and mathematical fields in 2007 required\n   a skill that was obsolete by 2019 (i.e. a skill that was common in 2007 but\n   relatively rare in 2019), more than double any other job category:\n\nAbout a third of the change in required skills in computer-related occupations\nis due to specific new software:\n\n * The fastest-growing software skills between 2007 and 2019 include Python, R,\n   and Apache Hadoop\n * Software that was popular in 2007 but effectively obsolete by 2019 includes\n   QuarkXpress, ActionScript, Solaris, IBM Websphere, and Adobe Flash (ah,\n   finally a name I recognize)\n\nData science, machine learning, and AI saw big increases among\ntechnology-intensive jobs as well. For example, the number of STEM-related jobs\nrequiring skills in machine learning and AI grew more than 4x from 2007-2017,\ntouching more than 15% of STEM jobs:\n\nTo better compare rates of skill change across occupations, the researchers came\nup with a measure of skill change that tracks the absolute growth or decline of\nvarious skills within each profession from 2007 to 2019. Occupations whose\nrequired skills change rapidly in prevalence among job postings receive a high\nscore, while jobs whose skills do not change much receive a lower score:\n\n * Computer-related occupations receive the highest score by far, 4.8. Note that\n   the mean and standard deviation of this measure are ~3 and ~1 respectively,\n   so computer-related jobs are nearly two standard deviations away from the\n   typical job in America\n * Meanwhile, jobs in education and and those involving manual labor have very\n   low skill change scores, typically less than 2.\n\nWe can get even more granular and look at specific job roles. This level of\ndetail makes the difference even more stark (only showing the fastest changing\nroles):\n\nWeb development has the highest rate of skill change among all jobs in the\ncountry. Next up are sales engineers, another often technical role. Database\nadministrators, computer network architects, sysadmins, and application\ndevelopers all make the top 10, and we see many other technical roles among the\ntop 30. The mean and standard deviation are similar here, placing web\ndevelopment more than 3 standard deviations away from the typical job in America \nin terms of skill change over time.\n\nSuffice to say, software development is a rapidly changing profession.\n\nYou might think, however, that skill change would eventually settle down as one\nbecomes more experienced.\n\nYou'd be wrong. The skills for software engineering jobs change rapidly\nthroughout the entire career lifecycle:\n\n * In entry-level roles in computer and engineering occupations all the way\n   through those requiring 12+ years of experience, the proportion of job\n   postings requiring at least one new skill in 2019 was effectively the same,\n   40-45%\n * In contrast, 29% of entry-level non-computing and engineering roles in 2019\n   required at least one new skill, but this proportion declines to 24% for jobs\n   requiring more than four years of experience\n\n> This means that experienced STEM workers seeking employment in 2019 are often\nrequired to possess skills that were not required when they entered the labor\nmarket in 2007 or earlier.\nSoftware engineers never escape the skill-change vortex, even many years into\ntheir careers. Experienced engineers must learn and adopt technologies that\ndidn't even exist when they started out. Developers must constantly retool\nthemselves, even well after their formal education\n[https://nnamdi.net/college-degrees-software-engineers/] ends.\n\nNothing's changed but my change [https://youtu.be/m1ERvlxgCD8?t=166]\nCollege majors associated with faster changing jobs pay more early on.\n\n * In professions with one standard deviation increased skill change, pay is \n   ~30% higher in the first few years of one's career\n * If we exclude both the fastest and slowest-changing fields\n   (Engineering/Computer Science at the high end, Health/Education at the low\n   end), the early earnings premium for faster-changing roles increases to ~60%:\n\nFast-changing fields pay better.\n\nNotice however that the pay advantage declines over time. By the time one\napproaches the age of 50, the pay premium for working in rapidly changing fields\nfalls dramatically to only 20-30% vs slower changing professions.\n\nHere's another way to see the eroding pay advantage. The below chart simulates\nthe earnings of the average worker by category of college degree from ages 23 to\n50 in 2016 dollars.\n\n * Computer science and engineering grads start off with sizable advantage vs\n   any other major\n * However, this premium falls over time as the earnings of CS and engineering\n   graduates plateau over time while the earnings of their peers grow faster for \n   longer\n * In fact, life and physical science graduates' earnings surpass their computer\n   and engineering classmates by the age of 40:\n\nExcluding business majors, the earnings premium of software engineering declines\nover time in both percentage and absolute dollar terms, to the point where\nengineers barely out-earn social science majors:\n\nBut the focus on college major is somewhat misleading. This phenomenon has less\nto do with one's field of study and more to do with choice of occupation.\n\nTo show this, researchers plotted the earnings premium of various categories\nworkers relative to those with a non-Engineering/Computer Science major working\nin a non-Engineering/Computer Science job.\n\n * Workers who major in Engineering or Computer Science but work in unrelated\n   fields actually see their earnings advantage compound over time, rather than\n   decline\n * On the other hand, regardless of major, individuals who work in Engineering\n   or Computer Science jobs see their earnings advantage erode over the years:\n\n> Declining relative returns is a feature of STEM jobs, not majors. The earnings\npremium for non-STEM majors in STEM occupations starts off near 40%, but\ndeclines to 20% within a decade. In contrast, the relative earnings advantage\ngrows over time for computer science and engineering majors working in non-STEM\noccupations.\nThe profession of software development drives the declining earnings premium, \nnot the college major.\n\nIn fact, computer science majors who work in non-CS fields experience the \nopposite dynamic of their non-developer peers â€” their relative earnings premium\nrises as they advance. A CS major who eschews the profession doesn't earn much\nmore than otherwise similar non-CS majors early on, but eventually out-earns\ntheir peers by nearly 20%.\n\nOK, that's enough about what is happening. Now let's see why it's happening.\n\nHuman capital depreciates too\nImagine a simple model where workers choose their profession in order to\nmaximize income, which is a derivative of their own skill or human capital. Over\ntime, workers gain new skills, while the value of their existing skills\ndepreciates somewhat due to changing times.\n\nSome workers, endowed with superior ability, learn faster than others, picking\nup skills at a quicker pace. Those workers will tend to sort into high-skilled,\nfast-changing professions initially, maximizing their early career earnings.\nLess impressive workers will sort into low-skilled, slower-changing professions.\n\nIn a world where human capital never depreciated, we could imagine that\nhigh-skilled individuals like software developers would maintain a relative\nhuman capital (and earnings) advantage over other professionals, leading to\nconsistently increasing pay and a stable relative premium:\n\nBut, if human capital depreciates over time and that rate of depreciation is\nhigher in rapidly-changing fields like software development, then developers'\ninitial advantage would erode over time, narrowing the gap vs. non-developers:\n\nThis simple model helps explain what we see in the data â€” the software\nengineering earnings advantage disappears as the effective human capital gap\nnarrows.\n\n> Applied majors such as computer science, engineering, and business teach\nvintage-specific skills that become less valuable as new skills are introduced\nto the workplace over time.\nSpecific skills in software development quickly become dated. Programming\nlanguages and development frameworks go out of style. Hadoop is hot one year,\nand it's old news the next. Like a fast, expensive car that quickly loses value\nas it's driven around town, the skills and human capital of software engineers\nfall apart without constant, expensive maintenance:\n\n> Intuitively, careers with high rates of obsolescence require workers to learn\nmany new tasks each year, which diminishes learning gains and lowers the returns\nto experience.\nQuick learners are fast dropouts\nThe hits don't stop there. Ironically, the quickest learners are also the\nquickest dropouts.\n\nTo understand why, think back to the model we just outlined. Quick learners\naccumulate human capital faster than their slower peers, which means they have\nthe most to lose when certain skills or abilities fall out of favor. In fact, \nthe return to being a fast learner is higher in jobs with low rates of skill\nchange because the learnings can compound\n[https://nnamdi.net/you-dont-understand-compound-growth/] over time instead of\ndwindle in relevance.\n\n> High-ability workers are faster learners, in all jobs. However, the relative\nreturn to ability is higher in careers that change less, because learning gains\naccumulate.\nSaid another way, the opportunity cost of working in a rapidly-changing field is\nhighest for the best learners. This creates immense pressure to drop out of\nsoftware engineering and other fast-changing careers into more stable roles and\nindustries.\n\nThe researchers show this by regressing STEM job status on a number of other\nvariables, including an interaction between age and score on the Armed Forces\nQualifying Test [https://www.military.com/join-armed-forces/asvab] (AFQT), a\ncommon measure of cognitive ability. The coefficient comes out negative and\nstatistically significant, implying that the relative probability of working in\nSTEM at any given age declines with cognitive ability (column 1 and 2 below):\n\n> The results imply that a worker with cognitive ability one standard deviation\nabove average is 4.9 percentage points more likely to work in STEM at age 23,\nbut only 1.6 percentage points more likely to be working in a STEM job by age 34\n.\nIn fact, by age 40, the regression predicts workers with higher cognitive\nability are less likely to work in STEM than those with lower cognitive ability.\n\nSimply put, professionals with higher cognitive ability drop out of STEM careers\nearlier and faster:\n\n> ... STEM majors with higher scores on the Armed Forces Qualifying Test (AFQT)â€”a\nwidely used proxy for academic aptitudeâ€”leave STEM careers more often and at\nyounger ages.\nImplication: Growing the software engineering talent pool is harder than you\nthink\nTwo points I want to drive home:\n\nFirst â€” software development has a turnover problem.\n\nGrowing the supply of software developers is not trivial because the field\nalready sees high levels of developer dropout and turnover, and this would only\nincrease if the field were to grow larger. A larger software development labor\npool would presumably drive down wages, encouraging even more developers to\nshift out of the profession, especially those past their career midpoints. On\nthat flat part of the earnings curve, the incentive to remain a developer is\nweak at best.\n\nSecond â€” software development also has a selection problem.\n\nThe highest ability, fastest learners disproportionately leave the field over\ntime. They have a multitude of other ways to profitably leverage their intellect\nand skills. Software development carries serious opportunity cost. Again, this\nis ironic because one would normally expect the best to stay and worst to leave,\nbut that's not what we see in the data. The software development talent pool mix\nshifts toward lower cognitive ability as any given cohort matures.\n\nCombined, these points suggest software development may be destined for\nperennial labor shortages unless the pace of change slows sufficiently.\n\n> ... rapid technological change can lead to a short shelf life for technical\nskills. This tradeoff between technology-specific and general skills is an\nimportant consideration for policymakers and colleges seeking to educate the\nworkers of today, while also building the skills of the next generation.\nTo conclude, I emphasize: highly skilled people prefer highly stable careers in\nthe long-run. This lets their relative ability and human capital advantage\ncompound over time. Rapid deterioration of skills continuously levels the\nplaying field, preventing the best from separating themselves from the pack. In\nsuch a situation, it makes more sense to quit the race early than get caught in\nthe pile up.\n\nThanks to David Deming [https://scholar.harvard.edu/ddeming/home], Kadeem Noray\n[https://scholar.harvard.edu/kadeem/home], the authors of the study\n[https://academic.oup.com/qje/article/135/4/1965/5858010] from which much of\nthis essay is derived.\n\nReceive my next long-form post\nThoughtful analysis of the business and economics of tech\n\n\n\nSubscribe","feature_image":"__GHOST_URL__/content/images/2020/10/header-v2-resized.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-10-23T08:02:15.000Z","updated_at":"2022-07-04T00:08:19.000Z","published_at":"2020-10-27T17:55:02.000Z","custom_excerpt":"Developers are dropping out of the profession in large numbers","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"5fdaf66417b26d3ef80d657e","uuid":"e0de7271-3261-47b3-94c5-cec2de8becfa","title":"Product-Market Fit is Lindy","slug":"product-market-fit-is-lindy","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/12/image-20201217101504390.png\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Product-Market Fit is Lindy\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Subscribe</span></button>\\n</form>\\n</section>\"}],[\"embed\",{\"url\":\"https://twitter.com/stanine/status/1290714927489880065\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">(1) It&#39;s been said, but now I get it in my gut: if you have to ask whether youâ€™ve found product-market fit, you havenâ€™t. Like most things, itâ€™s lognormal: better PMF yields way, way better biz performance. At a certain point, most assumptions about how to build a co. break. 2/7</p>&mdash; Matt MacInnis (@stanine) <a href=\\\"https://twitter.com/stanine/status/1290714927489880065?ref_src=twsrc%5Etfw\\\">August 4, 2020</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/12/lognormal-distribution.jpg\",\"alt\":\"lognormal-distribution\",\"title\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/12/image-20200906170720679.png\",\"alt\":\"image-20200906170720679\",\"title\":\"\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: Product-Market Fit is Lindy\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Subscribe</span></button>\\n</form>\\n</section>\"}]],\"markups\":[[\"em\"],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Lindy_effect\"]],[\"strong\"],[\"a\",[\"href\",\"https://twitter.com/stanine\"]],[\"a\",[\"href\",\"https://www.rippling.com/\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Log-normal_distribution\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Fat-tailed_distribution\"]],[\"a\",[\"href\",\"__GHOST_URL__/vcs-index-invest/\"]],[\"a\",[\"href\",\"https://eduardomazevedo.github.io/papers/azevedo-et-al-ab.pdf\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"The longer you search for product-market fit, the less likely you will find it.\"]]],[1,\"p\",[[0,[],0,\"This phenomenon is called the Lindy effect.\"]]],[1,\"p\",[[0,[],0,\"To be \\\"Lindy\\\" means the longer something survives, the more time it has left. Remaining life \"],[0,[0],1,\"extends\"],[0,[],0,\", rather than contracts, with age.\"]]],[1,\"p\",[[0,[],0,\"Perishable objects like flesh-and-blood humans don't work this way. As we age, our remaining time on this Earth decreases â€” a 90 year-old has less expected time left on the clock than an 80 year-old.\"]]],[1,\"p\",[[0,[],0,\"But certain non-perishables follow a different rule. Per \"],[0,[1],1,\"Wikipedia\"],[0,[],0,\":\"]]],[1,\"blockquote\",[[0,[],0,\"The Lindy effect is a theory that the future life expectancy of some non-perishable things like a technology or an idea is proportional to their current age, so that \"],[0,[2],1,\"every additional period of survival implies a longer remaining life expectancy\"],[0,[],0,\". Where the Lindy effect applies, \"],[0,[2],1,\"mortality rate decreases with time\"],[0,[],0,\".\"]]],[10,0],[1,\"p\",[[0,[],0,\"Product-market fit follows the Lindy effect.\"]]],[1,\"p\",[[0,[],0,\"More precisely, \"],[0,[0],1,\"lack\"],[0,[],0,\" of product-market fit is \\\"Lindy\\\". \"],[0,[2],1,\"The longer you don't have it, the longer you won't have it.\"]]],[1,\"p\",[[0,[],0,\"An additional year of \\\"no product-market fit\\\" implies a longer remaining period of \\\"no product-market fit.\\\" The odds of achieving product-market fit with any particular idea decline with time. Thus, \"],[0,[2],1,\"if you don't achieve product-market fit quickly, you may never achieve it at all.\"]]],[1,\"p\",[[0,[],0,\"Product-market fit, like the elusive \\\"cure\\\" for cancer, is not a fixed destination, guaranteed to be reached with enough time spent running toward it. In a weird way, moving \\\"toward\\\" it doesn't actually get you any closer to it â€” it only moves further away.\"]]],[1,\"p\",[[0,[],0,\"Product-market fit \"],[0,[0],1,\"escapes\"],[0,[],0,\" from you.\"]]],[10,1],[1,\"h2\",[[0,[],0,\"Product-market fit isn't normal\"]]],[1,\"p\",[[0,[],0,\"I was inspired to write this essay by a recent tweet by \"],[0,[3],1,\"Matt MacInnis\"],[0,[],0,\", COO of \"],[0,[4],1,\"Rippling\"],[0,[],0,\", where he claimed product-market fit is obvious once you have it, suggesting business performance is \"],[0,[5],1,\"lognormally distributed\"],[0,[],0,\" vis-a-vis product-market fit:\"]]],[10,2],[1,\"p\",[[0,[],0,\"No, he didn't mention the Lindy effect \"],[0,[0],1,\"directly\"],[0,[],0,\", but that's what instantly came to mind as I read the tweet.\"]]],[1,\"p\",[[0,[],0,\"Here's why.\"]]],[1,\"p\",[[0,[],0,\"A lognormal distribution is one which, if you take the logarithm of all its possible values, yields a normal distribution. Hence \\\"log\\\" \\\"normal\\\". Due to the exponential nature of the logarithm, lognormal distributions are skewed:\"]]],[10,3],[1,\"p\",[[0,[],0,\"Lognormal distributions are neither normally distributed nor thin-tailed. Instead, they are \"],[0,[6],1,\"fat-tailed\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"This is an important fact.\"]]],[1,\"p\",[[0,[],0,\"When MacInnis says performance is lognormal, or skewed, with respect to product-market fit, he's making the point that, once you have product-market fit, \"],[0,[2],1,\"you go straight to the tails\"],[0,[],0,\". Business performance accelerates so meaningfully that any ambiguity goes out the window. You get it \\\"in your gut.\\\" It becomes obvious, as nearly everything about the business gets better.\"]]],[1,\"h2\",[[0,[],0,\"A/B testing with fat tails\"]]],[1,\"p\",[[0,[],0,\"In \"],[0,[7],1,\"Why Don't VCs Index Invest\"],[0,[],0,\", I make the point that, when facing sufficiently fat-tailed distributions, it makes sense to spread your bets widely, avoiding concentration or dependence on any one investment or opportunity. Instead \\\"index invest,\\\" placing small bets in everything reasonable without overthinking it too much.\"]]],[1,\"p\",[[0,[],0,\"This extends to all domains where fat-tails reign. \"],[0,[8],1,\"A fascinating paper\"],[0,[],0,\" by researchers at Microsoft, HomeAway, Wharton, and Columbia University applies this logic to the domain of internet search engines and reaches similar conclusions.\"]]],[1,\"p\",[[0,[],0,\"Search platforms like Microsoft Bing and Google face a trade-off when A/B testing various changes:\"]]],[3,\"ul\",[[[0,[],0,\"run large, data-hungry experiments to get precise effect estimates for potential improvements to the platform\"]],[[0,[],0,\"run small, \\\"lean\\\" experiments that do not have much statistical power but nevertheless detect effects if they are large enough\"]]]],[1,\"p\",[[0,[],0,\"The conventional wisdom is that larger A/B tests are better because they increase statistical significance of the experimental results, building confidence that seemingly positive results are, in fact, positive.\"]]],[1,\"p\",[[0,[],0,\"It turns out, the optimal choice for how many users to assign to an experiment depends on the fat-tailedness of the distribution of potential returns, or what the researchers call, the \\\"innovation value distribution\\\":\"]]],[1,\"blockquote\",[[0,[],0,\"... \"],[0,[2],1,\"with sufficiently fat tails, this conventional wisdom reverses and the go lean approach of trying many small experiments is preferred\"],[0,[],0,\". Intuitively, with sufficiently fat tails, even small experiments are sufficient to detect the largest effects; which in this case account for most total value. Larger experiments detect subtler effects, but these constitute less of the total value; \"],[0,[2],1,\"making the value of information concave\"],[0,[],0,\". This case also has different implications for the marginal value of information.\"]]],[1,\"p\",[[0,[],0,\"To translate â€” when most of the potential gains come from a small number of experimental changes (i.e., innovation is fat-tailed), you're better off running as many experiments as possible so as not to miss the potential \\\"big one.\\\" Yes, this might come at the cost of statistical precision, but large effects are so large they can be detected even in small samples.\"]]],[1,\"p\",[[0,[],0,\"Another way to think about this is in terms of the \\\"value\\\" of information:\"]]],[1,\"blockquote\",[[0,[],0,\"while the production function is always concave for large numbers of assigned users, its shape with few users depends critically on the thickness of the tails of the prior. If the prior is not too fat-tailed... then the production function is convex. However, \"],[0,[2],1,\"we show that if the prior is very fat-tailed... the production function is concave.\"]]],[1,\"p\",[[0,[],0,\"Again, I translate â€” when the value of experimentation is fat-tailed, the marginal value of additional information declines as you gather more data because any large, positive innovation is easily detectable with only a small amount of data. Thus, collecting more information doesn't help much â€” the value of information is \"],[0,[0],1,\"concave\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"On the other hand, if the value of experimentation is normally distributed or thin-tailed, then there are almost no mammoths out there to find. Instead, most innovations are of middling value. In that range, precision matters, as it can be the difference between accidentally implementing a slightly worse change over a somewhat better one. More information helps decipher between the two. Thus, the value of information is \"],[0,[0],1,\"convex\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"We can see this in the chart below from the Bing paper, which shows the shape of the experiment \\\"production function\\\" (which effectively represents the value of experimentally gained information) when graphed against experiment sample size. The different lines represent various levels of \\\\(\\\\alpha\\\\) , or the assumed fat-tailedness of the innovation distribution. Lower \\\\(\\\\alpha\\\\) means fatter tails, and vice versa.\"]]],[1,\"p\",[[0,[],0,\"Fat-tailedness (small \\\\(\\\\alpha\\\\)) leads to a concave information value curve, whereas thin-tailedness (high \\\\(\\\\alpha\\\\)) leads to a convex information value curve:\"]]],[10,4],[1,\"h2\",[[0,[],0,\"You'll know it when you see it\"]]],[1,\"p\",[[0,[],0,\"So which is it?\"]]],[1,\"blockquote\",[[0,[],0,\"We present evidenceâ€”using a sample of approximately 1,505 experimentsâ€”suggesting that \"],[0,[2],1,\"innovations at Microsoft Bing have very fat tails\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[2],1,\"The innovation value distribution is fat-tailed.\"],[0,[],0,\" So small experiments can detect the largest effects, which represent most of the value of A/B testing:\"]]],[1,\"blockquote\",[[0,[2],1,\"If the distribution of innovation quality is sufficiently thick tailed, a few ideas are large outliers\"],[0,[],0,\", with very large negative or positive impacts. These are commonly referred to as black swans, or as big wins when they are positive. The production function is concave and has an infinite derivative at n = 0. \"],[0,[2],1,\"The optimal innovation strategy in this case is to run many small experiments, and to test all ideas.\"]]],[1,\"p\",[[0,[],0,\"OK, but what does A/B testing with fat tails have to do with product-market fit?\"]]],[1,\"p\",[[0,[],0,\"Think about the search for product-market fit as a sort of multifaceted A/B test. You try various permutations of the product, business, and go-to-market model, looking for something that especially resonates with users or customers. The vast majority of these combinations won't work out, but a handful will. Those few will work \"],[0,[0],1,\"so well\"],[0,[],0,\" in fact that they will \"],[0,[0],1,\"dwarf\"],[0,[],0,\" the performance of all the other iterations.\"]]],[1,\"p\",[[0,[],0,\"If it is true that product-market fit yields much better business performance, then product-market fit should be relatively obvious, even with little data. This suggests that, if you do have some data for an idea and it \"],[0,[0],1,\"still\"],[0,[],0,\" isn't obvious to you whether or not it achieves product-market fit, you may have a problem, especially if you've been at it for a while.\"]]],[1,\"p\",[[0,[],0,\"But isn't that exactly what MacInnis said?\"]]],[1,\"blockquote\",[[0,[2],1,\"\\\"If you have to ask whether you've found product-market fit, you haven't.\\\"\"]]],[1,\"p\",[[0,[],0,\"The Bing experiments provide the mathematical and empirical justification for MacInnis' bold statement. While I won't quibble over whether business performance is lognormal or some other distribution, it's clearly quite skewed, just as in the Big experiments. In that kind of world, product-market fit loses much of its mystique â€” it doesn't take a genius to know whether you have it:\"]]],[1,\"blockquote\",[[0,[],0,\"Consider a startup firm that uses a lean experimentation strategy. The firm tries out many ideas in small A/B tests, in hopes of finding one idea that is a big positive outlier. Even though the A/B tests are imprecise, the firm knows that, \"],[0,[2],1,\"if a signal is several standard errors above the mean, it is likely to be an outlier.\"],[0,[],0,\" So the firm decides to only implement ideas that are, say, 5 standard errors above the mean. \"],[0,[2],1,\"This means that the firm will almost certainly detect all outliers that are more than, say, 7 standard errors above the mean.\"]]],[1,\"p\",[[0,[],0,\"\\\"\"],[0,[0],1,\"You'll know it when you see it\"],[0,[],0,\"\\\" rings quite true.\"]]],[1,\"p\",[[0,[],0,\"Due to fat-tailed business performance, it doesn't take much data to know you've achieved product-market fit, nor does it require some complicated, made-up framework from a supposed startup guru. In the context of the Bing analysis, any A/B test that yielded a result more than several standard deviations above the baseline essentially achieved \\\"fit,\\\" with a high degree of certainty.\"]]],[1,\"h2\",[[0,[],0,\"Starting over\"]]],[1,\"p\",[[0,[],0,\"Let's end by returning to where we began â€” the Lindy effect.\"]]],[1,\"p\",[[0,[],0,\"MacInnis' statement is effectively a rephrasing of the Lindy effect â€”  if it's taken long to find product-market fit, it's likely going to take \"],[0,[0],1,\"a lot\"],[0,[],0,\" longer.\"]]],[1,\"p\",[[0,[],0,\"To rephrase once more: since it doesn't take much data to know you have product-market fit (assuming you do, in fact, have it), then if you haven't achieved it yet, you probably have a long way to go.\"]]],[1,\"p\",[[0,[],0,\"This is brutal stuff. However, via lean experimentation, planting many flags in various places and quickly shifting gears when no treasure is found, you can, in expectation, start \\\"closer\\\" to the goal. Per the Microsoft paper:\"]]],[1,\"blockquote\",[[0,[],0,\"We call this the \\\"lean experimentation\\\" strategy, as it involves running many cheap experiments in the hopes of finding big wins (or avoiding a negative outlier). This strategy is in line with the lean startup approach, which encourages companies to \"],[0,[2],1,\"quickly iterate through many ideas, experiment, and pivot from ideas that are not resounding successes\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"I want to emphasize that these are are all probabilistic statements and say nothing about any particular circumstance.\"]]],[1,\"p\",[[0,[],0,\"You and your team could have been chasing product-market fit for a given idea for the past year, and, for all anyone knows, it could be just around the corner. Many ideas seemed hopeless and for the longest time didn't work... until they finally did.\"]]],[1,\"p\",[[0,[],0,\"But that's not the norm.\"]]],[1,\"p\",[[0,[],0,\"Uber, Netflix, Facebook, DoorDash. In each case, soon after launch, it became quite clear they were doing something right. Even in companies that went through many iterations, things started to work very soon after landing on the right idea.\"]]],[1,\"p\",[[0,[],0,\"To be clear â€” the chase does not \"],[0,[0],1,\"cause\"],[0,[],0,\" product-market fit to never be achieved. It represents growing \"],[0,[0],1,\"evidence\"],[0,[],0,\" it won't be achieved. The chase represents \"],[0,[0],1,\"information\"],[0,[],0,\", the value of which is concave, meaning it has diminishing returns. That one needs to chase at all is, strangely enough, a sign you're on the wrong path.\"]]],[1,\"p\",[[0,[],0,\"More viscerally, if the trail through the forest seems much longer than it should be, \"],[0,[2],1,\"you're probably lost\"],[0,[],0,\". Breath, regroup, and try something different.\"]]],[10,5],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}","html":"<p>The longer you search for product-market fit, the less likely you will find it.</p><p>This phenomenon is called the Lindy effect.</p><p>To be \"Lindy\" means the longer something survives, the more time it has left. Remaining life <em>extends</em>, rather than contracts, with age.</p><p>Perishable objects like flesh-and-blood humans don't work this way. As we age, our remaining time on this Earth decreases â€” a 90 year-old has less expected time left on the clock than an 80 year-old.</p><p>But certain non-perishables follow a different rule. Per <a href=\"https://en.wikipedia.org/wiki/Lindy_effect\">Wikipedia</a>:</p><blockquote>The Lindy effect is a theory that the future life expectancy of some non-perishable things like a technology or an idea is proportional to their current age, so that <strong>every additional period of survival implies a longer remaining life expectancy</strong>. Where the Lindy effect applies, <strong>mortality rate decreases with time</strong>.</blockquote><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/12/image-20201217101504390.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Product-market fit follows the Lindy effect.</p><p>More precisely, <em>lack</em> of product-market fit is \"Lindy\". <strong>The longer you don't have it, the longer you won't have it.</strong></p><p>An additional year of \"no product-market fit\" implies a longer remaining period of \"no product-market fit.\" The odds of achieving product-market fit with any particular idea decline with time. Thus, <strong>if you don't achieve product-market fit quickly, you may never achieve it at all.</strong></p><p>Product-market fit, like the elusive \"cure\" for cancer, is not a fixed destination, guaranteed to be reached with enough time spent running toward it. In a weird way, moving \"toward\" it doesn't actually get you any closer to it â€” it only moves further away.</p><p>Product-market fit <em>escapes</em> from you.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Product-Market Fit is Lindy\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Subscribe</span></button>\n</form>\n</section><!--kg-card-end: html--><h2 id=\"product-market-fit-isn-t-normal\">Product-market fit isn't normal</h2><p>I was inspired to write this essay by a recent tweet by <a href=\"https://twitter.com/stanine\">Matt MacInnis</a>, COO of <a href=\"https://www.rippling.com/\">Rippling</a>, where he claimed product-market fit is obvious once you have it, suggesting business performance is <a href=\"https://en.wikipedia.org/wiki/Log-normal_distribution\">lognormally distributed</a> vis-a-vis product-market fit:</p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">(1) It&#39;s been said, but now I get it in my gut: if you have to ask whether youâ€™ve found product-market fit, you havenâ€™t. Like most things, itâ€™s lognormal: better PMF yields way, way better biz performance. At a certain point, most assumptions about how to build a co. break. 2/7</p>&mdash; Matt MacInnis (@stanine) <a href=\"https://twitter.com/stanine/status/1290714927489880065?ref_src=twsrc%5Etfw\">August 4, 2020</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><p>No, he didn't mention the Lindy effect <em>directly</em>, but that's what instantly came to mind as I read the tweet.</p><p>Here's why.</p><p>A lognormal distribution is one which, if you take the logarithm of all its possible values, yields a normal distribution. Hence \"log\" \"normal\". Due to the exponential nature of the logarithm, lognormal distributions are skewed:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/12/lognormal-distribution.jpg\" class=\"kg-image\" alt=\"lognormal-distribution\" loading=\"lazy\"></figure><p>Lognormal distributions are neither normally distributed nor thin-tailed. Instead, they are <a href=\"https://en.wikipedia.org/wiki/Fat-tailed_distribution\">fat-tailed</a>.</p><p>This is an important fact.</p><p>When MacInnis says performance is lognormal, or skewed, with respect to product-market fit, he's making the point that, once you have product-market fit, <strong>you go straight to the tails</strong>. Business performance accelerates so meaningfully that any ambiguity goes out the window. You get it \"in your gut.\" It becomes obvious, as nearly everything about the business gets better.</p><h2 id=\"a-b-testing-with-fat-tails\">A/B testing with fat tails</h2><p>In <a href=\"__GHOST_URL__/vcs-index-invest/\">Why Don't VCs Index Invest</a>, I make the point that, when facing sufficiently fat-tailed distributions, it makes sense to spread your bets widely, avoiding concentration or dependence on any one investment or opportunity. Instead \"index invest,\" placing small bets in everything reasonable without overthinking it too much.</p><p>This extends to all domains where fat-tails reign. <a href=\"https://eduardomazevedo.github.io/papers/azevedo-et-al-ab.pdf\">A fascinating paper</a> by researchers at Microsoft, HomeAway, Wharton, and Columbia University applies this logic to the domain of internet search engines and reaches similar conclusions.</p><p>Search platforms like Microsoft Bing and Google face a trade-off when A/B testing various changes:</p><ul><li>run large, data-hungry experiments to get precise effect estimates for potential improvements to the platform</li><li>run small, \"lean\" experiments that do not have much statistical power but nevertheless detect effects if they are large enough</li></ul><p>The conventional wisdom is that larger A/B tests are better because they increase statistical significance of the experimental results, building confidence that seemingly positive results are, in fact, positive.</p><p>It turns out, the optimal choice for how many users to assign to an experiment depends on the fat-tailedness of the distribution of potential returns, or what the researchers call, the \"innovation value distribution\":</p><blockquote>... <strong>with sufficiently fat tails, this conventional wisdom reverses and the go lean approach of trying many small experiments is preferred</strong>. Intuitively, with sufficiently fat tails, even small experiments are sufficient to detect the largest effects; which in this case account for most total value. Larger experiments detect subtler effects, but these constitute less of the total value; <strong>making the value of information concave</strong>. This case also has different implications for the marginal value of information.</blockquote><p>To translate â€” when most of the potential gains come from a small number of experimental changes (i.e., innovation is fat-tailed), you're better off running as many experiments as possible so as not to miss the potential \"big one.\" Yes, this might come at the cost of statistical precision, but large effects are so large they can be detected even in small samples.</p><p>Another way to think about this is in terms of the \"value\" of information:</p><blockquote>while the production function is always concave for large numbers of assigned users, its shape with few users depends critically on the thickness of the tails of the prior. If the prior is not too fat-tailed... then the production function is convex. However, <strong>we show that if the prior is very fat-tailed... the production function is concave.</strong></blockquote><p>Again, I translate â€” when the value of experimentation is fat-tailed, the marginal value of additional information declines as you gather more data because any large, positive innovation is easily detectable with only a small amount of data. Thus, collecting more information doesn't help much â€” the value of information is <em>concave</em>.</p><p>On the other hand, if the value of experimentation is normally distributed or thin-tailed, then there are almost no mammoths out there to find. Instead, most innovations are of middling value. In that range, precision matters, as it can be the difference between accidentally implementing a slightly worse change over a somewhat better one. More information helps decipher between the two. Thus, the value of information is <em>convex</em>.</p><p>We can see this in the chart below from the Bing paper, which shows the shape of the experiment \"production function\" (which effectively represents the value of experimentally gained information) when graphed against experiment sample size. The different lines represent various levels of \\(\\alpha\\) , or the assumed fat-tailedness of the innovation distribution. Lower \\(\\alpha\\) means fatter tails, and vice versa.</p><p>Fat-tailedness (small \\(\\alpha\\)) leads to a concave information value curve, whereas thin-tailedness (high \\(\\alpha\\)) leads to a convex information value curve:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/12/image-20200906170720679.png\" class=\"kg-image\" alt=\"image-20200906170720679\" loading=\"lazy\"></figure><h2 id=\"you-ll-know-it-when-you-see-it\">You'll know it when you see it</h2><p>So which is it?</p><blockquote>We present evidenceâ€”using a sample of approximately 1,505 experimentsâ€”suggesting that <strong>innovations at Microsoft Bing have very fat tails</strong>.</blockquote><p><strong>The innovation value distribution is fat-tailed.</strong> So small experiments can detect the largest effects, which represent most of the value of A/B testing:</p><blockquote><strong>If the distribution of innovation quality is sufficiently thick tailed, a few ideas are large outliers</strong>, with very large negative or positive impacts. These are commonly referred to as black swans, or as big wins when they are positive. The production function is concave and has an infinite derivative at n = 0. <strong>The optimal innovation strategy in this case is to run many small experiments, and to test all ideas.</strong></blockquote><p>OK, but what does A/B testing with fat tails have to do with product-market fit?</p><p>Think about the search for product-market fit as a sort of multifaceted A/B test. You try various permutations of the product, business, and go-to-market model, looking for something that especially resonates with users or customers. The vast majority of these combinations won't work out, but a handful will. Those few will work <em>so well</em> in fact that they will <em>dwarf</em> the performance of all the other iterations.</p><p>If it is true that product-market fit yields much better business performance, then product-market fit should be relatively obvious, even with little data. This suggests that, if you do have some data for an idea and it <em>still</em> isn't obvious to you whether or not it achieves product-market fit, you may have a problem, especially if you've been at it for a while.</p><p>But isn't that exactly what MacInnis said?</p><blockquote><strong>\"If you have to ask whether you've found product-market fit, you haven't.\"</strong></blockquote><p>The Bing experiments provide the mathematical and empirical justification for MacInnis' bold statement. While I won't quibble over whether business performance is lognormal or some other distribution, it's clearly quite skewed, just as in the Big experiments. In that kind of world, product-market fit loses much of its mystique â€” it doesn't take a genius to know whether you have it:</p><blockquote>Consider a startup firm that uses a lean experimentation strategy. The firm tries out many ideas in small A/B tests, in hopes of finding one idea that is a big positive outlier. Even though the A/B tests are imprecise, the firm knows that, <strong>if a signal is several standard errors above the mean, it is likely to be an outlier.</strong> So the firm decides to only implement ideas that are, say, 5 standard errors above the mean. <strong>This means that the firm will almost certainly detect all outliers that are more than, say, 7 standard errors above the mean.</strong></blockquote><p>\"<em>You'll know it when you see it</em>\" rings quite true.</p><p>Due to fat-tailed business performance, it doesn't take much data to know you've achieved product-market fit, nor does it require some complicated, made-up framework from a supposed startup guru. In the context of the Bing analysis, any A/B test that yielded a result more than several standard deviations above the baseline essentially achieved \"fit,\" with a high degree of certainty.</p><h2 id=\"starting-over\">Starting over</h2><p>Let's end by returning to where we began â€” the Lindy effect.</p><p>MacInnis' statement is effectively a rephrasing of the Lindy effect â€” Â if it's taken long to find product-market fit, it's likely going to take <em>a lot</em> longer.</p><p>To rephrase once more: since it doesn't take much data to know you have product-market fit (assuming you do, in fact, have it), then if you haven't achieved it yet, you probably have a long way to go.</p><p>This is brutal stuff. However, via lean experimentation, planting many flags in various places and quickly shifting gears when no treasure is found, you can, in expectation, start \"closer\" to the goal. Per the Microsoft paper:</p><blockquote>We call this the \"lean experimentation\" strategy, as it involves running many cheap experiments in the hopes of finding big wins (or avoiding a negative outlier). This strategy is in line with the lean startup approach, which encourages companies to <strong>quickly iterate through many ideas, experiment, and pivot from ideas that are not resounding successes</strong>.</blockquote><p>I want to emphasize that these are are all probabilistic statements and say nothing about any particular circumstance.</p><p>You and your team could have been chasing product-market fit for a given idea for the past year, and, for all anyone knows, it could be just around the corner. Many ideas seemed hopeless and for the longest time didn't work... until they finally did.</p><p>But that's not the norm.</p><p>Uber, Netflix, Facebook, DoorDash. In each case, soon after launch, it became quite clear they were doing something right. Even in companies that went through many iterations, things started to work very soon after landing on the right idea.</p><p>To be clear â€” the chase does not <em>cause</em> product-market fit to never be achieved. It represents growing <em>evidence</em> it won't be achieved. The chase represents <em>information</em>, the value of which is concave, meaning it has diminishing returns. That one needs to chase at all is, strangely enough, a sign you're on the wrong path.</p><p>More viscerally, if the trail through the forest seems much longer than it should be, <strong>you're probably lost</strong>. Breath, regroup, and try something different.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: Product-Market Fit is Lindy\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Subscribe</span></button>\n</form>\n</section><!--kg-card-end: html-->","comment_id":"5fdaf66417b26d3ef80d657e","plaintext":"The longer you search for product-market fit, the less likely you will find it.\n\nThis phenomenon is called the Lindy effect.\n\nTo be \"Lindy\" means the longer something survives, the more time it has left.\nRemaining life extends, rather than contracts, with age.\n\nPerishable objects like flesh-and-blood humans don't work this way. As we age,\nour remaining time on this Earth decreases â€” a 90 year-old has less expected\ntime left on the clock than an 80 year-old.\n\nBut certain non-perishables follow a different rule. Per Wikipedia\n[https://en.wikipedia.org/wiki/Lindy_effect]:\n\n> The Lindy effect is a theory that the future life expectancy of some\nnon-perishable things like a technology or an idea is proportional to their\ncurrent age, so that every additional period of survival implies a longer\nremaining life expectancy. Where the Lindy effect applies, mortality rate\ndecreases with time.\nProduct-market fit follows the Lindy effect.\n\nMore precisely, lack of product-market fit is \"Lindy\". The longer you don't have\nit, the longer you won't have it.\n\nAn additional year of \"no product-market fit\" implies a longer remaining period\nof \"no product-market fit.\" The odds of achieving product-market fit with any\nparticular idea decline with time. Thus, if you don't achieve product-market fit\nquickly, you may never achieve it at all.\n\nProduct-market fit, like the elusive \"cure\" for cancer, is not a fixed\ndestination, guaranteed to be reached with enough time spent running toward it.\nIn a weird way, moving \"toward\" it doesn't actually get you any closer to it â€”\nit only moves further away.\n\nProduct-market fit escapes from you.\n\nReceive my next long-form post\nThoughtful analysis of the business and economics of tech\n\n\n\nSubscribeProduct-market fit isn't normal\nI was inspired to write this essay by a recent tweet by Matt MacInnis\n[https://twitter.com/stanine], COO of Rippling [https://www.rippling.com/],\nwhere he claimed product-market fit is obvious once you have it, suggesting\nbusiness performance is lognormally distributed\n[https://en.wikipedia.org/wiki/Log-normal_distribution] vis-a-vis product-market\nfit:\n\n> (1) It's been said, but now I get it in my gut: if you have to ask whether\nyouâ€™ve found product-market fit, you havenâ€™t. Like most things, itâ€™s lognormal:\nbetter PMF yields way, way better biz performance. At a certain point, most\nassumptions about how to build a co. break. 2/7\n\nâ€” Matt MacInnis (@stanine) August 4, 2020\n[https://twitter.com/stanine/status/1290714927489880065?ref_src=twsrc%5Etfw]\nNo, he didn't mention the Lindy effect directly, but that's what instantly came\nto mind as I read the tweet.\n\nHere's why.\n\nA lognormal distribution is one which, if you take the logarithm of all its\npossible values, yields a normal distribution. Hence \"log\" \"normal\". Due to the\nexponential nature of the logarithm, lognormal distributions are skewed:\n\nLognormal distributions are neither normally distributed nor thin-tailed.\nInstead, they are fat-tailed\n[https://en.wikipedia.org/wiki/Fat-tailed_distribution].\n\nThis is an important fact.\n\nWhen MacInnis says performance is lognormal, or skewed, with respect to\nproduct-market fit, he's making the point that, once you have product-market\nfit, you go straight to the tails. Business performance accelerates so\nmeaningfully that any ambiguity goes out the window. You get it \"in your gut.\"\nIt becomes obvious, as nearly everything about the business gets better.\n\nA/B testing with fat tails\nIn Why Don't VCs Index Invest [__GHOST_URL__/vcs-index-invest/], I make the\npoint that, when facing sufficiently fat-tailed distributions, it makes sense to\nspread your bets widely, avoiding concentration or dependence on any one\ninvestment or opportunity. Instead \"index invest,\" placing small bets in\neverything reasonable without overthinking it too much.\n\nThis extends to all domains where fat-tails reign. A fascinating paper\n[https://eduardomazevedo.github.io/papers/azevedo-et-al-ab.pdf] by researchers\nat Microsoft, HomeAway, Wharton, and Columbia University applies this logic to\nthe domain of internet search engines and reaches similar conclusions.\n\nSearch platforms like Microsoft Bing and Google face a trade-off when A/B\ntesting various changes:\n\n * run large, data-hungry experiments to get precise effect estimates for\n   potential improvements to the platform\n * run small, \"lean\" experiments that do not have much statistical power but\n   nevertheless detect effects if they are large enough\n\nThe conventional wisdom is that larger A/B tests are better because they\nincrease statistical significance of the experimental results, building\nconfidence that seemingly positive results are, in fact, positive.\n\nIt turns out, the optimal choice for how many users to assign to an experiment\ndepends on the fat-tailedness of the distribution of potential returns, or what\nthe researchers call, the \"innovation value distribution\":\n\n> ... with sufficiently fat tails, this conventional wisdom reverses and the go\nlean approach of trying many small experiments is preferred. Intuitively, with\nsufficiently fat tails, even small experiments are sufficient to detect the\nlargest effects; which in this case account for most total value. Larger\nexperiments detect subtler effects, but these constitute less of the total\nvalue; making the value of information concave. This case also has different\nimplications for the marginal value of information.\nTo translate â€” when most of the potential gains come from a small number of\nexperimental changes (i.e., innovation is fat-tailed), you're better off running\nas many experiments as possible so as not to miss the potential \"big one.\" Yes,\nthis might come at the cost of statistical precision, but large effects are so\nlarge they can be detected even in small samples.\n\nAnother way to think about this is in terms of the \"value\" of information:\n\n> while the production function is always concave for large numbers of assigned\nusers, its shape with few users depends critically on the thickness of the tails\nof the prior. If the prior is not too fat-tailed... then the production function\nis convex. However, we show that if the prior is very fat-tailed... the\nproduction function is concave.\nAgain, I translate â€” when the value of experimentation is fat-tailed, the\nmarginal value of additional information declines as you gather more data\nbecause any large, positive innovation is easily detectable with only a small\namount of data. Thus, collecting more information doesn't help much â€” the value\nof information is concave.\n\nOn the other hand, if the value of experimentation is normally distributed or\nthin-tailed, then there are almost no mammoths out there to find. Instead, most\ninnovations are of middling value. In that range, precision matters, as it can\nbe the difference between accidentally implementing a slightly worse change over\na somewhat better one. More information helps decipher between the two. Thus,\nthe value of information is convex.\n\nWe can see this in the chart below from the Bing paper, which shows the shape of\nthe experiment \"production function\" (which effectively represents the value of\nexperimentally gained information) when graphed against experiment sample size.\nThe different lines represent various levels of \\(\\alpha\\) , or the assumed\nfat-tailedness of the innovation distribution. Lower \\(\\alpha\\) means fatter\ntails, and vice versa.\n\nFat-tailedness (small \\(\\alpha\\)) leads to a concave information value curve,\nwhereas thin-tailedness (high \\(\\alpha\\)) leads to a convex information value\ncurve:\n\nYou'll know it when you see it\nSo which is it?\n\n> We present evidenceâ€”using a sample of approximately 1,505 experimentsâ€”suggesting\nthat innovations at Microsoft Bing have very fat tails.\nThe innovation value distribution is fat-tailed. So small experiments can detect\nthe largest effects, which represent most of the value of A/B testing:\n\n> If the distribution of innovation quality is sufficiently thick tailed, a few\nideas are large outliers, with very large negative or positive impacts. These\nare commonly referred to as black swans, or as big wins when they are positive.\nThe production function is concave and has an infinite derivative at n = 0. The\noptimal innovation strategy in this case is to run many small experiments, and\nto test all ideas.\nOK, but what does A/B testing with fat tails have to do with product-market fit?\n\nThink about the search for product-market fit as a sort of multifaceted A/B\ntest. You try various permutations of the product, business, and go-to-market\nmodel, looking for something that especially resonates with users or customers.\nThe vast majority of these combinations won't work out, but a handful will.\nThose few will work so well in fact that they will dwarf the performance of all\nthe other iterations.\n\nIf it is true that product-market fit yields much better business performance,\nthen product-market fit should be relatively obvious, even with little data.\nThis suggests that, if you do have some data for an idea and it still isn't\nobvious to you whether or not it achieves product-market fit, you may have a\nproblem, especially if you've been at it for a while.\n\nBut isn't that exactly what MacInnis said?\n\n> \"If you have to ask whether you've found product-market fit, you haven't.\"\nThe Bing experiments provide the mathematical and empirical justification for\nMacInnis' bold statement. While I won't quibble over whether business\nperformance is lognormal or some other distribution, it's clearly quite skewed,\njust as in the Big experiments. In that kind of world, product-market fit loses\nmuch of its mystique â€” it doesn't take a genius to know whether you have it:\n\n> Consider a startup firm that uses a lean experimentation strategy. The firm\ntries out many ideas in small A/B tests, in hopes of finding one idea that is a\nbig positive outlier. Even though the A/B tests are imprecise, the firm knows\nthat, if a signal is several standard errors above the mean, it is likely to be\nan outlier. So the firm decides to only implement ideas that are, say, 5\nstandard errors above the mean. This means that the firm will almost certainly\ndetect all outliers that are more than, say, 7 standard errors above the mean.\n\"You'll know it when you see it\" rings quite true.\n\nDue to fat-tailed business performance, it doesn't take much data to know you've\nachieved product-market fit, nor does it require some complicated, made-up\nframework from a supposed startup guru. In the context of the Bing analysis, any\nA/B test that yielded a result more than several standard deviations above the\nbaseline essentially achieved \"fit,\" with a high degree of certainty.\n\nStarting over\nLet's end by returning to where we began â€” the Lindy effect.\n\nMacInnis' statement is effectively a rephrasing of the Lindy effect â€” Â if it's\ntaken long to find product-market fit, it's likely going to take a lot longer.\n\nTo rephrase once more: since it doesn't take much data to know you have\nproduct-market fit (assuming you do, in fact, have it), then if you haven't\nachieved it yet, you probably have a long way to go.\n\nThis is brutal stuff. However, via lean experimentation, planting many flags in\nvarious places and quickly shifting gears when no treasure is found, you can, in\nexpectation, start \"closer\" to the goal. Per the Microsoft paper:\n\n> We call this the \"lean experimentation\" strategy, as it involves running many\ncheap experiments in the hopes of finding big wins (or avoiding a negative\noutlier). This strategy is in line with the lean startup approach, which\nencourages companies to quickly iterate through many ideas, experiment, and\npivot from ideas that are not resounding successes.\nI want to emphasize that these are are all probabilistic statements and say\nnothing about any particular circumstance.\n\nYou and your team could have been chasing product-market fit for a given idea\nfor the past year, and, for all anyone knows, it could be just around the\ncorner. Many ideas seemed hopeless and for the longest time didn't work... until\nthey finally did.\n\nBut that's not the norm.\n\nUber, Netflix, Facebook, DoorDash. In each case, soon after launch, it became\nquite clear they were doing something right. Even in companies that went through\nmany iterations, things started to work very soon after landing on the right\nidea.\n\nTo be clear â€” the chase does not cause product-market fit to never be achieved.\nIt represents growing evidence it won't be achieved. The chase represents \ninformation, the value of which is concave, meaning it has diminishing returns.\nThat one needs to chase at all is, strangely enough, a sign you're on the wrong\npath.\n\nMore viscerally, if the trail through the forest seems much longer than it\nshould be, you're probably lost. Breath, regroup, and try something different.\n\nReceive my next long-form post\nThoughtful analysis of the business and economics of tech\n\n\n\nSubscribe","feature_image":"__GHOST_URL__/content/images/2020/12/header.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2020-12-17T06:10:44.000Z","updated_at":"2022-01-24T04:45:16.000Z","published_at":"2020-12-17T18:20:27.000Z","custom_excerpt":"The longer you search for product-market fit, the less likely you will find it.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"601c1e4e17b26d3ef80d65df","uuid":"5e6d35b8-8382-4d69-abf3-c61282383fad","title":"There's Nothing Magical About the SaaS Magic Number","slug":"magical-magic-number","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"I've never liked the SaaS \\\"magic number.\\\"\\n\\nIt always struck me as somewhat contrived â€” a simple metric with intuitive appeal, but one that is so overused and confused at this point that it harms analysis more than it helps.\\n\\nMy core beef with the metric is that it takes what is fundamentally a __correlational__ relationship and confuses it with __causality__, to the chagrin of many strategic finance teams on the inside and investors attempting to model and forecast businesses from the outside.\\n\\nWhile it'd be an overstep to say that sales and marketing doesn't cause revenue growth at all, I've realized most companies and investors are totally confused about the extent to which it does.\\n\\nI want to set the story straight.\\n\\nFirst, let's get definitions out of the way. \\\"[Magic number](https://www.thesaascfo.com/calculate-saas-magic-number/)\\\" is defined as follows:\\n\\n$$\\\\text{Magic Number} = \\\\frac{\\\\text{New ARR}}{\\\\text{Sales & Marketing}}$$\\n\\nMagic number is typically calculated on a quarterly basis, often with S&M shifted back one period, better matching and reflecting that software sales typically take anywhere from 3-6 months.\\n\\nMagic number is just a ratio â€” it's New ARR divided by S&M expense. It tells us nothing about the degree to which that spending caused the New ARR. In fact, for reasons I will illuminate, the degree to which S&M spending actually causes new revenue is almost certainly less than is implied by this not-so-magical ratio. In other words, **magic number overestimates the causal impact of S&M spending**, rendering it useless for decision making.\\n\\nHere's why:\\n\\n* **Omitted / confounding variables**\\n* **Reverse causality and simultaneity**\\n* **Observation vs. intervention**\\n\\nI'll walk through each in turn.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: There's Nothing Magical about the SaaS Magic Number\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Subscribe</span></button>\\n</form>\\n</section>\\n\\n## Omitted / confounding variables\\n\\nMagic number is a faulty metric because it ignores important revenue growth factors and incorrectly attributes those growth contributions to \\\"sales and marketing efficiency.\\\"\\n\\nTo illustrate this, I'll start with a very simple point. Refer back to the definition of magic number â€” New ARR divided by sales and marketing spend:\\n\\n$$\\\\text{Magic Number} = \\\\frac{\\\\text{New ARR}}{\\\\text{Sales & Marketing}}$$\\n\\nThe first thing to note is that New ARR has two sources â€” S&M and \\\"other stuff\\\":\\n\\n$$\\\\text{New ARR} = \\\\text{New ARR from S&M} + \\\\text{New ARR from Other Stuff}$$\\n\\nNew ARR can either come from our investments in S&M or it can come from other sources. This could include organic inbound (which may or may not be \\\"marketing\\\" driven depending on the situation), R&D (we release a new feature or product that the market already wants, and it effectively sells itself), etc:\"}],[\"embed\",{\"url\":\"https://twitter.com/martin_casado/status/1356013483305783299\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">Open source and product lead growth rely heavily on R&amp;D for GTM. Yet, sales metrics don&#39;t account for that.<br><br>Lately I pay more attention to gross burn vs. growth rather than sales metrics. The latter simply don&#39;t provide an accurate picture of the variable costs in the business.</p>&mdash; martin_casado (@martin_casado) <a href=\\\"https://twitter.com/martin_casado/status/1356013483305783299?ref_src=twsrc%5Etfw\\\">January 31, 2021</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\"}],[\"markdown\",{\"markdown\":\"Rather than enumerate all the possible alternative sources of revenue, let's just crudely summarize them under \\\"Other Stuff\\\" and modify our equation to reflect this attribution:\\n\\n$$\\\\text{Magic Number} = \\\\frac{\\\\text{New ARR from S&M} + \\\\text{New ARR from Other Stuff}}{\\\\text{Sales & Marketing}}$$\\n\\nIf we break this fraction into two parts, the first would represent \\\"true\\\" magic number â€” the true causal impact of S&M spend â€” while the second would represent the degree to which the typical measure of magic number is inflated by misattribution of New ARR:\\n\\n$$\\\\text{Measured Magic Number} = \\\\text{True Magic Number} + \\\\underbrace{\\\\frac{\\\\text{New ARR from Other Stuff}}{\\\\text{Sales & Marketing}}}_{\\\\text{Magic Number Inflation Factor}}$$\\n\\nIn other words, magic number omits important non-S&M contributors to revenue and in doing so falsely attributes the New ARR from these alternate sources to S&M. Thus, in a perverse way, we reward ourselves for S&M \\\"efficiency\\\" when in fact it is other factors that meaningfully drive revenue growth. For all we know, our sales and marketing expenditures could be woefully inefficient, but we fool ourselves into thinking otherwise.\\n\\nBecause these other sources of revenue nearly always contribute positively to ARR growth, the magic number inflation factor is almost always positive, meaning that the standard measure for magic number is typically an inflated estimate of the true causal influence of S&M spend. This has serious implications for our ability to model and forecast revenue growth based on assumed S&M inputs.\\n\\nThis also explains why magic number tends to decline when S&M grows rapidly and tends to increase when S&M spend is suddenly cut. It's partly because S&M has diminishing returns, i.e. \\\"true magic number\\\" tends to fluctuate with S&M spend itself. But the other reason is the inflation factor, which includes S&M in the denominator. This means that when S&M grows quickly (specifically, faster than \\\"New ARR from Other Stuff\\\"), the inflation factor decreases, so our measured magic number decreases. The reverse happens when S&M grows more slowly â€” magic number inflation increases.\\n\\nIn statistics parlance, magic number is __biased__ estimate of the \\\"true\\\" magic number due to omitted or confounding variables:\\n\\n![endogeneity](/content/images/2021/02/endogeneity.png)\\n\\nIn the diagram above, Y is New ARR, X is S&M, Z is a set of observed variables that influence both S&M and New ARR, and U is a set of unobserved variables that also influence our P&L. Unobservables are, by definition, not observed and therefore difficult to account for, but at a minimum we should attempt to control for those observed variables that influence S&M and/or New ARR.\\n\\nMagic number does neither, guaranteeing that it won't properly measure the impact of S&M on revenue. Magic number is therefore less a measure of sales efficiency and more a measure of its correlation with new revenue. Another name for this is **spurious correlation**. You've probably seen one of these funny charts before:\\n\\n![8GLG52Ye5Q](/content/images/2021/02/8GLG52Ye5Q.png)\\n\\nTwo variables can be totally unrelated, yet be nearly perfectly correlated. In this case, the \\\"magic number\\\" between margarine consumption and Maine divorces is totally meaningless. Again, the point here isn't that S&M and New ARR aren't at all related; the point is that because they tend to move together and are __plausibly__ related, we tend to think they are much more related than they in fact are.\\n\\n## Reverse causality and simultaneity\\n\\nThere's a tendency to think, \\\"Well, S&M is in the denominator and revenue is in the numerator, so S&M must be driving revenue.\\\" That way of thinking also accords with the way sales and marketing is framed most of the time â€” they are the \\\"revenue generating\\\" part of the business, so investments in S&M must, to some extent, drive revenue.\\n\\nBut rarely asked is the reverse â€” to what degree does revenue cause S&M expense?\\n\\nNow, that might at first seem absurd, but don't dismiss it so easily. Revenue almost certain does cause S&M. How? Well, in the most basic sense, aside from capital raised from the outside, the main source of funding for all expenses on the income statement is revenue. That's where the business earns the cash that it can then spend on various initiatives.\\n\\nIf you still don't believe me, think about this proof of concept. Does COGS (Cost of Goods Sold) cause revenue, or does revenue cause COGS? Clearly revenue causes COGS, by definition, since COGS is the cost of goods __sold__, so something has to be sold (and revenue has to be generated), in order for COGS expense to show up. So clearly, revenue can cause expenses to some degree.\\n\\nWhat we choose to spend on S&M is dependent on the revenue we __expect__ to earn. For example, if you know your S&M is highly effective at driving revenue growth, that is likely to encourage you to invest more in S&M. Conversely, if S&M is not very effective at driving revenue, you will likely spend less than you might otherwise. In that subtle way, revenue (or more accurately in this case, expected revenue) influences S&M spend.\\n\\nYou may not have ever considered this, but it shouldn't be too surprising. There's a reason you rarely see companies spending, say, 500% of revenue on S&M. Companies typically limit their S&M spend to some reasonable level relative to current revenue. Therefore, revenue in some way influences S&M spend. Economists would say that S&M is **[endogenously determined](https://en.wikipedia.org/wiki/Endogeneity_%28econometrics%29)** â€” it's not some number we pull out of thin air. Our expectations for how valuable it will be and how much revenue we have in the first place determine how much we invest in S&M. Further, our business plans and objectives (\\\"hitting $XM in ARR by year end\\\") influences our S&M spending decisions.\\n\\nThis phenomenon â€” where A causes B and B also causes A â€” is called **simultaneity** in statistics and econometrics. More colloquially, you might know this as **reverse causation**.\\n\\nReverse causation poses a serious problem to our attempts to forecast new revenue from sales and marketing expenditure. Because magic number estimates the relationship between S&M and revenue from observational data rather than some kind of controlled experiment, we don't know the degree to which one causes the other or the reverse. If a business has a magic number of 1, that could mean that \\\\$1 of S&M causes \\\\$1 of New ARR, or it could mean that businesses that __expect__ to add \\\\$1 in New ARR choose to limit their S&M to roughly $1.\\n\\nThe answer is somewhere in the middle, and yet magic number assumes the former. Not good.\\n\\n## Observation vs. intervention\\n\\nThe third and final problem with magic number is that is confuses **observation** and **intervention**. This is very related to the notion of correlation vs. causation but goes further by personifying causation a bit.\\n\\n*Observation* means watching something happen, making no attempts to influence the outcome or the relevant variables. As an analyst measuring the sales efficiency of a software business from the outside, magic number is an observational metric. You can't do anything to influence any of the inputs, you are merely reporting their values. Magic number is not a good measure of sales efficiency, but as long as you acknowledge this caveat, there's nothing inherently wrong with calculating its value, useless though it may be.\\n\\nHowever, if you are an actor inside the business intending to intervene in some way, choosing how much to spend on S&M, the entire game changes. In this case, magic number is not only useless as a measure of sales efficiency, but it is in fact a __logical fallacy__ to use it to forecast the revenue impact from assumed S&M spend.\\n\\nThe reasons behind this are somewhat subtle, but [this analogy](https://www.inference.vc/about/) should make it quite clear.\\n\\n![](https://upload.wikimedia.org/wikipedia/commons/4/4b/Modern_Aneroid_Barometer.jpg)\\n\\nImagine you have a barometer measuring the air pressure around you. If the barometer is functioning properly, we should __observe__ a tight relationship between the pressure reading on the barometer and the actual air pressure. In other words, air pressure and our barometer reading are highly *correlated*.\\n\\nHowever, if we were to hack the barometer and manually change the measurement it reports, would we expect the pressure in the room to change as a result? Obviously not. __Intervening__ by changing the pressure reading of the barometer does not impact actual air pressure, despite the 1:1 observational correlation between the two. The interventional or causal relationship between the barometer and air pressure is exactly zero in that direction (though there is a very strong causal influence in the other direction, air pressure to barometer reading). The observational relationship breaks down when we interfere with the system.\\n\\n> \\\"In summary, y and x are correlated or statistically dependent and therefore seeing x allows me to predict the value of y, but y is not caused by x so setting the value of x won't affect the distribution of y. Hence, p(y|x) and p(y|do(x)) behave very differently.\\\" â€” [ML beyond Curve Fitting](https://www.inference.vc/untitled/)\\n\\nEconomists know this as the [Lucas Critique](https://en.wikipedia.org/wiki/Lucas_critique), which tells us that attempting to conduct economic policy based on some macroeconomic model trained on observational data will inevitably fail, as the identified relationships disappear into the ether.\\n\\n**The same logic applies to sales and marketing spending.** We should not expect magic number, which is effectively a measure of the correlation between New ARR and S&M, to hold constant if we were to purposefully increase S&M. New ARR and S&M can be tightly correlated, and yet the observational correlation between the two breaks down when we intervene. Choosing to, say, double S&M next year does not in any way guarantee that we will book twice as much New ARR. Worse, the breakdown in the relationship tends to go against us â€” after a significant ramp in expense, sales efficiency almost always ends up being worse than expected, rather than better.\\n\\nIf we are interested in forecasting new revenue based on an intentional choice of S&M spending, magic number won't do. We need to find a better magic number, one that approximates the true causal impact:\\n\\n> \\\"In applications where you ultimately want to control or choose x based on the conditional you estimated, you should seek to estimate p(y|do(x)) instead. For example, if x is a medical treatment and y is the outcome, you are not merely interested in observing a naturally occurring treatment x and predicting the outcome, we want to proactively choose the treatment x given our understanding of how it affects the outcome y.\\\" â€” [ML beyond Curve Fitting](https://www.inference.vc/untitled/)\\n\\n## Magic multipliers\\n\\nIf you're a regular reader of mine, you'll know that this is the part where we transition from theory to data. Can we identify the true causal impact of S&M on revenue growth?\\n\\nWe can try.\\n\\nFunnily enough, economists regularly tackle a very similar issue â€” calculating how much the economy grows when the government spends more money, otherwise known as the \\\"fiscal multiplier.\\\" How exactly to calculate these multipliers is a constant debate among economists, but a few methods have emerged with some consensus. Here I will leverage a statistical method called \\\"[local projections](https://sites.google.com/site/oscarjorda/home/local-projections)\\\" which I won't explain in detail here, but I will summarize by saying it enables us to calculate the causal impact of an increase in S&M spend on New ARR over time via a special linear regression. The ratio of the increase in New ARR to the increase in S&M spend yields the \\\"multiplier\\\", or true magic number in our case.\\n\\nI've assembled a dataset of anonymized quarterly New ARR and sales and marketing spend for a sample of early to mid-stage software companies. This is far from a representative sample of all software vendors, but with 230 data points across 26 companies we can generate insights nonetheless. As evidence of its non-representativeness, the average magic number in my dataset is **2.1**. Most companies in fact hover closer to 1, but the logic is the same regardless.\\n\\nFirst we'll calculate the impact of an increase in S&M (relative to what it otherwise would have been) on New ARR (again, relative to the counterfactual). We'll recalculate this at various horizons â€” current quarter (labeled \\\"Q1\\\" below), one quarter out, two quarters out etc (chart on the left). To get the total effect we'll sum up the impacts across quarters (chart on the right):\\n\\n![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2FBYNBFHio-T.png?alt=media&token=bb38640a-7eae-4478-b4ab-a8914c006c11)\\n\\nA \\\\$1M increase in S&M this quarter generates \\\\$0.38 more New ARR that same quarter, \\\\$0.39 the next quarter, and so on. Cumulatively, over four quarters this adds up to about **$2** of additional New ARR vs. if S&M spend hadn't increased.\\n\\nNow if this was the entire story we'd say that the true magic number reaches two after four quarters and perhaps continues to increase after that. OK, so perhaps magic number as typically calculated doesn't measure the immediate impact of S&M spending, but it gets there eventually, right?\\n\\n__But it's not the whole story.__ We've cheated a bit here by only counting the initial $1 bump in S&M spend. But if we increase spending today, spending tomorrow will also be higher. Part of the effect on New ARR we measured above is due to higher spend in the current quarter, but part of it is also driven by higher spend next quarter (and the quarter after that, and so on).\\n\\nTo account for this, we must calculate the effect of S&M this quarter on S&M **next** quarter **AND** the quarters thereafter and include the cumulative effect in the denominator of our magic number calculation:\\n\\n![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2FYAnS6FgR3i.png?alt=media&token=c114258a-743d-4c16-b80f-a8924bb3fb7b)\\n\\nThe chart above shows the impact of S&M on __itself__ into the future. A \\\\$1 increase this quarter leads to the next quarter being \\\\$0.70 higher than it would have otherwise been, \\\\$0.86 the quarter after that, and so on. Cumulatively, we spend about \\\\$3.5M more after four quarters.\\n\\nNow we can compare the cumulative effect on New ARR to the cumulative increase in S&M to get a proper measure of the \\\"true\\\" magic number:\\n\\n![](https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2F1yocKpYAcw.png?alt=media&token=17eb3eb1-6cf8-4c6c-98f3-7a015c8704bf)\\n\\nThe true magic number is estimated to be only **0.6** after four quarters, this is less than a **third** of the average magic number in this dataset of 2.1. So not only is the true magic number much lower than the typical calculation, it takes many quarters to reach this much lower cumulative impact. Importantly â€” **we don't get nearly the bang-for-buck that the traditional magic number implies.**\\n\\nTo make this real â€” a forecast that New ARR will be \\\\$2.1 higher next quarter based on a \\\\$1 increase in S&M this quarter will be off by **80%** (per the first chart, New ARR one quarter out is only $0.39 higher) and cumulatively (including the first and second quarter impact) will be off by **78%** (based on 0.46 cumulative magic number at Q2).\\n\\n## Magic isn't real\\n\\nIt's worth pointing out some caveats here.\\n\\nI wasn't able to fully control for the \\\"other stuff\\\" that also drives New ARR. In my regressions I do control for the long-term trends of each variable (via a cubic polynomial time trend interacted with company fixed effects for those who care) which helps account for these unobserved factors, but this is not a perfect solution. I also don't identify a completely exogenous increase in S&M. Inherently, I assume that S&M deviations from trend imply unexpected increases in S&M, but that's also not totally right.\\n\\nThis is amateur econometrics, so it'll do.\\n\\nMy conclusions:\\n\\n* **Magic number is a bad metric.** It misleads us into thinking that by turning some knobs we can precisely control revenue growth. It commits the scandalous statistical sin of mixing correlation and causation\\n\\n* **S&M alone has little effect on New ARR.** Certainly not in the near term and to a much lesser degree than you might think in the longer run\\n\\n* **We don't really know how to calculate software sales efficiency.** This analysis leveraged 230 data points to get some level of certainty, but for any particular company it'd be difficult to replicate with only a few quarters or years of data\\n\\nSo what can we use as an alternative? \\n\\nI've always liked the easy heuristic of **New ARR vs. cash burned**. This ignores specific expense line items and gives companies credit for \\\"all-in\\\" capital efficiency, which is arguably what matters most anyway. It avoids the perils of attributing revenue growth to particular initiatives, like sales and marketing or research and development. Of course, we still have an omitted variable problem (burning cash is not the only way to drive revenue growth), but it's much less severe.\\n\\n*3,000 words later, I hope I've convinced you that magic number doesn't tell you much about sales efficiency or productivity. If you've found a better metric, I'd love to hear about it. Feel free to shoot me a note at first.last@gmail.com*\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}","html":"<!--kg-card-begin: markdown--><p>I've never liked the SaaS &quot;magic number.&quot;</p>\n<p>It always struck me as somewhat contrived â€” a simple metric with intuitive appeal, but one that is so overused and confused at this point that it harms analysis more than it helps.</p>\n<p>My core beef with the metric is that it takes what is fundamentally a <strong>correlational</strong> relationship and confuses it with <strong>causality</strong>, to the chagrin of many strategic finance teams on the inside and investors attempting to model and forecast businesses from the outside.</p>\n<p>While it'd be an overstep to say that sales and marketing doesn't cause revenue growth at all, I've realized most companies and investors are totally confused about the extent to which it does.</p>\n<p>I want to set the story straight.</p>\n<p>First, let's get definitions out of the way. &quot;<a href=\"https://www.thesaascfo.com/calculate-saas-magic-number/\">Magic number</a>&quot; is defined as follows:</p>\n<p>$$\\text{Magic Number} = \\frac{\\text{New ARR}}{\\text{Sales &amp; Marketing}}$$</p>\n<p>Magic number is typically calculated on a quarterly basis, often with S&amp;M shifted back one period, better matching and reflecting that software sales typically take anywhere from 3-6 months.</p>\n<p>Magic number is just a ratio â€” it's New ARR divided by S&amp;M expense. It tells us nothing about the degree to which that spending caused the New ARR. In fact, for reasons I will illuminate, the degree to which S&amp;M spending actually causes new revenue is almost certainly less than is implied by this not-so-magical ratio. In other words, <strong>magic number overestimates the causal impact of S&amp;M spending</strong>, rendering it useless for decision making.</p>\n<p>Here's why:</p>\n<ul>\n<li><strong>Omitted / confounding variables</strong></li>\n<li><strong>Reverse causality and simultaneity</strong></li>\n<li><strong>Observation vs. intervention</strong></li>\n</ul>\n<p>I'll walk through each in turn.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: There's Nothing Magical about the SaaS Magic Number\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Subscribe</span></button>\n</form>\n</section>\n<h2 id=\"omittedconfoundingvariables\">Omitted / confounding variables</h2>\n<p>Magic number is a faulty metric because it ignores important revenue growth factors and incorrectly attributes those growth contributions to &quot;sales and marketing efficiency.&quot;</p>\n<p>To illustrate this, I'll start with a very simple point. Refer back to the definition of magic number â€” New ARR divided by sales and marketing spend:</p>\n<p>$$\\text{Magic Number} = \\frac{\\text{New ARR}}{\\text{Sales &amp; Marketing}}$$</p>\n<p>The first thing to note is that New ARR has two sources â€” S&amp;M and &quot;other stuff&quot;:</p>\n<p>$$\\text{New ARR} = \\text{New ARR from S&amp;M} + \\text{New ARR from Other Stuff}$$</p>\n<p>New ARR can either come from our investments in S&amp;M or it can come from other sources. This could include organic inbound (which may or may not be &quot;marketing&quot; driven depending on the situation), R&amp;D (we release a new feature or product that the market already wants, and it effectively sells itself), etc:</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Open source and product lead growth rely heavily on R&amp;D for GTM. Yet, sales metrics don&#39;t account for that.<br><br>Lately I pay more attention to gross burn vs. growth rather than sales metrics. The latter simply don&#39;t provide an accurate picture of the variable costs in the business.</p>&mdash; martin_casado (@martin_casado) <a href=\"https://twitter.com/martin_casado/status/1356013483305783299?ref_src=twsrc%5Etfw\">January 31, 2021</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><!--kg-card-begin: markdown--><p>Rather than enumerate all the possible alternative sources of revenue, let's just crudely summarize them under &quot;Other Stuff&quot; and modify our equation to reflect this attribution:</p>\n<p>$$\\text{Magic Number} = \\frac{\\text{New ARR from S&amp;M} + \\text{New ARR from Other Stuff}}{\\text{Sales &amp; Marketing}}$$</p>\n<p>If we break this fraction into two parts, the first would represent &quot;true&quot; magic number â€” the true causal impact of S&amp;M spend â€” while the second would represent the degree to which the typical measure of magic number is inflated by misattribution of New ARR:</p>\n<p>$$\\text{Measured Magic Number} = \\text{True Magic Number} + \\underbrace{\\frac{\\text{New ARR from Other Stuff}}{\\text{Sales &amp; Marketing}}}_{\\text{Magic Number Inflation Factor}}$$</p>\n<p>In other words, magic number omits important non-S&amp;M contributors to revenue and in doing so falsely attributes the New ARR from these alternate sources to S&amp;M. Thus, in a perverse way, we reward ourselves for S&amp;M &quot;efficiency&quot; when in fact it is other factors that meaningfully drive revenue growth. For all we know, our sales and marketing expenditures could be woefully inefficient, but we fool ourselves into thinking otherwise.</p>\n<p>Because these other sources of revenue nearly always contribute positively to ARR growth, the magic number inflation factor is almost always positive, meaning that the standard measure for magic number is typically an inflated estimate of the true causal influence of S&amp;M spend. This has serious implications for our ability to model and forecast revenue growth based on assumed S&amp;M inputs.</p>\n<p>This also explains why magic number tends to decline when S&amp;M grows rapidly and tends to increase when S&amp;M spend is suddenly cut. It's partly because S&amp;M has diminishing returns, i.e. &quot;true magic number&quot; tends to fluctuate with S&amp;M spend itself. But the other reason is the inflation factor, which includes S&amp;M in the denominator. This means that when S&amp;M grows quickly (specifically, faster than &quot;New ARR from Other Stuff&quot;), the inflation factor decreases, so our measured magic number decreases. The reverse happens when S&amp;M grows more slowly â€” magic number inflation increases.</p>\n<p>In statistics parlance, magic number is <strong>biased</strong> estimate of the &quot;true&quot; magic number due to omitted or confounding variables:</p>\n<p><img src=\"/content/images/2021/02/endogeneity.png\" alt=\"endogeneity\" loading=\"lazy\"></p>\n<p>In the diagram above, Y is New ARR, X is S&amp;M, Z is a set of observed variables that influence both S&amp;M and New ARR, and U is a set of unobserved variables that also influence our P&amp;L. Unobservables are, by definition, not observed and therefore difficult to account for, but at a minimum we should attempt to control for those observed variables that influence S&amp;M and/or New ARR.</p>\n<p>Magic number does neither, guaranteeing that it won't properly measure the impact of S&amp;M on revenue. Magic number is therefore less a measure of sales efficiency and more a measure of its correlation with new revenue. Another name for this is <strong>spurious correlation</strong>. You've probably seen one of these funny charts before:</p>\n<p><img src=\"/content/images/2021/02/8GLG52Ye5Q.png\" alt=\"8GLG52Ye5Q\" loading=\"lazy\"></p>\n<p>Two variables can be totally unrelated, yet be nearly perfectly correlated. In this case, the &quot;magic number&quot; between margarine consumption and Maine divorces is totally meaningless. Again, the point here isn't that S&amp;M and New ARR aren't at all related; the point is that because they tend to move together and are <strong>plausibly</strong> related, we tend to think they are much more related than they in fact are.</p>\n<h2 id=\"reversecausalityandsimultaneity\">Reverse causality and simultaneity</h2>\n<p>There's a tendency to think, &quot;Well, S&amp;M is in the denominator and revenue is in the numerator, so S&amp;M must be driving revenue.&quot; That way of thinking also accords with the way sales and marketing is framed most of the time â€” they are the &quot;revenue generating&quot; part of the business, so investments in S&amp;M must, to some extent, drive revenue.</p>\n<p>But rarely asked is the reverse â€” to what degree does revenue cause S&amp;M expense?</p>\n<p>Now, that might at first seem absurd, but don't dismiss it so easily. Revenue almost certain does cause S&amp;M. How? Well, in the most basic sense, aside from capital raised from the outside, the main source of funding for all expenses on the income statement is revenue. That's where the business earns the cash that it can then spend on various initiatives.</p>\n<p>If you still don't believe me, think about this proof of concept. Does COGS (Cost of Goods Sold) cause revenue, or does revenue cause COGS? Clearly revenue causes COGS, by definition, since COGS is the cost of goods <strong>sold</strong>, so something has to be sold (and revenue has to be generated), in order for COGS expense to show up. So clearly, revenue can cause expenses to some degree.</p>\n<p>What we choose to spend on S&amp;M is dependent on the revenue we <strong>expect</strong> to earn. For example, if you know your S&amp;M is highly effective at driving revenue growth, that is likely to encourage you to invest more in S&amp;M. Conversely, if S&amp;M is not very effective at driving revenue, you will likely spend less than you might otherwise. In that subtle way, revenue (or more accurately in this case, expected revenue) influences S&amp;M spend.</p>\n<p>You may not have ever considered this, but it shouldn't be too surprising. There's a reason you rarely see companies spending, say, 500% of revenue on S&amp;M. Companies typically limit their S&amp;M spend to some reasonable level relative to current revenue. Therefore, revenue in some way influences S&amp;M spend. Economists would say that S&amp;M is <strong><a href=\"https://en.wikipedia.org/wiki/Endogeneity_%28econometrics%29\">endogenously determined</a></strong> â€” it's not some number we pull out of thin air. Our expectations for how valuable it will be and how much revenue we have in the first place determine how much we invest in S&amp;M. Further, our business plans and objectives (&quot;hitting $XM in ARR by year end&quot;) influences our S&amp;M spending decisions.</p>\n<p>This phenomenon â€” where A causes B and B also causes A â€” is called <strong>simultaneity</strong> in statistics and econometrics. More colloquially, you might know this as <strong>reverse causation</strong>.</p>\n<p>Reverse causation poses a serious problem to our attempts to forecast new revenue from sales and marketing expenditure. Because magic number estimates the relationship between S&amp;M and revenue from observational data rather than some kind of controlled experiment, we don't know the degree to which one causes the other or the reverse. If a business has a magic number of 1, that could mean that $1 of S&amp;M causes $1 of New ARR, or it could mean that businesses that <strong>expect</strong> to add $1 in New ARR choose to limit their S&amp;M to roughly $1.</p>\n<p>The answer is somewhere in the middle, and yet magic number assumes the former. Not good.</p>\n<h2 id=\"observationvsintervention\">Observation vs. intervention</h2>\n<p>The third and final problem with magic number is that is confuses <strong>observation</strong> and <strong>intervention</strong>. This is very related to the notion of correlation vs. causation but goes further by personifying causation a bit.</p>\n<p><em>Observation</em> means watching something happen, making no attempts to influence the outcome or the relevant variables. As an analyst measuring the sales efficiency of a software business from the outside, magic number is an observational metric. You can't do anything to influence any of the inputs, you are merely reporting their values. Magic number is not a good measure of sales efficiency, but as long as you acknowledge this caveat, there's nothing inherently wrong with calculating its value, useless though it may be.</p>\n<p>However, if you are an actor inside the business intending to intervene in some way, choosing how much to spend on S&amp;M, the entire game changes. In this case, magic number is not only useless as a measure of sales efficiency, but it is in fact a <strong>logical fallacy</strong> to use it to forecast the revenue impact from assumed S&amp;M spend.</p>\n<p>The reasons behind this are somewhat subtle, but <a href=\"https://www.inference.vc/about/\">this analogy</a> should make it quite clear.</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/4/4b/Modern_Aneroid_Barometer.jpg\" alt=\"\" loading=\"lazy\"></p>\n<p>Imagine you have a barometer measuring the air pressure around you. If the barometer is functioning properly, we should <strong>observe</strong> a tight relationship between the pressure reading on the barometer and the actual air pressure. In other words, air pressure and our barometer reading are highly <em>correlated</em>.</p>\n<p>However, if we were to hack the barometer and manually change the measurement it reports, would we expect the pressure in the room to change as a result? Obviously not. <strong>Intervening</strong> by changing the pressure reading of the barometer does not impact actual air pressure, despite the 1:1 observational correlation between the two. The interventional or causal relationship between the barometer and air pressure is exactly zero in that direction (though there is a very strong causal influence in the other direction, air pressure to barometer reading). The observational relationship breaks down when we interfere with the system.</p>\n<blockquote>\n<p>&quot;In summary, y and x are correlated or statistically dependent and therefore seeing x allows me to predict the value of y, but y is not caused by x so setting the value of x won't affect the distribution of y. Hence, p(y|x) and p(y|do(x)) behave very differently.&quot; â€” <a href=\"https://www.inference.vc/untitled/\">ML beyond Curve Fitting</a></p>\n</blockquote>\n<p>Economists know this as the <a href=\"https://en.wikipedia.org/wiki/Lucas_critique\">Lucas Critique</a>, which tells us that attempting to conduct economic policy based on some macroeconomic model trained on observational data will inevitably fail, as the identified relationships disappear into the ether.</p>\n<p><strong>The same logic applies to sales and marketing spending.</strong> We should not expect magic number, which is effectively a measure of the correlation between New ARR and S&amp;M, to hold constant if we were to purposefully increase S&amp;M. New ARR and S&amp;M can be tightly correlated, and yet the observational correlation between the two breaks down when we intervene. Choosing to, say, double S&amp;M next year does not in any way guarantee that we will book twice as much New ARR. Worse, the breakdown in the relationship tends to go against us â€” after a significant ramp in expense, sales efficiency almost always ends up being worse than expected, rather than better.</p>\n<p>If we are interested in forecasting new revenue based on an intentional choice of S&amp;M spending, magic number won't do. We need to find a better magic number, one that approximates the true causal impact:</p>\n<blockquote>\n<p>&quot;In applications where you ultimately want to control or choose x based on the conditional you estimated, you should seek to estimate p(y|do(x)) instead. For example, if x is a medical treatment and y is the outcome, you are not merely interested in observing a naturally occurring treatment x and predicting the outcome, we want to proactively choose the treatment x given our understanding of how it affects the outcome y.&quot; â€” <a href=\"https://www.inference.vc/untitled/\">ML beyond Curve Fitting</a></p>\n</blockquote>\n<h2 id=\"magicmultipliers\">Magic multipliers</h2>\n<p>If you're a regular reader of mine, you'll know that this is the part where we transition from theory to data. Can we identify the true causal impact of S&amp;M on revenue growth?</p>\n<p>We can try.</p>\n<p>Funnily enough, economists regularly tackle a very similar issue â€” calculating how much the economy grows when the government spends more money, otherwise known as the &quot;fiscal multiplier.&quot; How exactly to calculate these multipliers is a constant debate among economists, but a few methods have emerged with some consensus. Here I will leverage a statistical method called &quot;<a href=\"https://sites.google.com/site/oscarjorda/home/local-projections\">local projections</a>&quot; which I won't explain in detail here, but I will summarize by saying it enables us to calculate the causal impact of an increase in S&amp;M spend on New ARR over time via a special linear regression. The ratio of the increase in New ARR to the increase in S&amp;M spend yields the &quot;multiplier&quot;, or true magic number in our case.</p>\n<p>I've assembled a dataset of anonymized quarterly New ARR and sales and marketing spend for a sample of early to mid-stage software companies. This is far from a representative sample of all software vendors, but with 230 data points across 26 companies we can generate insights nonetheless. As evidence of its non-representativeness, the average magic number in my dataset is <strong>2.1</strong>. Most companies in fact hover closer to 1, but the logic is the same regardless.</p>\n<p>First we'll calculate the impact of an increase in S&amp;M (relative to what it otherwise would have been) on New ARR (again, relative to the counterfactual). We'll recalculate this at various horizons â€” current quarter (labeled &quot;Q1&quot; below), one quarter out, two quarters out etc (chart on the left). To get the total effect we'll sum up the impacts across quarters (chart on the right):</p>\n<p><img src=\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2FBYNBFHio-T.png?alt=media&amp;token=bb38640a-7eae-4478-b4ab-a8914c006c11\" alt=\"\" loading=\"lazy\"></p>\n<p>A $1M increase in S&amp;M this quarter generates $0.38 more New ARR that same quarter, $0.39 the next quarter, and so on. Cumulatively, over four quarters this adds up to about <strong>$2</strong> of additional New ARR vs. if S&amp;M spend hadn't increased.</p>\n<p>Now if this was the entire story we'd say that the true magic number reaches two after four quarters and perhaps continues to increase after that. OK, so perhaps magic number as typically calculated doesn't measure the immediate impact of S&amp;M spending, but it gets there eventually, right?</p>\n<p><strong>But it's not the whole story.</strong> We've cheated a bit here by only counting the initial $1 bump in S&amp;M spend. But if we increase spending today, spending tomorrow will also be higher. Part of the effect on New ARR we measured above is due to higher spend in the current quarter, but part of it is also driven by higher spend next quarter (and the quarter after that, and so on).</p>\n<p>To account for this, we must calculate the effect of S&amp;M this quarter on S&amp;M <strong>next</strong> quarter <strong>AND</strong> the quarters thereafter and include the cumulative effect in the denominator of our magic number calculation:</p>\n<p><img src=\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2FYAnS6FgR3i.png?alt=media&amp;token=c114258a-743d-4c16-b80f-a8924bb3fb7b\" alt=\"\" loading=\"lazy\"></p>\n<p>The chart above shows the impact of S&amp;M on <strong>itself</strong> into the future. A $1 increase this quarter leads to the next quarter being $0.70 higher than it would have otherwise been, $0.86 the quarter after that, and so on. Cumulatively, we spend about $3.5M more after four quarters.</p>\n<p>Now we can compare the cumulative effect on New ARR to the cumulative increase in S&amp;M to get a proper measure of the &quot;true&quot; magic number:</p>\n<p><img src=\"https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2Fwhoisnnamdi%2F1yocKpYAcw.png?alt=media&amp;token=17eb3eb1-6cf8-4c6c-98f3-7a015c8704bf\" alt=\"\" loading=\"lazy\"></p>\n<p>The true magic number is estimated to be only <strong>0.6</strong> after four quarters, this is less than a <strong>third</strong> of the average magic number in this dataset of 2.1. So not only is the true magic number much lower than the typical calculation, it takes many quarters to reach this much lower cumulative impact. Importantly â€” <strong>we don't get nearly the bang-for-buck that the traditional magic number implies.</strong></p>\n<p>To make this real â€” a forecast that New ARR will be $2.1 higher next quarter based on a $1 increase in S&amp;M this quarter will be off by <strong>80%</strong> (per the first chart, New ARR one quarter out is only $0.39 higher) and cumulatively (including the first and second quarter impact) will be off by <strong>78%</strong> (based on 0.46 cumulative magic number at Q2).</p>\n<h2 id=\"magicisntreal\">Magic isn't real</h2>\n<p>It's worth pointing out some caveats here.</p>\n<p>I wasn't able to fully control for the &quot;other stuff&quot; that also drives New ARR. In my regressions I do control for the long-term trends of each variable (via a cubic polynomial time trend interacted with company fixed effects for those who care) which helps account for these unobserved factors, but this is not a perfect solution. I also don't identify a completely exogenous increase in S&amp;M. Inherently, I assume that S&amp;M deviations from trend imply unexpected increases in S&amp;M, but that's also not totally right.</p>\n<p>This is amateur econometrics, so it'll do.</p>\n<p>My conclusions:</p>\n<ul>\n<li>\n<p><strong>Magic number is a bad metric.</strong> It misleads us into thinking that by turning some knobs we can precisely control revenue growth. It commits the scandalous statistical sin of mixing correlation and causation</p>\n</li>\n<li>\n<p><strong>S&amp;M alone has little effect on New ARR.</strong> Certainly not in the near term and to a much lesser degree than you might think in the longer run</p>\n</li>\n<li>\n<p><strong>We don't really know how to calculate software sales efficiency.</strong> This analysis leveraged 230 data points to get some level of certainty, but for any particular company it'd be difficult to replicate with only a few quarters or years of data</p>\n</li>\n</ul>\n<p>So what can we use as an alternative?</p>\n<p>I've always liked the easy heuristic of <strong>New ARR vs. cash burned</strong>. This ignores specific expense line items and gives companies credit for &quot;all-in&quot; capital efficiency, which is arguably what matters most anyway. It avoids the perils of attributing revenue growth to particular initiatives, like sales and marketing or research and development. Of course, we still have an omitted variable problem (burning cash is not the only way to drive revenue growth), but it's much less severe.</p>\n<p><em>3,000 words later, I hope I've convinced you that magic number doesn't tell you much about sales efficiency or productivity. If you've found a better metric, I'd love to hear about it. Feel free to shoot me a note at <a href=\"mailto:first.last@gmail.com\">first.last@gmail.com</a></em></p>\n<!--kg-card-end: markdown-->","comment_id":"601c1e4e17b26d3ef80d65df","plaintext":"I've never liked the SaaS \"magic number.\"\n\nIt always struck me as somewhat contrived â€” a simple metric with intuitive\nappeal, but one that is so overused and confused at this point that it harms\nanalysis more than it helps.\n\nMy core beef with the metric is that it takes what is fundamentally a \ncorrelational relationship and confuses it with causality, to the chagrin of\nmany strategic finance teams on the inside and investors attempting to model and\nforecast businesses from the outside.\n\nWhile it'd be an overstep to say that sales and marketing doesn't cause revenue\ngrowth at all, I've realized most companies and investors are totally confused\nabout the extent to which it does.\n\nI want to set the story straight.\n\nFirst, let's get definitions out of the way. \"Magic number\n[https://www.thesaascfo.com/calculate-saas-magic-number/]\" is defined as\nfollows:\n\n$$\\text{Magic Number} = \\frac{\\text{New ARR}}{\\text{Sales & Marketing}}$$\n\nMagic number is typically calculated on a quarterly basis, often with S&M\nshifted back one period, better matching and reflecting that software sales\ntypically take anywhere from 3-6 months.\n\nMagic number is just a ratio â€” it's New ARR divided by S&M expense. It tells us\nnothing about the degree to which that spending caused the New ARR. In fact, for\nreasons I will illuminate, the degree to which S&M spending actually causes new\nrevenue is almost certainly less than is implied by this not-so-magical ratio.\nIn other words, magic number overestimates the causal impact of S&M spending,\nrendering it useless for decision making.\n\nHere's why:\n\n * Omitted / confounding variables\n * Reverse causality and simultaneity\n * Observation vs. intervention\n\nI'll walk through each in turn.\n\nReceive my next long-form post\nThoughtful analysis of the business and economics of tech\n\n\n\nSubscribeOmitted / confounding variables\nMagic number is a faulty metric because it ignores important revenue growth\nfactors and incorrectly attributes those growth contributions to \"sales and\nmarketing efficiency.\"\n\nTo illustrate this, I'll start with a very simple point. Refer back to the\ndefinition of magic number â€” New ARR divided by sales and marketing spend:\n\n$$\\text{Magic Number} = \\frac{\\text{New ARR}}{\\text{Sales & Marketing}}$$\n\nThe first thing to note is that New ARR has two sources â€” S&M and \"other stuff\":\n\n$$\\text{New ARR} = \\text{New ARR from S&M} + \\text{New ARR from Other Stuff}$$\n\nNew ARR can either come from our investments in S&M or it can come from other\nsources. This could include organic inbound (which may or may not be \"marketing\"\ndriven depending on the situation), R&D (we release a new feature or product\nthat the market already wants, and it effectively sells itself), etc:\n\n> Open source and product lead growth rely heavily on R&D for GTM. Yet, sales\nmetrics don't account for that.\n\nLately I pay more attention to gross burn vs. growth rather than sales metrics.\nThe latter simply don't provide an accurate picture of the variable costs in the\nbusiness.\n\nâ€” martin_casado (@martin_casado) January 31, 2021\n[https://twitter.com/martin_casado/status/1356013483305783299?ref_src=twsrc%5Etfw]\nRather than enumerate all the possible alternative sources of revenue, let's\njust crudely summarize them under \"Other Stuff\" and modify our equation to\nreflect this attribution:\n\n$$\\text{Magic Number} = \\frac{\\text{New ARR from S&M} + \\text{New ARR from Other\nStuff}}{\\text{Sales & Marketing}}$$\n\nIf we break this fraction into two parts, the first would represent \"true\" magic\nnumber â€” the true causal impact of S&M spend â€” while the second would represent\nthe degree to which the typical measure of magic number is inflated by\nmisattribution of New ARR:\n\n$$\\text{Measured Magic Number} = \\text{True Magic Number} +\n\\underbrace{\\frac{\\text{New ARR from Other Stuff}}{\\text{Sales &\nMarketing}}}_{\\text{Magic Number Inflation Factor}}$$\n\nIn other words, magic number omits important non-S&M contributors to revenue and\nin doing so falsely attributes the New ARR from these alternate sources to S&M.\nThus, in a perverse way, we reward ourselves for S&M \"efficiency\" when in fact\nit is other factors that meaningfully drive revenue growth. For all we know, our\nsales and marketing expenditures could be woefully inefficient, but we fool\nourselves into thinking otherwise.\n\nBecause these other sources of revenue nearly always contribute positively to\nARR growth, the magic number inflation factor is almost always positive, meaning\nthat the standard measure for magic number is typically an inflated estimate of\nthe true causal influence of S&M spend. This has serious implications for our\nability to model and forecast revenue growth based on assumed S&M inputs.\n\nThis also explains why magic number tends to decline when S&M grows rapidly and\ntends to increase when S&M spend is suddenly cut. It's partly because S&M has\ndiminishing returns, i.e. \"true magic number\" tends to fluctuate with S&M spend\nitself. But the other reason is the inflation factor, which includes S&M in the\ndenominator. This means that when S&M grows quickly (specifically, faster than\n\"New ARR from Other Stuff\"), the inflation factor decreases, so our measured\nmagic number decreases. The reverse happens when S&M grows more slowly â€” magic\nnumber inflation increases.\n\nIn statistics parlance, magic number is biased estimate of the \"true\" magic\nnumber due to omitted or confounding variables:\n\n\n\nIn the diagram above, Y is New ARR, X is S&M, Z is a set of observed variables\nthat influence both S&M and New ARR, and U is a set of unobserved variables that\nalso influence our P&L. Unobservables are, by definition, not observed and\ntherefore difficult to account for, but at a minimum we should attempt to\ncontrol for those observed variables that influence S&M and/or New ARR.\n\nMagic number does neither, guaranteeing that it won't properly measure the\nimpact of S&M on revenue. Magic number is therefore less a measure of sales\nefficiency and more a measure of its correlation with new revenue. Another name\nfor this is spurious correlation. You've probably seen one of these funny charts\nbefore:\n\n\n\nTwo variables can be totally unrelated, yet be nearly perfectly correlated. In\nthis case, the \"magic number\" between margarine consumption and Maine divorces\nis totally meaningless. Again, the point here isn't that S&M and New ARR aren't\nat all related; the point is that because they tend to move together and are \nplausibly related, we tend to think they are much more related than they in fact\nare.\n\nReverse causality and simultaneity\nThere's a tendency to think, \"Well, S&M is in the denominator and revenue is in\nthe numerator, so S&M must be driving revenue.\" That way of thinking also\naccords with the way sales and marketing is framed most of the time â€” they are\nthe \"revenue generating\" part of the business, so investments in S&M must, to\nsome extent, drive revenue.\n\nBut rarely asked is the reverse â€” to what degree does revenue cause S&M expense?\n\nNow, that might at first seem absurd, but don't dismiss it so easily. Revenue\nalmost certain does cause S&M. How? Well, in the most basic sense, aside from\ncapital raised from the outside, the main source of funding for all expenses on\nthe income statement is revenue. That's where the business earns the cash that\nit can then spend on various initiatives.\n\nIf you still don't believe me, think about this proof of concept. Does COGS\n(Cost of Goods Sold) cause revenue, or does revenue cause COGS? Clearly revenue\ncauses COGS, by definition, since COGS is the cost of goods sold, so something\nhas to be sold (and revenue has to be generated), in order for COGS expense to\nshow up. So clearly, revenue can cause expenses to some degree.\n\nWhat we choose to spend on S&M is dependent on the revenue we expect to earn.\nFor example, if you know your S&M is highly effective at driving revenue growth,\nthat is likely to encourage you to invest more in S&M. Conversely, if S&M is not\nvery effective at driving revenue, you will likely spend less than you might\notherwise. In that subtle way, revenue (or more accurately in this case,\nexpected revenue) influences S&M spend.\n\nYou may not have ever considered this, but it shouldn't be too surprising.\nThere's a reason you rarely see companies spending, say, 500% of revenue on S&M.\nCompanies typically limit their S&M spend to some reasonable level relative to\ncurrent revenue. Therefore, revenue in some way influences S&M spend. Economists\nwould say that S&M is endogenously determined\n[https://en.wikipedia.org/wiki/Endogeneity_%28econometrics%29] â€” it's not some\nnumber we pull out of thin air. Our expectations for how valuable it will be and\nhow much revenue we have in the first place determine how much we invest in S&M.\nFurther, our business plans and objectives (\"hitting $XM in ARR by year end\")\ninfluences our S&M spending decisions.\n\nThis phenomenon â€” where A causes B and B also causes A â€” is called simultaneity \nin statistics and econometrics. More colloquially, you might know this as \nreverse causation.\n\nReverse causation poses a serious problem to our attempts to forecast new\nrevenue from sales and marketing expenditure. Because magic number estimates the\nrelationship between S&M and revenue from observational data rather than some\nkind of controlled experiment, we don't know the degree to which one causes the\nother or the reverse. If a business has a magic number of 1, that could mean\nthat $1 of S&M causes $1 of New ARR, or it could mean that businesses that \nexpect to add $1 in New ARR choose to limit their S&M to roughly $1.\n\nThe answer is somewhere in the middle, and yet magic number assumes the former.\nNot good.\n\nObservation vs. intervention\nThe third and final problem with magic number is that is confuses observation \nand intervention. This is very related to the notion of correlation vs.\ncausation but goes further by personifying causation a bit.\n\nObservation means watching something happen, making no attempts to influence the\noutcome or the relevant variables. As an analyst measuring the sales efficiency\nof a software business from the outside, magic number is an observational\nmetric. You can't do anything to influence any of the inputs, you are merely\nreporting their values. Magic number is not a good measure of sales efficiency,\nbut as long as you acknowledge this caveat, there's nothing inherently wrong\nwith calculating its value, useless though it may be.\n\nHowever, if you are an actor inside the business intending to intervene in some\nway, choosing how much to spend on S&M, the entire game changes. In this case,\nmagic number is not only useless as a measure of sales efficiency, but it is in\nfact a logical fallacy to use it to forecast the revenue impact from assumed S&M\nspend.\n\nThe reasons behind this are somewhat subtle, but this analogy\n[https://www.inference.vc/about/] should make it quite clear.\n\n\n\nImagine you have a barometer measuring the air pressure around you. If the\nbarometer is functioning properly, we should observe a tight relationship\nbetween the pressure reading on the barometer and the actual air pressure. In\nother words, air pressure and our barometer reading are highly correlated.\n\nHowever, if we were to hack the barometer and manually change the measurement it\nreports, would we expect the pressure in the room to change as a result?\nObviously not. Intervening by changing the pressure reading of the barometer\ndoes not impact actual air pressure, despite the 1:1 observational correlation\nbetween the two. The interventional or causal relationship between the barometer\nand air pressure is exactly zero in that direction (though there is a very\nstrong causal influence in the other direction, air pressure to barometer\nreading). The observational relationship breaks down when we interfere with the\nsystem.\n\n> \"In summary, y and x are correlated or statistically dependent and therefore\nseeing x allows me to predict the value of y, but y is not caused by x so\nsetting the value of x won't affect the distribution of y. Hence, p(y|x) and\np(y|do(x)) behave very differently.\" â€” ML beyond Curve Fitting\n[https://www.inference.vc/untitled/]\n\n\nEconomists know this as the Lucas Critique\n[https://en.wikipedia.org/wiki/Lucas_critique], which tells us that attempting\nto conduct economic policy based on some macroeconomic model trained on\nobservational data will inevitably fail, as the identified relationships\ndisappear into the ether.\n\nThe same logic applies to sales and marketing spending. We should not expect\nmagic number, which is effectively a measure of the correlation between New ARR\nand S&M, to hold constant if we were to purposefully increase S&M. New ARR and\nS&M can be tightly correlated, and yet the observational correlation between the\ntwo breaks down when we intervene. Choosing to, say, double S&M next year does\nnot in any way guarantee that we will book twice as much New ARR. Worse, the\nbreakdown in the relationship tends to go against us â€” after a significant ramp\nin expense, sales efficiency almost always ends up being worse than expected,\nrather than better.\n\nIf we are interested in forecasting new revenue based on an intentional choice\nof S&M spending, magic number won't do. We need to find a better magic number,\none that approximates the true causal impact:\n\n> \"In applications where you ultimately want to control or choose x based on the\nconditional you estimated, you should seek to estimate p(y|do(x)) instead. For\nexample, if x is a medical treatment and y is the outcome, you are not merely\ninterested in observing a naturally occurring treatment x and predicting the\noutcome, we want to proactively choose the treatment x given our understanding\nof how it affects the outcome y.\" â€” ML beyond Curve Fitting\n[https://www.inference.vc/untitled/]\n\n\nMagic multipliers\nIf you're a regular reader of mine, you'll know that this is the part where we\ntransition from theory to data. Can we identify the true causal impact of S&M on\nrevenue growth?\n\nWe can try.\n\nFunnily enough, economists regularly tackle a very similar issue â€” calculating\nhow much the economy grows when the government spends more money, otherwise\nknown as the \"fiscal multiplier.\" How exactly to calculate these multipliers is\na constant debate among economists, but a few methods have emerged with some\nconsensus. Here I will leverage a statistical method called \"local projections\n[https://sites.google.com/site/oscarjorda/home/local-projections]\" which I won't\nexplain in detail here, but I will summarize by saying it enables us to\ncalculate the causal impact of an increase in S&M spend on New ARR over time via\na special linear regression. The ratio of the increase in New ARR to the\nincrease in S&M spend yields the \"multiplier\", or true magic number in our case.\n\nI've assembled a dataset of anonymized quarterly New ARR and sales and marketing\nspend for a sample of early to mid-stage software companies. This is far from a\nrepresentative sample of all software vendors, but with 230 data points across\n26 companies we can generate insights nonetheless. As evidence of its\nnon-representativeness, the average magic number in my dataset is 2.1. Most\ncompanies in fact hover closer to 1, but the logic is the same regardless.\n\nFirst we'll calculate the impact of an increase in S&M (relative to what it\notherwise would have been) on New ARR (again, relative to the counterfactual).\nWe'll recalculate this at various horizons â€” current quarter (labeled \"Q1\"\nbelow), one quarter out, two quarters out etc (chart on the left). To get the\ntotal effect we'll sum up the impacts across quarters (chart on the right):\n\n\n\nA $1M increase in S&M this quarter generates $0.38 more New ARR that same\nquarter, $0.39 the next quarter, and so on. Cumulatively, over four quarters\nthis adds up to about $2 of additional New ARR vs. if S&M spend hadn't\nincreased.\n\nNow if this was the entire story we'd say that the true magic number reaches two\nafter four quarters and perhaps continues to increase after that. OK, so perhaps\nmagic number as typically calculated doesn't measure the immediate impact of S&M\nspending, but it gets there eventually, right?\n\nBut it's not the whole story. We've cheated a bit here by only counting the\ninitial $1 bump in S&M spend. But if we increase spending today, spending\ntomorrow will also be higher. Part of the effect on New ARR we measured above is\ndue to higher spend in the current quarter, but part of it is also driven by\nhigher spend next quarter (and the quarter after that, and so on).\n\nTo account for this, we must calculate the effect of S&M this quarter on S&M \nnext quarter AND the quarters thereafter and include the cumulative effect in\nthe denominator of our magic number calculation:\n\n\n\nThe chart above shows the impact of S&M on itself into the future. A $1 increase\nthis quarter leads to the next quarter being $0.70 higher than it would have\notherwise been, $0.86 the quarter after that, and so on. Cumulatively, we spend\nabout $3.5M more after four quarters.\n\nNow we can compare the cumulative effect on New ARR to the cumulative increase\nin S&M to get a proper measure of the \"true\" magic number:\n\n\n\nThe true magic number is estimated to be only 0.6 after four quarters, this is\nless than a third of the average magic number in this dataset of 2.1. So not\nonly is the true magic number much lower than the typical calculation, it takes\nmany quarters to reach this much lower cumulative impact. Importantly â€” we don't\nget nearly the bang-for-buck that the traditional magic number implies.\n\nTo make this real â€” a forecast that New ARR will be $2.1 higher next quarter\nbased on a $1 increase in S&M this quarter will be off by 80% (per the first\nchart, New ARR one quarter out is only $0.39 higher) and cumulatively (including\nthe first and second quarter impact) will be off by 78% (based on 0.46\ncumulative magic number at Q2).\n\nMagic isn't real\nIt's worth pointing out some caveats here.\n\nI wasn't able to fully control for the \"other stuff\" that also drives New ARR.\nIn my regressions I do control for the long-term trends of each variable (via a\ncubic polynomial time trend interacted with company fixed effects for those who\ncare) which helps account for these unobserved factors, but this is not a\nperfect solution. I also don't identify a completely exogenous increase in S&M.\nInherently, I assume that S&M deviations from trend imply unexpected increases\nin S&M, but that's also not totally right.\n\nThis is amateur econometrics, so it'll do.\n\nMy conclusions:\n\n * Magic number is a bad metric. It misleads us into thinking that by turning\n   some knobs we can precisely control revenue growth. It commits the scandalous\n   statistical sin of mixing correlation and causation\n   \n   \n * S&M alone has little effect on New ARR. Certainly not in the near term and to\n   a much lesser degree than you might think in the longer run\n   \n   \n * We don't really know how to calculate software sales efficiency. This\n   analysis leveraged 230 data points to get some level of certainty, but for\n   any particular company it'd be difficult to replicate with only a few\n   quarters or years of data\n   \n   \n\nSo what can we use as an alternative?\n\nI've always liked the easy heuristic of New ARR vs. cash burned. This ignores\nspecific expense line items and gives companies credit for \"all-in\" capital\nefficiency, which is arguably what matters most anyway. It avoids the perils of\nattributing revenue growth to particular initiatives, like sales and marketing\nor research and development. Of course, we still have an omitted variable\nproblem (burning cash is not the only way to drive revenue growth), but it's\nmuch less severe.\n\n3,000 words later, I hope I've convinced you that magic number doesn't tell you\nmuch about sales efficiency or productivity. If you've found a better metric,\nI'd love to hear about it. Feel free to shoot me a note at first.last@gmail.com","feature_image":"__GHOST_URL__/content/images/2021/02/1yocKpYAcw.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2021-02-04T16:18:22.000Z","updated_at":"2021-06-24T23:29:01.000Z","published_at":"2021-02-04T22:38:47.000Z","custom_excerpt":"Magic number is a bad metric. Sales and marketing drives much less revenue than this not-so-magical number implies","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"603c97fd17b26d3ef80d665c","uuid":"83f301fa-1314-4cab-9eaf-132a2ddfb832","title":"Robinhood Traders are Last to the Party","slug":"robinhood-party","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"The recent Robinhood and Gamestop / Gamestock / Gamestonk fiasco shed a light on some of the complex financial infrastructure that undergirds equity trading.\\n\\nOne mechanism, [payment for order flow](https://www.investopedia.com/terms/p/paymentoforderflow.asp), plays a large role in how Robinhood provides commission-free trading to its users.\\n\\nPayment for order flow is often characterized as a shady practice that enables high-frequency traders (HFTs) to front-run Robinhood traders, siphoning off a sliver of profit as they do.\\n\\nI tend to think such concerns are overblown. From the perspective of an individual Robinhood trader, HFTs are of almost no importance, and their impact on trading profits is imperceptible, especially if one only transacts periodically.\\n\\nThe truth is much more ironic.\\n\\nRobinhood traders get fleeced not by HFTs front-running milliseconds before their order hits but **by other retail investors, days earlier.**\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Robinhood Traders are Last to the Party\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Subscribe</span></button>\\n</form>\\n</section>\\n\\n## The party ended \\\\*five\\\\* days ago\\n\\nIt turns out, [trading activity among Robinhood users lags the rest of the retail community by multiple days](https://papers.ssrn.com/abstract=3776874), more than enough time to squeeze out any potential profits.\\n\\nA few charts demonstrate this dynamic. The graph below plots \\\"abnormal retail trading volume\\\" against the days before and after a stock peaks on WallStreetBets, the popular Reddit community, measured in terms of mentions. You can think of day zero as representing the day when mentions of a particular stock, say GME, peaked, with \\\"-5\\\" representing five days before, \\\"5\\\" representing five days after, and so on. \\\"Abnormal\\\" simply means retail trading activity relative to the prior 20-day moving average of retail trading volume for a particular stock.\\n\\nNotice how retail trading volume peaks about two days before WSB mentions peak:\\n\\n![image-20210222140135524](/content/images/2021/03/image-20210222140135524.png)\\n\\nIn other words, popularity on WallStreetBets lags the broader retail market. Stocks first get popular among non-Robinhood retail traders, and the subreddit subsequently picks this up, increasing how often the name is mentioned.\\n\\nNow let's look at Robinhood volume relative to WallStreetBets mentions. Robinhood activity peaks 2-3 days *after* WSB activity:\\n\\n![image-20210222140228350](/content/images/2021/03/image-20210222140228350.png)\\n\\nAll in all, that's a five day delay between when a stock begins to cool off among most retail investors and when Robinhood traders finally get the memo.\\n\\nBy the time most Robinhood users actually trade, the party is over. And when the festivities end, so do the profits.\\n\\n## Noise traders\\n\\nI started the piece with my skepticism about the impact HFTs have on the profits of Robinhood traders. But if retail investors are taking advantage of market opportunities a full *five days* ahead of Robinhood traders, I'm much more inclined to think that could have an effect.\\n\\nThe data proves this out. While recent research has shown that retail traders are in fact informed (measure as a positive correlation between retail trading activity and future stock returns), **Robinhood activity has no positive relationship with future returns**.\\n\\nThe table below shows the results of a regression of future returns at 3, 5, and 20-day intervals on Robinhood user ownership and aggregate retail trading volume, along with a number of control variables. While the coefficient on retail volume is positive and statistically significant in all cases, suggesting that *non-Robinhood* retail trading volume predicts future returns, the coefficient on Robinhood ownership is negative and statistically insignificant, meaning that **Robinhood activity has little relationship with future returns**:\\n\\n![image-20210222140349147](/content/images/2021/03/image-20210222140349147.png)\\n\\nThis finding led the authors to conclude the following:\\n\\n> Contrasting with recent evidence that retail traders are informed, we find that Robinhood ownership changes are unrelated with future returns, suggesting that zero-commission investors behave as noise traders.\\n\\nIf case you don't read a ton of academic finance research, that's an extremely polite and understated way of saying: **Robinhood trading is random** (with respect to financial returns at least). In other words, there's no *there* there.\\n\\nAnd I should say: nothing about the app necessitates that. It's the behavior of the folks using it.\\n\\n## There's no such thing as free alpha\\n\\nI think it's great that Robinhood exists. I love that individuals have more ways of accessing the financial markets without coughing up exorbitant fees.\\n\\n**But access isn't everything.** We all have \\\"access\\\" to Las Vegas, but that doesn't make it a path to wealth creation. Likewise, if Robinhood traders use the app to merely gamble on 50/50 bets that a particular stock will go up or down, little wealth or value creation will result.\\n\\nDespite the app's name, Robinhood users for the most part redistribute among themselves the breadcrumbs left by the rest of the market.\\n\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}","html":"<!--kg-card-begin: markdown--><p>The recent Robinhood and Gamestop / Gamestock / Gamestonk fiasco shed a light on some of the complex financial infrastructure that undergirds equity trading.</p>\n<p>One mechanism, <a href=\"https://www.investopedia.com/terms/p/paymentoforderflow.asp\">payment for order flow</a>, plays a large role in how Robinhood provides commission-free trading to its users.</p>\n<p>Payment for order flow is often characterized as a shady practice that enables high-frequency traders (HFTs) to front-run Robinhood traders, siphoning off a sliver of profit as they do.</p>\n<p>I tend to think such concerns are overblown. From the perspective of an individual Robinhood trader, HFTs are of almost no importance, and their impact on trading profits is imperceptible, especially if one only transacts periodically.</p>\n<p>The truth is much more ironic.</p>\n<p>Robinhood traders get fleeced not by HFTs front-running milliseconds before their order hits but <strong>by other retail investors, days earlier.</strong></p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Robinhood Traders are Last to the Party\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Subscribe</span></button>\n</form>\n</section>\n<h2 id=\"thepartyendedfivedaysago\">The party ended *five* days ago</h2>\n<p>It turns out, <a href=\"https://papers.ssrn.com/abstract=3776874\">trading activity among Robinhood users lags the rest of the retail community by multiple days</a>, more than enough time to squeeze out any potential profits.</p>\n<p>A few charts demonstrate this dynamic. The graph below plots &quot;abnormal retail trading volume&quot; against the days before and after a stock peaks on WallStreetBets, the popular Reddit community, measured in terms of mentions. You can think of day zero as representing the day when mentions of a particular stock, say GME, peaked, with &quot;-5&quot; representing five days before, &quot;5&quot; representing five days after, and so on. &quot;Abnormal&quot; simply means retail trading activity relative to the prior 20-day moving average of retail trading volume for a particular stock.</p>\n<p>Notice how retail trading volume peaks about two days before WSB mentions peak:</p>\n<p><img src=\"/content/images/2021/03/image-20210222140135524.png\" alt=\"image-20210222140135524\" loading=\"lazy\"></p>\n<p>In other words, popularity on WallStreetBets lags the broader retail market. Stocks first get popular among non-Robinhood retail traders, and the subreddit subsequently picks this up, increasing how often the name is mentioned.</p>\n<p>Now let's look at Robinhood volume relative to WallStreetBets mentions. Robinhood activity peaks 2-3 days <em>after</em> WSB activity:</p>\n<p><img src=\"/content/images/2021/03/image-20210222140228350.png\" alt=\"image-20210222140228350\" loading=\"lazy\"></p>\n<p>All in all, that's a five day delay between when a stock begins to cool off among most retail investors and when Robinhood traders finally get the memo.</p>\n<p>By the time most Robinhood users actually trade, the party is over. And when the festivities end, so do the profits.</p>\n<h2 id=\"noisetraders\">Noise traders</h2>\n<p>I started the piece with my skepticism about the impact HFTs have on the profits of Robinhood traders. But if retail investors are taking advantage of market opportunities a full <em>five days</em> ahead of Robinhood traders, I'm much more inclined to think that could have an effect.</p>\n<p>The data proves this out. While recent research has shown that retail traders are in fact informed (measure as a positive correlation between retail trading activity and future stock returns), <strong>Robinhood activity has no positive relationship with future returns</strong>.</p>\n<p>The table below shows the results of a regression of future returns at 3, 5, and 20-day intervals on Robinhood user ownership and aggregate retail trading volume, along with a number of control variables. While the coefficient on retail volume is positive and statistically significant in all cases, suggesting that <em>non-Robinhood</em> retail trading volume predicts future returns, the coefficient on Robinhood ownership is negative and statistically insignificant, meaning that <strong>Robinhood activity has little relationship with future returns</strong>:</p>\n<p><img src=\"/content/images/2021/03/image-20210222140349147.png\" alt=\"image-20210222140349147\" loading=\"lazy\"></p>\n<p>This finding led the authors to conclude the following:</p>\n<blockquote>\n<p>Contrasting with recent evidence that retail traders are informed, we find that Robinhood ownership changes are unrelated with future returns, suggesting that zero-commission investors behave as noise traders.</p>\n</blockquote>\n<p>If case you don't read a ton of academic finance research, that's an extremely polite and understated way of saying: <strong>Robinhood trading is random</strong> (with respect to financial returns at least). In other words, there's no <em>there</em> there.</p>\n<p>And I should say: nothing about the app necessitates that. It's the behavior of the folks using it.</p>\n<h2 id=\"theresnosuchthingasfreealpha\">There's no such thing as free alpha</h2>\n<p>I think it's great that Robinhood exists. I love that individuals have more ways of accessing the financial markets without coughing up exorbitant fees.</p>\n<p><strong>But access isn't everything.</strong> We all have &quot;access&quot; to Las Vegas, but that doesn't make it a path to wealth creation. Likewise, if Robinhood traders use the app to merely gamble on 50/50 bets that a particular stock will go up or down, little wealth or value creation will result.</p>\n<p>Despite the app's name, Robinhood users for the most part redistribute among themselves the breadcrumbs left by the rest of the market.</p>\n<!--kg-card-end: markdown-->","comment_id":"603c97fd17b26d3ef80d665c","plaintext":"The recent Robinhood and Gamestop / Gamestock / Gamestonk fiasco shed a light on\nsome of the complex financial infrastructure that undergirds equity trading.\n\nOne mechanism, payment for order flow\n[https://www.investopedia.com/terms/p/paymentoforderflow.asp], plays a large\nrole in how Robinhood provides commission-free trading to its users.\n\nPayment for order flow is often characterized as a shady practice that enables\nhigh-frequency traders (HFTs) to front-run Robinhood traders, siphoning off a\nsliver of profit as they do.\n\nI tend to think such concerns are overblown. From the perspective of an\nindividual Robinhood trader, HFTs are of almost no importance, and their impact\non trading profits is imperceptible, especially if one only transacts\nperiodically.\n\nThe truth is much more ironic.\n\nRobinhood traders get fleeced not by HFTs front-running milliseconds before\ntheir order hits but by other retail investors, days earlier.\n\nReceive my next long-form post\nThoughtful analysis of the business and economics of tech\n\n\n\nSubscribeThe party ended *five* days ago\nIt turns out, trading activity among Robinhood users lags the rest of the\nretail\ncommunity by multiple days [https://papers.ssrn.com/abstract=3776874], more than\nenough time to squeeze out any potential profits.\n\nA few charts demonstrate this dynamic. The graph below plots \"abnormal retail\ntrading volume\" against the days before and after a stock peaks on\nWallStreetBets, the popular Reddit community, measured in terms of mentions. You\ncan think of day zero as representing the day when mentions of a particular\nstock, say GME, peaked, with \"-5\" representing five days before, \"5\"\nrepresenting five days after, and so on. \"Abnormal\" simply means retail trading\nactivity relative to the prior 20-day moving average of retail trading volume\nfor a particular stock.\n\nNotice how retail trading volume peaks about two days before WSB mentions peak:\n\n\n\nIn other words, popularity on WallStreetBets lags the broader retail market.\nStocks first get popular among non-Robinhood retail traders, and the subreddit\nsubsequently picks this up, increasing how often the name is mentioned.\n\nNow let's look at Robinhood volume relative to WallStreetBets mentions.\nRobinhood activity peaks 2-3 days after WSB activity:\n\n\n\nAll in all, that's a five day delay between when a stock begins to cool off\namong most retail investors and when Robinhood traders finally get the memo.\n\nBy the time most Robinhood users actually trade, the party is over. And when the\nfestivities end, so do the profits.\n\nNoise traders\nI started the piece with my skepticism about the impact HFTs have on the profits\nof Robinhood traders. But if retail investors are taking advantage of market\nopportunities a full five days ahead of Robinhood traders, I'm much more\ninclined to think that could have an effect.\n\nThe data proves this out. While recent research has shown that retail traders\nare in fact informed (measure as a positive correlation between retail trading\nactivity and future stock returns), Robinhood activity has no positive\nrelationship with future returns.\n\nThe table below shows the results of a regression of future returns at 3, 5, and\n20-day intervals on Robinhood user ownership and aggregate retail trading\nvolume, along with a number of control variables. While the coefficient on\nretail volume is positive and statistically significant in all cases, suggesting\nthat non-Robinhood retail trading volume predicts future returns, the\ncoefficient on Robinhood ownership is negative and statistically insignificant,\nmeaning that Robinhood activity has little relationship with future returns:\n\n\n\nThis finding led the authors to conclude the following:\n\n> Contrasting with recent evidence that retail traders are informed, we find that\nRobinhood ownership changes are unrelated with future returns, suggesting that\nzero-commission investors behave as noise traders.\n\n\nIf case you don't read a ton of academic finance research, that's an extremely\npolite and understated way of saying: Robinhood trading is random (with respect\nto financial returns at least). In other words, there's no there there.\n\nAnd I should say: nothing about the app necessitates that. It's the behavior of\nthe folks using it.\n\nThere's no such thing as free alpha\nI think it's great that Robinhood exists. I love that individuals have more ways\nof accessing the financial markets without coughing up exorbitant fees.\n\nBut access isn't everything. We all have \"access\" to Las Vegas, but that doesn't\nmake it a path to wealth creation. Likewise, if Robinhood traders use the app to\nmerely gamble on 50/50 bets that a particular stock will go up or down, little\nwealth or value creation will result.\n\nDespite the app's name, Robinhood users for the most part redistribute among\nthemselves the breadcrumbs left by the rest of the market.","feature_image":"__GHOST_URL__/content/images/2021/03/header.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2021-03-01T07:30:05.000Z","updated_at":"2021-03-01T08:21:38.000Z","published_at":"2021-03-01T08:10:00.000Z","custom_excerpt":"Robinhood traders get fleeced not by HFTs front-running milliseconds before their order hits but by other retail investors, days earlier.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"6046922f17b26d3ef80d6686","uuid":"b7059cd7-fc38-40ba-9f39-186dbd201c5f","title":"Four Challenges Facing Developer Productivity Startups","slug":"developer-productivity-challenges","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Developer productivity is undergoing a tectonic shift. New software development paradigms and tooling have accelerated the pace and productivity of modern software teams, quickening the \\\"shipping speed\\\" of new software.\\n\\nTo better understand the strategic landscape, my good friend and colleague, [Clio Smurro](https://www.linkedin.com/in/clio-smurro-31967b9/), and I interviewed founders and executives at next-generation software and infrastructure startups pushing the developer productivity frontier to get their thoughts and insights. They shared their views on:\\n\\n* [major industry trends](/developer-productivity-trends/),\\n* [top strategic priorities](/developer-productivity-strategic-priorities/), and\\n* biggest challenges and pain points (you are here)\\n\\nIn this third and final chapter, we share our findings on the **top challenges and pain points** facing developer productivity startups, including:\\n\\n* [Defining and planning for success](#definingandplanningforsuccess)\\n* [Integrating with other technologies](#integratingwithothertechnologies)\\n* [Building mindshare](#buildingmindshare)\\n* [Scaling developer relations](#scalingdeveloperrelations)\\n\\nSubscribe below to receive a nicely formatted PDF of our research!\\n\\n<section class=\\\"subscribe-form\\\">\\n                <h3 class=\\\"subscribe-form-title\\\">Receive a report with the full results</h3>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Your Email Address\\\" id=\\\"mce-EMAIL\\\" required>\\n<input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Four Challenges Facing Developer Productivity Startups\\\">\\n<input type=\\\"checkbox\\\" value=\\\"8\\\" name=\\\"group[78969][16]\\\" id=\\\"mce-group[78969]-78969-0\\\" style=\\\"display:none\\\" checked>\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Send Report âš¡</span></button>\\n</form>\\n            </section>\\n\\n## Defining and planning for success\\n\\nIt's common for developer productivity startups to take an engineering-first approach to development, where engineers take the lead on deciding what to build and when to build it, often leveraging personal intuitions as consumers of the product.\\n\\n> We don't have PMs. We decide what to build democratically. For each sprint, everyone comes up with an idea and we discuss â€” Manager, Developer Tools Startup\\n\\nWhile this works initially, without some sort of formalized product management function, teams soon hit a wall of confusion:\\n\\n>We emulated the Stripe model initially, focusing on engineering and growth. We don't have any PMs and so we don't have a clear framework for what to build â€” Manager, Developer Tools Startup\\n\\nIt's difficult to chart out long-term priorities and product roadmaps that support the business and revenue generation without product-minded individuals that can liaison between the technical and  commercial needs of the company.\\n\\nIf not tackled early, the more haphazard approach to product development can lead to a nonsensical multi-year roadmap of features no one can rigorously justify. With no North Star, new, potentially interesting ideas get shut out and ignored, for lack of space:\\n\\n>We know all the things we would like to build but our roadmap is full â€” Director, Data Science Startup\\n\\nTo where should developer productivity startups look for signals on what to build next? Customers, ideally. But it's not always that simple. Depending on the customer, signals can be more or less easy to detect. Self-serve users, for example, often silently churn, never indicating what drove the decision:\\n\\n>Self-serve users donâ€™t really tell you what they want, they just churn if they are unsatisfied â€” Manager, Developer Tools Startup\\n\\nTelemetry can drive insight into these churn patterns. The problem, however, is that many developer productivity tools are open source, so users typically have the ability to disable usage tracking, cutting off a vital information source. Many tools launch without any tracking in the first place, later causing a riot among their community when implementing telemetry  later.\\n\\nWhen we can collect user feedback, the next question arises â€” what to do with it? Should we first solve the problems of our loudest, most-vocal users? Should we focus on features that will help us close revenue in the near-term, perhaps even features that were specifically asked for by prospects? These are all valid questions with no easy answer.\\n\\n> This is a general problem that all dev tools companies run into... building features that specific customers need so that you can close the deal, without any holistic product management framework â€” Manager, Developer Tools Startup\\n\\nThough it's somewhat unknowable, developer productivity companies must grapple with and come to a view on the state of the product and whether it's ready for prime-time. One could always collect more data, but eventually you reach critical mass, and decisions can be made. Knowing when you've crossed this key milestone is critical. In other words, **what does success look like?**\\n\\nBefore reaching this point, it can be hard to tell whether you are on your way or marching in an entirely wrong direction product-wise:\\n\\n> How do you know when you know enough? How do you know when you've seen enough? Are you consensus or non-consensus? If you talk to the market and get 100 \\\"NO\\\"s, but 5 \\\"YES\\\"es, are you right about your idea or are you wrong? â€” Founder, Data Science Startup\\n\\n> How do you know if you need to change the product geometry? Also, how do you set the right KPIs? â€” Founder, Data Science Startup\\n\\nOnce product-market fit has been confidently achieved, it's time to pour fuel on the flame and scale up the team. As the team grows, engineering processes inevitably need to change to keep up. This is a key advantages of big tech organizations like Google or Amazon â€” they've built development processes that work at scale and have been doing so for some time. Developer productivity startups must also set themselves up for success:\\n\\n> Having an effective engineering organization will be a key advantage for us. Big companies like Google and Amazon donâ€™t just have innovative products. They also have innovative engineering processes â€” Founder, Application Infrastructure Startup\\n\\n## Integrating with other technologies\\n\\nFew developer productivity startups begin by building an end-to-end solution. Invariably, developer productivity products integrate with other parts of the software development toolchain.\\n\\n> The ML landscape is very messy; very noisy. For the different steps of the ML workflow, people will use the tools which integrate best with each other â€” Founder, Data Science Startup\\n\\n> Tools should follow UNIX philosophy of working well individually AND integrating with other tools well â€” Founder, Data Science Startup\\n\\nIt turns out, this is a different skill set from core product building, as many quickly find out:\\n\\n>Seamless integration to our partners technically is challenging. Weâ€™re trying to mitigate that by hiring very well-seasoned experts in each of the areas that weâ€™re growing â€” Founder, Data Science Startup\\n\\nIntegrating with other technologies often involves hiring that particular skill set into the organization. Though it's possible to build integration into tooling that the team doesn't have personal experience with, teams with first-hand knowledge of the complementary technology build the best integrations.\\n\\nIntegration is as much a technological problem as a people problem:\\n\\n>And the human aspect...if you make this huge effort, you want to make sure itâ€™s not just you entering their community, but them really integrating with yours â€” Founder, Data Science Startup\\n\\n> We need to go one by one in building integrations with each of these open-source communities â€” Founder, Data Science Startup\\n\\nCommunities already exist around the technologies with which developer productivity startups want to integrate. **Ingratiating** oneself with these communities is as important as **integrating** with their tooling.\\n\\n>Weâ€™re open source...we have to go into their databases and make sure we get buy-in from their existing developers â€” Founder, Data Science Startup\\n\\nGreasing the wheels in this way helps build goodwill among users of the target technologies, which can open doors. The core contributors of the target technology may make an architectural change on their end that makes your integration work much easier. Mutual trust and respect enable this kind of deep collaboration.\\n\\nFurther, people who've spent time in these other ecosystems bring a wealth of knowledge and insights, and can help fledgling developer productivity startups avoid the mistakes of their elders:\\n\\n>Our biggest challenge...we want to learn from each of these communities, and make sure that weâ€™re not repeating any mistakes â€” Founder, Data Science Startup\\n\\nDeveloper productivity startups can't afford to integrate with everything. Resources are limited, and integration work is often not a core competency. Startups must prioritize different integration options. Like sizing up the market opportunity for an entire company, startups should evaluate the market potential of complementary technologies:\\n\\n> Postgres and MySQLâ€¦.youâ€™ll cover ~70% of the market if you serve those two â€” Manager, Developer Tools Startup\\n\\nThe proliferation of developer tooling makes it harder make such decisions:\\n\\n>Addressable market for applications is large, but that makes it harder to focus. We need to make sure weâ€™re strategic in choosing which applications to prioritize â€” Founder, Application Infrastructure Startup\\n\\nEven among the tools that teams make an affirmative decision to integrate with, quality will vary meaningfully:\\n\\n>We serve like 45 different tools with integration. We do a really good job at serving a few key integrations â€” Manager, Developer Tools Startup\\n\\n## Building mindshare\\n\\nMindshare always precedes dollar share. Potential users make important architectural decisions early, requiring that they know about your technology well ahead of project intiation. Further, up-and-coming vendors must navigate any risk aversion or reticence towards new tooling, which is easier said than done:\\n\\n> Unless developers have the foresight to future proof, theyâ€™ll still be building with Postgres or some other older database. We often hear \\\"we'll start with MySQL and the move to you guys if we run into issues\\\" â€” Executive, Application Infrastructure Startup\\n\\nMethods for building mindshare are many and varied. Some are subtle. One answer that surprised us but makes complete sense in retrospect? Online classes. Online courses are a common learning vehicle for developers, and the content of most courses naturally tends to skew toward more mature technologies with larger userbases.\\n\\nThis is a sort of network effect whereby MongoDB developers, for example, benefit from the presence of other MongoDB developers because those same developers create an ecosystem of learning content around the database, flattening the learning curve:\\n\\n> An example of mindshare: online courses are teaching other databases, not ours â€” Executive, Application Infrastructure Startup\\n\\nIf the community isn't large enough, vendors themselves can help cover the gap. Tutorials and documentation help developers both learn how to use a tool but also learn of a tool in the first place. This is classic content marketing, with a developer-focused spin:\\n\\n> One challenge we face is improving our content. Writing tutorials, making videos, helping people use the product better â€” Manager, Developer Tools Startup\\n\\nMindshare has been especially difficult to build during the era of COVID-19, which has put a damper on in-person meetups and other ways in which upstart developer productivity companies build community and evangelism. Startups have rethought more formal events like conferences:\\n\\n>Evangelism has been stymied. The developer ecosystem is very meetup-driven, so thatâ€™s been cut â€” Executive, Application Security Startup\\n\\n>Conferences used to be really important, so weâ€™ll see how being virtual affects that â€” Developer Advocate, Application Infrastructure Startup\\n\\nThese events often serve as meaningful lead generation channels for developer productivity companies, leading to potential pipeline impacts:\\n\\n>We have a strong pipeline, but we need to make sure we keep that up, especially with everything being virtual now â€” Developer Advocate, Application Infrastructure Startup\\n\\nMindshare, once achieved, can act as powerful social proof. Though many developers claim to be driven by first principles in their design decisions and choice of tools, like all other homo sapiens, they care about what other people think. C-suite buyers care even more about the choices of their peers, so high quality customer logos definitely matter and should be displayed prominently:\\n\\n> We need more logos on our website. Getting named case studies is key for us. CIOs want to know that someone else is using this thing â€” Executive, Application Infrastructure Startup\\n\\n## Scaling developer relations\\n\\nSpeaking of building mindshare, developer relations (DevRel), also known as developer evangelism, developer advocacy, developer experience, etc. has emerged as an incredible way for developer productivity startups to ramp up mindshare and market awareness. Developers may not like being sold to, but they don't mind nerding out on cool tech with someone who speaks the same language:\\n\\n> Developers don't want to hear from sales folks. They don't want to be told what to do by their CIO. They want to be part of broader community, contribute, participate â€” Developer Advocate, Analytics Infrastructure Startup\\n\\n> Developers don't like being sold to, but they trust other developers â€” Developer Advocate, Application Infrastructure Startup\\n\\nSimple enough. But even if you're fully onboard with the idea of developer relations, doing it well is tough. To start, developer advocates are hard to come by. There just aren't many DevRel folks out there. The function is still relatively new, and career pipelines into the role have yet to fully materialize:\\n\\n> There is a serious lack of talent for DevRel. The ones who are good have already been hired. And the ones who could be good often have a hard time getting a foot in the door without a Twitter presence â€” Developer Advocate, Application Infrastructure Startup\\n\\n> DevRel is a hard spec to hire for. Technical folks are usually introverts. Extroverts are typically not technical â€” Developer Advocate, Analytics Infrastructure Startup\\n\\nKnowing who to hire among available candidates is also tricky. Companies often use social media following as an indicator of DevRel potential. But nearly of the DevRel professionals we spoke to cautioned *against* using social media following as an rubric for hiring developer advocates, with many saying it's entirely unnecessary for the job. Further, a large social media following is only helpful if it's backed up by **technical ability** and **credibility** with the developer community:\\n\\n> You don't really need to have a following to be good at DevRel. It's much more important to have street cred [with developers] â€” Developer Advocate, Analytics Infrastructure Startup\\n\\n> Social media is just one part of the toolbox. Further, social following in one area does not necessarily translate to another â€” Developer Advocate, Analytics Infrastructure Startup\\n\\n> There are lots of people with big social media following who no one actually likes â€” Developer Advocate, Application Infrastructure Startup (author note: ðŸ¤£)\\n\\nOnce the DevRel team begins to scale, questions emerge around where it fits within the broader org chart and hierarchy. This quickly gets contentious, and rarely do DevRel teams get to decide their own fate. This leads to bad situations where DevRel ends up in a part of the organization that isn't truly aligned with the practice, or worse, DevRel ends up straddling multiple functions:\\n\\n> Developer relations often gets stuck in the middle between different functions â€” Developer Advocate, Developer Tools Startup\\n\\n> In the past people didn't really understand DevRel. This lack of understanding drove poor outcomes. Future will be DevRel as its own organization â€” Developer Advocate, Application Infrastructure Startup\\n\\nPoor understanding of what DevRel is and its potential drives significant consternation. Again, because there are so few of these individuals and the function is so nascent, identifying enlightened executives and manager to lead these efforts is not trivial. With the right leadership, however, DevRel can thrive:\\n\\n> It's much better to have someone run the team who is involved in developer relations themselves. Having adamant buy in really helps â€” Developer Advocate, Application Infrastructure Startup\\n\\nBut inevitably the question emerges â€” how should we measure DevRel's successes (or failures for that matter)?\\n\\n> A lot of people don't know how to be effective in DevRel. You need analytics of some sort. You need to understand your funnel â€” Developer Advocate, Analytics Infrastructure Startup\\n\\nThis is another point of serious contention within the developer relations community. There are no standard metrics or KPIs in DevRel, leading to difficult conversations within the DevRel team and the rest of the company about whether and how DevRel is pulling its weight:\\n\\n> Metrics are tough. The metrics you end up measuring are often defined by the function you fall under â€” Developer Advocate, Developer Tools Startup\\n\\n> You will just be looked at as a cost center if you can't quantify this stuff. Really you are revenue generating, and you need to think of yourself that way â€” Developer Advocate, Analytics Infrastructure Startup\\n\\nThough there may not be a perfect KPI for DevRel that works for all companies and communities, in picking a set of metrics, it helps to keep in mind a \\\"North Star\\\" tied to the fundamental values and purpose of the business:\\n\\n> Define success by how you serve other developers. Are you giving them what they need so they can build? â€” Developer Advocate, Application Infrastructure Startup\\n\\n## Conclusion\\n\\nIt was amazing to speak to so many developer productivity founders and operators about the major trends shaping their businesses, their strategic priorities, and their biggest challenges and pain points as they've scaled up. The discussions around challenges were especially humbling. With all the glitz and glamour around startups and Silicon Valley these days, it's easy to forget the fundamentals â€” building a company in any sector is really, really hard, and developer productivity is no exception.\\n\\nWe hope you've enjoyed this series on developer productivity. We'd love to continue the conversation. If you are a developer productivity founder or operator who's resonated with any of these findings, let's chat!\\n\\n[Clio Smurro](https://www.linkedin.com/in/clio-smurro-31967b9/) & [Nnamdi Iregbulem](https://www.linkedin.com/in/nnamdiiregbulem/)\"}]],\"markups\":[],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}","html":"<!--kg-card-begin: markdown--><p>Developer productivity is undergoing a tectonic shift. New software development paradigms and tooling have accelerated the pace and productivity of modern software teams, quickening the &quot;shipping speed&quot; of new software.</p>\n<p>To better understand the strategic landscape, my good friend and colleague, <a href=\"https://www.linkedin.com/in/clio-smurro-31967b9/\">Clio Smurro</a>, and I interviewed founders and executives at next-generation software and infrastructure startups pushing the developer productivity frontier to get their thoughts and insights. They shared their views on:</p>\n<ul>\n<li><a href=\"/developer-productivity-trends/\">major industry trends</a>,</li>\n<li><a href=\"/developer-productivity-strategic-priorities/\">top strategic priorities</a>, and</li>\n<li>biggest challenges and pain points (you are here)</li>\n</ul>\n<p>In this third and final chapter, we share our findings on the <strong>top challenges and pain points</strong> facing developer productivity startups, including:</p>\n<ul>\n<li><a href=\"#definingandplanningforsuccess\">Defining and planning for success</a></li>\n<li><a href=\"#integratingwithothertechnologies\">Integrating with other technologies</a></li>\n<li><a href=\"#buildingmindshare\">Building mindshare</a></li>\n<li><a href=\"#scalingdeveloperrelations\">Scaling developer relations</a></li>\n</ul>\n<p>Subscribe below to receive a nicely formatted PDF of our research!</p>\n<section class=\"subscribe-form\">\n                <h3 class=\"subscribe-form-title\">Receive a report with the full results</h3>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Your Email Address\" id=\"mce-EMAIL\" required>\n<input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Four Challenges Facing Developer Productivity Startups\">\n<input type=\"checkbox\" value=\"8\" name=\"group[78969][16]\" id=\"mce-group[78969]-78969-0\" style=\"display:none\" checked>\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Send Report âš¡</span></button>\n</form>\n            </section>\n<h2 id=\"definingandplanningforsuccess\">Defining and planning for success</h2>\n<p>It's common for developer productivity startups to take an engineering-first approach to development, where engineers take the lead on deciding what to build and when to build it, often leveraging personal intuitions as consumers of the product.</p>\n<blockquote>\n<p>We don't have PMs. We decide what to build democratically. For each sprint, everyone comes up with an idea and we discuss â€” Manager, Developer Tools Startup</p>\n</blockquote>\n<p>While this works initially, without some sort of formalized product management function, teams soon hit a wall of confusion:</p>\n<blockquote>\n<p>We emulated the Stripe model initially, focusing on engineering and growth. We don't have any PMs and so we don't have a clear framework for what to build â€” Manager, Developer Tools Startup</p>\n</blockquote>\n<p>It's difficult to chart out long-term priorities and product roadmaps that support the business and revenue generation without product-minded individuals that can liaison between the technical and  commercial needs of the company.</p>\n<p>If not tackled early, the more haphazard approach to product development can lead to a nonsensical multi-year roadmap of features no one can rigorously justify. With no North Star, new, potentially interesting ideas get shut out and ignored, for lack of space:</p>\n<blockquote>\n<p>We know all the things we would like to build but our roadmap is full â€” Director, Data Science Startup</p>\n</blockquote>\n<p>To where should developer productivity startups look for signals on what to build next? Customers, ideally. But it's not always that simple. Depending on the customer, signals can be more or less easy to detect. Self-serve users, for example, often silently churn, never indicating what drove the decision:</p>\n<blockquote>\n<p>Self-serve users donâ€™t really tell you what they want, they just churn if they are unsatisfied â€” Manager, Developer Tools Startup</p>\n</blockquote>\n<p>Telemetry can drive insight into these churn patterns. The problem, however, is that many developer productivity tools are open source, so users typically have the ability to disable usage tracking, cutting off a vital information source. Many tools launch without any tracking in the first place, later causing a riot among their community when implementing telemetry  later.</p>\n<p>When we can collect user feedback, the next question arises â€” what to do with it? Should we first solve the problems of our loudest, most-vocal users? Should we focus on features that will help us close revenue in the near-term, perhaps even features that were specifically asked for by prospects? These are all valid questions with no easy answer.</p>\n<blockquote>\n<p>This is a general problem that all dev tools companies run into... building features that specific customers need so that you can close the deal, without any holistic product management framework â€” Manager, Developer Tools Startup</p>\n</blockquote>\n<p>Though it's somewhat unknowable, developer productivity companies must grapple with and come to a view on the state of the product and whether it's ready for prime-time. One could always collect more data, but eventually you reach critical mass, and decisions can be made. Knowing when you've crossed this key milestone is critical. In other words, <strong>what does success look like?</strong></p>\n<p>Before reaching this point, it can be hard to tell whether you are on your way or marching in an entirely wrong direction product-wise:</p>\n<blockquote>\n<p>How do you know when you know enough? How do you know when you've seen enough? Are you consensus or non-consensus? If you talk to the market and get 100 &quot;NO&quot;s, but 5 &quot;YES&quot;es, are you right about your idea or are you wrong? â€” Founder, Data Science Startup</p>\n</blockquote>\n<blockquote>\n<p>How do you know if you need to change the product geometry? Also, how do you set the right KPIs? â€” Founder, Data Science Startup</p>\n</blockquote>\n<p>Once product-market fit has been confidently achieved, it's time to pour fuel on the flame and scale up the team. As the team grows, engineering processes inevitably need to change to keep up. This is a key advantages of big tech organizations like Google or Amazon â€” they've built development processes that work at scale and have been doing so for some time. Developer productivity startups must also set themselves up for success:</p>\n<blockquote>\n<p>Having an effective engineering organization will be a key advantage for us. Big companies like Google and Amazon donâ€™t just have innovative products. They also have innovative engineering processes â€” Founder, Application Infrastructure Startup</p>\n</blockquote>\n<h2 id=\"integratingwithothertechnologies\">Integrating with other technologies</h2>\n<p>Few developer productivity startups begin by building an end-to-end solution. Invariably, developer productivity products integrate with other parts of the software development toolchain.</p>\n<blockquote>\n<p>The ML landscape is very messy; very noisy. For the different steps of the ML workflow, people will use the tools which integrate best with each other â€” Founder, Data Science Startup</p>\n</blockquote>\n<blockquote>\n<p>Tools should follow UNIX philosophy of working well individually AND integrating with other tools well â€” Founder, Data Science Startup</p>\n</blockquote>\n<p>It turns out, this is a different skill set from core product building, as many quickly find out:</p>\n<blockquote>\n<p>Seamless integration to our partners technically is challenging. Weâ€™re trying to mitigate that by hiring very well-seasoned experts in each of the areas that weâ€™re growing â€” Founder, Data Science Startup</p>\n</blockquote>\n<p>Integrating with other technologies often involves hiring that particular skill set into the organization. Though it's possible to build integration into tooling that the team doesn't have personal experience with, teams with first-hand knowledge of the complementary technology build the best integrations.</p>\n<p>Integration is as much a technological problem as a people problem:</p>\n<blockquote>\n<p>And the human aspect...if you make this huge effort, you want to make sure itâ€™s not just you entering their community, but them really integrating with yours â€” Founder, Data Science Startup</p>\n</blockquote>\n<blockquote>\n<p>We need to go one by one in building integrations with each of these open-source communities â€” Founder, Data Science Startup</p>\n</blockquote>\n<p>Communities already exist around the technologies with which developer productivity startups want to integrate. <strong>Ingratiating</strong> oneself with these communities is as important as <strong>integrating</strong> with their tooling.</p>\n<blockquote>\n<p>Weâ€™re open source...we have to go into their databases and make sure we get buy-in from their existing developers â€” Founder, Data Science Startup</p>\n</blockquote>\n<p>Greasing the wheels in this way helps build goodwill among users of the target technologies, which can open doors. The core contributors of the target technology may make an architectural change on their end that makes your integration work much easier. Mutual trust and respect enable this kind of deep collaboration.</p>\n<p>Further, people who've spent time in these other ecosystems bring a wealth of knowledge and insights, and can help fledgling developer productivity startups avoid the mistakes of their elders:</p>\n<blockquote>\n<p>Our biggest challenge...we want to learn from each of these communities, and make sure that weâ€™re not repeating any mistakes â€” Founder, Data Science Startup</p>\n</blockquote>\n<p>Developer productivity startups can't afford to integrate with everything. Resources are limited, and integration work is often not a core competency. Startups must prioritize different integration options. Like sizing up the market opportunity for an entire company, startups should evaluate the market potential of complementary technologies:</p>\n<blockquote>\n<p>Postgres and MySQLâ€¦.youâ€™ll cover ~70% of the market if you serve those two â€” Manager, Developer Tools Startup</p>\n</blockquote>\n<p>The proliferation of developer tooling makes it harder make such decisions:</p>\n<blockquote>\n<p>Addressable market for applications is large, but that makes it harder to focus. We need to make sure weâ€™re strategic in choosing which applications to prioritize â€” Founder, Application Infrastructure Startup</p>\n</blockquote>\n<p>Even among the tools that teams make an affirmative decision to integrate with, quality will vary meaningfully:</p>\n<blockquote>\n<p>We serve like 45 different tools with integration. We do a really good job at serving a few key integrations â€” Manager, Developer Tools Startup</p>\n</blockquote>\n<h2 id=\"buildingmindshare\">Building mindshare</h2>\n<p>Mindshare always precedes dollar share. Potential users make important architectural decisions early, requiring that they know about your technology well ahead of project intiation. Further, up-and-coming vendors must navigate any risk aversion or reticence towards new tooling, which is easier said than done:</p>\n<blockquote>\n<p>Unless developers have the foresight to future proof, theyâ€™ll still be building with Postgres or some other older database. We often hear &quot;we'll start with MySQL and the move to you guys if we run into issues&quot; â€” Executive, Application Infrastructure Startup</p>\n</blockquote>\n<p>Methods for building mindshare are many and varied. Some are subtle. One answer that surprised us but makes complete sense in retrospect? Online classes. Online courses are a common learning vehicle for developers, and the content of most courses naturally tends to skew toward more mature technologies with larger userbases.</p>\n<p>This is a sort of network effect whereby MongoDB developers, for example, benefit from the presence of other MongoDB developers because those same developers create an ecosystem of learning content around the database, flattening the learning curve:</p>\n<blockquote>\n<p>An example of mindshare: online courses are teaching other databases, not ours â€” Executive, Application Infrastructure Startup</p>\n</blockquote>\n<p>If the community isn't large enough, vendors themselves can help cover the gap. Tutorials and documentation help developers both learn how to use a tool but also learn of a tool in the first place. This is classic content marketing, with a developer-focused spin:</p>\n<blockquote>\n<p>One challenge we face is improving our content. Writing tutorials, making videos, helping people use the product better â€” Manager, Developer Tools Startup</p>\n</blockquote>\n<p>Mindshare has been especially difficult to build during the era of COVID-19, which has put a damper on in-person meetups and other ways in which upstart developer productivity companies build community and evangelism. Startups have rethought more formal events like conferences:</p>\n<blockquote>\n<p>Evangelism has been stymied. The developer ecosystem is very meetup-driven, so thatâ€™s been cut â€” Executive, Application Security Startup</p>\n</blockquote>\n<blockquote>\n<p>Conferences used to be really important, so weâ€™ll see how being virtual affects that â€” Developer Advocate, Application Infrastructure Startup</p>\n</blockquote>\n<p>These events often serve as meaningful lead generation channels for developer productivity companies, leading to potential pipeline impacts:</p>\n<blockquote>\n<p>We have a strong pipeline, but we need to make sure we keep that up, especially with everything being virtual now â€” Developer Advocate, Application Infrastructure Startup</p>\n</blockquote>\n<p>Mindshare, once achieved, can act as powerful social proof. Though many developers claim to be driven by first principles in their design decisions and choice of tools, like all other homo sapiens, they care about what other people think. C-suite buyers care even more about the choices of their peers, so high quality customer logos definitely matter and should be displayed prominently:</p>\n<blockquote>\n<p>We need more logos on our website. Getting named case studies is key for us. CIOs want to know that someone else is using this thing â€” Executive, Application Infrastructure Startup</p>\n</blockquote>\n<h2 id=\"scalingdeveloperrelations\">Scaling developer relations</h2>\n<p>Speaking of building mindshare, developer relations (DevRel), also known as developer evangelism, developer advocacy, developer experience, etc. has emerged as an incredible way for developer productivity startups to ramp up mindshare and market awareness. Developers may not like being sold to, but they don't mind nerding out on cool tech with someone who speaks the same language:</p>\n<blockquote>\n<p>Developers don't want to hear from sales folks. They don't want to be told what to do by their CIO. They want to be part of broader community, contribute, participate â€” Developer Advocate, Analytics Infrastructure Startup</p>\n</blockquote>\n<blockquote>\n<p>Developers don't like being sold to, but they trust other developers â€” Developer Advocate, Application Infrastructure Startup</p>\n</blockquote>\n<p>Simple enough. But even if you're fully onboard with the idea of developer relations, doing it well is tough. To start, developer advocates are hard to come by. There just aren't many DevRel folks out there. The function is still relatively new, and career pipelines into the role have yet to fully materialize:</p>\n<blockquote>\n<p>There is a serious lack of talent for DevRel. The ones who are good have already been hired. And the ones who could be good often have a hard time getting a foot in the door without a Twitter presence â€” Developer Advocate, Application Infrastructure Startup</p>\n</blockquote>\n<blockquote>\n<p>DevRel is a hard spec to hire for. Technical folks are usually introverts. Extroverts are typically not technical â€” Developer Advocate, Analytics Infrastructure Startup</p>\n</blockquote>\n<p>Knowing who to hire among available candidates is also tricky. Companies often use social media following as an indicator of DevRel potential. But nearly of the DevRel professionals we spoke to cautioned <em>against</em> using social media following as an rubric for hiring developer advocates, with many saying it's entirely unnecessary for the job. Further, a large social media following is only helpful if it's backed up by <strong>technical ability</strong> and <strong>credibility</strong> with the developer community:</p>\n<blockquote>\n<p>You don't really need to have a following to be good at DevRel. It's much more important to have street cred [with developers] â€” Developer Advocate, Analytics Infrastructure Startup</p>\n</blockquote>\n<blockquote>\n<p>Social media is just one part of the toolbox. Further, social following in one area does not necessarily translate to another â€” Developer Advocate, Analytics Infrastructure Startup</p>\n</blockquote>\n<blockquote>\n<p>There are lots of people with big social media following who no one actually likes â€” Developer Advocate, Application Infrastructure Startup (author note: ðŸ¤£)</p>\n</blockquote>\n<p>Once the DevRel team begins to scale, questions emerge around where it fits within the broader org chart and hierarchy. This quickly gets contentious, and rarely do DevRel teams get to decide their own fate. This leads to bad situations where DevRel ends up in a part of the organization that isn't truly aligned with the practice, or worse, DevRel ends up straddling multiple functions:</p>\n<blockquote>\n<p>Developer relations often gets stuck in the middle between different functions â€” Developer Advocate, Developer Tools Startup</p>\n</blockquote>\n<blockquote>\n<p>In the past people didn't really understand DevRel. This lack of understanding drove poor outcomes. Future will be DevRel as its own organization â€” Developer Advocate, Application Infrastructure Startup</p>\n</blockquote>\n<p>Poor understanding of what DevRel is and its potential drives significant consternation. Again, because there are so few of these individuals and the function is so nascent, identifying enlightened executives and manager to lead these efforts is not trivial. With the right leadership, however, DevRel can thrive:</p>\n<blockquote>\n<p>It's much better to have someone run the team who is involved in developer relations themselves. Having adamant buy in really helps â€” Developer Advocate, Application Infrastructure Startup</p>\n</blockquote>\n<p>But inevitably the question emerges â€” how should we measure DevRel's successes (or failures for that matter)?</p>\n<blockquote>\n<p>A lot of people don't know how to be effective in DevRel. You need analytics of some sort. You need to understand your funnel â€” Developer Advocate, Analytics Infrastructure Startup</p>\n</blockquote>\n<p>This is another point of serious contention within the developer relations community. There are no standard metrics or KPIs in DevRel, leading to difficult conversations within the DevRel team and the rest of the company about whether and how DevRel is pulling its weight:</p>\n<blockquote>\n<p>Metrics are tough. The metrics you end up measuring are often defined by the function you fall under â€” Developer Advocate, Developer Tools Startup</p>\n</blockquote>\n<blockquote>\n<p>You will just be looked at as a cost center if you can't quantify this stuff. Really you are revenue generating, and you need to think of yourself that way â€” Developer Advocate, Analytics Infrastructure Startup</p>\n</blockquote>\n<p>Though there may not be a perfect KPI for DevRel that works for all companies and communities, in picking a set of metrics, it helps to keep in mind a &quot;North Star&quot; tied to the fundamental values and purpose of the business:</p>\n<blockquote>\n<p>Define success by how you serve other developers. Are you giving them what they need so they can build? â€” Developer Advocate, Application Infrastructure Startup</p>\n</blockquote>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>It was amazing to speak to so many developer productivity founders and operators about the major trends shaping their businesses, their strategic priorities, and their biggest challenges and pain points as they've scaled up. The discussions around challenges were especially humbling. With all the glitz and glamour around startups and Silicon Valley these days, it's easy to forget the fundamentals â€” building a company in any sector is really, really hard, and developer productivity is no exception.</p>\n<p>We hope you've enjoyed this series on developer productivity. We'd love to continue the conversation. If you are a developer productivity founder or operator who's resonated with any of these findings, let's chat!</p>\n<p><a href=\"https://www.linkedin.com/in/clio-smurro-31967b9/\">Clio Smurro</a> &amp; <a href=\"https://www.linkedin.com/in/nnamdiiregbulem/\">Nnamdi Iregbulem</a></p>\n<!--kg-card-end: markdown-->","comment_id":"6046922f17b26d3ef80d6686","plaintext":"Developer productivity is undergoing a tectonic shift. New software development\nparadigms and tooling have accelerated the pace and productivity of modern\nsoftware teams, quickening the \"shipping speed\" of new software.\n\nTo better understand the strategic landscape, my good friend and colleague, \nClio\nSmurro [https://www.linkedin.com/in/clio-smurro-31967b9/], and I interviewed\nfounders and executives at next-generation software and infrastructure startups\npushing the developer productivity frontier to get their thoughts and insights.\nThey shared their views on:\n\n * major industry trends [/developer-productivity-trends/],\n * top strategic priorities [/developer-productivity-strategic-priorities/], and\n * biggest challenges and pain points (you are here)\n\nIn this third and final chapter, we share our findings on the top challenges and\npain points facing developer productivity startups, including:\n\n * Defining and planning for success\n * Integrating with other technologies\n * Building mindshare\n * Scaling developer relations\n\nSubscribe below to receive a nicely formatted PDF of our research!\n\nReceive a report with the full results\n\n\nSend Report âš¡ Defining and planning for success\nIt's common for developer productivity startups to take an engineering-first\napproach to development, where engineers take the lead on deciding what to build\nand when to build it, often leveraging personal intuitions as consumers of the\nproduct.\n\n> We don't have PMs. We decide what to build democratically. For each sprint,\neveryone comes up with an idea and we discuss â€” Manager, Developer Tools Startup\n\n\nWhile this works initially, without some sort of formalized product management\nfunction, teams soon hit a wall of confusion:\n\n> We emulated the Stripe model initially, focusing on engineering and growth. We\ndon't have any PMs and so we don't have a clear framework for what to build â€”\nManager, Developer Tools Startup\n\n\nIt's difficult to chart out long-term priorities and product roadmaps that\nsupport the business and revenue generation without product-minded individuals\nthat can liaison between the technical and commercial needs of the company.\n\nIf not tackled early, the more haphazard approach to product development can\nlead to a nonsensical multi-year roadmap of features no one can rigorously\njustify. With no North Star, new, potentially interesting ideas get shut out and\nignored, for lack of space:\n\n> We know all the things we would like to build but our roadmap is full â€”\nDirector, Data Science Startup\n\n\nTo where should developer productivity startups look for signals on what to\nbuild next? Customers, ideally. But it's not always that simple. Depending on\nthe customer, signals can be more or less easy to detect. Self-serve users, for\nexample, often silently churn, never indicating what drove the decision:\n\n> Self-serve users donâ€™t really tell you what they want, they just churn if they\nare unsatisfied â€” Manager, Developer Tools Startup\n\n\nTelemetry can drive insight into these churn patterns. The problem, however, is\nthat many developer productivity tools are open source, so users typically have\nthe ability to disable usage tracking, cutting off a vital information source.\nMany tools launch without any tracking in the first place, later causing a riot\namong their community when implementing telemetry later.\n\nWhen we can collect user feedback, the next question arises â€” what to do with\nit? Should we first solve the problems of our loudest, most-vocal users? Should\nwe focus on features that will help us close revenue in the near-term, perhaps\neven features that were specifically asked for by prospects? These are all valid\nquestions with no easy answer.\n\n> This is a general problem that all dev tools companies run into... building\nfeatures that specific customers need so that you can close the deal, without\nany holistic product management framework â€” Manager, Developer Tools Startup\n\n\nThough it's somewhat unknowable, developer productivity companies must grapple\nwith and come to a view on the state of the product and whether it's ready for\nprime-time. One could always collect more data, but eventually you reach\ncritical mass, and decisions can be made. Knowing when you've crossed this key\nmilestone is critical. In other words, what does success look like?\n\nBefore reaching this point, it can be hard to tell whether you are on your way\nor marching in an entirely wrong direction product-wise:\n\n> How do you know when you know enough? How do you know when you've seen enough?\nAre you consensus or non-consensus? If you talk to the market and get 100 \"NO\"s,\nbut 5 \"YES\"es, are you right about your idea or are you wrong? â€” Founder, Data\nScience Startup\n\n\n> How do you know if you need to change the product geometry? Also, how do you set\nthe right KPIs? â€” Founder, Data Science Startup\n\n\nOnce product-market fit has been confidently achieved, it's time to pour fuel on\nthe flame and scale up the team. As the team grows, engineering processes\ninevitably need to change to keep up. This is a key advantages of big tech\norganizations like Google or Amazon â€” they've built development processes that\nwork at scale and have been doing so for some time. Developer productivity\nstartups must also set themselves up for success:\n\n> Having an effective engineering organization will be a key advantage for us. Big\ncompanies like Google and Amazon donâ€™t just have innovative products. They also\nhave innovative engineering processes â€” Founder, Application Infrastructure\nStartup\n\n\nIntegrating with other technologies\nFew developer productivity startups begin by building an end-to-end solution.\nInvariably, developer productivity products integrate with other parts of the\nsoftware development toolchain.\n\n> The ML landscape is very messy; very noisy. For the different steps of the ML\nworkflow, people will use the tools which integrate best with each other â€”\nFounder, Data Science Startup\n\n\n> Tools should follow UNIX philosophy of working well individually AND integrating\nwith other tools well â€” Founder, Data Science Startup\n\n\nIt turns out, this is a different skill set from core product building, as many\nquickly find out:\n\n> Seamless integration to our partners technically is challenging. Weâ€™re trying to\nmitigate that by hiring very well-seasoned experts in each of the areas that\nweâ€™re growing â€” Founder, Data Science Startup\n\n\nIntegrating with other technologies often involves hiring that particular skill\nset into the organization. Though it's possible to build integration into\ntooling that the team doesn't have personal experience with, teams with\nfirst-hand knowledge of the complementary technology build the best\nintegrations.\n\nIntegration is as much a technological problem as a people problem:\n\n> And the human aspect...if you make this huge effort, you want to make sure itâ€™s\nnot just you entering their community, but them really integrating with yours â€”\nFounder, Data Science Startup\n\n\n> We need to go one by one in building integrations with each of these open-source\ncommunities â€” Founder, Data Science Startup\n\n\nCommunities already exist around the technologies with which developer\nproductivity startups want to integrate. Ingratiating oneself with these\ncommunities is as important as integrating with their tooling.\n\n> Weâ€™re open source...we have to go into their databases and make sure we get\nbuy-in from their existing developers â€” Founder, Data Science Startup\n\n\nGreasing the wheels in this way helps build goodwill among users of the target\ntechnologies, which can open doors. The core contributors of the target\ntechnology may make an architectural change on their end that makes your\nintegration work much easier. Mutual trust and respect enable this kind of deep\ncollaboration.\n\nFurther, people who've spent time in these other ecosystems bring a wealth of\nknowledge and insights, and can help fledgling developer productivity startups\navoid the mistakes of their elders:\n\n> Our biggest challenge...we want to learn from each of these communities, and\nmake sure that weâ€™re not repeating any mistakes â€” Founder, Data Science Startup\n\n\nDeveloper productivity startups can't afford to integrate with everything.\nResources are limited, and integration work is often not a core competency.\nStartups must prioritize different integration options. Like sizing up the\nmarket opportunity for an entire company, startups should evaluate the market\npotential of complementary technologies:\n\n> Postgres and MySQLâ€¦.youâ€™ll cover ~70% of the market if you serve those two â€”\nManager, Developer Tools Startup\n\n\nThe proliferation of developer tooling makes it harder make such decisions:\n\n> Addressable market for applications is large, but that makes it harder to focus.\nWe need to make sure weâ€™re strategic in choosing which applications to\nprioritize â€” Founder, Application Infrastructure Startup\n\n\nEven among the tools that teams make an affirmative decision to integrate with,\nquality will vary meaningfully:\n\n> We serve like 45 different tools with integration. We do a really good job at\nserving a few key integrations â€” Manager, Developer Tools Startup\n\n\nBuilding mindshare\nMindshare always precedes dollar share. Potential users make important\narchitectural decisions early, requiring that they know about your technology\nwell ahead of project intiation. Further, up-and-coming vendors must navigate\nany risk aversion or reticence towards new tooling, which is easier said than\ndone:\n\n> Unless developers have the foresight to future proof, theyâ€™ll still be building\nwith Postgres or some other older database. We often hear \"we'll start with\nMySQL and the move to you guys if we run into issues\" â€” Executive, Application\nInfrastructure Startup\n\n\nMethods for building mindshare are many and varied. Some are subtle. One answer\nthat surprised us but makes complete sense in retrospect? Online classes. Online\ncourses are a common learning vehicle for developers, and the content of most\ncourses naturally tends to skew toward more mature technologies with larger\nuserbases.\n\nThis is a sort of network effect whereby MongoDB developers, for example,\nbenefit from the presence of other MongoDB developers because those same\ndevelopers create an ecosystem of learning content around the database,\nflattening the learning curve:\n\n> An example of mindshare: online courses are teaching other databases, not ours â€”\nExecutive, Application Infrastructure Startup\n\n\nIf the community isn't large enough, vendors themselves can help cover the gap.\nTutorials and documentation help developers both learn how to use a tool but\nalso learn of a tool in the first place. This is classic content marketing, with\na developer-focused spin:\n\n> One challenge we face is improving our content. Writing tutorials, making\nvideos, helping people use the product better â€” Manager, Developer Tools Startup\n\n\nMindshare has been especially difficult to build during the era of COVID-19,\nwhich has put a damper on in-person meetups and other ways in which upstart\ndeveloper productivity companies build community and evangelism. Startups have\nrethought more formal events like conferences:\n\n> Evangelism has been stymied. The developer ecosystem is very meetup-driven, so\nthatâ€™s been cut â€” Executive, Application Security Startup\n\n\n> Conferences used to be really important, so weâ€™ll see how being virtual affects\nthat â€” Developer Advocate, Application Infrastructure Startup\n\n\nThese events often serve as meaningful lead generation channels for developer\nproductivity companies, leading to potential pipeline impacts:\n\n> We have a strong pipeline, but we need to make sure we keep that up, especially\nwith everything being virtual now â€” Developer Advocate, Application\nInfrastructure Startup\n\n\nMindshare, once achieved, can act as powerful social proof. Though many\ndevelopers claim to be driven by first principles in their design decisions and\nchoice of tools, like all other homo sapiens, they care about what other people\nthink. C-suite buyers care even more about the choices of their peers, so high\nquality customer logos definitely matter and should be displayed prominently:\n\n> We need more logos on our website. Getting named case studies is key for us.\nCIOs want to know that someone else is using this thing â€” Executive, Application\nInfrastructure Startup\n\n\nScaling developer relations\nSpeaking of building mindshare, developer relations (DevRel), also known as\ndeveloper evangelism, developer advocacy, developer experience, etc. has emerged\nas an incredible way for developer productivity startups to ramp up mindshare\nand market awareness. Developers may not like being sold to, but they don't mind\nnerding out on cool tech with someone who speaks the same language:\n\n> Developers don't want to hear from sales folks. They don't want to be told what\nto do by their CIO. They want to be part of broader community, contribute,\nparticipate â€” Developer Advocate, Analytics Infrastructure Startup\n\n\n> Developers don't like being sold to, but they trust other developers â€” Developer\nAdvocate, Application Infrastructure Startup\n\n\nSimple enough. But even if you're fully onboard with the idea of developer\nrelations, doing it well is tough. To start, developer advocates are hard to\ncome by. There just aren't many DevRel folks out there. The function is still\nrelatively new, and career pipelines into the role have yet to fully\nmaterialize:\n\n> There is a serious lack of talent for DevRel. The ones who are good have already\nbeen hired. And the ones who could be good often have a hard time getting a foot\nin the door without a Twitter presence â€” Developer Advocate, Application\nInfrastructure Startup\n\n\n> DevRel is a hard spec to hire for. Technical folks are usually introverts.\nExtroverts are typically not technical â€” Developer Advocate, Analytics\nInfrastructure Startup\n\n\nKnowing who to hire among available candidates is also tricky. Companies often\nuse social media following as an indicator of DevRel potential. But nearly of\nthe DevRel professionals we spoke to cautioned against using social media\nfollowing as an rubric for hiring developer advocates, with many saying it's\nentirely unnecessary for the job. Further, a large social media following is\nonly helpful if it's backed up by technical ability and credibility with the\ndeveloper community:\n\n> You don't really need to have a following to be good at DevRel. It's much more\nimportant to have street cred [with developers] â€” Developer Advocate, Analytics\nInfrastructure Startup\n\n\n> Social media is just one part of the toolbox. Further, social following in one\narea does not necessarily translate to another â€” Developer Advocate, Analytics\nInfrastructure Startup\n\n\n> There are lots of people with big social media following who no one actually\nlikes â€” Developer Advocate, Application Infrastructure Startup (author note: ðŸ¤£)\n\n\nOnce the DevRel team begins to scale, questions emerge around where it fits\nwithin the broader org chart and hierarchy. This quickly gets contentious, and\nrarely do DevRel teams get to decide their own fate. This leads to bad\nsituations where DevRel ends up in a part of the organization that isn't truly\naligned with the practice, or worse, DevRel ends up straddling multiple\nfunctions:\n\n> Developer relations often gets stuck in the middle between different functions â€”\nDeveloper Advocate, Developer Tools Startup\n\n\n> In the past people didn't really understand DevRel. This lack of understanding\ndrove poor outcomes. Future will be DevRel as its own organization â€” Developer\nAdvocate, Application Infrastructure Startup\n\n\nPoor understanding of what DevRel is and its potential drives significant\nconsternation. Again, because there are so few of these individuals and the\nfunction is so nascent, identifying enlightened executives and manager to lead\nthese efforts is not trivial. With the right leadership, however, DevRel can\nthrive:\n\n> It's much better to have someone run the team who is involved in developer\nrelations themselves. Having adamant buy in really helps â€” Developer Advocate,\nApplication Infrastructure Startup\n\n\nBut inevitably the question emerges â€” how should we measure DevRel's successes\n(or failures for that matter)?\n\n> A lot of people don't know how to be effective in DevRel. You need analytics of\nsome sort. You need to understand your funnel â€” Developer Advocate, Analytics\nInfrastructure Startup\n\n\nThis is another point of serious contention within the developer relations\ncommunity. There are no standard metrics or KPIs in DevRel, leading to difficult\nconversations within the DevRel team and the rest of the company about whether\nand how DevRel is pulling its weight:\n\n> Metrics are tough. The metrics you end up measuring are often defined by the\nfunction you fall under â€” Developer Advocate, Developer Tools Startup\n\n\n> You will just be looked at as a cost center if you can't quantify this stuff.\nReally you are revenue generating, and you need to think of yourself that way â€”\nDeveloper Advocate, Analytics Infrastructure Startup\n\n\nThough there may not be a perfect KPI for DevRel that works for all companies\nand communities, in picking a set of metrics, it helps to keep in mind a \"North\nStar\" tied to the fundamental values and purpose of the business:\n\n> Define success by how you serve other developers. Are you giving them what they\nneed so they can build? â€” Developer Advocate, Application Infrastructure Startup\n\n\nConclusion\nIt was amazing to speak to so many developer productivity founders and operators\nabout the major trends shaping their businesses, their strategic priorities, and\ntheir biggest challenges and pain points as they've scaled up. The discussions\naround challenges were especially humbling. With all the glitz and glamour\naround startups and Silicon Valley these days, it's easy to forget the\nfundamentals â€” building a company in any sector is really, really hard, and\ndeveloper productivity is no exception.\n\nWe hope you've enjoyed this series on developer productivity. We'd love to\ncontinue the conversation. If you are a developer productivity founder or\noperator who's resonated with any of these findings, let's chat!\n\nClio Smurro [https://www.linkedin.com/in/clio-smurro-31967b9/] & Nnamdi\nIregbulem [https://www.linkedin.com/in/nnamdiiregbulem/]","feature_image":"__GHOST_URL__/content/images/2021/03/header-1.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2021-03-08T21:07:59.000Z","updated_at":"2021-03-11T08:05:00.000Z","published_at":"2021-03-11T08:05:00.000Z","custom_excerpt":"The biggest challenges facing developer productivity startups today","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"609990d417b26d3ef80d66da","uuid":"e1b8c197-5cf0-4890-905f-2a971fc5fa60","title":"Why Developers Love Redpanda","slug":"why-developers-love-redpanda","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Why Developers Love Redpanda\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Subscribe</span></button>\\n</form>\\n</section>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/05/No_JVM__Redpanda_vectorized_img.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/05/0_rzLnKt-j8CZ6Ezd6.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/05/The_future_of_streaming_Redpanda_vectorized_img.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/05/Hold_my_core_Redpanda_vectorized_img.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/05/End-to-End_Latency_Percentiles_Redpanda_vectorized_img.png\"}],[\"embed\",{\"url\":\"https://twitter.com/JordanALewis/status/1354149159755010056\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">Congratulations to <a href=\\\"https://twitter.com/emaxerrno?ref_src=twsrc%5Etfw\\\">@emaxerrno</a> and the <a href=\\\"https://twitter.com/VectorizedIO?ref_src=twsrc%5Etfw\\\">@VectorizedIO</a> team on their funding!<br><br>Their mission to make a faster and more reliable Kafka alternative is a worthy one. Our industry deserves diverse data infrastructure options, and it&#39;s exciting to see so many new ones getting traction.</p>&mdash; Large Data Bank (@JordanALewis) <a href=\\\"https://twitter.com/JordanALewis/status/1354149159755010056?ref_src=twsrc%5Etfw\\\">January 26, 2021</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\"}]],\"markups\":[[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Red_panda\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://github.com/vectorizedio/redpanda\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://vectorized.io/\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://techcrunch.com/2021/01/26/vectorized-announces-15-5m-investment-to-build-simpler-streaming-data-tool/\",\"rel\",\"noopener nofollow\"]],[\"em\"],[\"strong\"],[\"a\",[\"href\",\"https://zookeeper.apache.org/\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://raft.github.io/\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://webassembly.org/\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://vectorized.io/blog/tpc-buffers/\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://vectorized.io/blog/autotune-series-part-1-storage/\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://vectorized.io/slack\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://vectorized.io/cloud\",\"rel\",\"noopener nofollow\"]]],\"sections\":[[1,\"p\",[[0,[0],1,\"Red pandas\"],[0,[],0,\" are cute. But for a while, that was the only thing they had going for them.\"]]],[1,\"p\",[[0,[],0,\"No longer. As with whales (Docker) and elephants (Hadoop, Postgres) before them, red pandas finally have the backing of a hardcore application infrastructure technology.\"]]],[1,\"p\",[[0,[],0,\"Meet \"],[0,[1],1,\"Redpanda\"],[0,[],0,\", a real-time event streaming platform backed by \"],[0,[2],1,\"Vectorized\"],[0,[],0,\". We at Lightspeed led the companyâ€™s \"],[0,[3],1,\"recently announced\"],[0,[],0,\" Seed and Series A rounds, and we couldnâ€™t be more excited about the potential for Vectorized to revolutionize real-time streaming.\"]]],[1,\"p\",[[0,[],0,\"Vectorized is one of the most technical companies Iâ€™ve ever worked with. But unlike many products, where deep technical innovation often comes at the cost of incredible complexity, Redpanda bucks this trade-off. Like its animal namesake, Redpanda is approachable, combining a simple and accessible developer experience with an underlying engine that pushes streaming to never-before-seen performance levels.\"]]],[1,\"p\",[[0,[],0,\"Vectorized is maniacally focused on the developer experience. As a result, it â€œjust worksâ€:\"]]],[1,\"blockquote\",[[0,[4,4,4],1,\"â€œRedPandaâ€™s performance, simplicity and ease of operation dramatically improves next generation data applications. Switching our development environment from Kafka to Redpanda dramatically lowered development overhead, while pipelines feeding Clickhouse â€œjust workedâ€ and moved our I/O bottleneck back to the disks where it belongs. Recommended.â€ â€” \"],[0,[5,5,4],5,\"Eric LaBianca, CTO, The Seventh Sense\"]]],[1,\"p\",[[0,[],0,\"In this post, I want to highlight three key aspects of the Redpanda developer experience â€” \"],[0,[5,5],2,\"simplicity\"],[0,[],0,\", \"],[0,[5,5],2,\"accessibility\"],[0,[],0,\", and \"],[0,[5,5],2,\"performance\"],[0,[],0,\" â€” and discuss why we think Vectorizedâ€™s emphasis on usability will unlock real-time streaming for the great majority of developers, who are underserved by existing solutions. Youâ€™ll also hear it straight from members of the community, who Iâ€™ve quoted throughout.\"]]],[10,0],[1,\"h1\",[[0,[],0,\"Simple is beautiful\"]]],[1,\"p\",[[0,[],0,\"Redpanda abstracts away the complexity that often prevents the typical developer from adopting real-time streaming. Thereâ€™s a long list of optimizations that I wonâ€™t entirely do justice to here, but I wanted to highlight two of the most impactful: \"],[0,[5,5],2,\"No Zookeeper\"],[0,[],0,\" and \"],[0,[5,5],2,\"No JVM (Java Virtual Machine)\"],[0,[],0,\".\"]]],[1,\"h1\",[[0,[],0,\"No Zookeeper\"]]],[1,\"p\",[[0,[6],1,\"Apache Zookeeper\"],[0,[],0,\" is a critical piece of infrastructure in Kafka and many other big data technologies. Its core purpose is to manage coordination of nodes and metadata in distributed systems, and it runs as a separate set of machines that must themselves be managed by the operator.\"]]],[1,\"p\",[[0,[],0,\"Zookeeper is hardened tech at this point and does its job reasonably well. However, itâ€™s a pain to manage and requires a separate set of Zookeeper-specific expertise to deal with problems as they inevitably occur. No one asked to manage an entirely separate distributed system, yet it has historically been a hard requirement in streaming technologies like Kafka, creating additional operational overhead and burden for many Kafka users:\"]]],[1,\"blockquote\",[[0,[4,4,4],1,\"â€œRunning five node zookeeper clusters was pure overhead.â€ â€” \"],[0,[5,5,4],5,\"Hacker News\"]]],[1,\"p\",[[0,[],0,\"The issue is near and dear to me â€” while a product manager at Confluent, I made the case for the removal of the Zookeeper dependency, eventually resulting in the landmark \"],[0,[7],1,\"KIP (Kafka Improvement Proposal)-500\"],[0,[],0,\" which proposed replacing Zookeeper with a self-managed quorum. KIP-500 was met with applause from much of the Kafka community, who were sick and tired of dealing with Zookeeper. It was time for the Zookeeper to retire.\"]]],[1,\"p\",[[0,[],0,\"Removing a core dependency from a decade-old technology is not trivial. A year and a half after the publication of KIP-500, Zookeeper removal proceeds with incremental steps, necessary to mitigate potential migration issues. This canâ€™t be done in a single update.\"]]],[1,\"p\",[[0,[],0,\"Redpanda takes a different approach. Thoughtfully architected from the start to leverage the open source \"],[0,[8],1,\"Raft consensus algorithm\"],[0,[],0,\", Redpanda obviates the need for a third-party consensus system like Zookeeper. This meaningfully reduces operational complexity and has a direct, positive impact on developer productivity:\"]]],[1,\"blockquote\",[[0,[4,4,4],1,\"â€œWe care about reliability and performance at Zenly, so no Zookeeper and 10x faster was a no brainer.â€ â€” \"],[0,[5,5,4],5,\"Jean-Baptiste Dalido, Head of Infrastructure Engineering, Zenly\"]]],[1,\"h1\",[[0,[],0,\"No JVM\"]]],[1,\"blockquote\",[[0,[4,4,4],1,\"â€œI was avoiding Kafka for some time because of admin costs and lack of JVM expertiseâ€ â€” \"],[0,[5,5,4],5,\"Vectorized Community Slack\"]]],[1,\"p\",[[0,[],0,\"Another driver of complexity in the event streaming ecosystem historically has been the Java Virtual Machine, or JVM, a hard requirement in Java-based systems. The JVM is the virtual machine that enables applications compiled to Java bytecode to run, acting as an intermediary between the source code and the system.\"]]],[1,\"p\",[[0,[],0,\"Unfortunately, JVM expertise is in low supply outside of the Java/Scala developers. Ironically, the JVM is often the source of issues when working with Kafka.\"]]],[1,\"p\",[[0,[],0,\"Developers want streaming, but they donâ€™t necessarily want to become Java (assuming they werenâ€™t already familiar) or distributed systems experts. There is meaningful pent-up demand among developers for a non-JVM based streaming architecture to power modern real-time applications. Sizing this up, the Python and JavaScript communities alone could be an order of magnitude greater than the existing Kafka/Java population:\"]]],[10,1],[1,\"p\",[[0,[],0,\"Written in C++, Redpanda needs no JVM and thus users need no JVM knowledge or expertise. This finally moves streaming technology away from Java, a big deal given how many data infrastructure technologies have been built around Java or the JVM over the years:\"]]],[1,\"blockquote\",[[0,[4,4,4],1,\"â€œThis looks awesome! Iâ€™ve been waiting for a long time for someone to think outside the JVM, and I really hope this is a growing trend. The â€œbig dataâ€ industry has seemingly been joined at the hip with Java ever since Hadoop came onto the scene, and the Apache community in particular has a lot of apps that are deeply unfriendly to non-Java appsâ€ â€” \"],[0,[5,5,4],5,\"Hacker News\"]]],[1,\"h1\",[[0,[],0,\"Power to the developers\"]]],[1,\"p\",[[0,[],0,\"Real-time event streaming technologies are not always accessible to the typical software developer. In fact, most individual developers have been left behind in the streaming revolution. Seeing this untapped opportunity, the team at Vectorized architected Redpanda in ways that expand the pool of developers that can productively operate the system.\"]]],[1,\"h1\",[[0,[],0,\"Kafka compatibility\"]]],[10,2],[1,\"p\",[[0,[],0,\"Too often, when new technology comes around it bifurcates the existing community in an attempt to grow adoption. This leaves individual developers and teams in the ensuing crossfire.\"]]],[1,\"p\",[[0,[],0,\"In building the future of real-time streaming, Redpanda respects what came before it. Despite all its improvement under the hood, Redpanda maintains \"],[0,[5,5],2,\"full API compatibility with Kafka\"],[0,[],0,\". This means that existing Kafka-based systems can be swapped over to Redpanda with no changes to existing applications, making for an easy and straightforward migration path.\"]]],[1,\"p\",[[0,[],0,\"More than a smart business move, maintaining Kafka compatibility makes Redpanda much more accessible to existing Kafka users. This is important because developers in fact love the Kafka \"],[0,[4,4],2,\"API\"],[0,[],0,\", though they donâ€™t always love managing the associated infrastructure.\"]]],[1,\"p\",[[0,[],0,\"Further, Kafka API compatibility means that Redpanda users can continue to leverage the amazing Kafka ecosystem that has built up over the years. This can lead to interesting combinations of Kaka-related tools and Redpanda as the core streaming engine:\"]]],[1,\"blockquote\",[[0,[4,4,4],1,\"â€œVery cool â€” I was able to use a kafka connector to get websocket fanout out of a redpanda installation no problem. Iâ€™ll be writing a blogpost about this.â€ â€” \"],[0,[5,5,4],5,\"Vectorized Community Slack\"]]],[1,\"h1\",[[0,[],0,\"WebAssembly\"]]],[10,3],[1,\"p\",[[0,[9],1,\"WebAssembly\"],[0,[],0,\", or WASM, is one of the most exciting up-and-coming technologies in software development today. WebAssembly lets developers write code in any major language, translate that code to the compact WASM format, and run it on the web with the high performance of a native application.\"]]],[1,\"p\",[[0,[],0,\"Redpanda is one of the first infrastructure technologies to take advantage of WASM, enabling developers to â€œwrite and edit code in their favorite programming language to perform one-shot transformations, like guaranteeing GDPR compliance by removing personal information or to provide filtering and simple aggregation functions.â€ Hereâ€™s how one community member described Redpandaâ€™s WASM engine:\"]]],[1,\"blockquote\",[[0,[4,4,4],1,\"â€œVery clever and useful way to take advantage of WASMâ€¦ It reminds me a little bit of JS-derived views in CouchDB, just way more powerful and performant thanks to WASM rather than plain JS interpreterâ€ \"],[0,[5,5,4],5,\"â€” Vectorized Community Slack\"]]],[1,\"p\",[[0,[],0,\"JavaScript, Python, Rust, Go â€” anything that compiles to WebAssembly (basically everything at this point) can be used to transform data. Again the key is accessibility â€” inline WASM transforms in Redpanda represent just that. WASM also unlocks interesting use cases beginning to emerge among the community:\"]]],[1,\"blockquote\",[[0,[4,4,4],1,\"â€œWhat excites me the most is the WebAssembly feature, as it enables us to create a â€œData Firewallâ€™â€™, the last mile of access, transforms and policy.â€ â€” \"],[0,[5,5,4],5,\"Jean-Baptiste Dalido, Head of Infrastructure Engineering, Zenly\"]]],[1,\"h1\",[[0,[],0,\"Gotta go fast\"]]],[1,\"p\",[[0,[],0,\"Performance isnâ€™t often pitched as a productivity boost. But it is, especially at scale.\"]]],[1,\"p\",[[0,[],0,\"Better performance at the \"],[0,[4,4],2,\"infrastructure\"],[0,[],0,\" level leaves more room for the application itself to function as intended without running into resource constraints. This means less optimization work by the developer and also opens up streaming to other languages like JavaScript and Python, whose worse performance as high-level languages is balanced out by speed at the infrastructure level.\"]]],[1,\"p\",[[0,[],0,\"To better understand this, letâ€™s talk cores and tails.\"]]],[1,\"h1\",[[0,[],0,\"Hold my Coors, I mean, cores\"]]],[10,4],[1,\"p\",[[0,[],0,\"Hardware is moving target, continuously evolving and improving. The last 15 years have been no exception. The underlying hardware targeted by streaming and message queue systems has changed meaningfully since the advent of real-time systems, opening up new opportunities for performance enhancements that take advantage of new physical resources.\"]]],[1,\"p\",[[0,[],0,\"Written in lower-level C++, Redpandaâ€™s \"],[0,[10],1,\"thread-per-core architecture\"],[0,[],0,\" is optimized for modern hardware and squeezes out every last bit of performance, fully exploiting the resources it runs on. Redpanda also comes with \"],[0,[11],1,\"intelligent auto-tuning\"],[0,[],0,\" out-of-the-box, which automatically generates optimal settings for your specific hardware/kernel/Redpanda setup. Organizations can do more with less, and the benefits extends down to the level of the individual developer too, who now has more â€œbreathing roomâ€ when it comes to performance due to Redpandaâ€™s more efficient streaming engine. Developers can worry less about optimization and just write the applications they want, enhancing developer productivity.\"]]],[1,\"h1\",[[0,[],0,\"Donâ€™t fail in the tail\"]]],[1,\"p\",[[0,[],0,\"Averages rarely tell the whole story when it comes to performance. Latency, for example, can be, on average, quite similar between two systems and yet diverge meaningfully at the 99th+ percentile. Reliable performance â€œin the tailsâ€ is critical for certain use cases like fraud detection, where financial institutions must return decisions ASAP at the point of sale.\"]]],[1,\"p\",[[0,[],0,\"Unfortunately, performance issues often â€œhideâ€ in the tails of the latency distribution, only rearing their head periodically. But when they do pop up, the delays can be monstrous.\"]]],[1,\"p\",[[0,[],0,\"Because Vectorized built a new storage engine from scratch that removes much of the overhead in Kafka and can fully saturate the underlying device, Redpanda operates with stable tail latencies. This means architects get predictable performance in their applications and fewer unexpected spikes in latency.\"]]],[10,5],[1,\"p\",[[0,[],0,\"This sort of reliability is difficult to achieve in JVM-based systems like Kafka. With a C++-based architecture and CPU-level optimizations, Redpanda achieves 19x better tail latency.\"]]],[1,\"h1\",[[0,[],0,\"Developer love always wins\"]]],[1,\"p\",[[0,[],0,\"We love Vectorizedâ€™s focus on improving the developer experience for real-time infrastructure. Redpanda represents an improvement to the status quo along multiple dimensions. Through simplicity, accessibility, and performance enhancements, Redpanda opens up streaming to a wider audience of developers who, at the end of the day, simply want to write applications â€” \"],[0,[4,4],2,\"without\"],[0,[],0,\" having to struggle with operational complexity.\"]]],[1,\"p\",[[0,[],0,\"Hereâ€™s how one engineer put it:\"]]],[10,6],[1,\"p\",[[0,[],0,\"We at Lightspeed couldnâ€™t agree more.\"]]],[1,\"p\",[[0,[4,4],2,\"Want to learn more, connect with the Vectorized team, and meet other Redpanda users? Join the \"],[0,[12,4,4],3,\"Slack community\"],[0,[4,4],2,\", check out the \"],[0,[1,4,4],3,\"repo\"],[0,[4,4],2,\", and sign up for early access to \"],[0,[13,4,4],3,\"Vectorized Cloud\"],[0,[4,4],2,\".\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p><a href=\"https://en.wikipedia.org/wiki/Red_panda\" rel=\"noopener nofollow\">Red pandas</a> are cute. But for a while, that was the only thing they had going for them.</p><p>No longer. As with whales (Docker) and elephants (Hadoop, Postgres) before them, red pandas finally have the backing of a hardcore application infrastructure technology.</p><p>Meet <a href=\"https://github.com/vectorizedio/redpanda\" rel=\"noopener nofollow\">Redpanda</a>, a real-time event streaming platform backed by <a href=\"https://vectorized.io/\" rel=\"noopener nofollow\">Vectorized</a>. We at Lightspeed led the companyâ€™s <a href=\"https://techcrunch.com/2021/01/26/vectorized-announces-15-5m-investment-to-build-simpler-streaming-data-tool/\" rel=\"noopener nofollow\">recently announced</a> Seed and Series A rounds, and we couldnâ€™t be more excited about the potential for Vectorized to revolutionize real-time streaming.</p><p>Vectorized is one of the most technical companies Iâ€™ve ever worked with. But unlike many products, where deep technical innovation often comes at the cost of incredible complexity, Redpanda bucks this trade-off. Like its animal namesake, Redpanda is approachable, combining a simple and accessible developer experience with an underlying engine that pushes streaming to never-before-seen performance levels.</p><p>Vectorized is maniacally focused on the developer experience. As a result, it â€œjust worksâ€:</p><blockquote><em><em><em>â€œRedPandaâ€™s performance, simplicity and ease of operation dramatically improves next generation data applications. Switching our development environment from Kafka to Redpanda dramatically lowered development overhead, while pipelines feeding Clickhouse â€œjust workedâ€ and moved our I/O bottleneck back to the disks where it belongs. Recommended.â€ â€” </em><strong><strong><em>Eric LaBianca, CTO, The Seventh Sense</em></strong></strong></em></em></blockquote><p>In this post, I want to highlight three key aspects of the Redpanda developer experience â€” <strong><strong>simplicity</strong></strong>, <strong><strong>accessibility</strong></strong>, and <strong><strong>performance</strong></strong> â€” and discuss why we think Vectorizedâ€™s emphasis on usability will unlock real-time streaming for the great majority of developers, who are underserved by existing solutions. Youâ€™ll also hear it straight from members of the community, who Iâ€™ve quoted throughout.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Why Developers Love Redpanda\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Subscribe</span></button>\n</form>\n</section><!--kg-card-end: html--><h1 id=\"simple-is-beautiful\">Simple is beautiful</h1><p>Redpanda abstracts away the complexity that often prevents the typical developer from adopting real-time streaming. Thereâ€™s a long list of optimizations that I wonâ€™t entirely do justice to here, but I wanted to highlight two of the most impactful: <strong><strong>No Zookeeper</strong></strong> and <strong><strong>No JVM (Java Virtual Machine)</strong></strong>.</p><h1 id=\"no-zookeeper\">No Zookeeper</h1><p><a href=\"https://zookeeper.apache.org/\" rel=\"noopener nofollow\">Apache Zookeeper</a> is a critical piece of infrastructure in Kafka and many other big data technologies. Its core purpose is to manage coordination of nodes and metadata in distributed systems, and it runs as a separate set of machines that must themselves be managed by the operator.</p><p>Zookeeper is hardened tech at this point and does its job reasonably well. However, itâ€™s a pain to manage and requires a separate set of Zookeeper-specific expertise to deal with problems as they inevitably occur. No one asked to manage an entirely separate distributed system, yet it has historically been a hard requirement in streaming technologies like Kafka, creating additional operational overhead and burden for many Kafka users:</p><blockquote><em><em><em>â€œRunning five node zookeeper clusters was pure overhead.â€ â€” </em><strong><strong><em>Hacker News</em></strong></strong></em></em></blockquote><p>The issue is near and dear to me â€” while a product manager at Confluent, I made the case for the removal of the Zookeeper dependency, eventually resulting in the landmark <a href=\"https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum\" rel=\"noopener nofollow\">KIP (Kafka Improvement Proposal)-500</a> which proposed replacing Zookeeper with a self-managed quorum. KIP-500 was met with applause from much of the Kafka community, who were sick and tired of dealing with Zookeeper. It was time for the Zookeeper to retire.</p><p>Removing a core dependency from a decade-old technology is not trivial. A year and a half after the publication of KIP-500, Zookeeper removal proceeds with incremental steps, necessary to mitigate potential migration issues. This canâ€™t be done in a single update.</p><p>Redpanda takes a different approach. Thoughtfully architected from the start to leverage the open source <a href=\"https://raft.github.io/\" rel=\"noopener nofollow\">Raft consensus algorithm</a>, Redpanda obviates the need for a third-party consensus system like Zookeeper. This meaningfully reduces operational complexity and has a direct, positive impact on developer productivity:</p><blockquote><em><em><em>â€œWe care about reliability and performance at Zenly, so no Zookeeper and 10x faster was a no brainer.â€ â€” </em><strong><strong><em>Jean-Baptiste Dalido, Head of Infrastructure Engineering, Zenly</em></strong></strong></em></em></blockquote><h1 id=\"no-jvm\">No JVM</h1><blockquote><em><em><em>â€œI was avoiding Kafka for some time because of admin costs and lack of JVM expertiseâ€ â€” </em><strong><strong><em>Vectorized Community Slack</em></strong></strong></em></em></blockquote><p>Another driver of complexity in the event streaming ecosystem historically has been the Java Virtual Machine, or JVM, a hard requirement in Java-based systems. The JVM is the virtual machine that enables applications compiled to Java bytecode to run, acting as an intermediary between the source code and the system.</p><p>Unfortunately, JVM expertise is in low supply outside of the Java/Scala developers. Ironically, the JVM is often the source of issues when working with Kafka.</p><p>Developers want streaming, but they donâ€™t necessarily want to become Java (assuming they werenâ€™t already familiar) or distributed systems experts. There is meaningful pent-up demand among developers for a non-JVM based streaming architecture to power modern real-time applications. Sizing this up, the Python and JavaScript communities alone could be an order of magnitude greater than the existing Kafka/Java population:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/05/No_JVM__Redpanda_vectorized_img.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Written in C++, Redpanda needs no JVM and thus users need no JVM knowledge or expertise. This finally moves streaming technology away from Java, a big deal given how many data infrastructure technologies have been built around Java or the JVM over the years:</p><blockquote><em><em><em>â€œThis looks awesome! Iâ€™ve been waiting for a long time for someone to think outside the JVM, and I really hope this is a growing trend. The â€œbig dataâ€ industry has seemingly been joined at the hip with Java ever since Hadoop came onto the scene, and the Apache community in particular has a lot of apps that are deeply unfriendly to non-Java appsâ€ â€” </em><strong><strong><em>Hacker News</em></strong></strong></em></em></blockquote><h1 id=\"power-to-the-developers\">Power to the developers</h1><p>Real-time event streaming technologies are not always accessible to the typical software developer. In fact, most individual developers have been left behind in the streaming revolution. Seeing this untapped opportunity, the team at Vectorized architected Redpanda in ways that expand the pool of developers that can productively operate the system.</p><h1 id=\"kafka-compatibility\">Kafka compatibility</h1><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/05/0_rzLnKt-j8CZ6Ezd6.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Too often, when new technology comes around it bifurcates the existing community in an attempt to grow adoption. This leaves individual developers and teams in the ensuing crossfire.</p><p>In building the future of real-time streaming, Redpanda respects what came before it. Despite all its improvement under the hood, Redpanda maintains <strong><strong>full API compatibility with Kafka</strong></strong>. This means that existing Kafka-based systems can be swapped over to Redpanda with no changes to existing applications, making for an easy and straightforward migration path.</p><p>More than a smart business move, maintaining Kafka compatibility makes Redpanda much more accessible to existing Kafka users. This is important because developers in fact love the Kafka <em><em>API</em></em>, though they donâ€™t always love managing the associated infrastructure.</p><p>Further, Kafka API compatibility means that Redpanda users can continue to leverage the amazing Kafka ecosystem that has built up over the years. This can lead to interesting combinations of Kaka-related tools and Redpanda as the core streaming engine:</p><blockquote><em><em><em>â€œVery cool â€” I was able to use a kafka connector to get websocket fanout out of a redpanda installation no problem. Iâ€™ll be writing a blogpost about this.â€ â€” </em><strong><strong><em>Vectorized Community Slack</em></strong></strong></em></em></blockquote><h1 id=\"webassembly\">WebAssembly</h1><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/05/The_future_of_streaming_Redpanda_vectorized_img.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p><a href=\"https://webassembly.org/\" rel=\"noopener nofollow\">WebAssembly</a>, or WASM, is one of the most exciting up-and-coming technologies in software development today. WebAssembly lets developers write code in any major language, translate that code to the compact WASM format, and run it on the web with the high performance of a native application.</p><p>Redpanda is one of the first infrastructure technologies to take advantage of WASM, enabling developers to â€œwrite and edit code in their favorite programming language to perform one-shot transformations, like guaranteeing GDPR compliance by removing personal information or to provide filtering and simple aggregation functions.â€ Hereâ€™s how one community member described Redpandaâ€™s WASM engine:</p><blockquote><em><em><em>â€œVery clever and useful way to take advantage of WASMâ€¦ It reminds me a little bit of JS-derived views in CouchDB, just way more powerful and performant thanks to WASM rather than plain JS interpreterâ€ </em><strong><strong><em>â€” Vectorized Community Slack</em></strong></strong></em></em></blockquote><p>JavaScript, Python, Rust, Go â€” anything that compiles to WebAssembly (basically everything at this point) can be used to transform data. Again the key is accessibility â€” inline WASM transforms in Redpanda represent just that. WASM also unlocks interesting use cases beginning to emerge among the community:</p><blockquote><em><em><em>â€œWhat excites me the most is the WebAssembly feature, as it enables us to create a â€œData Firewallâ€™â€™, the last mile of access, transforms and policy.â€ â€” </em><strong><strong><em>Jean-Baptiste Dalido, Head of Infrastructure Engineering, Zenly</em></strong></strong></em></em></blockquote><h1 id=\"gotta-go-fast\">Gotta go fast</h1><p>Performance isnâ€™t often pitched as a productivity boost. But it is, especially at scale.</p><p>Better performance at the <em><em>infrastructure</em></em> level leaves more room for the application itself to function as intended without running into resource constraints. This means less optimization work by the developer and also opens up streaming to other languages like JavaScript and Python, whose worse performance as high-level languages is balanced out by speed at the infrastructure level.</p><p>To better understand this, letâ€™s talk cores and tails.</p><h1 id=\"hold-my-coors-i-mean-cores\">Hold my Coors, I mean, cores</h1><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/05/Hold_my_core_Redpanda_vectorized_img.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Hardware is moving target, continuously evolving and improving. The last 15 years have been no exception. The underlying hardware targeted by streaming and message queue systems has changed meaningfully since the advent of real-time systems, opening up new opportunities for performance enhancements that take advantage of new physical resources.</p><p>Written in lower-level C++, Redpandaâ€™s <a href=\"https://vectorized.io/blog/tpc-buffers/\" rel=\"noopener nofollow\">thread-per-core architecture</a> is optimized for modern hardware and squeezes out every last bit of performance, fully exploiting the resources it runs on. Redpanda also comes with <a href=\"https://vectorized.io/blog/autotune-series-part-1-storage/\" rel=\"noopener nofollow\">intelligent auto-tuning</a> out-of-the-box, which automatically generates optimal settings for your specific hardware/kernel/Redpanda setup. Organizations can do more with less, and the benefits extends down to the level of the individual developer too, who now has more â€œbreathing roomâ€ when it comes to performance due to Redpandaâ€™s more efficient streaming engine. Developers can worry less about optimization and just write the applications they want, enhancing developer productivity.</p><h1 id=\"don-t-fail-in-the-tail\">Donâ€™t fail in the tail</h1><p>Averages rarely tell the whole story when it comes to performance. Latency, for example, can be, on average, quite similar between two systems and yet diverge meaningfully at the 99th+ percentile. Reliable performance â€œin the tailsâ€ is critical for certain use cases like fraud detection, where financial institutions must return decisions ASAP at the point of sale.</p><p>Unfortunately, performance issues often â€œhideâ€ in the tails of the latency distribution, only rearing their head periodically. But when they do pop up, the delays can be monstrous.</p><p>Because Vectorized built a new storage engine from scratch that removes much of the overhead in Kafka and can fully saturate the underlying device, Redpanda operates with stable tail latencies. This means architects get predictable performance in their applications and fewer unexpected spikes in latency.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/05/End-to-End_Latency_Percentiles_Redpanda_vectorized_img.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>This sort of reliability is difficult to achieve in JVM-based systems like Kafka. With a C++-based architecture and CPU-level optimizations, Redpanda achieves 19x better tail latency.</p><h1 id=\"developer-love-always-wins\">Developer love always wins</h1><p>We love Vectorizedâ€™s focus on improving the developer experience for real-time infrastructure. Redpanda represents an improvement to the status quo along multiple dimensions. Through simplicity, accessibility, and performance enhancements, Redpanda opens up streaming to a wider audience of developers who, at the end of the day, simply want to write applications â€” <em><em>without</em></em> having to struggle with operational complexity.</p><p>Hereâ€™s how one engineer put it:</p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Congratulations to <a href=\"https://twitter.com/emaxerrno?ref_src=twsrc%5Etfw\">@emaxerrno</a> and the <a href=\"https://twitter.com/VectorizedIO?ref_src=twsrc%5Etfw\">@VectorizedIO</a> team on their funding!<br><br>Their mission to make a faster and more reliable Kafka alternative is a worthy one. Our industry deserves diverse data infrastructure options, and it&#39;s exciting to see so many new ones getting traction.</p>&mdash; Large Data Bank (@JordanALewis) <a href=\"https://twitter.com/JordanALewis/status/1354149159755010056?ref_src=twsrc%5Etfw\">January 26, 2021</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><p>We at Lightspeed couldnâ€™t agree more.</p><p><em><em>Want to learn more, connect with the Vectorized team, and meet other Redpanda users? Join the </em></em><a href=\"https://vectorized.io/slack\" rel=\"noopener nofollow\"><em><em>Slack community</em></em></a><em><em>, check out the </em></em><a href=\"https://github.com/vectorizedio/redpanda\" rel=\"noopener nofollow\"><em><em>repo</em></em></a><em><em>, and sign up for early access to </em></em><a href=\"https://vectorized.io/cloud\" rel=\"noopener nofollow\"><em><em>Vectorized Cloud</em></em></a><em><em>.</em></em></p>","comment_id":"609990d417b26d3ef80d66da","plaintext":"Red pandas [https://en.wikipedia.org/wiki/Red_panda] are cute. But for a while,\nthat was the only thing they had going for them.\n\nNo longer. As with whales (Docker) and elephants (Hadoop, Postgres) before them,\nred pandas finally have the backing of a hardcore application infrastructure\ntechnology.\n\nMeet Redpanda [https://github.com/vectorizedio/redpanda], a real-time event\nstreaming platform backed by Vectorized [https://vectorized.io/]. We at\nLightspeed led the companyâ€™s recently announced\n[https://techcrunch.com/2021/01/26/vectorized-announces-15-5m-investment-to-build-simpler-streaming-data-tool/] \nSeed and Series A rounds, and we couldnâ€™t be more excited about the potential\nfor Vectorized to revolutionize real-time streaming.\n\nVectorized is one of the most technical companies Iâ€™ve ever worked with. But\nunlike many products, where deep technical innovation often comes at the cost of\nincredible complexity, Redpanda bucks this trade-off. Like its animal namesake,\nRedpanda is approachable, combining a simple and accessible developer experience\nwith an underlying engine that pushes streaming to never-before-seen performance\nlevels.\n\nVectorized is maniacally focused on the developer experience. As a result, it\nâ€œjust worksâ€:\n\n> â€œRedPandaâ€™s performance, simplicity and ease of operation dramatically improves\nnext generation data applications. Switching our development environment from\nKafka to Redpanda dramatically lowered development overhead, while pipelines\nfeeding Clickhouse â€œjust workedâ€ and moved our I/O bottleneck back to the disks\nwhere it belongs. Recommended.â€ â€” Eric LaBianca, CTO, The Seventh Sense\nIn this post, I want to highlight three key aspects of the Redpanda developer\nexperience â€” simplicity, accessibility, and performance â€” and discuss why we\nthink Vectorizedâ€™s emphasis on usability will unlock real-time streaming for the\ngreat majority of developers, who are underserved by existing solutions. Youâ€™ll\nalso hear it straight from members of the community, who Iâ€™ve quoted throughout.\n\nReceive my next long-form post\nThoughtful analysis of the business and economics of tech\n\n\n\nSubscribeSimple is beautiful\nRedpanda abstracts away the complexity that often prevents the typical developer\nfrom adopting real-time streaming. Thereâ€™s a long list of optimizations that I\nwonâ€™t entirely do justice to here, but I wanted to highlight two of the most\nimpactful: No Zookeeper and No JVM (Java Virtual Machine).\n\nNo Zookeeper\nApache Zookeeper [https://zookeeper.apache.org/] is a critical piece of\ninfrastructure in Kafka and many other big data technologies. Its core purpose\nis to manage coordination of nodes and metadata in distributed systems, and it\nruns as a separate set of machines that must themselves be managed by the\noperator.\n\nZookeeper is hardened tech at this point and does its job reasonably well.\nHowever, itâ€™s a pain to manage and requires a separate set of Zookeeper-specific\nexpertise to deal with problems as they inevitably occur. No one asked to manage\nan entirely separate distributed system, yet it has historically been a hard\nrequirement in streaming technologies like Kafka, creating additional\noperational overhead and burden for many Kafka users:\n\n> â€œRunning five node zookeeper clusters was pure overhead.â€ â€” Hacker News\nThe issue is near and dear to me â€” while a product manager at Confluent, I made\nthe case for the removal of the Zookeeper dependency, eventually resulting in\nthe landmark KIP (Kafka Improvement Proposal)-500\n[https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum] \nwhich proposed replacing Zookeeper with a self-managed quorum. KIP-500 was met\nwith applause from much of the Kafka community, who were sick and tired of\ndealing with Zookeeper. It was time for the Zookeeper to retire.\n\nRemoving a core dependency from a decade-old technology is not trivial. A year\nand a half after the publication of KIP-500, Zookeeper removal proceeds with\nincremental steps, necessary to mitigate potential migration issues. This canâ€™t\nbe done in a single update.\n\nRedpanda takes a different approach. Thoughtfully architected from the start to\nleverage the open source Raft consensus algorithm [https://raft.github.io/],\nRedpanda obviates the need for a third-party consensus system like Zookeeper.\nThis meaningfully reduces operational complexity and has a direct, positive\nimpact on developer productivity:\n\n> â€œWe care about reliability and performance at Zenly, so no Zookeeper and 10x\nfaster was a no brainer.â€ â€” Jean-Baptiste Dalido, Head of Infrastructure\nEngineering, Zenly\nNo JVM\n> â€œI was avoiding Kafka for some time because of admin costs and lack of JVM\nexpertiseâ€ â€” Vectorized Community Slack\nAnother driver of complexity in the event streaming ecosystem historically has\nbeen the Java Virtual Machine, or JVM, a hard requirement in Java-based systems.\nThe JVM is the virtual machine that enables applications compiled to Java\nbytecode to run, acting as an intermediary between the source code and the\nsystem.\n\nUnfortunately, JVM expertise is in low supply outside of the Java/Scala\ndevelopers. Ironically, the JVM is often the source of issues when working with\nKafka.\n\nDevelopers want streaming, but they donâ€™t necessarily want to become Java\n(assuming they werenâ€™t already familiar) or distributed systems experts. There\nis meaningful pent-up demand among developers for a non-JVM based streaming\narchitecture to power modern real-time applications. Sizing this up, the Python\nand JavaScript communities alone could be an order of magnitude greater than the\nexisting Kafka/Java population:\n\nWritten in C++, Redpanda needs no JVM and thus users need no JVM knowledge or\nexpertise. This finally moves streaming technology away from Java, a big deal\ngiven how many data infrastructure technologies have been built around Java or\nthe JVM over the years:\n\n> â€œThis looks awesome! Iâ€™ve been waiting for a long time for someone to think\noutside the JVM, and I really hope this is a growing trend. The â€œbig dataâ€\nindustry has seemingly been joined at the hip with Java ever since Hadoop came\nonto the scene, and the Apache community in particular has a lot of apps that\nare deeply unfriendly to non-Java appsâ€ â€” Hacker News\nPower to the developers\nReal-time event streaming technologies are not always accessible to the typical\nsoftware developer. In fact, most individual developers have been left behind in\nthe streaming revolution. Seeing this untapped opportunity, the team at\nVectorized architected Redpanda in ways that expand the pool of developers that\ncan productively operate the system.\n\nKafka compatibility\nToo often, when new technology comes around it bifurcates the existing community\nin an attempt to grow adoption. This leaves individual developers and teams in\nthe ensuing crossfire.\n\nIn building the future of real-time streaming, Redpanda respects what came\nbefore it. Despite all its improvement under the hood, Redpanda maintains full\nAPI compatibility with Kafka. This means that existing Kafka-based systems can\nbe swapped over to Redpanda with no changes to existing applications, making for\nan easy and straightforward migration path.\n\nMore than a smart business move, maintaining Kafka compatibility makes Redpanda\nmuch more accessible to existing Kafka users. This is important because\ndevelopers in fact love the Kafka API, though they donâ€™t always love managing\nthe associated infrastructure.\n\nFurther, Kafka API compatibility means that Redpanda users can continue to\nleverage the amazing Kafka ecosystem that has built up over the years. This can\nlead to interesting combinations of Kaka-related tools and Redpanda as the core\nstreaming engine:\n\n> â€œVery cool â€” I was able to use a kafka connector to get websocket fanout out of\na redpanda installation no problem. Iâ€™ll be writing a blogpost about this.â€ â€” \nVectorized Community Slack\nWebAssembly\nWebAssembly [https://webassembly.org/], or WASM, is one of the most exciting\nup-and-coming technologies in software development today. WebAssembly lets\ndevelopers write code in any major language, translate that code to the compact\nWASM format, and run it on the web with the high performance of a native\napplication.\n\nRedpanda is one of the first infrastructure technologies to take advantage of\nWASM, enabling developers to â€œwrite and edit code in their favorite programming\nlanguage to perform one-shot transformations, like guaranteeing GDPR compliance\nby removing personal information or to provide filtering and simple aggregation\nfunctions.â€ Hereâ€™s how one community member described Redpandaâ€™s WASM engine:\n\n> â€œVery clever and useful way to take advantage of WASMâ€¦ It reminds me a little\nbit of JS-derived views in CouchDB, just way more powerful and performant thanks\nto WASM rather than plain JS interpreterâ€ â€” Vectorized Community Slack\nJavaScript, Python, Rust, Go â€” anything that compiles to WebAssembly (basically\neverything at this point) can be used to transform data. Again the key is\naccessibility â€” inline WASM transforms in Redpanda represent just that. WASM\nalso unlocks interesting use cases beginning to emerge among the community:\n\n> â€œWhat excites me the most is the WebAssembly feature, as it enables us to create\na â€œData Firewallâ€™â€™, the last mile of access, transforms and policy.â€ â€” \nJean-Baptiste Dalido, Head of Infrastructure Engineering, Zenly\nGotta go fast\nPerformance isnâ€™t often pitched as a productivity boost. But it is, especially\nat scale.\n\nBetter performance at the infrastructure level leaves more room for the\napplication itself to function as intended without running into resource\nconstraints. This means less optimization work by the developer and also opens\nup streaming to other languages like JavaScript and Python, whose worse\nperformance as high-level languages is balanced out by speed at the\ninfrastructure level.\n\nTo better understand this, letâ€™s talk cores and tails.\n\nHold my Coors, I mean, cores\nHardware is moving target, continuously evolving and improving. The last 15\nyears have been no exception. The underlying hardware targeted by streaming and\nmessage queue systems has changed meaningfully since the advent of real-time\nsystems, opening up new opportunities for performance enhancements that take\nadvantage of new physical resources.\n\nWritten in lower-level C++, Redpandaâ€™s thread-per-core architecture\n[https://vectorized.io/blog/tpc-buffers/] is optimized for modern hardware and\nsqueezes out every last bit of performance, fully exploiting the resources it\nruns on. Redpanda also comes with intelligent auto-tuning\n[https://vectorized.io/blog/autotune-series-part-1-storage/] out-of-the-box,\nwhich automatically generates optimal settings for your specific\nhardware/kernel/Redpanda setup. Organizations can do more with less, and the\nbenefits extends down to the level of the individual developer too, who now has\nmore â€œbreathing roomâ€ when it comes to performance due to Redpandaâ€™s more\nefficient streaming engine. Developers can worry less about optimization and\njust write the applications they want, enhancing developer productivity.\n\nDonâ€™t fail in the tail\nAverages rarely tell the whole story when it comes to performance. Latency, for\nexample, can be, on average, quite similar between two systems and yet diverge\nmeaningfully at the 99th+ percentile. Reliable performance â€œin the tailsâ€ is\ncritical for certain use cases like fraud detection, where financial\ninstitutions must return decisions ASAP at the point of sale.\n\nUnfortunately, performance issues often â€œhideâ€ in the tails of the latency\ndistribution, only rearing their head periodically. But when they do pop up, the\ndelays can be monstrous.\n\nBecause Vectorized built a new storage engine from scratch that removes much of\nthe overhead in Kafka and can fully saturate the underlying device, Redpanda\noperates with stable tail latencies. This means architects get predictable\nperformance in their applications and fewer unexpected spikes in latency.\n\nThis sort of reliability is difficult to achieve in JVM-based systems like\nKafka. With a C++-based architecture and CPU-level optimizations, Redpanda\nachieves 19x better tail latency.\n\nDeveloper love always wins\nWe love Vectorizedâ€™s focus on improving the developer experience for real-time\ninfrastructure. Redpanda represents an improvement to the status quo along\nmultiple dimensions. Through simplicity, accessibility, and performance\nenhancements, Redpanda opens up streaming to a wider audience of developers who,\nat the end of the day, simply want to write applications â€” without having to\nstruggle with operational complexity.\n\nHereâ€™s how one engineer put it:\n\n> Congratulations to @emaxerrno\n[https://twitter.com/emaxerrno?ref_src=twsrc%5Etfw] and the @VectorizedIO\n[https://twitter.com/VectorizedIO?ref_src=twsrc%5Etfw] team on their funding!\n\nTheir mission to make a faster and more reliable Kafka alternative is a worthy\none. Our industry deserves diverse data infrastructure options, and it's\nexciting to see so many new ones getting traction.\n\nâ€” Large Data Bank (@JordanALewis) January 26, 2021\n[https://twitter.com/JordanALewis/status/1354149159755010056?ref_src=twsrc%5Etfw]\nWe at Lightspeed couldnâ€™t agree more.\n\nWant to learn more, connect with the Vectorized team, and meet other Redpanda\nusers? Join the Slack community [https://vectorized.io/slack], check out the \nrepo [https://github.com/vectorizedio/redpanda], and sign up for early access to \nVectorized Cloud [https://vectorized.io/cloud].","feature_image":"__GHOST_URL__/content/images/2021/05/Why_Developers_Love_Redpanda_vectorized_img.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2021-05-10T20:00:20.000Z","updated_at":"2022-07-13T01:29:13.000Z","published_at":"2021-02-10T21:02:00.000Z","custom_excerpt":"Why Vectorized's focus on developer experience will unlock real-time streaming for the great majority of developers","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"609b6a4317b26d3ef80d6722","uuid":"448cb596-b967-4080-b475-5dec415723da","title":"The Developer Productivity Manifesto Part 1 â€” The Flywheel","slug":"the-developer-productivity-flywheel","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"/content/images/2021/05/image-1.png\",\"cardWidth\":\"wide\"}],[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: The Developer Productivity Manifesto Part 1 â€” The Flywheel\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Subscribe</span></button>\\n</form>\\n</section>\"}],[\"image\",{\"src\":\"/content/images/2021/05/0_A8QJ_-v0lvk9FBMK-1.jpg\",\"caption\":\"\"}],[\"image\",{\"src\":\"/content/images/2021/05/0_Ol16aBbPuF5r3spw.png\"}],[\"image\",{\"src\":\"/content/images/2021/05/0_NoQVuock22zuDfIb.png\"}],[\"image\",{\"src\":\"/content/images/2021/05/0_pmFjSDd8dI9N6Zya.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2021/05/image-2.png\"}],[\"image\",{\"src\":\"/content/images/2021/05/image-3.png\"}],[\"image\",{\"src\":\"/content/images/2021/05/0_xguhYnmT9lSWPdzn.png\"}],[\"image\",{\"src\":\"/content/images/2021/05/0_jP2mHx71qNSVYIJ6.png\"}],[\"image\",{\"src\":\"/content/images/2021/05/0_S7ptnoyf9hy99zxq.png\"}],[\"image\",{\"src\":\"/content/images/2021/05/0_s5vJJ4hKzJd4QmVq.png\"}],[\"image\",{\"src\":\"/content/images/2021/05/image-4.png\"}],[\"image\",{\"src\":\"/content/images/2021/05/0_pTVPwZPyFQf8MbbR.png\",\"caption\":\"<a href=\\\"https://www.primedesignprojects.com/ProductImages/IC.jpg\\\" rel=\\\"noopener nofollow\\\">Original version</a>\"}],[\"image\",{\"src\":\"/content/images/2021/05/0__phAC3txzmraNUQN.png\"}],[\"image\",{\"src\":\"/content/images/2021/05/0_f1Yu2MIu3fMkyDFN.png\"}],[\"image\",{\"src\":\"/content/images/2021/05/dev_prod_flywheel.py.png\"}],[\"image\",{\"src\":\"/content/images/2021/05/0_6kZsFEsFISGZIQMY.png\",\"cardWidth\":\"wide\"}]],\"markups\":[[\"em\"],[\"a\",[\"href\",\"https://stripe.com/about\",\"rel\",\"noopener nofollow\"]],[\"strong\"],[\"a\",[\"href\",\"__GHOST_URL__/more-developers-isnt-always-more/\"]],[\"a\",[\"href\",\"__GHOST_URL__/leaving-software-on-the-table/\"]],[\"a\",[\"href\",\"https://www.confluent.io/blog/every-company-is-becoming-software/\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://stripe.com/files/reports/the-developer-coefficient.pdf\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Moore's_law\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://web.stanford.edu/~chadj/IdeaPF.pdf\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://www.derrickreimer.com/essays/2018/03/02/the-war-on-developer-productivity.html\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3346739\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://www.khanacademy.org/economics-finance-domain/ap-microeconomics/factor-markets/ap-labor-marginal-product-rev/v/shifts-in-demand-for-labor\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://www.cgl.ucsf.edu/Outreach/pc204/NoSilverBullet.html\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://twitter.com/whoisnnamdi\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"__GHOST_URL__/\",\"rel\",\"noopener nofollow\"]]],\"sections\":[[1,\"p\",[[0,[0,0],2,\"TL;DR: I invest in productivity-enhancing tools for software developers and other technical knowledge workers. If youâ€™re building something along these lines, ping me at nnamdi@lsvp.com\"]]],[1,\"p\",[[0,[],0,\"Iâ€™ve been obsessed with developer productivity for a long time.\"]]],[1,\"p\",[[0,[],0,\"As developments within software tooling, application infrastructure, and data science over the last decade have vindicated my quixotic enthusiasm, I thought Iâ€™d finally articulate my rationale in writing.\"]]],[1,\"p\",[[0,[],0,\"Manifestos should have mission statements. Iâ€™ve always loved \"],[0,[1],1,\"Stripeâ€™s\"],[0,[],0,\":\"]]],[1,\"blockquote\",[[0,[0,0],2,\"Our mission is to increase the GDP (gross domestic product) of the internet\"]]],[1,\"p\",[[0,[],0,\"They say great artists steal. My artistic design skills are, frankly, terrible (especially relative to Stripeâ€™s), but Iâ€™ll steal some inspiration anyway and lay out my mission as follows:\"]]],[1,\"blockquote\",[[0,[0,0],2,\"My mission is to increase total software output\"]]],[10,0],[1,\"p\",[[0,[],0,\"Developer productivity is the best way to achieve this. This essay explains why.\"]]],[1,\"p\",[[0,[],0,\"The Developer Productivity Manifesto has three parts, this is part 1:\"]]],[3,\"ul\",[[[0,[2,2],2,\"Part 1: The Developer Productivity Flywheel (you are here)\"]],[[0,[3],1,\"Part 2: More (Developers) Isnâ€™t Always More\"]],[[0,[4],1,\"Part 3: Leaving Software on the Table\"]]]],[10,1],[1,\"h2\",[[0,[],0,\"Every company is becoming a software factory\"]]],[10,2],[1,\"p\",[[0,[],0,\"Itâ€™s been said before, and itâ€™s worth repeating: \"],[0,[5],1,\"every company is becoming a software company\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Like Henry Fordâ€™s assembly line 100 years ago, which revolutionized mass production of physical goods, innovation in the production of complex, intricate software products and services promise to transform modern software development.\"]]],[1,\"p\",[[0,[],0,\"The Software Revolution \"],[0,[0,0],2,\"is\"],[0,[],0,\" the new Industrial Revolution.\"]]],[1,\"p\",[[0,[],0,\"Agile, scrum, waterfall etc. â€” the various paradigms analogize the factory assembly line and modify it for the modern context. They pose the provocative question, \"],[0,[2,2],2,\"â€œWhat can the world of bits learn from the world of atoms?â€\"]]],[1,\"p\",[[0,[],0,\"In this light, I modify the above: every company is becoming a software \"],[0,[2,2],2,\"factory\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"But analogies to old-school industry only take us so far.\"]]],[1,\"p\",[[0,[],0,\"In the factories of old, labor was poorly-skilled, poorly educated, poorly treated, and poorly compensated. Today, as before, labor remains the key input to production. However, in the modern \"],[0,[0,0],2,\"software factory\"],[0,[],0,\", labor (i.e. software developers) is highly-skilled, well-educated, well-treated (at least in more progressive companies), and mostly importantly, \"],[0,[0,0],2,\"well-paid\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"My goal as an investor and citizen of Silicon Valley is to increase total software output. Maximizing the software output requires understanding what I call, the \"],[0,[2,2],2,\"software production function\"],[0,[],0,\" â€” how we map from inputs to outputs in software development. The exact function is likely unknowable, but we know for sure developers are \"],[0,[0,0],2,\"the\"],[0,[],0,\" key input. Therefore, letâ€™s start with this simple mapping:\"]]],[10,3],[1,\"p\",[[0,[],0,\"Basic enough, but we can do better. Economists often decompose variables into the \"],[0,[0,0],2,\"extensive\"],[0,[],0,\" (â€œhow much inputâ€ / â€œhow many software developersâ€) and \"],[0,[0,0],2,\"intensive\"],[0,[],0,\" (â€œhow much per inputâ€ / â€œhow productiveâ€) margins:\"]]],[10,4],[1,\"p\",[[0,[],0,\"So, we can grow software output in two ways: \"],[0,[2,2],2,\"more developers\"],[0,[],0,\" or \"],[0,[2,2],2,\"higher developer productivity\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"Why we should care about developer productivity\"]]],[1,\"blockquote\",[[0,[0,0],0,\"â€œWhile many people posit that lack of developers is the primary problem, this studyâ€¦ found that \"],[0,[2,2],2,\"businesses need to better leverage their existing software engineering talent\"],[0,[],0,\" if they want to move faster, build new products, and tap into new and emerging trendsâ€ â€” \"],[0,[6,2,2],5,\"The Developer Coefficient 2018, Stripe\"]]],[1,\"p\",[[0,[],0,\"Software developers are the scarce, precious resource of software development â€” extremely expensive to obtain, train, and retain. \"],[0,[2,2],2,\"Anything that makes software developers more productive will itself be highly valuable.\"]]],[1,\"p\",[[0,[],0,\"However, productivity in software development tends to \"],[0,[0,0],2,\"decline\"],[0,[],0,\" over time rather than increase.\"]]],[1,\"p\",[[0,[],0,\"This is a counterintuitive claim, so letâ€™s unpack it.\"]]],[1,\"p\",[[0,[],0,\"First, it helps to delineate two different types of production â€” the production of tangible and intangible goods:\"]]],[10,5],[1,\"p\",[[0,[2,2],2,\"Tangible goods\"],[0,[],0,\" include traditional, physical products and services like cars, televisions, clothing, etc. Importantly, due to their tangibility, replicas have value. Two cars are better than one, and so on. It therefore makes sense to talk about gross â€œunitsâ€ of production â€” cars assembled, televisions manufactured, etc.\"]]],[1,\"p\",[[0,[],0,\"On the other hand, \"],[0,[2,2],2,\"intangible goods\"],[0,[],0,\" constitute non-physical products like ideas, patents, andâ€¦ software. Intangibles are infinitely reproducible at nearly zero marginal cost. As such, it doesnâ€™t make sense to measure intangible output in terms of \"],[0,[0,0],2,\"gross\"],[0,[],0,\" â€œunitsâ€™â€™ of output. Rather, only \"],[0,[0,0],2,\"net new\"],[0,[],0,\" output matters.\"]]],[1,\"p\",[[0,[],0,\"Software is one such intangible. Copying existing code is as easy as running git clone on a repository. This alone does not generate incremental value â€” the value was in writing the original code.\"]]],[1,\"p\",[[0,[],0,\"With intangibles, \"],[0,[2,2],2,\"novelty\"],[0,[],0,\" is what matters: new ideas, new designs, and new software. Thereâ€™s a reason you canâ€™t patent something already patented â€” thereâ€™d be no value in doing so. Similarly, new code moves the ball forward.\"]]],[1,\"p\",[[0,[],0,\"Letâ€™s edit our previous equation to emphasize novelty:\"]]],[10,6],[1,\"p\",[[0,[],0,\"It turns out, this trivial change makes a \"],[0,[2,2],2,\"huge\"],[0,[],0,\" difference.\"]]],[1,\"p\",[[0,[],0,\"Why? Economic evidence suggests that, unlike physical goods, idea productivity tends to decline over time. The intensive margin of the â€œidea production functionâ€, i.e. the number of new ideas generated by a given number of researchers, falls dramatically as a field progresses:\"]]],[10,7],[1,\"p\",[[0,[],0,\"â€‹Donâ€™t believe me? Hereâ€™s one example that should resonate with fellow technologists: \"],[0,[2,2],2,\"Mooreâ€™s Law\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"Are ideas getting harder to find?\"]]],[10,8],[1,\"p\",[[0,[7],1,\"Mooreâ€™s Law\"],[0,[],0,\" describes how manufacturers cram twice as many transistors onto computer chips every two years.\"]]],[1,\"p\",[[0,[],0,\"Sustaining this self-fulling prophecy of â€œ2X every 2 yearsâ€ requires massive research teams to churn out new ideas and insights around chip design and manufacturing. Itâ€™s clear from the data that Mooreâ€™s Law is not some \"],[0,[0,0],2,\"a priori\"],[0,[],0,\" law of the universe, but rather a \"],[0,[2,2],2,\"goal\"],[0,[],0,\" set by chip manufacturers and researchers:\"]]],[1,\"blockquote\",[[0,[0,0],0,\"â€œMany commentators note that Mooreâ€™s Law is not a law of nature but instead results from intense research effort: doubling the transistor density is often viewed as a goal or target for research programs.â€ â€” \"],[0,[8,2,2],5,\"Are Ideas Getting Harder to Find?\"]]],[1,\"p\",[[0,[],0,\"Transistors are tangible, but the \"],[0,[0,0],2,\"ability\"],[0,[],0,\" or \"],[0,[0,0],2,\"know-how\"],[0,[],0,\" to condense their size over time is an idea and, therefore, intangible. Intellectually, we should separate the \"],[0,[0,0],2,\"physical\"],[0,[],0,\" production of literal computer chips from the \"],[0,[0,0],2,\"ideas\"],[0,[],0,\" that enable this feat.\"]]],[1,\"p\",[[0,[],0,\"As it turns out, the old ideas just wonâ€™t do â€” what got you \"],[0,[0,0],2,\"here\"],[0,[],0,\" wonâ€™t get you \"],[0,[0,0],2,\"there\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"In a fascinating and landmark \"],[0,[8],1,\"paper\"],[0,[],0,\", Stanford and MIT economists Nicholas Bloom, Charles Jones (hey professor!), John Van Reenan, and Michael Webb frame the constant growth in the density of transistors as evidence of a constant flow of new ideas and innovations:\"]]],[10,9],[1,\"p\",[[0,[],0,\"If idea output is constant, growth in the number of researchers implies shrinking research productivity. If the flow of new ideas in semiconductor manufacturing is constant (as evidenced by Mooreâ€™s Law roughly holding steady) and the number of chip researchers increases over time, then we know (via simple arithmetic) research or idea productivity \"],[0,[2,2],2,\"must\"],[0,[],0,\" decline:\"]]],[10,10],[1,\"p\",[[0,[],0,\"â€‹And thatâ€™s exactly what we see. Generating constant growth in the number of transistors on a chip has required many more semiconductor researchers and scientists over time, \"],[0,[2,2],2,\"about 18 times as many in 2014 relative to 1971\"],[0,[],0,\":\"]]],[10,11],[1,\"p\",[[0,[],0,\"Measured in terms of transistor density gains, \"],[0,[2,2],2,\"research productivity has declined 18X over a 45-year period\"],[0,[],0,\", which is to say itâ€™s about \"],[0,[2,2],2,\"5%\"],[0,[],0,\" of what it used to be, a dramatic, precipitous decline in idea productivity. And as presented in the paper, the same phenomenon holds true in many sectors, such as agricultural and medical research.\"]]],[1,\"p\",[[0,[],0,\"The evidence is clear: \"],[0,[2,2],2,\"new ideas are hard to find and only getting harder\"],[0,[],0,\". Analogously, if we assume new software represents new ideas, it only follows that new software is increasingly difficult to create too.\"]]],[1,\"p\",[[0,[],0,\"The work of software developers is analogous to semiconductor R&D. \"],[0,[2,2],2,\"Engineering teams are tiny idea factories\"],[0,[],0,\", and new ideas get harder to produce over time.\"]]],[1,\"p\",[[0,[0,0],2,\"This\"],[0,[],0,\" is why developer productivity falls over time. The ability of software developers to write novel applications tends to decline over time, as happens in almost any idea-centric production process. When so much code has already been written, itâ€™s difficult to improve upon the status quo.\"]]],[1,\"h2\",[[0,[],0,\"The developer productivity flywheel\"]]],[1,\"p\",[[0,[],0,\"Breaking away from this gravitational, productivity-sucking force field wonâ€™t be easy. However, we can reach escape velocity by aggressively enhancing developer productivity rather than watching it deteriorate.\"]]],[1,\"p\",[[0,[],0,\"Flywheels help technology startups achieve velocity, and software development is no exception. Since no mention of flywheels in a technology essay is complete without a visualized loop, here it is:\"]]],[10,12],[1,\"p\",[[0,[],0,\"To explain:\"]]],[3,\"ol\",[[[0,[2,2],2,\"New developer productivity tools make software developers more productive.\"]]]],[1,\"p\",[[0,[],0,\"Simple enough, though we shouldnâ€™t be so naive as to think it \"],[0,[9],1,\"always works out so cleanly\"],[0,[],0,\". New tools initially impair developer productivity, as individual contributors and teams adjust to new software, interfaces, and workflows. Complex tooling can drive productivity through the ground if recklessly implemented.\"]]],[1,\"p\",[[0,[],0,\"This dynamic generates the familiar â€œJ-Curveâ€ of initially declining productivity before tangible benefits are eventually realized:\"]]],[10,13],[1,\"p\",[[0,[],0,\"So I should be precise â€” new productivity tools \"],[0,[0,0],2,\"thoughtfully applied\"],[0,[],0,\" make developers more productive. That productivity may not immediately materialize, either because itâ€™s \"],[0,[10],1,\"difficult to measure\"],[0,[],0,\" (Commits? Lines of code? Shipped releases?) or because adjustment takes time. This only reinforces the importance of investing sooner, as to frontload the trough.\"]]],[1,\"p\",[[0,[2,2],2,\"2. Higher developer productivity drives companies to hire more software engineers.\"]]],[1,\"p\",[[0,[],0,\"Remember your supply and demand curves from \"],[0,[11],1,\"economics 101\"],[0,[],0,\"? Higher productivity pushes out the developer demand curve. Companies take advantage of enhanced productivity by hiring more developers and paying them more too:\"]]],[10,14],[1,\"p\",[[0,[],0,\"In some cases, the enhanced productivity not only makes existing developers more productive but lowers the bar enough that others can now become software developers too. This pushes out the the developer supply curve, increasing employment further:\"]]],[10,15],[1,\"p\",[[0,[2,2],2,\"3. More developers working at higher productivity levels ship more software, a subset of which is itself developer productivity tooling.\"]]],[1,\"p\",[[0,[],0,\"As previously discussed, if we simply increase the number of developers without maintaining productivity, we merely tread water. Whatâ€™s crucial here is that developer productivity and employment \"],[0,[0,0],2,\"rise together\"],[0,[],0,\". If they do, we get more software output, and that new software will itself drive higher productivity.\"]]],[1,\"p\",[[0,[2,2],2,\"4. Loop\"]]],[1,\"p\",[[0,[],0,\"For the technically inclined, hereâ€™s how the logic goes in code form (much more compact ðŸ˜…):\"]]],[10,16],[1,\"p\",[[0,[],0,\"In other words:\"]]],[10,17],[1,\"p\",[[0,[],0,\"This is what I like to call, \"],[0,[2,2],2,\"the developer productivity flywheel\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"The future of productive, economical software development rests on running this flywheel as quickly as possible, iteratively looping through virtuous cycles of productivity, employment, and software output growth.\"]]],[1,\"p\",[[0,[],0,\"However, there is â€œ\"],[0,[12],1,\"no silver bullet\"],[0,[],0,\".â€ There isnâ€™t â€œone weird trickâ€ to massively supercharge developer productivity.\"]]],[1,\"p\",[[0,[],0,\"Instead, we must attack the problem from \"],[0,[0,0],2,\"every available angle\"],[0,[],0,\" if we are to succeed.\"]]],[1,\"p\",[[0,[],0,\"Ready for more? Here's \"],[0,[3],1,\"Part 2\"],[0,[],0,\". \"]]],[1,\"p\",[[0,[2,2],2,\"Follow me on \"],[0,[13,2,2],3,\"Twitter\"],[0,[2,2],2,\", subscribe to my monthly essays \"],[0,[14,2,2],3,\"here\"],[0,[2,2],2,\", and reach out to me directly via nnamdi@lsvp.com\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p><em><em>TL;DR: I invest in productivity-enhancing tools for software developers and other technical knowledge workers. If youâ€™re building something along these lines, ping me at nnamdi@lsvp.com</em></em></p><p>Iâ€™ve been obsessed with developer productivity for a long time.</p><p>As developments within software tooling, application infrastructure, and data science over the last decade have vindicated my quixotic enthusiasm, I thought Iâ€™d finally articulate my rationale in writing.</p><p>Manifestos should have mission statements. Iâ€™ve always loved <a href=\"https://stripe.com/about\" rel=\"noopener nofollow\">Stripeâ€™s</a>:</p><blockquote><em><em>Our mission is to increase the GDP (gross domestic product) of the internet</em></em></blockquote><p>They say great artists steal. My artistic design skills are, frankly, terrible (especially relative to Stripeâ€™s), but Iâ€™ll steal some inspiration anyway and lay out my mission as follows:</p><blockquote><em><em>My mission is to increase total software output</em></em></blockquote><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2021/05/image-1.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Developer productivity is the best way to achieve this. This essay explains why.</p><p>The Developer Productivity Manifesto has three parts, this is part 1:</p><ul><li><strong><strong>Part 1: The Developer Productivity Flywheel (you are here)</strong></strong></li><li><a href=\"__GHOST_URL__/more-developers-isnt-always-more/\">Part 2: More (Developers) Isnâ€™t Always More</a></li><li><a href=\"__GHOST_URL__/leaving-software-on-the-table/\">Part 3: Leaving Software on the Table</a></li></ul><!--kg-card-begin: html--><section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: The Developer Productivity Manifesto Part 1 â€” The Flywheel\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Subscribe</span></button>\n</form>\n</section><!--kg-card-end: html--><h2 id=\"every-company-is-becoming-a-software-factory\">Every company is becoming a software factory</h2><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2021/05/0_A8QJ_-v0lvk9FBMK-1.jpg\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Itâ€™s been said before, and itâ€™s worth repeating: <a href=\"https://www.confluent.io/blog/every-company-is-becoming-software/\" rel=\"noopener nofollow\">every company is becoming a software company</a>.</p><p>Like Henry Fordâ€™s assembly line 100 years ago, which revolutionized mass production of physical goods, innovation in the production of complex, intricate software products and services promise to transform modern software development.</p><p>The Software Revolution <em><em>is</em></em> the new Industrial Revolution.</p><p>Agile, scrum, waterfall etc. â€” the various paradigms analogize the factory assembly line and modify it for the modern context. They pose the provocative question, <strong><strong>â€œWhat can the world of bits learn from the world of atoms?â€</strong></strong></p><p>In this light, I modify the above: every company is becoming a software <strong><strong>factory</strong></strong>.</p><p>But analogies to old-school industry only take us so far.</p><p>In the factories of old, labor was poorly-skilled, poorly educated, poorly treated, and poorly compensated. Today, as before, labor remains the key input to production. However, in the modern <em><em>software factory</em></em>, labor (i.e. software developers) is highly-skilled, well-educated, well-treated (at least in more progressive companies), and mostly importantly, <em><em>well-paid</em></em>.</p><p>My goal as an investor and citizen of Silicon Valley is to increase total software output. Maximizing the software output requires understanding what I call, the <strong><strong>software production function</strong></strong> â€” how we map from inputs to outputs in software development. The exact function is likely unknowable, but we know for sure developers are <em><em>the</em></em> key input. Therefore, letâ€™s start with this simple mapping:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2021/05/0_Ol16aBbPuF5r3spw.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Basic enough, but we can do better. Economists often decompose variables into the <em><em>extensive</em></em> (â€œhow much inputâ€ / â€œhow many software developersâ€) and <em><em>intensive</em></em> (â€œhow much per inputâ€ / â€œhow productiveâ€) margins:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2021/05/0_NoQVuock22zuDfIb.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>So, we can grow software output in two ways: <strong><strong>more developers</strong></strong> or <strong><strong>higher developer productivity</strong></strong>.</p><h2 id=\"why-we-should-care-about-developer-productivity\">Why we should care about developer productivity</h2><blockquote><em><em>â€œWhile many people posit that lack of developers is the primary problem, this studyâ€¦ found that <strong><strong>businesses need to better leverage their existing software engineering talent</strong></strong> if they want to move faster, build new products, and tap into new and emerging trendsâ€ â€” <a href=\"https://stripe.com/files/reports/the-developer-coefficient.pdf\" rel=\"noopener nofollow\"><strong><strong>The Developer Coefficient 2018, Stripe</strong></strong></a></em></em></blockquote><p>Software developers are the scarce, precious resource of software development â€” extremely expensive to obtain, train, and retain. <strong><strong>Anything that makes software developers more productive will itself be highly valuable.</strong></strong></p><p>However, productivity in software development tends to <em><em>decline</em></em> over time rather than increase.</p><p>This is a counterintuitive claim, so letâ€™s unpack it.</p><p>First, it helps to delineate two different types of production â€” the production of tangible and intangible goods:</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2021/05/0_pmFjSDd8dI9N6Zya.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p><strong><strong>Tangible goods</strong></strong> include traditional, physical products and services like cars, televisions, clothing, etc. Importantly, due to their tangibility, replicas have value. Two cars are better than one, and so on. It therefore makes sense to talk about gross â€œunitsâ€ of production â€” cars assembled, televisions manufactured, etc.</p><p>On the other hand, <strong><strong>intangible goods</strong></strong> constitute non-physical products like ideas, patents, andâ€¦ software. Intangibles are infinitely reproducible at nearly zero marginal cost. As such, it doesnâ€™t make sense to measure intangible output in terms of <em><em>gross</em></em> â€œunitsâ€™â€™ of output. Rather, only <em><em>net new</em></em> output matters.</p><p>Software is one such intangible. Copying existing code is as easy as running git clone on a repository. This alone does not generate incremental value â€” the value was in writing the original code.</p><p>With intangibles, <strong><strong>novelty</strong></strong> is what matters: new ideas, new designs, and new software. Thereâ€™s a reason you canâ€™t patent something already patented â€” thereâ€™d be no value in doing so. Similarly, new code moves the ball forward.</p><p>Letâ€™s edit our previous equation to emphasize novelty:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2021/05/image-2.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>It turns out, this trivial change makes a <strong><strong>huge</strong></strong> difference.</p><p>Why? Economic evidence suggests that, unlike physical goods, idea productivity tends to decline over time. The intensive margin of the â€œidea production functionâ€, i.e. the number of new ideas generated by a given number of researchers, falls dramatically as a field progresses:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2021/05/image-3.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>â€‹Donâ€™t believe me? Hereâ€™s one example that should resonate with fellow technologists: <strong><strong>Mooreâ€™s Law</strong></strong>.</p><h2 id=\"are-ideas-getting-harder-to-find\">Are ideas getting harder to find?</h2><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2021/05/0_xguhYnmT9lSWPdzn.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p><a href=\"https://en.wikipedia.org/wiki/Moore's_law\" rel=\"noopener nofollow\">Mooreâ€™s Law</a> describes how manufacturers cram twice as many transistors onto computer chips every two years.</p><p>Sustaining this self-fulling prophecy of â€œ2X every 2 yearsâ€ requires massive research teams to churn out new ideas and insights around chip design and manufacturing. Itâ€™s clear from the data that Mooreâ€™s Law is not some <em><em>a priori</em></em> law of the universe, but rather a <strong><strong>goal</strong></strong> set by chip manufacturers and researchers:</p><blockquote><em><em>â€œMany commentators note that Mooreâ€™s Law is not a law of nature but instead results from intense research effort: doubling the transistor density is often viewed as a goal or target for research programs.â€ â€” <a href=\"https://web.stanford.edu/~chadj/IdeaPF.pdf\" rel=\"noopener nofollow\"><strong><strong>Are Ideas Getting Harder to Find?</strong></strong></a></em></em></blockquote><p>Transistors are tangible, but the <em><em>ability</em></em> or <em><em>know-how</em></em> to condense their size over time is an idea and, therefore, intangible. Intellectually, we should separate the <em><em>physical</em></em> production of literal computer chips from the <em><em>ideas</em></em> that enable this feat.</p><p>As it turns out, the old ideas just wonâ€™t do â€” what got you <em><em>here</em></em> wonâ€™t get you <em><em>there</em></em>.</p><p>In a fascinating and landmark <a href=\"https://web.stanford.edu/~chadj/IdeaPF.pdf\" rel=\"noopener nofollow\">paper</a>, Stanford and MIT economists Nicholas Bloom, Charles Jones (hey professor!), John Van Reenan, and Michael Webb frame the constant growth in the density of transistors as evidence of a constant flow of new ideas and innovations:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2021/05/0_jP2mHx71qNSVYIJ6.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>If idea output is constant, growth in the number of researchers implies shrinking research productivity. If the flow of new ideas in semiconductor manufacturing is constant (as evidenced by Mooreâ€™s Law roughly holding steady) and the number of chip researchers increases over time, then we know (via simple arithmetic) research or idea productivity <strong><strong>must</strong></strong> decline:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2021/05/0_S7ptnoyf9hy99zxq.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>â€‹And thatâ€™s exactly what we see. Generating constant growth in the number of transistors on a chip has required many more semiconductor researchers and scientists over time, <strong><strong>about 18 times as many in 2014 relative to 1971</strong></strong>:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2021/05/0_s5vJJ4hKzJd4QmVq.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Measured in terms of transistor density gains, <strong><strong>research productivity has declined 18X over a 45-year period</strong></strong>, which is to say itâ€™s about <strong><strong>5%</strong></strong> of what it used to be, a dramatic, precipitous decline in idea productivity. And as presented in the paper, the same phenomenon holds true in many sectors, such as agricultural and medical research.</p><p>The evidence is clear: <strong><strong>new ideas are hard to find and only getting harder</strong></strong>. Analogously, if we assume new software represents new ideas, it only follows that new software is increasingly difficult to create too.</p><p>The work of software developers is analogous to semiconductor R&amp;D. <strong><strong>Engineering teams are tiny idea factories</strong></strong>, and new ideas get harder to produce over time.</p><p><em><em>This</em></em> is why developer productivity falls over time. The ability of software developers to write novel applications tends to decline over time, as happens in almost any idea-centric production process. When so much code has already been written, itâ€™s difficult to improve upon the status quo.</p><h2 id=\"the-developer-productivity-flywheel\">The developer productivity flywheel</h2><p>Breaking away from this gravitational, productivity-sucking force field wonâ€™t be easy. However, we can reach escape velocity by aggressively enhancing developer productivity rather than watching it deteriorate.</p><p>Flywheels help technology startups achieve velocity, and software development is no exception. Since no mention of flywheels in a technology essay is complete without a visualized loop, here it is:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2021/05/image-4.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>To explain:</p><ol><li><strong><strong>New developer productivity tools make software developers more productive.</strong></strong></li></ol><p>Simple enough, though we shouldnâ€™t be so naive as to think it <a href=\"https://www.derrickreimer.com/essays/2018/03/02/the-war-on-developer-productivity.html\" rel=\"noopener nofollow\">always works out so cleanly</a>. New tools initially impair developer productivity, as individual contributors and teams adjust to new software, interfaces, and workflows. Complex tooling can drive productivity through the ground if recklessly implemented.</p><p>This dynamic generates the familiar â€œJ-Curveâ€ of initially declining productivity before tangible benefits are eventually realized:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"/content/images/2021/05/0_pTVPwZPyFQf8MbbR.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption><a href=\"https://www.primedesignprojects.com/ProductImages/IC.jpg\" rel=\"noopener nofollow\">Original version</a></figcaption></figure><p>So I should be precise â€” new productivity tools <em><em>thoughtfully applied</em></em> make developers more productive. That productivity may not immediately materialize, either because itâ€™s <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3346739\" rel=\"noopener nofollow\">difficult to measure</a> (Commits? Lines of code? Shipped releases?) or because adjustment takes time. This only reinforces the importance of investing sooner, as to frontload the trough.</p><p><strong><strong>2. Higher developer productivity drives companies to hire more software engineers.</strong></strong></p><p>Remember your supply and demand curves from <a href=\"https://www.khanacademy.org/economics-finance-domain/ap-microeconomics/factor-markets/ap-labor-marginal-product-rev/v/shifts-in-demand-for-labor\" rel=\"noopener nofollow\">economics 101</a>? Higher productivity pushes out the developer demand curve. Companies take advantage of enhanced productivity by hiring more developers and paying them more too:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2021/05/0__phAC3txzmraNUQN.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>In some cases, the enhanced productivity not only makes existing developers more productive but lowers the bar enough that others can now become software developers too. This pushes out the the developer supply curve, increasing employment further:</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2021/05/0_f1Yu2MIu3fMkyDFN.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p><strong><strong>3. More developers working at higher productivity levels ship more software, a subset of which is itself developer productivity tooling.</strong></strong></p><p>As previously discussed, if we simply increase the number of developers without maintaining productivity, we merely tread water. Whatâ€™s crucial here is that developer productivity and employment <em><em>rise together</em></em>. If they do, we get more software output, and that new software will itself drive higher productivity.</p><p><strong><strong>4. Loop</strong></strong></p><p>For the technically inclined, hereâ€™s how the logic goes in code form (much more compact ðŸ˜…):</p><figure class=\"kg-card kg-image-card\"><img src=\"/content/images/2021/05/dev_prod_flywheel.py.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>In other words:</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2021/05/0_6kZsFEsFISGZIQMY.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>This is what I like to call, <strong><strong>the developer productivity flywheel</strong></strong>.</p><p>The future of productive, economical software development rests on running this flywheel as quickly as possible, iteratively looping through virtuous cycles of productivity, employment, and software output growth.</p><p>However, there is â€œ<a href=\"https://www.cgl.ucsf.edu/Outreach/pc204/NoSilverBullet.html\" rel=\"noopener nofollow\">no silver bullet</a>.â€ There isnâ€™t â€œone weird trickâ€ to massively supercharge developer productivity.</p><p>Instead, we must attack the problem from <em><em>every available angle</em></em> if we are to succeed.</p><p>Ready for more? Here's <a href=\"__GHOST_URL__/more-developers-isnt-always-more/\">Part 2</a>. </p><p><strong><strong>Follow me on </strong></strong><a href=\"https://twitter.com/whoisnnamdi\" rel=\"noopener nofollow\"><strong><strong>Twitter</strong></strong></a><strong><strong>, subscribe to my monthly essays </strong></strong><a href=\"__GHOST_URL__/\" rel=\"noopener nofollow\"><strong><strong>here</strong></strong></a><strong><strong>, and reach out to me directly via nnamdi@lsvp.com</strong></strong></p>","comment_id":"609b6a4317b26d3ef80d6722","plaintext":"TL;DR: I invest in productivity-enhancing tools for software developers and\nother technical knowledge workers. If youâ€™re building something along these\nlines, ping me at nnamdi@lsvp.com\n\nIâ€™ve been obsessed with developer productivity for a long time.\n\nAs developments within software tooling, application infrastructure, and data\nscience over the last decade have vindicated my quixotic enthusiasm, I thought\nIâ€™d finally articulate my rationale in writing.\n\nManifestos should have mission statements. Iâ€™ve always loved Stripeâ€™s\n[https://stripe.com/about]:\n\n> Our mission is to increase the GDP (gross domestic product) of the internet\nThey say great artists steal. My artistic design skills are, frankly, terrible\n(especially relative to Stripeâ€™s), but Iâ€™ll steal some inspiration anyway and\nlay out my mission as follows:\n\n> My mission is to increase total software output\nDeveloper productivity is the best way to achieve this. This essay explains why.\n\nThe Developer Productivity Manifesto has three parts, this is part 1:\n\n * Part 1: The Developer Productivity Flywheel (you are here)\n * Part 2: More (Developers) Isnâ€™t Always More\n   [__GHOST_URL__/more-developers-isnt-always-more/]\n * Part 3: Leaving Software on the Table\n   [__GHOST_URL__/leaving-software-on-the-table/]\n\nReceive my next long-form post\nThoughtful analysis of the business and economics of tech\n\n\n\nSubscribeEvery company is becoming a software factory\nItâ€™s been said before, and itâ€™s worth repeating: every company is becoming a\nsoftware company\n[https://www.confluent.io/blog/every-company-is-becoming-software/].\n\nLike Henry Fordâ€™s assembly line 100 years ago, which revolutionized mass\nproduction of physical goods, innovation in the production of complex, intricate\nsoftware products and services promise to transform modern software development.\n\nThe Software Revolution is the new Industrial Revolution.\n\nAgile, scrum, waterfall etc. â€” the various paradigms analogize the factory\nassembly line and modify it for the modern context. They pose the provocative\nquestion, â€œWhat can the world of bits learn from the world of atoms?â€\n\nIn this light, I modify the above: every company is becoming a software factory.\n\nBut analogies to old-school industry only take us so far.\n\nIn the factories of old, labor was poorly-skilled, poorly educated, poorly\ntreated, and poorly compensated. Today, as before, labor remains the key input\nto production. However, in the modern software factory, labor (i.e. software\ndevelopers) is highly-skilled, well-educated, well-treated (at least in more\nprogressive companies), and mostly importantly, well-paid.\n\nMy goal as an investor and citizen of Silicon Valley is to increase total\nsoftware output. Maximizing the software output requires understanding what I\ncall, the software production function â€” how we map from inputs to outputs in\nsoftware development. The exact function is likely unknowable, but we know for\nsure developers are the key input. Therefore, letâ€™s start with this simple\nmapping:\n\nBasic enough, but we can do better. Economists often decompose variables into\nthe extensive (â€œhow much inputâ€ / â€œhow many software developersâ€) and intensive \n(â€œhow much per inputâ€ / â€œhow productiveâ€) margins:\n\nSo, we can grow software output in two ways: more developers or higher developer\nproductivity.\n\nWhy we should care about developer productivity\n> â€œWhile many people posit that lack of developers is the primary problem, this\nstudyâ€¦ found that businesses need to better leverage their existing software\nengineering talent if they want to move faster, build new products, and tap into\nnew and emerging trendsâ€ â€” The Developer Coefficient 2018, Stripe\n[https://stripe.com/files/reports/the-developer-coefficient.pdf]\nSoftware developers are the scarce, precious resource of software development â€”\nextremely expensive to obtain, train, and retain. Anything that makes software\ndevelopers more productive will itself be highly valuable.\n\nHowever, productivity in software development tends to decline over time rather\nthan increase.\n\nThis is a counterintuitive claim, so letâ€™s unpack it.\n\nFirst, it helps to delineate two different types of production â€” the production\nof tangible and intangible goods:\n\nTangible goods include traditional, physical products and services like cars,\ntelevisions, clothing, etc. Importantly, due to their tangibility, replicas have\nvalue. Two cars are better than one, and so on. It therefore makes sense to talk\nabout gross â€œunitsâ€ of production â€” cars assembled, televisions manufactured,\netc.\n\nOn the other hand, intangible goods constitute non-physical products like ideas,\npatents, andâ€¦ software. Intangibles are infinitely reproducible at nearly zero\nmarginal cost. As such, it doesnâ€™t make sense to measure intangible output in\nterms of gross â€œunitsâ€™â€™ of output. Rather, only net new output matters.\n\nSoftware is one such intangible. Copying existing code is as easy as running git\nclone on a repository. This alone does not generate incremental value â€” the\nvalue was in writing the original code.\n\nWith intangibles, novelty is what matters: new ideas, new designs, and new\nsoftware. Thereâ€™s a reason you canâ€™t patent something already patented â€” thereâ€™d\nbe no value in doing so. Similarly, new code moves the ball forward.\n\nLetâ€™s edit our previous equation to emphasize novelty:\n\nIt turns out, this trivial change makes a huge difference.\n\nWhy? Economic evidence suggests that, unlike physical goods, idea productivity\ntends to decline over time. The intensive margin of the â€œidea production\nfunctionâ€, i.e. the number of new ideas generated by a given number of\nresearchers, falls dramatically as a field progresses:\n\nâ€‹Donâ€™t believe me? Hereâ€™s one example that should resonate with fellow\ntechnologists: Mooreâ€™s Law.\n\nAre ideas getting harder to find?\nMooreâ€™s Law [https://en.wikipedia.org/wiki/Moore's_law] describes how\nmanufacturers cram twice as many transistors onto computer chips every two\nyears.\n\nSustaining this self-fulling prophecy of â€œ2X every 2 yearsâ€ requires massive\nresearch teams to churn out new ideas and insights around chip design and\nmanufacturing. Itâ€™s clear from the data that Mooreâ€™s Law is not some a priori \nlaw of the universe, but rather a goal set by chip manufacturers and\nresearchers:\n\n> â€œMany commentators note that Mooreâ€™s Law is not a law of nature but instead\nresults from intense research effort: doubling the transistor density is often\nviewed as a goal or target for research programs.â€ â€” Are Ideas Getting Harder\nto\nFind? [https://web.stanford.edu/~chadj/IdeaPF.pdf]\nTransistors are tangible, but the ability or know-how to condense their size\nover time is an idea and, therefore, intangible. Intellectually, we should\nseparate the physical production of literal computer chips from the ideas that\nenable this feat.\n\nAs it turns out, the old ideas just wonâ€™t do â€” what got you here wonâ€™t get you \nthere.\n\nIn a fascinating and landmark paper [https://web.stanford.edu/~chadj/IdeaPF.pdf]\n, Stanford and MIT economists Nicholas Bloom, Charles Jones (hey professor!),\nJohn Van Reenan, and Michael Webb frame the constant growth in the density of\ntransistors as evidence of a constant flow of new ideas and innovations:\n\nIf idea output is constant, growth in the number of researchers implies\nshrinking research productivity. If the flow of new ideas in semiconductor\nmanufacturing is constant (as evidenced by Mooreâ€™s Law roughly holding steady)\nand the number of chip researchers increases over time, then we know (via simple\narithmetic) research or idea productivity must decline:\n\nâ€‹And thatâ€™s exactly what we see. Generating constant growth in the number of\ntransistors on a chip has required many more semiconductor researchers and\nscientists over time, about 18 times as many in 2014 relative to 1971:\n\nMeasured in terms of transistor density gains, research productivity has\ndeclined 18X over a 45-year period, which is to say itâ€™s about 5% of what it\nused to be, a dramatic, precipitous decline in idea productivity. And as\npresented in the paper, the same phenomenon holds true in many sectors, such as\nagricultural and medical research.\n\nThe evidence is clear: new ideas are hard to find and only getting harder.\nAnalogously, if we assume new software represents new ideas, it only follows\nthat new software is increasingly difficult to create too.\n\nThe work of software developers is analogous to semiconductor R&D. Engineering\nteams are tiny idea factories, and new ideas get harder to produce over time.\n\nThis is why developer productivity falls over time. The ability of software\ndevelopers to write novel applications tends to decline over time, as happens in\nalmost any idea-centric production process. When so much code has already been\nwritten, itâ€™s difficult to improve upon the status quo.\n\nThe developer productivity flywheel\nBreaking away from this gravitational, productivity-sucking force field wonâ€™t be\neasy. However, we can reach escape velocity by aggressively enhancing developer\nproductivity rather than watching it deteriorate.\n\nFlywheels help technology startups achieve velocity, and software development is\nno exception. Since no mention of flywheels in a technology essay is complete\nwithout a visualized loop, here it is:\n\nTo explain:\n\n 1. New developer productivity tools make software developers more productive.\n\nSimple enough, though we shouldnâ€™t be so naive as to think it always works out\nso cleanly\n[https://www.derrickreimer.com/essays/2018/03/02/the-war-on-developer-productivity.html]\n. New tools initially impair developer productivity, as individual contributors\nand teams adjust to new software, interfaces, and workflows. Complex tooling can\ndrive productivity through the ground if recklessly implemented.\n\nThis dynamic generates the familiar â€œJ-Curveâ€ of initially declining\nproductivity before tangible benefits are eventually realized:\n\nOriginal version [https://www.primedesignprojects.com/ProductImages/IC.jpg]So I\nshould be precise â€” new productivity tools thoughtfully applied make developers\nmore productive. That productivity may not immediately materialize, either\nbecause itâ€™s difficult to measure\n[https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3346739] (Commits? Lines of\ncode? Shipped releases?) or because adjustment takes time. This only reinforces\nthe importance of investing sooner, as to frontload the trough.\n\n2. Higher developer productivity drives companies to hire more software\nengineers.\n\nRemember your supply and demand curves from economics 101\n[https://www.khanacademy.org/economics-finance-domain/ap-microeconomics/factor-markets/ap-labor-marginal-product-rev/v/shifts-in-demand-for-labor]\n? Higher productivity pushes out the developer demand curve. Companies take\nadvantage of enhanced productivity by hiring more developers and paying them\nmore too:\n\nIn some cases, the enhanced productivity not only makes existing developers more\nproductive but lowers the bar enough that others can now become software\ndevelopers too. This pushes out the the developer supply curve, increasing\nemployment further:\n\n3. More developers working at higher productivity levels ship more software, a\nsubset of which is itself developer productivity tooling.\n\nAs previously discussed, if we simply increase the number of developers without\nmaintaining productivity, we merely tread water. Whatâ€™s crucial here is that\ndeveloper productivity and employment rise together. If they do, we get more\nsoftware output, and that new software will itself drive higher productivity.\n\n4. Loop\n\nFor the technically inclined, hereâ€™s how the logic goes in code form (much more\ncompact ðŸ˜…):\n\nIn other words:\n\nThis is what I like to call, the developer productivity flywheel.\n\nThe future of productive, economical software development rests on running this\nflywheel as quickly as possible, iteratively looping through virtuous cycles of\nproductivity, employment, and software output growth.\n\nHowever, there is â€œno silver bullet\n[https://www.cgl.ucsf.edu/Outreach/pc204/NoSilverBullet.html].â€ There isnâ€™t â€œone\nweird trickâ€ to massively supercharge developer productivity.\n\nInstead, we must attack the problem from every available angle if we are to\nsucceed.\n\nReady for more? Here's Part 2 [__GHOST_URL__/more-developers-isnt-always-more/]. \n\nFollow me on Twitter [https://twitter.com/whoisnnamdi], subscribe to my monthly\nessays here [__GHOST_URL__/], and reach out to me directly via nnamdi@lsvp.com","feature_image":"__GHOST_URL__/content/images/2021/05/header.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2021-05-12T05:40:19.000Z","updated_at":"2021-06-20T22:42:18.000Z","published_at":"2021-03-31T05:40:00.000Z","custom_excerpt":"Developer productivity is falling. But it doesn't have to. The solution? The Developer Productivity Flywheel","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"609b702517b26d3ef80d677e","uuid":"23fd08ed-7b37-4904-9d32-b9e876473e5c","title":"The Developer Productivity Manifesto Part 2 â€” More (Developers) Isnâ€™t Always More","slug":"more-developers-isnt-always-more","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: The Developer Productivity Manifesto Part 2 â€” More (Developers) Isnâ€™t Always More\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Subscribe</span></button>\\n</form>\\n</section>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/05/image-20210405202322027.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/size/w2000/2021/05/ballmer_600.gif\",\"alt\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/05/image-20210405115615714.png\",\"caption\":\"<a href=\\\"https://boycewire.com/types-of-diseconomies-of-scale/\\\" rel=\\\"noopener nofollow\\\">Source</a>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/05/image-20210405115744208.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/05/0_4RM_2yR4dbE_6mb5.png\",\"caption\":\"<a href=\\\"https://web.stanford.edu/~chadj/IdeaPF.pdf\\\" rel=\\\"noopener nofollow\\\">Source</a>\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/05/0_NHviru2DykbIv-9N.png\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/05/image-5.png\"}]],\"markups\":[[\"a\",[\"href\",\"__GHOST_URL__/the-developer-productivity-flywheel/\"]],[\"em\"],[\"strong\"],[\"a\",[\"href\",\"__GHOST_URL__/leaving-software-on-the-table/\"]],[\"a\",[\"href\",\"https://www.amazon.com/Mythical-Man-Month-Software-Engineering-Anniversary/dp/0201835959\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Brooks%27s_law\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://redbeardlab.com/2020/01/19/software-is-a-focus-intensive-industry/\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://stripe.com/files/reports/the-developer-coefficient.pdf\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"__GHOST_URL__/never-enough-developers/\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"http://drock.mit.edu/sites/default/files/documents/techMV_mostrecent.pdf\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://twitter.com/whoisnnamdi\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"__GHOST_URL__/\",\"rel\",\"noopener nofollow\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"In software development, more (developers) isnâ€™t always more.\"]]],[1,\"p\",[[0,[],0,\"In \"],[0,[0],1,\"part 1\"],[0,[],0,\" of â€œThe Developer Productivity Manifesto,â€ I argued that developer productivity, measured in terms of new software, falls over time as low-hanging fruit is picked and new ideas become harder to find.\"]]],[1,\"p\",[[0,[],0,\"An understandable response would be â€” why not just throw more engineers at the problem?\"]]],[1,\"p\",[[0,[],0,\"If youâ€™ve ever worked in software development, you know adding more cooks to the kitchen rarely helps. For those who \"],[0,[1,1],2,\"havenâ€™t\"],[0,[],0,\" worked in software development, this essay tells you why.\"]]],[1,\"p\",[[0,[],0,\"The Developer Productivity Manifesto has three parts, this is part 2:\"]]],[3,\"ul\",[[[0,[0],1,\"Part 1: The Developer Productivity Flywheel\"]],[[0,[2,2],2,\"Part 2: More (Developers) Isnâ€™t Always More (you are here)\"]],[[0,[3],1,\"Part 3: Leaving Software on the Table\"]]]],[10,0],[1,\"h2\",[[0,[],0,\"The Mythical Man-Month\"]]],[10,1],[1,\"p\",[[0,[4],1,\"â€œThe Mythical Man-Month\"],[0,[],0,\"â€ is a classic and hugely influential book about software engineering and project management. Across a series of essays, Fred Brooks (himself a former IBM project manager) lays out the cognitive errors software development teams tend to make in estimating the time to completion for software projects. His core thesis is best encapsulated by \"],[0,[5],1,\"Brooksâ€™ law\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Brooksâ€™ law of software project management states that:\"]]],[1,\"blockquote\",[[0,[1,1],2,\"Adding manpower to a late software project makes it later\"]]],[1,\"p\",[[0,[],0,\"If anything, adding more cooks to the kitchen \"],[0,[1,1],2,\"lengthens\"],[0,[],0,\" cooking time. We shouldnâ€™t assume a simple, linear, and directly causal relationship between developers as inputs and software as output. He lays this out in dire terms:\"]]],[1,\"blockquote\",[[0,[1,1],0,\"â€¦ when schedule slippage is recognized, the natural (and traditional) response is to add manpower. Like dousing a fire with gasoline, \"],[0,[2,2],2,\"this makes matters worse, much worse\"],[0,[],2,\". More fire requires more gasoline, and thus begins a regenerative cycle which ends in disaster.\"]]],[10,2],[1,\"p\",[[0,[],0,\"This counterintuitive phenomenon has multiple causes:\"]]],[3,\"ul\",[[[0,[2,2],2,\"Ramp up time:\"],[0,[],0,\" Even seasoned developers take time to get up to speed on new projects, and newbie engineers must learn core skills on top of company-specific ones\"]],[[0,[2,2],2,\"Communication and coordination complexity:\"],[0,[],0,\" The larger the team, the harder it is to coordinate productive work and communicate progress across teammates\"]],[[0,[2,2],2,\"Indivisibility of work:\"],[0,[],0,\" The basic unit of work in software development canâ€™t always be divided among multiple contributors\"]]]],[1,\"p\",[[0,[],0,\"That last point forms the basis of the title and main thrust of the book, the fallacy of â€œman-monthsâ€ â€” distinct units of work achievable by a single developer in a set period of time. As Brooks argues, there is no such thing, and thus we should be wary of simplistic solutions to complex endeavors like software development.\"]]],[1,\"blockquote\",[[0,[1,1],0,\"Software is not labor-intensive. Not many people are necessary in order to produce good softwareâ€¦ What makes or breaks a project, itâ€™s the amount of FOCUS developers can pour into it â€” \"],[0,[6],3,\"RedBeardLab\"]]],[1,\"h2\",[[0,[],0,\"Diseconomies of scale\"]]],[10,3],[1,\"p\",[[0,[],0,\"While it is common to assume \"],[0,[1,1],2,\"economies of scale\"],[0,[],0,\", \"],[0,[2,2],2,\"diseconomies of scale\"],[0,[],0,\" are arguably just as relevant in software development.\"]]],[1,\"p\",[[0,[],0,\"Diseconomies of scale are where unit costs (the costs of producing an additional unit of output) increase rather than decrease with scale. Here, itâ€™s better to \"],[0,[1,1],2,\"cut back\"],[0,[],0,\" or \"],[0,[1,1],2,\"lower\"],[0,[],0,\" output, rather than maximize it. Despite many advances, these occur more often than weâ€™d like to admit in modern software development.\"]]],[1,\"p\",[[0,[],0,\"Diseconomies of scale can take many forms, and many overlap with the underlying causes behind the mythical â€œman-monthâ€:\"]]],[3,\"ul\",[[[0,[2,2],2,\"Complexity:\"],[0,[],0,\" Things become disproportionately complex as they scale, as complexity increases non-linearly with size. Complexity creates overhead, making large organizations less efficient than medium-sized ones. Bureaucracy is one manifestation, but there are others.\"]],[[0,[2,2],2,\"Black Swans:\"],[0,[],0,\" Large systems fail in spectacular fashion. Itâ€™s why big companies create systemic risk while small businesses and startups fail in the thousands without cause for alarm. Within software, this might be a large monolithic application, prone to serious, single point failures.\"]]]],[1,\"p\",[[0,[],0,\"Humans, being the independent and unpredictable automatons we are, are especially prone to diseconomies of scale. Coordination costs eventually overwhelm even the most thoughtful engineering leaders. Application deployments are themselves quite brittle, necessitating vastly more manpower and attention as they grow.\"]]],[1,\"h2\",[[0,[],0,\"We will never have enough software developers\"]]],[1,\"blockquote\",[[0,[1,1],0,\"Senior executives report that the lack of developer talent is one of the biggest potential threats to their businesses â€” \"],[0,[7],3,\"The Developer Coefficient 2018, Stripe\"]]],[1,\"p\",[[0,[],0,\"Executives believe that insufficient developer talent is one of the biggest threats to their business, and yet thereâ€™s good reason to think this might never be solved.\"]]],[10,4],[1,\"p\",[[0,[],0,\"As I discuss in a previous essay, \"],[0,[8],1,\"Why We Will Never Have Enough Software Developers\"],[0,[],0,\", changes in the underlying technologies of modern software development whittle away the accumulated human capital of software developers:\"]]],[1,\"blockquote\",[[0,[1,1,2,2],2,\"Specific skills in software development quickly become dated.\"],[0,[],2,\" Programming languages and development frameworks go out of style. Hadoop is hot one year, and itâ€™s old news the next. Like a fast, expensive car that quickly loses value as itâ€™s driven around town, the skills and human capital of software engineers fall apart without constant, expensive maintenance\"]]],[1,\"p\",[[0,[],0,\"Though young engineers can keep up with the latest programming languages, frameworks, and tooling, eventually the torrential wave of new tools becomes too much to bear, and developers either tune out or drop out:\"]]],[1,\"blockquote\",[[0,[1,1],0,\"At age 26, 59% of engineering and computer science grads work in occupations related to their field of study. By age 50, only 41% work in the same domain, meaning a full \"],[0,[2,2],4,\"~30% drop out of the field by mid-career\"]]],[1,\"p\",[[0,[],0,\"The never-ending drumbeat of new technologies drives developers out of the field. New tooling is important and valuable, but their overall effect on developer productivity depends on how much they upend existing workflows and place additional burden on already taxed developers.\"]]],[1,\"p\",[[0,[],0,\"As I conclude:\"]]],[1,\"blockquote\",[[0,[1,1,2,2],2,\"Growing the supply of software developers is not trivial\"],[0,[],2,\" because the field already sees high levels of developer dropout and turnover, and this would only increase if the field were to grow larger.\"]]],[1,\"p\",[[0,[],0,\"I favor efforts to grow the software engineering talent pool, but if weâ€™re not careful, like quicksand, our efforts will be counterproductive.\"]]],[1,\"h2\",[[0,[],0,\"More developers, lower productivity\"]]],[1,\"p\",[[0,[],0,\"As we saw in part 1, more researchers donâ€™t necessarily lead to faster progress. In the case of Mooreâ€™s Law, it merely maintains the rate of progress, at significant expense.\"]]],[1,\"p\",[[0,[],0,\"But is this true of the economy overall? It turns out, the answer is yes. Cross-industry data proves that simply throwing more people at a problem doesnâ€™t work.\"]]],[1,\"p\",[[0,[],0,\"The chart below plots the growth in the number of employed researchers and their productivity levels (measured in terms of revenue growth generated per researcher) for ~1,700 publicly-traded U.S.-based companies over a 20-year period. Most firms â€œthrew more bodies at the problemâ€ (orange histogram > 1), but \"],[0,[2,2],2,\"~80% of firms saw declining research productivity\"],[0,[],0,\" (blue histogram < 1):\"]]],[10,5],[1,\"p\",[[0,[],0,\"Hiring more researchers doesnâ€™t necessarily \"],[0,[1,1],2,\"cause\"],[0,[],0,\" productivity to decline, but regardless, growing research teams and declining productivity go hand-in-hand more often than not.\"]]],[1,\"p\",[[0,[],0,\"Software development could fall prey to the same trap. Most companies are growing the number of software engineers they employ, mirroring the researcher employment trends, but letâ€™s not forget productivity:\"]]],[10,6],[1,\"p\",[[0,[],0,\"Research productivity, and analogously developer productivity, falls over time unless acted upon by an outside force. Like gravity, this phenomenon is pervasive and ubiquitous, a force field dragging down all idea-generative industries.\"]]],[1,\"h2\",[[0,[],0,\"Busy work doesnâ€™t work\"]]],[1,\"p\",[[0,[],0,\"I love this quote from Stripe:\"]]],[1,\"blockquote\",[[0,[1,1],0,\"Despite the number of developers increasing year-over-year at most companies, \"],[0,[2,2],2,\"developers working on the right things can accelerate a companyâ€™s move into new markets or product areas and help companies differentiate themselves at disproportionate rates.\"],[0,[],0,\" This underscores the most important point about developers as force-multipliers: \"],[0,[2,2],2,\"Itâ€™s not just how many devs companies have; itâ€™s also how theyâ€™re being leveraged\"],[0,[],0,\" â€” \"],[0,[7],3,\"The Developer Coefficient 2018, Stripe\"]]],[1,\"p\",[[0,[],0,\"In my last essay I talked about the importance of measuring productivity in terms of new software output. Another reason why more engineers is not necessarily the solution is that much of the value of the marginal engineer is in their \"],[0,[2,2],2,\"innovation\"],[0,[],0,\" activities rather than their \"],[0,[1,1],2,\"maintenance\"],[0,[],0,\" work.\"]]],[1,\"p\",[[0,[],0,\"We can quantify the impact of engineering time spent maintaining old code rather than writing new code. According to \"],[0,[9],1,\"one analysis\"],[0,[],0,\", an engineer engaged in purely non-innovative activity \"],[0,[1,1],2,\"destroys\"],[0,[],0,\" nearly $600K in employer market value. On the other hand, the average engineer, working on a combination of maintenance and innovation activities, \"],[0,[2,2],2,\"adds\"],[0,[],0,\" $855K in market value to their employer.\"]]],[10,7],[1,\"p\",[[0,[],0,\"As the studyâ€™s author speculates:\"]]],[1,\"blockquote\",[[0,[1,1],0,\"â€¦ the value of the engineer is a bundled combination of \"],[0,[2,2],2,\"maintenance activities which have negative value\"],[0,[],0,\" and \"],[0,[2,2],4,\"innovation activities with positive value\"]]],[1,\"p\",[[0,[],0,\"Further, he echoes Brookâ€™s Law:\"]]],[1,\"blockquote\",[[0,[1,1],0,\"It may also be the case that \"],[0,[2,2],2,\"more engineers does not always make for easier problem solving\"],[0,[],2,\" and on the margin, removing innovative activity, [they are] a net drain on the firmâ€™s value\"]]],[1,\"p\",[[0,[],0,\"I want to be clear: maintenance matters too. When things break, as they inevitably do, development teams must stand at the ready to fix problems and bring systems back online. This is critical work that should not be minimized in a narrow pursuit of newer, shinier objects.\"]]],[1,\"p\",[[0,[],0,\"That said, mere maintenance is table stakes. It doesnâ€™t pay the bills â€” an engineerâ€™s salary, first and foremost.\"]]],[1,\"h2\",[[0,[],0,\"Hidden figures\"]]],[1,\"p\",[[0,[],0,\"Again, Stripe gets it right:\"]]],[1,\"blockquote\",[[0,[1,1],0,\"While many people posit that lack of developers is the primary problem, this studyâ€¦ found that \"],[0,[2,2],2,\"businesses need to better leverage their existing software engineering talent\"],[0,[],0,\" if they want to move \"],[0,[2,2],2,\"faster\"],[0,[],0,\", build \"],[0,[2,2],2,\"new\"],[0,[],0,\" products, and tap into \"],[0,[2,2],2,\"new and emerging\"],[0,[],0,\" trends â€” \"],[0,[7,2,2],5,\"The Developer Coefficient 2018, Stripe\"]]],[1,\"p\",[[0,[],0,\"Notice the emphasis on newness and speed. We can and should grow the talent pool for software engineering, but we can also do a much better job with the engineering talent \"],[0,[1,1],2,\"we already have\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Maintenance matters but so does fundamental innovation. As software projects grow, and their teams with them, thoughtful engineering managers must strike the right balance or see their most precious resource go to waste.\"]]],[1,\"p\",[[0,[],0,\"Industry-wide we are, unfortunately, out of balance. In my next and final piece, Iâ€™ll explore exactly how much software weâ€™re â€œleaving on the tableâ€ as a result.\"]]],[1,\"p\",[[0,[],0,\"Ready for more? Here's \"],[0,[3],1,\"Part 3\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[2,2],2,\"Follow me on \"],[0,[10,2,2],3,\"Twitter\"],[0,[2,2],2,\", subscribe to my monthly essays \"],[0,[11,2,2],3,\"here\"],[0,[2,2],2,\", and reach out to me directly via nnamdi@lsvp.com\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p>In software development, more (developers) isnâ€™t always more.</p><p>In <a href=\"__GHOST_URL__/the-developer-productivity-flywheel/\">part 1</a> of â€œThe Developer Productivity Manifesto,â€ I argued that developer productivity, measured in terms of new software, falls over time as low-hanging fruit is picked and new ideas become harder to find.</p><p>An understandable response would be â€” why not just throw more engineers at the problem?</p><p>If youâ€™ve ever worked in software development, you know adding more cooks to the kitchen rarely helps. For those who <em><em>havenâ€™t</em></em> worked in software development, this essay tells you why.</p><p>The Developer Productivity Manifesto has three parts, this is part 2:</p><ul><li><a href=\"__GHOST_URL__/the-developer-productivity-flywheel/\">Part 1: The Developer Productivity Flywheel</a></li><li><strong><strong>Part 2: More (Developers) Isnâ€™t Always More (you are here)</strong></strong></li><li><a href=\"__GHOST_URL__/leaving-software-on-the-table/\">Part 3: Leaving Software on the Table</a></li></ul><!--kg-card-begin: html--><section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: The Developer Productivity Manifesto Part 2 â€” More (Developers) Isnâ€™t Always More\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Subscribe</span></button>\n</form>\n</section><!--kg-card-end: html--><h2 id=\"the-mythical-man-month\">The Mythical Man-Month</h2><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/05/image-20210405202322027.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p><a href=\"https://www.amazon.com/Mythical-Man-Month-Software-Engineering-Anniversary/dp/0201835959\" rel=\"noopener nofollow\">â€œThe Mythical Man-Month</a>â€ is a classic and hugely influential book about software engineering and project management. Across a series of essays, Fred Brooks (himself a former IBM project manager) lays out the cognitive errors software development teams tend to make in estimating the time to completion for software projects. His core thesis is best encapsulated by <a href=\"https://en.wikipedia.org/wiki/Brooks%27s_law\" rel=\"noopener nofollow\">Brooksâ€™ law</a>.</p><p>Brooksâ€™ law of software project management states that:</p><blockquote><em><em>Adding manpower to a late software project makes it later</em></em></blockquote><p>If anything, adding more cooks to the kitchen <em><em>lengthens</em></em> cooking time. We shouldnâ€™t assume a simple, linear, and directly causal relationship between developers as inputs and software as output. He lays this out in dire terms:</p><blockquote><em><em>â€¦ when schedule slippage is recognized, the natural (and traditional) response is to add manpower. Like dousing a fire with gasoline, <strong><strong>this makes matters worse, much worse</strong></strong>. More fire requires more gasoline, and thus begins a regenerative cycle which ends in disaster.</em></em></blockquote><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/size/w2000/2021/05/ballmer_600.gif\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>This counterintuitive phenomenon has multiple causes:</p><ul><li><strong><strong>Ramp up time:</strong></strong> Even seasoned developers take time to get up to speed on new projects, and newbie engineers must learn core skills on top of company-specific ones</li><li><strong><strong>Communication and coordination complexity:</strong></strong> The larger the team, the harder it is to coordinate productive work and communicate progress across teammates</li><li><strong><strong>Indivisibility of work:</strong></strong> The basic unit of work in software development canâ€™t always be divided among multiple contributors</li></ul><p>That last point forms the basis of the title and main thrust of the book, the fallacy of â€œman-monthsâ€ â€” distinct units of work achievable by a single developer in a set period of time. As Brooks argues, there is no such thing, and thus we should be wary of simplistic solutions to complex endeavors like software development.</p><blockquote><em><em>Software is not labor-intensive. Not many people are necessary in order to produce good softwareâ€¦ What makes or breaks a project, itâ€™s the amount of FOCUS developers can pour into it â€” <a href=\"https://redbeardlab.com/2020/01/19/software-is-a-focus-intensive-industry/\" rel=\"noopener nofollow\">RedBeardLab</a></em></em></blockquote><h2 id=\"diseconomies-of-scale\">Diseconomies of scale</h2><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/05/image-20210405115615714.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption><a href=\"https://boycewire.com/types-of-diseconomies-of-scale/\" rel=\"noopener nofollow\">Source</a></figcaption></figure><p>While it is common to assume <em><em>economies of scale</em></em>, <strong><strong>diseconomies of scale</strong></strong> are arguably just as relevant in software development.</p><p>Diseconomies of scale are where unit costs (the costs of producing an additional unit of output) increase rather than decrease with scale. Here, itâ€™s better to <em><em>cut back</em></em> or <em><em>lower</em></em> output, rather than maximize it. Despite many advances, these occur more often than weâ€™d like to admit in modern software development.</p><p>Diseconomies of scale can take many forms, and many overlap with the underlying causes behind the mythical â€œman-monthâ€:</p><ul><li><strong><strong>Complexity:</strong></strong> Things become disproportionately complex as they scale, as complexity increases non-linearly with size. Complexity creates overhead, making large organizations less efficient than medium-sized ones. Bureaucracy is one manifestation, but there are others.</li><li><strong><strong>Black Swans:</strong></strong> Large systems fail in spectacular fashion. Itâ€™s why big companies create systemic risk while small businesses and startups fail in the thousands without cause for alarm. Within software, this might be a large monolithic application, prone to serious, single point failures.</li></ul><p>Humans, being the independent and unpredictable automatons we are, are especially prone to diseconomies of scale. Coordination costs eventually overwhelm even the most thoughtful engineering leaders. Application deployments are themselves quite brittle, necessitating vastly more manpower and attention as they grow.</p><h2 id=\"we-will-never-have-enough-software-developers\">We will never have enough software developers</h2><blockquote><em><em>Senior executives report that the lack of developer talent is one of the biggest potential threats to their businesses â€” <a href=\"https://stripe.com/files/reports/the-developer-coefficient.pdf\" rel=\"noopener nofollow\">The Developer Coefficient 2018, Stripe</a></em></em></blockquote><p>Executives believe that insufficient developer talent is one of the biggest threats to their business, and yet thereâ€™s good reason to think this might never be solved.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/05/image-20210405115744208.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>As I discuss in a previous essay, <a href=\"__GHOST_URL__/never-enough-developers/\" rel=\"noopener nofollow\">Why We Will Never Have Enough Software Developers</a>, changes in the underlying technologies of modern software development whittle away the accumulated human capital of software developers:</p><blockquote><em><em><strong><strong>Specific skills in software development quickly become dated.</strong></strong> Programming languages and development frameworks go out of style. Hadoop is hot one year, and itâ€™s old news the next. Like a fast, expensive car that quickly loses value as itâ€™s driven around town, the skills and human capital of software engineers fall apart without constant, expensive maintenance</em></em></blockquote><p>Though young engineers can keep up with the latest programming languages, frameworks, and tooling, eventually the torrential wave of new tools becomes too much to bear, and developers either tune out or drop out:</p><blockquote><em><em>At age 26, 59% of engineering and computer science grads work in occupations related to their field of study. By age 50, only 41% work in the same domain, meaning a full <strong><strong>~30% drop out of the field by mid-career</strong></strong></em></em></blockquote><p>The never-ending drumbeat of new technologies drives developers out of the field. New tooling is important and valuable, but their overall effect on developer productivity depends on how much they upend existing workflows and place additional burden on already taxed developers.</p><p>As I conclude:</p><blockquote><em><em><strong><strong>Growing the supply of software developers is not trivial</strong></strong> because the field already sees high levels of developer dropout and turnover, and this would only increase if the field were to grow larger.</em></em></blockquote><p>I favor efforts to grow the software engineering talent pool, but if weâ€™re not careful, like quicksand, our efforts will be counterproductive.</p><h2 id=\"more-developers-lower-productivity\">More developers, lower productivity</h2><p>As we saw in part 1, more researchers donâ€™t necessarily lead to faster progress. In the case of Mooreâ€™s Law, it merely maintains the rate of progress, at significant expense.</p><p>But is this true of the economy overall? It turns out, the answer is yes. Cross-industry data proves that simply throwing more people at a problem doesnâ€™t work.</p><p>The chart below plots the growth in the number of employed researchers and their productivity levels (measured in terms of revenue growth generated per researcher) for ~1,700 publicly-traded U.S.-based companies over a 20-year period. Most firms â€œthrew more bodies at the problemâ€ (orange histogram &gt; 1), but <strong><strong>~80% of firms saw declining research productivity</strong></strong> (blue histogram &lt; 1):</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2021/05/0_4RM_2yR4dbE_6mb5.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption><a href=\"https://web.stanford.edu/~chadj/IdeaPF.pdf\" rel=\"noopener nofollow\">Source</a></figcaption></figure><p>Hiring more researchers doesnâ€™t necessarily <em><em>cause</em></em> productivity to decline, but regardless, growing research teams and declining productivity go hand-in-hand more often than not.</p><p>Software development could fall prey to the same trap. Most companies are growing the number of software engineers they employ, mirroring the researcher employment trends, but letâ€™s not forget productivity:</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/05/0_NHviru2DykbIv-9N.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Research productivity, and analogously developer productivity, falls over time unless acted upon by an outside force. Like gravity, this phenomenon is pervasive and ubiquitous, a force field dragging down all idea-generative industries.</p><h2 id=\"busy-work-doesn-t-work\">Busy work doesnâ€™t work</h2><p>I love this quote from Stripe:</p><blockquote><em><em>Despite the number of developers increasing year-over-year at most companies, <strong><strong>developers working on the right things can accelerate a companyâ€™s move into new markets or product areas and help companies differentiate themselves at disproportionate rates.</strong></strong> This underscores the most important point about developers as force-multipliers: <strong><strong>Itâ€™s not just how many devs companies have; itâ€™s also how theyâ€™re being leveraged</strong></strong> â€” <a href=\"https://stripe.com/files/reports/the-developer-coefficient.pdf\" rel=\"noopener nofollow\">The Developer Coefficient 2018, Stripe</a></em></em></blockquote><p>In my last essay I talked about the importance of measuring productivity in terms of new software output. Another reason why more engineers is not necessarily the solution is that much of the value of the marginal engineer is in their <strong><strong>innovation</strong></strong> activities rather than their <em><em>maintenance</em></em> work.</p><p>We can quantify the impact of engineering time spent maintaining old code rather than writing new code. According to <a href=\"http://drock.mit.edu/sites/default/files/documents/techMV_mostrecent.pdf\" rel=\"noopener nofollow\">one analysis</a>, an engineer engaged in purely non-innovative activity <em><em>destroys</em></em> nearly $600K in employer market value. On the other hand, the average engineer, working on a combination of maintenance and innovation activities, <strong><strong>adds</strong></strong> $855K in market value to their employer.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/05/image-5.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>As the studyâ€™s author speculates:</p><blockquote><em><em>â€¦ the value of the engineer is a bundled combination of <strong><strong>maintenance activities which have negative value</strong></strong> and <strong><strong>innovation activities with positive value</strong></strong></em></em></blockquote><p>Further, he echoes Brookâ€™s Law:</p><blockquote><em><em>It may also be the case that <strong><strong>more engineers does not always make for easier problem solving</strong></strong> and on the margin, removing innovative activity, [they are] a net drain on the firmâ€™s value</em></em></blockquote><p>I want to be clear: maintenance matters too. When things break, as they inevitably do, development teams must stand at the ready to fix problems and bring systems back online. This is critical work that should not be minimized in a narrow pursuit of newer, shinier objects.</p><p>That said, mere maintenance is table stakes. It doesnâ€™t pay the bills â€” an engineerâ€™s salary, first and foremost.</p><h2 id=\"hidden-figures\">Hidden figures</h2><p>Again, Stripe gets it right:</p><blockquote><em><em>While many people posit that lack of developers is the primary problem, this studyâ€¦ found that <strong><strong>businesses need to better leverage their existing software engineering talent</strong></strong> if they want to move <strong><strong>faster</strong></strong>, build <strong><strong>new</strong></strong> products, and tap into <strong><strong>new and emerging</strong></strong> trends â€” <a href=\"https://stripe.com/files/reports/the-developer-coefficient.pdf\" rel=\"noopener nofollow\"><strong><strong>The Developer Coefficient 2018, Stripe</strong></strong></a></em></em></blockquote><p>Notice the emphasis on newness and speed. We can and should grow the talent pool for software engineering, but we can also do a much better job with the engineering talent <em><em>we already have</em></em>.</p><p>Maintenance matters but so does fundamental innovation. As software projects grow, and their teams with them, thoughtful engineering managers must strike the right balance or see their most precious resource go to waste.</p><p>Industry-wide we are, unfortunately, out of balance. In my next and final piece, Iâ€™ll explore exactly how much software weâ€™re â€œleaving on the tableâ€ as a result.</p><p>Ready for more? Here's <a href=\"__GHOST_URL__/leaving-software-on-the-table/\">Part 3</a>.</p><p><strong><strong>Follow me on </strong></strong><a href=\"https://twitter.com/whoisnnamdi\" rel=\"noopener nofollow\"><strong><strong>Twitter</strong></strong></a><strong><strong>, subscribe to my monthly essays </strong></strong><a href=\"__GHOST_URL__/\" rel=\"noopener nofollow\"><strong><strong>here</strong></strong></a><strong><strong>, and reach out to me directly via nnamdi@lsvp.com</strong></strong></p>","comment_id":"609b702517b26d3ef80d677e","plaintext":"In software development, more (developers) isnâ€™t always more.\n\nIn part 1 [__GHOST_URL__/the-developer-productivity-flywheel/] of â€œThe\nDeveloper Productivity Manifesto,â€ I argued that developer productivity,\nmeasured in terms of new software, falls over time as low-hanging fruit is\npicked and new ideas become harder to find.\n\nAn understandable response would be â€” why not just throw more engineers at the\nproblem?\n\nIf youâ€™ve ever worked in software development, you know adding more cooks to the\nkitchen rarely helps. For those who havenâ€™t worked in software development, this\nessay tells you why.\n\nThe Developer Productivity Manifesto has three parts, this is part 2:\n\n * Part 1: The Developer Productivity Flywheel\n   [__GHOST_URL__/the-developer-productivity-flywheel/]\n * Part 2: More (Developers) Isnâ€™t Always More (you are here)\n * Part 3: Leaving Software on the Table\n   [__GHOST_URL__/leaving-software-on-the-table/]\n\nReceive my next long-form post\nThoughtful analysis of the business and economics of tech\n\n\n\nSubscribeThe Mythical Man-Month\nâ€œThe Mythical Man-Month\n[https://www.amazon.com/Mythical-Man-Month-Software-Engineering-Anniversary/dp/0201835959]\nâ€ is a classic and hugely influential book about software engineering and\nproject management. Across a series of essays, Fred Brooks (himself a former IBM\nproject manager) lays out the cognitive errors software development teams tend\nto make in estimating the time to completion for software projects. His core\nthesis is best encapsulated by Brooksâ€™ law\n[https://en.wikipedia.org/wiki/Brooks%27s_law].\n\nBrooksâ€™ law of software project management states that:\n\n> Adding manpower to a late software project makes it later\nIf anything, adding more cooks to the kitchen lengthens cooking time. We\nshouldnâ€™t assume a simple, linear, and directly causal relationship between\ndevelopers as inputs and software as output. He lays this out in dire terms:\n\n> â€¦ when schedule slippage is recognized, the natural (and traditional) response\nis to add manpower. Like dousing a fire with gasoline, this makes matters worse,\nmuch worse. More fire requires more gasoline, and thus begins a regenerative\ncycle which ends in disaster.\nThis counterintuitive phenomenon has multiple causes:\n\n * Ramp up time: Even seasoned developers take time to get up to speed on new\n   projects, and newbie engineers must learn core skills on top of\n   company-specific ones\n * Communication and coordination complexity: The larger the team, the harder it\n   is to coordinate productive work and communicate progress across teammates\n * Indivisibility of work: The basic unit of work in software development canâ€™t\n   always be divided among multiple contributors\n\nThat last point forms the basis of the title and main thrust of the book, the\nfallacy of â€œman-monthsâ€ â€” distinct units of work achievable by a single\ndeveloper in a set period of time. As Brooks argues, there is no such thing, and\nthus we should be wary of simplistic solutions to complex endeavors like\nsoftware development.\n\n> Software is not labor-intensive. Not many people are necessary in order to\nproduce good softwareâ€¦ What makes or breaks a project, itâ€™s the amount of FOCUS\ndevelopers can pour into it â€” RedBeardLab\n[https://redbeardlab.com/2020/01/19/software-is-a-focus-intensive-industry/]\nDiseconomies of scale\nSource [https://boycewire.com/types-of-diseconomies-of-scale/]While it is common\nto assume economies of scale, diseconomies of scale are arguably just as\nrelevant in software development.\n\nDiseconomies of scale are where unit costs (the costs of producing an additional\nunit of output) increase rather than decrease with scale. Here, itâ€™s better to \ncut back or lower output, rather than maximize it. Despite many advances, these\noccur more often than weâ€™d like to admit in modern software development.\n\nDiseconomies of scale can take many forms, and many overlap with the underlying\ncauses behind the mythical â€œman-monthâ€:\n\n * Complexity: Things become disproportionately complex as they scale, as\n   complexity increases non-linearly with size. Complexity creates overhead,\n   making large organizations less efficient than medium-sized ones. Bureaucracy\n   is one manifestation, but there are others.\n * Black Swans: Large systems fail in spectacular fashion. Itâ€™s why big\n   companies create systemic risk while small businesses and startups fail in\n   the thousands without cause for alarm. Within software, this might be a large\n   monolithic application, prone to serious, single point failures.\n\nHumans, being the independent and unpredictable automatons we are, are\nespecially prone to diseconomies of scale. Coordination costs eventually\noverwhelm even the most thoughtful engineering leaders. Application deployments\nare themselves quite brittle, necessitating vastly more manpower and attention\nas they grow.\n\nWe will never have enough software developers\n> Senior executives report that the lack of developer talent is one of the biggest\npotential threats to their businesses â€” The Developer Coefficient 2018, Stripe\n[https://stripe.com/files/reports/the-developer-coefficient.pdf]\nExecutives believe that insufficient developer talent is one of the biggest\nthreats to their business, and yet thereâ€™s good reason to think this might never\nbe solved.\n\nAs I discuss in a previous essay, Why We Will Never Have Enough Software\nDevelopers [__GHOST_URL__/never-enough-developers/], changes in the\nunderlying technologies of modern software development whittle away the\naccumulated human capital of software developers:\n\n> Specific skills in software development quickly become dated. Programming\nlanguages and development frameworks go out of style. Hadoop is hot one year,\nand itâ€™s old news the next. Like a fast, expensive car that quickly loses value\nas itâ€™s driven around town, the skills and human capital of software engineers\nfall apart without constant, expensive maintenance\nThough young engineers can keep up with the latest programming languages,\nframeworks, and tooling, eventually the torrential wave of new tools becomes too\nmuch to bear, and developers either tune out or drop out:\n\n> At age 26, 59% of engineering and computer science grads work in occupations\nrelated to their field of study. By age 50, only 41% work in the same domain,\nmeaning a full ~30% drop out of the field by mid-career\nThe never-ending drumbeat of new technologies drives developers out of the\nfield. New tooling is important and valuable, but their overall effect on\ndeveloper productivity depends on how much they upend existing workflows and\nplace additional burden on already taxed developers.\n\nAs I conclude:\n\n> Growing the supply of software developers is not trivial because the field\nalready sees high levels of developer dropout and turnover, and this would only\nincrease if the field were to grow larger.\nI favor efforts to grow the software engineering talent pool, but if weâ€™re not\ncareful, like quicksand, our efforts will be counterproductive.\n\nMore developers, lower productivity\nAs we saw in part 1, more researchers donâ€™t necessarily lead to faster progress.\nIn the case of Mooreâ€™s Law, it merely maintains the rate of progress, at\nsignificant expense.\n\nBut is this true of the economy overall? It turns out, the answer is yes.\nCross-industry data proves that simply throwing more people at a problem doesnâ€™t\nwork.\n\nThe chart below plots the growth in the number of employed researchers and their\nproductivity levels (measured in terms of revenue growth generated per\nresearcher) for ~1,700 publicly-traded U.S.-based companies over a 20-year\nperiod. Most firms â€œthrew more bodies at the problemâ€ (orange histogram > 1),\nbut ~80% of firms saw declining research productivity (blue histogram < 1):\n\nSource [https://web.stanford.edu/~chadj/IdeaPF.pdf]Hiring more researchers\ndoesnâ€™t necessarily cause productivity to decline, but regardless, growing\nresearch teams and declining productivity go hand-in-hand more often than not.\n\nSoftware development could fall prey to the same trap. Most companies are\ngrowing the number of software engineers they employ, mirroring the researcher\nemployment trends, but letâ€™s not forget productivity:\n\nResearch productivity, and analogously developer productivity, falls over time\nunless acted upon by an outside force. Like gravity, this phenomenon is\npervasive and ubiquitous, a force field dragging down all idea-generative\nindustries.\n\nBusy work doesnâ€™t work\nI love this quote from Stripe:\n\n> Despite the number of developers increasing year-over-year at most companies, \ndevelopers working on the right things can accelerate a companyâ€™s move into new\nmarkets or product areas and help companies differentiate themselves at\ndisproportionate rates. This underscores the most important point about\ndevelopers as force-multipliers: Itâ€™s not just how many devs companies have;\nitâ€™s also how theyâ€™re being leveraged â€” The Developer Coefficient 2018, Stripe\n[https://stripe.com/files/reports/the-developer-coefficient.pdf]\nIn my last essay I talked about the importance of measuring productivity in\nterms of new software output. Another reason why more engineers is not\nnecessarily the solution is that much of the value of the marginal engineer is\nin their innovation activities rather than their maintenance work.\n\nWe can quantify the impact of engineering time spent maintaining old code rather\nthan writing new code. According to one analysis\n[http://drock.mit.edu/sites/default/files/documents/techMV_mostrecent.pdf], an\nengineer engaged in purely non-innovative activity destroys nearly $600K in\nemployer market value. On the other hand, the average engineer, working on a\ncombination of maintenance and innovation activities, adds $855K in market value\nto their employer.\n\nAs the studyâ€™s author speculates:\n\n> â€¦ the value of the engineer is a bundled combination of maintenance activities\nwhich have negative value and innovation activities with positive value\nFurther, he echoes Brookâ€™s Law:\n\n> It may also be the case that more engineers does not always make for easier\nproblem solving and on the margin, removing innovative activity, [they are] a\nnet drain on the firmâ€™s value\nI want to be clear: maintenance matters too. When things break, as they\ninevitably do, development teams must stand at the ready to fix problems and\nbring systems back online. This is critical work that should not be minimized in\na narrow pursuit of newer, shinier objects.\n\nThat said, mere maintenance is table stakes. It doesnâ€™t pay the bills â€” an\nengineerâ€™s salary, first and foremost.\n\nHidden figures\nAgain, Stripe gets it right:\n\n> While many people posit that lack of developers is the primary problem, this\nstudyâ€¦ found that businesses need to better leverage their existing software\nengineering talent if they want to move faster, build new products, and tap into \nnew and emerging trends â€” The Developer Coefficient 2018, Stripe\n[https://stripe.com/files/reports/the-developer-coefficient.pdf]\nNotice the emphasis on newness and speed. We can and should grow the talent pool\nfor software engineering, but we can also do a much better job with the\nengineering talent we already have.\n\nMaintenance matters but so does fundamental innovation. As software projects\ngrow, and their teams with them, thoughtful engineering managers must strike the\nright balance or see their most precious resource go to waste.\n\nIndustry-wide we are, unfortunately, out of balance. In my next and final piece,\nIâ€™ll explore exactly how much software weâ€™re â€œleaving on the tableâ€ as a result.\n\nReady for more? Here's Part 3\n[https://nnamdi.net/leaving-software-on-the-table/].\n\nFollow me on Twitter [https://twitter.com/whoisnnamdi], subscribe to my monthly\nessays here [__GHOST_URL__/], and reach out to me directly via\nnnamdi@lsvp.com","feature_image":"__GHOST_URL__/content/images/2021/07/ballmer-compressed.gif","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2021-05-12T06:05:25.000Z","updated_at":"2021-08-31T16:57:47.000Z","published_at":"2021-04-16T06:13:00.000Z","custom_excerpt":"Adding more cooks to the kitchen rarely helps","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"609b71db17b26d3ef80d67a8","uuid":"4b887047-314a-41e9-83fa-e2f6e10384d6","title":"The Developer Productivity Manifesto Part 3 â€” Leaving Software on the Table","slug":"leaving-software-on-the-table","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"html\":\"<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: The Developer Productivity Manifesto Part 3 â€” Leaving Software on the Table\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Subscribe</span></button>\\n</form>\\n</section>\"}],[\"image\",{\"src\":\"/content/images/2021/05/hindering.png\",\"caption\":\"Source: <a href=\\\"https://stripe.com/files/reports/the-developer-coefficient.pdf\\\" rel=\\\"noopener nofollow\\\">The Developer Coefficient, Stripe</a>\"}],[\"image\",{\"src\":\"/content/images/2021/05/debt-hours.png\",\"caption\":\"Source: <a href=\\\"https://stripe.com/files/reports/the-developer-coefficient.pdf\\\" rel=\\\"noopener nofollow\\\">The Developer Coefficient, Stripe</a>\"}],[\"image\",{\"src\":\"/content/images/2021/05/dev-work-week.png\",\"caption\":\"Source: <a href=\\\"https://stripe.com/files/reports/the-developer-coefficient.pdf\\\" rel=\\\"noopener nofollow\\\">The Developer Coefficient, Stripe</a>\"}],[\"image\",{\"src\":\"/content/images/2021/05/how-productive.png\",\"caption\":\"Source: <a href=\\\"https://stripe.com/files/reports/the-developer-coefficient.pdf\\\" rel=\\\"noopener nofollow\\\">The Developer Coefficient, Stripe</a>\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2021/05/extra-productive-hours.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2021/05/stripe-calc.png\",\"caption\":\"Source: <a href=\\\"https://stripe.com/files/reports/the-developer-coefficient.pdf\\\" rel=\\\"noopener nofollow\\\">The Developer Coefficient, Stripe</a>\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2021/05/image-20210425201756326.png\",\"cardWidth\":\"wide\"}],[\"image\",{\"src\":\"/content/images/2021/05/software-calc.png\",\"cardWidth\":\"wide\"}]],\"markups\":[[\"a\",[\"href\",\"__GHOST_URL__/the-developer-productivity-flywheel/\"]],[\"a\",[\"href\",\"__GHOST_URL__/more-developers-isnt-always-more/\"]],[\"strong\"],[\"em\"],[\"a\",[\"href\",\"https://stripe.com/files/reports/the-developer-coefficient.pdf\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://www.daxx.com/blog/development-trends/software-developer-shortage-us\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"__GHOST_URL__/about-me/\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"https://twitter.com/whoisnnamdi\",\"rel\",\"noopener nofollow\"]],[\"a\",[\"href\",\"__GHOST_URL__/\",\"rel\",\"noopener nofollow\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Developer inefficiency drives hundreds of billions of dollars of lost software output annually.\"]]],[1,\"p\",[[0,[],0,\"The sum is striking but also predictable in light of data showing we donâ€™t even come close to maximizing developer productivity.\"]]],[1,\"p\",[[0,[],0,\"Mountains of technical debt and poor development practices burden and bog down developers. We lose billions as a result.\"]]],[1,\"p\",[[0,[],0,\"The Developer Productivity Manifesto has three parts, this is part 3:\"]]],[3,\"ul\",[[[0,[0],1,\"Part 1: The Developer Productivity Flywheel\"]],[[0,[1],1,\"Part 2: More (Developers) Isnâ€™t Always More\"]],[[0,[2,2],2,\"Part 3: Leaving Software on the Table (you are here)\"]]]],[1,\"p\",[[0,[],0,\"In part 1, I talked about falling developer productivity and how spinning \"],[0,[0],1,\"the developer productivity flywheel\"],[0,[],0,\" can counteract this trend.\"]]],[1,\"p\",[[0,[],0,\"In part 2, I argued that \"],[0,[1],1,\"more developers wonâ€™t solve all our software engineering problems.\"]]],[1,\"p\",[[0,[],0,\"Iâ€™ve thrown around a lot of equations, literary references, and even some memes. In this third and final piece, Iâ€™ll talk dollars and cents, quantifying the impact of lost developer productivity and how much software weâ€™re â€œleaving on the tableâ€ as a result.\"]]],[10,0],[1,\"h2\",[[0,[],0,\"(Technical) debt to (developer) GDP\"]]],[1,\"p\",[[0,[],0,\"In \"],[0,[1],1,\"part 2\"],[0,[],0,\", I made the case that software maintenance is not sufficiently value generating to cover engineering salary expenses. In other words, \"],[0,[2,2],2,\"busy work doesnâ€™t work\"],[0,[],0,\":\"]]],[1,\"blockquote\",[[0,[3,3],0,\"According to one analysis, an engineer engaged in purely non-innovative activity \"],[0,[2,2],2,\"destroys\"],[0,[],0,\" nearly $600K in employer market value. On the other hand, the average engineer, working on a combination of maintenance and innovation activities, \"],[0,[2,2],2,\"adds\"],[0,[],2,\" $855K in market value to their employer.\"]]],[1,\"p\",[[0,[],0,\"In a global, cross-industry \"],[0,[4],1,\"survey\"],[0,[],0,\", Stripe asked developers why productivity was lower than it otherwise could be. \"],[0,[2,2],2,\"Maintenance of legacy systems / technical debt\"],[0,[],0,\" took the top spot:\"]]],[10,1],[1,\"p\",[[0,[],0,\"Even developers themselves see maintenance work as unproductive. Asking them to quantify this reveals that the typical developer spends \"],[0,[2,2],2,\"13.5 hours per week\"],[0,[],0,\" addressing technical debt:\"]]],[10,2],[1,\"p\",[[0,[],0,\"Add to that another \"],[0,[2,2],2,\"3.8 hours per week fixing â€œbad codeâ€\"],[0,[],0,\" (debugging, refactoring, etc.). That totals 17.3 hours per week spent fixing the past rather than building the future. The typical work week among the surveyed was 41.1 hours, implying that a full \"],[0,[2,2],2,\"42% of developer time is lost to drudgery\"],[0,[],0,\":\"]]],[10,3],[1,\"p\",[[0,[],0,\"I like to call this \"],[0,[2,2],2,\"technical debt to developer GDP\"],[0,[],0,\". While some level of technical debt is unavoidable, it eventually becomes an unbearable drag on software output and developer productivity. It eats up engineering time leaves little for generative development work.\"]]],[1,\"h2\",[[0,[],0,\"Developers could be 46% more productive\"]]],[1,\"p\",[[0,[],0,\"In another question, Stripe asked developers to rate the productivity of their engineering teams on a scale of 0â€“100%. The average response? \"],[0,[2,2],2,\"68.4%\"],[0,[],0,\":\"]]],[10,4],[1,\"p\",[[0,[],0,\"Said differently, the average developer could potentially be (100% â€” 68.4%) / 68.4% = \"],[0,[2,2],2,\"46%\"],[0,[],0,\" more productive that they are today, nearly 50%.\"]]],[1,\"p\",[[0,[],0,\"With a 41.1 hour work week, such a productivity boost would be the equivalent of an \"],[0,[2,2],2,\"additional ~19 hours of productive development work\"],[0,[],0,\", enough to completely compensate for all that time spent on technical debt and bad, buggy code.\"]]],[10,5],[1,\"h2\",[[0,[],0,\"A $425B dollar bill on the ground\"]]],[1,\"p\",[[0,[],0,\"Based on the survey, Stripe conducted a back-of-the-envelope calculation multiplying estimates of the value generated by software developers around the world with the estimated productivity losses to arrive at an estimate for the global GDP lost due to software developer inefficiency.\"]]],[1,\"p\",[[0,[],0,\"I take issue with some of the assumptions, but the calculation is illustrative regardless. Assuming $900B of aggregate developer GDP and 31.6 percentage points of productivity lost suggests a $300B annual GDP shortfall:\"]]],[10,6],[1,\"p\",[[0,[],0,\"This is an underestimate, in fact. Stripeâ€™s math assumes 100% â€” 68.4% = 31.6% lost relative to existing productivity, but as I showed above, itâ€™s in fact 31.6% / 68.4% = 46%. With this efficiency loss relative to maximum productivity, GDP lost to developer inefficiency grows to \"],[0,[2,2],2,\"~$425B\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"So our failure to maximize productivity is losing us hundreds of billions in software production. Not exactly chump change.\"]]],[1,\"h2\",[[0,[],0,\"SUM()-ing it all up\"]]],[1,\"p\",[[0,[],0,\"To end, I want to return to where I started qualitatively, my goal to increase total software output, and quantitatively, the decomposition of software output into developers and developer productivity, and finally connect the two perspectives.\"]]],[1,\"p\",[[0,[2,2],2,\"How much more software output could we get with more developers and higher productivity?:\"]]],[10,7],[1,\"p\",[[0,[],0,\"Letâ€™s start with developers. I tend to be skeptical of perennial â€œshortagesâ€ unless thereâ€™s some specific, identifiable reason for it. Regardless, estimates suggest thereâ€™s a ~3M shortage of software developers globally, with \"],[0,[5],1,\"1.4M unfilled computer science jobs\"],[0,[],0,\" in the US alone.\"]]],[1,\"p\",[[0,[],0,\"To make the numbers easy, letâ€™s round up Stripeâ€™s estimate for the global software engineering labor force from 18M to 20M (Iâ€™ve seen other estimates in the 20â€“25M range, so this feels reasonable). That would imply a 3M / 20M = 15% developer shortage at current levels of demand.\"]]],[1,\"p\",[[0,[],0,\"So we have a 15% developer shortage and a 50% productivity â€œshortageâ€. Multiplied, that yields a massive \"],[0,[2,2],2,\"73% potential gain in software output\"],[0,[],0,\":\"]]],[10,8],[1,\"p\",[[0,[],0,\"Said another way, \"],[0,[2,2],2,\"current software output is only about 100% / 173% = 58% of what it could be\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Thatâ€™s \"],[0,[2,2],2,\"$670B\"],[0,[],0,\" of software weâ€™re leaving on the table.\"]]],[1,\"p\",[[0,[],0,\"This calculation is admittedly simplistic. One could argue that weâ€™d need fewer developers if they were more productive. I push back on that â€” thereâ€™s so much weâ€™ve yet to build, and more developers working more productively would unlock entirely new opportunities that we havenâ€™t had the capacity to explore or canâ€™t even yet imagine. This would further spur developer hiring and employment, another \"],[0,[0],1,\"flywheel\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"We can do better\"]]],[1,\"p\",[[0,[],0,\"In this series Iâ€™ve made the case that by investing in \"],[0,[6,3,3],3,\"technical tools for technical people\"],[0,[],0,\", we can reverse the trend of declining developer productivity, spin the productivity flywheel in the right direction, and see massive gains in software output as a result.\"]]],[1,\"p\",[[0,[],0,\"As Iâ€™ve hopefully made clear, we can do A LOT better of a job maximizing developer productivity. I hope youâ€™ll join me in my mission to do exactly that.\"]]],[1,\"p\",[[0,[3,3],2,\"Thanks so much for reading this â€” I hope it resonated with you. If it did, please share that feedback!\"]]],[1,\"p\",[[0,[2,2],2,\"Follow me on \"],[0,[7,2,2],3,\"Twitter\"],[0,[2,2],2,\", subscribe to my monthly essays \"],[0,[8,2,2],3,\"here\"],[0,[2,2],2,\", and reach out to me directly via nnamdi@lsvp.com\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p>Developer inefficiency drives hundreds of billions of dollars of lost software output annually.</p><p>The sum is striking but also predictable in light of data showing we donâ€™t even come close to maximizing developer productivity.</p><p>Mountains of technical debt and poor development practices burden and bog down developers. We lose billions as a result.</p><p>The Developer Productivity Manifesto has three parts, this is part 3:</p><ul><li><a href=\"__GHOST_URL__/the-developer-productivity-flywheel/\">Part 1: The Developer Productivity Flywheel</a></li><li><a href=\"__GHOST_URL__/more-developers-isnt-always-more/\">Part 2: More (Developers) Isnâ€™t Always More</a></li><li><strong><strong>Part 3: Leaving Software on the Table (you are here)</strong></strong></li></ul><p>In part 1, I talked about falling developer productivity and how spinning <a href=\"__GHOST_URL__/the-developer-productivity-flywheel/\">the developer productivity flywheel</a> can counteract this trend.</p><p>In part 2, I argued that <a href=\"__GHOST_URL__/more-developers-isnt-always-more/\">more developers wonâ€™t solve all our software engineering problems.</a></p><p>Iâ€™ve thrown around a lot of equations, literary references, and even some memes. In this third and final piece, Iâ€™ll talk dollars and cents, quantifying the impact of lost developer productivity and how much software weâ€™re â€œleaving on the tableâ€ as a result.</p><!--kg-card-begin: html--><section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: The Developer Productivity Manifesto Part 3 â€” Leaving Software on the Table\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Subscribe</span></button>\n</form>\n</section><!--kg-card-end: html--><h2 id=\"-technical-debt-to-developer-gdp\">(Technical) debt to (developer) GDP</h2><p>In <a href=\"__GHOST_URL__/more-developers-isnt-always-more/\">part 2</a>, I made the case that software maintenance is not sufficiently value generating to cover engineering salary expenses. In other words, <strong><strong>busy work doesnâ€™t work</strong></strong>:</p><blockquote><em><em>According to one analysis, an engineer engaged in purely non-innovative activity <strong><strong>destroys</strong></strong> nearly $600K in employer market value. On the other hand, the average engineer, working on a combination of maintenance and innovation activities, <strong><strong>adds</strong></strong> $855K in market value to their employer.</em></em></blockquote><p>In a global, cross-industry <a href=\"https://stripe.com/files/reports/the-developer-coefficient.pdf\" rel=\"noopener nofollow\">survey</a>, Stripe asked developers why productivity was lower than it otherwise could be. <strong><strong>Maintenance of legacy systems / technical debt</strong></strong> took the top spot:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"/content/images/2021/05/hindering.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>Source: <a href=\"https://stripe.com/files/reports/the-developer-coefficient.pdf\" rel=\"noopener nofollow\">The Developer Coefficient, Stripe</a></figcaption></figure><p>Even developers themselves see maintenance work as unproductive. Asking them to quantify this reveals that the typical developer spends <strong><strong>13.5 hours per week</strong></strong> addressing technical debt:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"/content/images/2021/05/debt-hours.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>Source: <a href=\"https://stripe.com/files/reports/the-developer-coefficient.pdf\" rel=\"noopener nofollow\">The Developer Coefficient, Stripe</a></figcaption></figure><p>Add to that another <strong><strong>3.8 hours per week fixing â€œbad codeâ€</strong></strong> (debugging, refactoring, etc.). That totals 17.3 hours per week spent fixing the past rather than building the future. The typical work week among the surveyed was 41.1 hours, implying that a full <strong><strong>42% of developer time is lost to drudgery</strong></strong>:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"/content/images/2021/05/dev-work-week.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>Source: <a href=\"https://stripe.com/files/reports/the-developer-coefficient.pdf\" rel=\"noopener nofollow\">The Developer Coefficient, Stripe</a></figcaption></figure><p>I like to call this <strong><strong>technical debt to developer GDP</strong></strong>. While some level of technical debt is unavoidable, it eventually becomes an unbearable drag on software output and developer productivity. It eats up engineering time leaves little for generative development work.</p><h2 id=\"developers-could-be-46-more-productive\">Developers could be 46% more productive</h2><p>In another question, Stripe asked developers to rate the productivity of their engineering teams on a scale of 0â€“100%. The average response? <strong><strong>68.4%</strong></strong>:</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"/content/images/2021/05/how-productive.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>Source: <a href=\"https://stripe.com/files/reports/the-developer-coefficient.pdf\" rel=\"noopener nofollow\">The Developer Coefficient, Stripe</a></figcaption></figure><p>Said differently, the average developer could potentially be (100% â€” 68.4%) / 68.4% = <strong><strong>46%</strong></strong> more productive that they are today, nearly 50%.</p><p>With a 41.1 hour work week, such a productivity boost would be the equivalent of an <strong><strong>additional ~19 hours of productive development work</strong></strong>, enough to completely compensate for all that time spent on technical debt and bad, buggy code.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2021/05/extra-productive-hours.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><h2 id=\"a-425b-dollar-bill-on-the-ground\">A $425B dollar bill on the ground</h2><p>Based on the survey, Stripe conducted a back-of-the-envelope calculation multiplying estimates of the value generated by software developers around the world with the estimated productivity losses to arrive at an estimate for the global GDP lost due to software developer inefficiency.</p><p>I take issue with some of the assumptions, but the calculation is illustrative regardless. Assuming $900B of aggregate developer GDP and 31.6 percentage points of productivity lost suggests a $300B annual GDP shortfall:</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"/content/images/2021/05/stripe-calc.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>Source: <a href=\"https://stripe.com/files/reports/the-developer-coefficient.pdf\" rel=\"noopener nofollow\">The Developer Coefficient, Stripe</a></figcaption></figure><p>This is an underestimate, in fact. Stripeâ€™s math assumes 100% â€” 68.4% = 31.6% lost relative to existing productivity, but as I showed above, itâ€™s in fact 31.6% / 68.4% = 46%. With this efficiency loss relative to maximum productivity, GDP lost to developer inefficiency grows to <strong><strong>~$425B</strong></strong>.</p><p>So our failure to maximize productivity is losing us hundreds of billions in software production. Not exactly chump change.</p><h2 id=\"sum-ing-it-all-up\">SUM()-ing it all up</h2><p>To end, I want to return to where I started qualitatively, my goal to increase total software output, and quantitatively, the decomposition of software output into developers and developer productivity, and finally connect the two perspectives.</p><p><strong><strong>How much more software output could we get with more developers and higher productivity?:</strong></strong></p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2021/05/image-20210425201756326.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Letâ€™s start with developers. I tend to be skeptical of perennial â€œshortagesâ€ unless thereâ€™s some specific, identifiable reason for it. Regardless, estimates suggest thereâ€™s a ~3M shortage of software developers globally, with <a href=\"https://www.daxx.com/blog/development-trends/software-developer-shortage-us\" rel=\"noopener nofollow\">1.4M unfilled computer science jobs</a> in the US alone.</p><p>To make the numbers easy, letâ€™s round up Stripeâ€™s estimate for the global software engineering labor force from 18M to 20M (Iâ€™ve seen other estimates in the 20â€“25M range, so this feels reasonable). That would imply a 3M / 20M = 15% developer shortage at current levels of demand.</p><p>So we have a 15% developer shortage and a 50% productivity â€œshortageâ€. Multiplied, that yields a massive <strong><strong>73% potential gain in software output</strong></strong>:</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"/content/images/2021/05/software-calc.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>Said another way, <strong><strong>current software output is only about 100% / 173% = 58% of what it could be</strong></strong>.</p><p>Thatâ€™s <strong><strong>$670B</strong></strong> of software weâ€™re leaving on the table.</p><p>This calculation is admittedly simplistic. One could argue that weâ€™d need fewer developers if they were more productive. I push back on that â€” thereâ€™s so much weâ€™ve yet to build, and more developers working more productively would unlock entirely new opportunities that we havenâ€™t had the capacity to explore or canâ€™t even yet imagine. This would further spur developer hiring and employment, another <a href=\"__GHOST_URL__/the-developer-productivity-flywheel/\">flywheel</a>.</p><h2 id=\"we-can-do-better\">We can do better</h2><p>In this series Iâ€™ve made the case that by investing in <a href=\"__GHOST_URL__/about-me/\" rel=\"noopener nofollow\"><em><em>technical tools for technical people</em></em></a>, we can reverse the trend of declining developer productivity, spin the productivity flywheel in the right direction, and see massive gains in software output as a result.</p><p>As Iâ€™ve hopefully made clear, we can do A LOT better of a job maximizing developer productivity. I hope youâ€™ll join me in my mission to do exactly that.</p><p><em><em>Thanks so much for reading this â€” I hope it resonated with you. If it did, please share that feedback!</em></em></p><p><strong><strong>Follow me on </strong></strong><a href=\"https://twitter.com/whoisnnamdi\" rel=\"noopener nofollow\"><strong><strong>Twitter</strong></strong></a><strong><strong>, subscribe to my monthly essays </strong></strong><a href=\"__GHOST_URL__/\" rel=\"noopener nofollow\"><strong><strong>here</strong></strong></a><strong><strong>, and reach out to me directly via nnamdi@lsvp.com</strong></strong></p>","comment_id":"609b71db17b26d3ef80d67a8","plaintext":"Developer inefficiency drives hundreds of billions of dollars of lost software\noutput annually.\n\nThe sum is striking but also predictable in light of data showing we donâ€™t even\ncome close to maximizing developer productivity.\n\nMountains of technical debt and poor development practices burden and bog down\ndevelopers. We lose billions as a result.\n\nThe Developer Productivity Manifesto has three parts, this is part 3:\n\n * Part 1: The Developer Productivity Flywheel\n   [__GHOST_URL__/the-developer-productivity-flywheel/]\n * Part 2: More (Developers) Isnâ€™t Always More\n   [__GHOST_URL__/more-developers-isnt-always-more/]\n * Part 3: Leaving Software on the Table (you are here)\n\nIn part 1, I talked about falling developer productivity and how spinning the\ndeveloper productivity flywheel\n[__GHOST_URL__/the-developer-productivity-flywheel/] can counteract this trend.\n\nIn part 2, I argued that more developers wonâ€™t solve all our software\nengineering problems. [__GHOST_URL__/more-developers-isnt-always-more/]\n\nIâ€™ve thrown around a lot of equations, literary references, and even some memes.\nIn this third and final piece, Iâ€™ll talk dollars and cents, quantifying the\nimpact of lost developer productivity and how much software weâ€™re â€œleaving on\nthe tableâ€ as a result.\n\nReceive my next long-form post\nThoughtful analysis of the business and economics of tech\n\n\n\nSubscribe(Technical) debt to (developer) GDP\nIn part 2 [__GHOST_URL__/more-developers-isnt-always-more/], I made the case\nthat software maintenance is not sufficiently value generating to cover\nengineering salary expenses. In other words, busy work doesnâ€™t work:\n\n> According to one analysis, an engineer engaged in purely non-innovative activity \ndestroys nearly $600K in employer market value. On the other hand, the average\nengineer, working on a combination of maintenance and innovation activities, \nadds $855K in market value to their employer.\nIn a global, cross-industry survey\n[https://stripe.com/files/reports/the-developer-coefficient.pdf], Stripe asked\ndevelopers why productivity was lower than it otherwise could be. Maintenance of\nlegacy systems / technical debt took the top spot:\n\nSource: The Developer Coefficient, Stripe\n[https://stripe.com/files/reports/the-developer-coefficient.pdf]Even developers\nthemselves see maintenance work as unproductive. Asking them to quantify this\nreveals that the typical developer spends 13.5 hours per week addressing\ntechnical debt:\n\nSource: The Developer Coefficient, Stripe\n[https://stripe.com/files/reports/the-developer-coefficient.pdf]Add to that\nanother 3.8 hours per week fixing â€œbad codeâ€ (debugging, refactoring, etc.).\nThat totals 17.3 hours per week spent fixing the past rather than building the\nfuture. The typical work week among the surveyed was 41.1 hours, implying that a\nfull 42% of developer time is lost to drudgery:\n\nSource: The Developer Coefficient, Stripe\n[https://stripe.com/files/reports/the-developer-coefficient.pdf]I like to call\nthis technical debt to developer GDP. While some level of technical debt is\nunavoidable, it eventually becomes an unbearable drag on software output and\ndeveloper productivity. It eats up engineering time leaves little for generative\ndevelopment work.\n\nDevelopers could be 46% more productive\nIn another question, Stripe asked developers to rate the productivity of their\nengineering teams on a scale of 0â€“100%. The average response? 68.4%:\n\nSource: The Developer Coefficient, Stripe\n[https://stripe.com/files/reports/the-developer-coefficient.pdf]Said\ndifferently, the average developer could potentially be (100% â€” 68.4%) / 68.4% = \n46% more productive that they are today, nearly 50%.\n\nWith a 41.1 hour work week, such a productivity boost would be the equivalent of\nan additional ~19 hours of productive development work, enough to completely\ncompensate for all that time spent on technical debt and bad, buggy code.\n\nA $425B dollar bill on the ground\nBased on the survey, Stripe conducted a back-of-the-envelope calculation\nmultiplying estimates of the value generated by software developers around the\nworld with the estimated productivity losses to arrive at an estimate for the\nglobal GDP lost due to software developer inefficiency.\n\nI take issue with some of the assumptions, but the calculation is illustrative\nregardless. Assuming $900B of aggregate developer GDP and 31.6 percentage points\nof productivity lost suggests a $300B annual GDP shortfall:\n\nSource: The Developer Coefficient, Stripe\n[https://stripe.com/files/reports/the-developer-coefficient.pdf]This is an\nunderestimate, in fact. Stripeâ€™s math assumes 100% â€” 68.4% = 31.6% lost relative\nto existing productivity, but as I showed above, itâ€™s in fact 31.6% / 68.4% =\n46%. With this efficiency loss relative to maximum productivity, GDP lost to\ndeveloper inefficiency grows to ~$425B.\n\nSo our failure to maximize productivity is losing us hundreds of billions in\nsoftware production. Not exactly chump change.\n\nSUM()-ing it all up\nTo end, I want to return to where I started qualitatively, my goal to increase\ntotal software output, and quantitatively, the decomposition of software output\ninto developers and developer productivity, and finally connect the two\nperspectives.\n\nHow much more software output could we get with more developers and higher\nproductivity?:\n\nLetâ€™s start with developers. I tend to be skeptical of perennial â€œshortagesâ€\nunless thereâ€™s some specific, identifiable reason for it. Regardless, estimates\nsuggest thereâ€™s a ~3M shortage of software developers globally, with 1.4M\nunfilled computer science jobs\n[https://www.daxx.com/blog/development-trends/software-developer-shortage-us] in\nthe US alone.\n\nTo make the numbers easy, letâ€™s round up Stripeâ€™s estimate for the global\nsoftware engineering labor force from 18M to 20M (Iâ€™ve seen other estimates in\nthe 20â€“25M range, so this feels reasonable). That would imply a 3M / 20M = 15%\ndeveloper shortage at current levels of demand.\n\nSo we have a 15% developer shortage and a 50% productivity â€œshortageâ€.\nMultiplied, that yields a massive 73% potential gain in software output:\n\nSaid another way, current software output is only about 100% / 173% = 58% of\nwhat it could be.\n\nThatâ€™s $670B of software weâ€™re leaving on the table.\n\nThis calculation is admittedly simplistic. One could argue that weâ€™d need fewer\ndevelopers if they were more productive. I push back on that â€” thereâ€™s so much\nweâ€™ve yet to build, and more developers working more productively would unlock\nentirely new opportunities that we havenâ€™t had the capacity to explore or canâ€™t\neven yet imagine. This would further spur developer hiring and employment,\nanother flywheel [__GHOST_URL__/the-developer-productivity-flywheel/].\n\nWe can do better\nIn this series Iâ€™ve made the case that by investing in technical tools for\ntechnical people [__GHOST_URL__/about-me/], we can reverse the trend of\ndeclining developer productivity, spin the productivity flywheel in the right\ndirection, and see massive gains in software output as a result.\n\nAs Iâ€™ve hopefully made clear, we can do A LOT better of a job maximizing\ndeveloper productivity. I hope youâ€™ll join me in my mission to do exactly that.\n\nThanks so much for reading this â€” I hope it resonated with you. If it did,\nplease share that feedback!\n\nFollow me on Twitter [https://twitter.com/whoisnnamdi], subscribe to my monthly\nessays here [__GHOST_URL__/], and reach out to me directly via nnamdi@lsvp.com","feature_image":"__GHOST_URL__/content/images/2021/05/header-software-table.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2021-05-12T06:12:43.000Z","updated_at":"2021-06-20T22:27:50.000Z","published_at":"2021-05-05T06:13:00.000Z","custom_excerpt":"Quantifying the billion dollar impact of developer inefficiency","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"60acfa5595eadd54d31a7b9a","uuid":"1a39e5b1-5537-4bff-a125-b827bf026165","title":"Awesome Developer Advocates Are Hiding in Plain Sight","slug":"developer-advocates-plain-sight","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"[Developer relations](https://www.marythengvall.com/blog/2019/5/22/what-is-developer-relations-and-why-should-you-care) (DevRel) is one of the toughest hires to make in early stage, developer-centric startups.\\n\\nIn [Four Challenges Facing Developer Productivity Startups](__GHOST_URL__/developer-productivity-challenges/) I identified scaling developer relations as one of the key challenges facing developer productivity startups today:\\n\\n> ... even if you're fully onboard with the idea of developer relations, doing it well is tough. To start, developer advocates are hard to come by. There just aren't many DevRel folks out there. The function is still relatively new, and career pipelines into the role have yet to fully materialize â€” [Four Challenges Facing Developer Productivity Startups](__GHOST_URL__/developer-productivity-challenges/#scalingdeveloperrelations)\\n\\nTo some extent this is a supply and demand issue â€” many more startups want to bring on developer advocates than there are available developer advocates.\\n\\nBut there are structural issues behind the small quantity of available developer advocates â€” it leverages a combination of skill sets not often found in a single package, making it a tough role to hire for:\\n\\n> DevRel is a hard spec to hire for. Technical folks are usually introverts. Extroverts are typically not technical â€” Developer Advocate, Analytics Infrastructure Startup\\n\\n> I want them to be technical, and I'm always looking for empathy. It's very hard to find these things in a single person, this combination â€” Head of Developer Relations, Web Development Startup\\n\\nEven among the available pool of developer relations talent, companies have a hard time knowing who will be better at the role and what the key success factors are. How much does prior experience matter? How critical is it to have a large social media following?\\n\\nI've spoken to numerous founders and developer relations professionals to tease out best practices for DevRel hiring. This piece focuses on how to find high quality developer advocates despite the scarce supply.\\n\\nHere's some concrete advice:\\n\\n## Most developer advocates are former engineers. So, talk to some current engineers\\n\\nCurrent engineers are future developer advocates hiding in plain sight:\\n\\n> Getting into this career can be hard, but there are many developers that I'd bet on to be great first time developer advocates â€” [Tessa Kriesel @ Devocate](https://www.devocate.com/devocate-for-developers/)\\n\\nAt some point, everyone gets their first gig in Developer Relations, and most of those people were developers themselves just before. Thus, current engineers are a great potential source of DevRel talent, if you're willing to do the work to pitch them on the role.\\n\\nIn fact, many people who could be great developer advocates don't know how to break into the field. For example, many engineers simply haven't spent the the time to build up a large social media following, but this doesn't mean they couldn't be successful in the role:\\n\\n> ... the ones who could be good often have a hard time getting a foot in the door without a Twitter presence â€” Developer Advocate, Application Infrastructure Startup\\n\\nSome companies have realized this and shifted most of their DevRel hiring internally, focusing mainly on convincing existing engineers to try it out.\\n\\nThe pitch? Developer advocates can often have impact much sooner and more frequently than engineers:\\n\\n> We hire most of the DevRel team internally. Folks realized they could make an impact much sooner as DevRel than as engineers. Software releases take so long, but content takes much less time â€” Head of Developer Relations, Web Development Startup\\n\\nDeveloper advocates \\\"ship\\\" faster. A piece of content â€” a blog post, a Twitch stream, etc â€” is often much quicker to assemble and publish than shipping some piece of software, like a new feature, to production: \\n\\n> Sometimes it's enough just to write an article just to start a conversation. It doesn't have to be a full fledged feature release like in software â€” Head of Developer Relations, Web Development Startup\\n\\nI haven't run the numbers, but it wouldn't surprise me if there were more *potential* developer advocates among current software engineers than *actual* developer advocates out there.\\n\\nSo if you're having difficulty finding candidates for your open DevRel role, talk to some current engineers, even one's working at your company.\\n\\nAnd when you do, leave your biases at the door with respect to experience or social media following...\\n\\n## Don't filter for DevRel experience or social media following\\n\\nAs with any role, it's super tempting to assume \\\"only someone who's done this before could be good at it.\\\" Not so with DevRel:\\n\\n> You can't look for experience, DevRel has barely existed for very long. If anything, non-traditional folks are often the best â€” Developer Success Engineer, Application Infrastructure Startup\\n\\nDevRel as a formal practice has not existed for long. You can't expect most people to have meaningful experience doing it. Again, this reinforces the idea that many potentially great developer advocates aren't currently in the role.\\n\\nAnother important point to keep in mind is the job description for DevRel tends to be loose and ill-defined in many ways due to the nature of the role:\\n\\n> The job description is extremely loose. Best people need to grow into it to some extent â€” Developer Success Engineer, Application Infrastructure Startup\\n\\nRegardless of what *you* think the person needs to do, the reality on the ground will look somewhat different. Accept this, and know that the best developer advocates will navigate this ambiguity regardless of whether they are an \\\"obvious\\\" fit based on their professional experience to date.\\n\\nOne of the \\\"obvious\\\" characteristics people often filter on is social media following. But not so fast:\\n\\n> Social media is just one part of the toolbox. Further, social following in one area does not necessarily translate to another â€” Developer Advocate, Analytics Infrastructure Startup\\n\\nIt's debatable how much a social media following is in fact required for success in DevRel. It's typically helpful for sure, but it's not everything. Being able to authentically and credibly connect with other developers is much more important:\\n\\n> You don't really need to have a following to be good at DevRel. It's much more important to have street cred [with developers] â€” Founder and Former Developer Advocate, Application Infrastructure Startup\\n\\nIn fact, social media can sometimes backfire (as we all know). In DevRel in particular, it can sometimes create the impression the person was merely \\\"acqui-hired\\\" for their social media sway rather than technical skills developers tend to appreciate and respect. I wouldn't say this is enough of a risk to be too worried about, but it's worth keeping in mind:\\n\\n> Social media helps, but it can also be problematic in certain ways. It can sometimes create the perception that they were just hired for the followers they have, rather than their technical capacity. That can problematic for the person and the company â€” Product Manager and Former Developer Advocate, Big Tech\\n\\n## Look for the core characteristics, regardless of current title\\n\\nRather than hire based on surface-level characteristics like current title or social media following, focus on identifying raw talent and passion for a key aspect of the role â€” [working in public](https://www.amazon.com/Working-Public-Making-Maintenance-Software/dp/0578675862/):\\n\\n> There's a lot of raw talent out there. They are often already blogging. They are trying to get permission to speak at conferences â€” Director of Developer Relations, Web Development Startup\\n\\nLook for people who are already doing DevRel without necessarily having a title for their efforts (yet). These are engineers who are writing blog posts (either for their employer or their personal blog), speaking at conferences, and publicly interacting with other developers. This is where social media can be value â€” it's not so much about having a *following* as much as it's about having a *participatory presence*:\\n\\n> Look for people who are already stepping up and doing the work. They are speaking at conferences, authoring blog posts, interacting on Twitter. Doesn't matter what their title is â€” Product Manager and Former Developer Advocate, Application Infrastructure Startup\\n\\nIn addition to behaviors, attitudes matter too. We've already discussed the importance of empathy, but a core desire to teach and help others is important too. Self-taught programmers are often great about this (since they know how hard it is to learn something on your own):\\n\\n> Self-taught programmers are great. They often have a chip on their shoulder and a willingness to teach others. They understand how valuable help is â€” Developer Success Engineer, Application Infrastructure Startup\\n\\nThe founders and DevRel folks I spoke to agreed: these core characteristics are more critical to success in the role than prior experience or social media following. You likely have engineers in your team today with these traits. Maybe it's worth having a conversation about DevRel?\\n\\n## Acres of DevRel diamonds\\n\\nConstraints drive [creativity](https://www.fastcompany.com/3067925/how-constraints-force-your-brain-to-be-more-creative) and [innovation](https://hbr.org/2019/11/why-constraints-are-good-for-innovation). The market for developer relations talent is certainly constrained, and we need to get creative in response. Expanding your perspective for what DevRel \\\"looks like\\\" beyond social media following and title will help you find [acres of DevRel diamonds](https://www.amazon.com/Acres-Diamonds-Life-Changing-Classics-Audio/dp/0937539783) where you least expect.\\n\\nAgain, remember this simple logic: \\n\\n* IF most *current* DevRel professionals were **past** engineers,\\n* THEN most *future* DevRel professionals are **current** engineers.\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}","html":"<!--kg-card-begin: markdown--><p><a href=\"https://www.marythengvall.com/blog/2019/5/22/what-is-developer-relations-and-why-should-you-care\">Developer relations</a> (DevRel) is one of the toughest hires to make in early stage, developer-centric startups.</p>\n<p>In <a href=\"__GHOST_URL__/developer-productivity-challenges/\">Four Challenges Facing Developer Productivity Startups</a> I identified scaling developer relations as one of the key challenges facing developer productivity startups today:</p>\n<blockquote>\n<p>... even if you're fully onboard with the idea of developer relations, doing it well is tough. To start, developer advocates are hard to come by. There just aren't many DevRel folks out there. The function is still relatively new, and career pipelines into the role have yet to fully materialize â€” <a href=\"__GHOST_URL__/developer-productivity-challenges/#scalingdeveloperrelations\">Four Challenges Facing Developer Productivity Startups</a></p>\n</blockquote>\n<p>To some extent this is a supply and demand issue â€” many more startups want to bring on developer advocates than there are available developer advocates.</p>\n<p>But there are structural issues behind the small quantity of available developer advocates â€” it leverages a combination of skill sets not often found in a single package, making it a tough role to hire for:</p>\n<blockquote>\n<p>DevRel is a hard spec to hire for. Technical folks are usually introverts. Extroverts are typically not technical â€” Developer Advocate, Analytics Infrastructure Startup</p>\n</blockquote>\n<blockquote>\n<p>I want them to be technical, and I'm always looking for empathy. It's very hard to find these things in a single person, this combination â€” Head of Developer Relations, Web Development Startup</p>\n</blockquote>\n<p>Even among the available pool of developer relations talent, companies have a hard time knowing who will be better at the role and what the key success factors are. How much does prior experience matter? How critical is it to have a large social media following?</p>\n<p>I've spoken to numerous founders and developer relations professionals to tease out best practices for DevRel hiring. This piece focuses on how to find high quality developer advocates despite the scarce supply.</p>\n<p>Here's some concrete advice:</p>\n<h2 id=\"mostdeveloperadvocatesareformerengineerssotalktosomecurrentengineers\">Most developer advocates are former engineers. So, talk to some current engineers</h2>\n<p>Current engineers are future developer advocates hiding in plain sight:</p>\n<blockquote>\n<p>Getting into this career can be hard, but there are many developers that I'd bet on to be great first time developer advocates â€” <a href=\"https://www.devocate.com/devocate-for-developers/\">Tessa Kriesel @ Devocate</a></p>\n</blockquote>\n<p>At some point, everyone gets their first gig in Developer Relations, and most of those people were developers themselves just before. Thus, current engineers are a great potential source of DevRel talent, if you're willing to do the work to pitch them on the role.</p>\n<p>In fact, many people who could be great developer advocates don't know how to break into the field. For example, many engineers simply haven't spent the the time to build up a large social media following, but this doesn't mean they couldn't be successful in the role:</p>\n<blockquote>\n<p>... the ones who could be good often have a hard time getting a foot in the door without a Twitter presence â€” Developer Advocate, Application Infrastructure Startup</p>\n</blockquote>\n<p>Some companies have realized this and shifted most of their DevRel hiring internally, focusing mainly on convincing existing engineers to try it out.</p>\n<p>The pitch? Developer advocates can often have impact much sooner and more frequently than engineers:</p>\n<blockquote>\n<p>We hire most of the DevRel team internally. Folks realized they could make an impact much sooner as DevRel than as engineers. Software releases take so long, but content takes much less time â€” Head of Developer Relations, Web Development Startup</p>\n</blockquote>\n<p>Developer advocates &quot;ship&quot; faster. A piece of content â€” a blog post, a Twitch stream, etc â€” is often much quicker to assemble and publish than shipping some piece of software, like a new feature, to production:</p>\n<blockquote>\n<p>Sometimes it's enough just to write an article just to start a conversation. It doesn't have to be a full fledged feature release like in software â€” Head of Developer Relations, Web Development Startup</p>\n</blockquote>\n<p>I haven't run the numbers, but it wouldn't surprise me if there were more <em>potential</em> developer advocates among current software engineers than <em>actual</em> developer advocates out there.</p>\n<p>So if you're having difficulty finding candidates for your open DevRel role, talk to some current engineers, even one's working at your company.</p>\n<p>And when you do, leave your biases at the door with respect to experience or social media following...</p>\n<h2 id=\"dontfilterfordevrelexperienceorsocialmediafollowing\">Don't filter for DevRel experience or social media following</h2>\n<p>As with any role, it's super tempting to assume &quot;only someone who's done this before could be good at it.&quot; Not so with DevRel:</p>\n<blockquote>\n<p>You can't look for experience, DevRel has barely existed for very long. If anything, non-traditional folks are often the best â€” Developer Success Engineer, Application Infrastructure Startup</p>\n</blockquote>\n<p>DevRel as a formal practice has not existed for long. You can't expect most people to have meaningful experience doing it. Again, this reinforces the idea that many potentially great developer advocates aren't currently in the role.</p>\n<p>Another important point to keep in mind is the job description for DevRel tends to be loose and ill-defined in many ways due to the nature of the role:</p>\n<blockquote>\n<p>The job description is extremely loose. Best people need to grow into it to some extent â€” Developer Success Engineer, Application Infrastructure Startup</p>\n</blockquote>\n<p>Regardless of what <em>you</em> think the person needs to do, the reality on the ground will look somewhat different. Accept this, and know that the best developer advocates will navigate this ambiguity regardless of whether they are an &quot;obvious&quot; fit based on their professional experience to date.</p>\n<p>One of the &quot;obvious&quot; characteristics people often filter on is social media following. But not so fast:</p>\n<blockquote>\n<p>Social media is just one part of the toolbox. Further, social following in one area does not necessarily translate to another â€” Developer Advocate, Analytics Infrastructure Startup</p>\n</blockquote>\n<p>It's debatable how much a social media following is in fact required for success in DevRel. It's typically helpful for sure, but it's not everything. Being able to authentically and credibly connect with other developers is much more important:</p>\n<blockquote>\n<p>You don't really need to have a following to be good at DevRel. It's much more important to have street cred [with developers] â€” Founder and Former Developer Advocate, Application Infrastructure Startup</p>\n</blockquote>\n<p>In fact, social media can sometimes backfire (as we all know). In DevRel in particular, it can sometimes create the impression the person was merely &quot;acqui-hired&quot; for their social media sway rather than technical skills developers tend to appreciate and respect. I wouldn't say this is enough of a risk to be too worried about, but it's worth keeping in mind:</p>\n<blockquote>\n<p>Social media helps, but it can also be problematic in certain ways. It can sometimes create the perception that they were just hired for the followers they have, rather than their technical capacity. That can problematic for the person and the company â€” Product Manager and Former Developer Advocate, Big Tech</p>\n</blockquote>\n<h2 id=\"lookforthecorecharacteristicsregardlessofcurrenttitle\">Look for the core characteristics, regardless of current title</h2>\n<p>Rather than hire based on surface-level characteristics like current title or social media following, focus on identifying raw talent and passion for a key aspect of the role â€” <a href=\"https://www.amazon.com/Working-Public-Making-Maintenance-Software/dp/0578675862/\">working in public</a>:</p>\n<blockquote>\n<p>There's a lot of raw talent out there. They are often already blogging. They are trying to get permission to speak at conferences â€” Director of Developer Relations, Web Development Startup</p>\n</blockquote>\n<p>Look for people who are already doing DevRel without necessarily having a title for their efforts (yet). These are engineers who are writing blog posts (either for their employer or their personal blog), speaking at conferences, and publicly interacting with other developers. This is where social media can be value â€” it's not so much about having a <em>following</em> as much as it's about having a <em>participatory presence</em>:</p>\n<blockquote>\n<p>Look for people who are already stepping up and doing the work. They are speaking at conferences, authoring blog posts, interacting on Twitter. Doesn't matter what their title is â€” Product Manager and Former Developer Advocate, Application Infrastructure Startup</p>\n</blockquote>\n<p>In addition to behaviors, attitudes matter too. We've already discussed the importance of empathy, but a core desire to teach and help others is important too. Self-taught programmers are often great about this (since they know how hard it is to learn something on your own):</p>\n<blockquote>\n<p>Self-taught programmers are great. They often have a chip on their shoulder and a willingness to teach others. They understand how valuable help is â€” Developer Success Engineer, Application Infrastructure Startup</p>\n</blockquote>\n<p>The founders and DevRel folks I spoke to agreed: these core characteristics are more critical to success in the role than prior experience or social media following. You likely have engineers in your team today with these traits. Maybe it's worth having a conversation about DevRel?</p>\n<h2 id=\"acresofdevreldiamonds\">Acres of DevRel diamonds</h2>\n<p>Constraints drive <a href=\"https://www.fastcompany.com/3067925/how-constraints-force-your-brain-to-be-more-creative\">creativity</a> and <a href=\"https://hbr.org/2019/11/why-constraints-are-good-for-innovation\">innovation</a>. The market for developer relations talent is certainly constrained, and we need to get creative in response. Expanding your perspective for what DevRel &quot;looks like&quot; beyond social media following and title will help you find <a href=\"https://www.amazon.com/Acres-Diamonds-Life-Changing-Classics-Audio/dp/0937539783\">acres of DevRel diamonds</a> where you least expect.</p>\n<p>Again, remember this simple logic:</p>\n<ul>\n<li>IF most <em>current</em> DevRel professionals were <strong>past</strong> engineers,</li>\n<li>THEN most <em>future</em> DevRel professionals are <strong>current</strong> engineers.</li>\n</ul>\n<!--kg-card-end: markdown-->","comment_id":"60acfa5595eadd54d31a7b9a","plaintext":"Developer relations\n[https://www.marythengvall.com/blog/2019/5/22/what-is-developer-relations-and-why-should-you-care] \n(DevRel) is one of the toughest hires to make in early stage, developer-centric\nstartups.\n\nIn Four Challenges Facing Developer Productivity Startups\n[/developer-productivity-challenges/] I identified scaling developer relations\nas one of the key challenges facing developer productivity startups today:\n\n> ... even if you're fully onboard with the idea of developer relations, doing it\nwell is tough. To start, developer advocates are hard to come by. There just\naren't many DevRel folks out there. The function is still relatively new, and\ncareer pipelines into the role have yet to fully materialize â€” Four Challenges\nFacing Developer Productivity Startups\n[/developer-productivity-challenges/#scalingdeveloperrelations]\n\n\nTo some extent this is a supply and demand issue â€” many more startups want to\nbring on developer advocates than there are available developer advocates.\n\nBut there are structural issues behind the small quantity of available developer\nadvocates â€” it leverages a combination of skill sets not often found in a single\npackage, making it a tough role to hire for:\n\n> DevRel is a hard spec to hire for. Technical folks are usually introverts.\nExtroverts are typically not technical â€” Developer Advocate, Analytics\nInfrastructure Startup\n\n\n> I want them to be technical, and I'm always looking for empathy. It's very hard\nto find these things in a single person, this combination â€” Head of Developer\nRelations, Web Development Startup\n\n\nEven among the available pool of developer relations talent, companies have a\nhard time knowing who will be better at the role and what the key success\nfactors are. How much does prior experience matter? How critical is it to have a\nlarge social media following?\n\nI've spoken to numerous founders and developer relations professionals to tease\nout best practices for DevRel hiring. This piece focuses on how to find high\nquality developer advocates despite the scarce supply.\n\nHere's some concrete advice:\n\nMost developer advocates are former engineers. So, talk to some current\nengineers\nCurrent engineers are future developer advocates hiding in plain sight:\n\n> Getting into this career can be hard, but there are many developers that I'd bet\non to be great first time developer advocates â€” Tessa Kriesel @ Devocate\n[https://www.devocate.com/devocate-for-developers/]\n\n\nAt some point, everyone gets their first gig in Developer Relations, and most of\nthose people were developers themselves just before. Thus, current engineers are\na great potential source of DevRel talent, if you're willing to do the work to\npitch them on the role.\n\nIn fact, many people who could be great developer advocates don't know how to\nbreak into the field. For example, many engineers simply haven't spent the the\ntime to build up a large social media following, but this doesn't mean they\ncouldn't be successful in the role:\n\n> ... the ones who could be good often have a hard time getting a foot in the door\nwithout a Twitter presence â€” Developer Advocate, Application Infrastructure\nStartup\n\n\nSome companies have realized this and shifted most of their DevRel hiring\ninternally, focusing mainly on convincing existing engineers to try it out.\n\nThe pitch? Developer advocates can often have impact much sooner and more\nfrequently than engineers:\n\n> We hire most of the DevRel team internally. Folks realized they could make an\nimpact much sooner as DevRel than as engineers. Software releases take so long,\nbut content takes much less time â€” Head of Developer Relations, Web Development\nStartup\n\n\nDeveloper advocates \"ship\" faster. A piece of content â€” a blog post, a Twitch\nstream, etc â€” is often much quicker to assemble and publish than shipping some\npiece of software, like a new feature, to production:\n\n> Sometimes it's enough just to write an article just to start a conversation. It\ndoesn't have to be a full fledged feature release like in software â€” Head of\nDeveloper Relations, Web Development Startup\n\n\nI haven't run the numbers, but it wouldn't surprise me if there were more \npotential developer advocates among current software engineers than actual \ndeveloper advocates out there.\n\nSo if you're having difficulty finding candidates for your open DevRel role,\ntalk to some current engineers, even one's working at your company.\n\nAnd when you do, leave your biases at the door with respect to experience or\nsocial media following...\n\nDon't filter for DevRel experience or social media following\nAs with any role, it's super tempting to assume \"only someone who's done this\nbefore could be good at it.\" Not so with DevRel:\n\n> You can't look for experience, DevRel has barely existed for very long. If\nanything, non-traditional folks are often the best â€” Developer Success Engineer,\nApplication Infrastructure Startup\n\n\nDevRel as a formal practice has not existed for long. You can't expect most\npeople to have meaningful experience doing it. Again, this reinforces the idea\nthat many potentially great developer advocates aren't currently in the role.\n\nAnother important point to keep in mind is the job description for DevRel tends\nto be loose and ill-defined in many ways due to the nature of the role:\n\n> The job description is extremely loose. Best people need to grow into it to some\nextent â€” Developer Success Engineer, Application Infrastructure Startup\n\n\nRegardless of what you think the person needs to do, the reality on the ground\nwill look somewhat different. Accept this, and know that the best developer\nadvocates will navigate this ambiguity regardless of whether they are an\n\"obvious\" fit based on their professional experience to date.\n\nOne of the \"obvious\" characteristics people often filter on is social media\nfollowing. But not so fast:\n\n> Social media is just one part of the toolbox. Further, social following in one\narea does not necessarily translate to another â€” Developer Advocate, Analytics\nInfrastructure Startup\n\n\nIt's debatable how much a social media following is in fact required for success\nin DevRel. It's typically helpful for sure, but it's not everything. Being able\nto authentically and credibly connect with other developers is much more\nimportant:\n\n> You don't really need to have a following to be good at DevRel. It's much more\nimportant to have street cred [with developers] â€” Founder and Former Developer\nAdvocate, Application Infrastructure Startup\n\n\nIn fact, social media can sometimes backfire (as we all know). In DevRel in\nparticular, it can sometimes create the impression the person was merely\n\"acqui-hired\" for their social media sway rather than technical skills\ndevelopers tend to appreciate and respect. I wouldn't say this is enough of a\nrisk to be too worried about, but it's worth keeping in mind:\n\n> Social media helps, but it can also be problematic in certain ways. It can\nsometimes create the perception that they were just hired for the followers they\nhave, rather than their technical capacity. That can problematic for the person\nand the company â€” Product Manager and Former Developer Advocate, Big Tech\n\n\nLook for the core characteristics, regardless of current title\nRather than hire based on surface-level characteristics like current title or\nsocial media following, focus on identifying raw talent and passion for a key\naspect of the role â€” working in public\n[https://www.amazon.com/Working-Public-Making-Maintenance-Software/dp/0578675862/]\n:\n\n> There's a lot of raw talent out there. They are often already blogging. They are\ntrying to get permission to speak at conferences â€” Director of Developer\nRelations, Web Development Startup\n\n\nLook for people who are already doing DevRel without necessarily having a title\nfor their efforts (yet). These are engineers who are writing blog posts (either\nfor their employer or their personal blog), speaking at conferences, and\npublicly interacting with other developers. This is where social media can be\nvalue â€” it's not so much about having a following as much as it's about having a \nparticipatory presence:\n\n> Look for people who are already stepping up and doing the work. They are\nspeaking at conferences, authoring blog posts, interacting on Twitter. Doesn't\nmatter what their title is â€” Product Manager and Former Developer Advocate,\nApplication Infrastructure Startup\n\n\nIn addition to behaviors, attitudes matter too. We've already discussed the\nimportance of empathy, but a core desire to teach and help others is important\ntoo. Self-taught programmers are often great about this (since they know how\nhard it is to learn something on your own):\n\n> Self-taught programmers are great. They often have a chip on their shoulder and\na willingness to teach others. They understand how valuable help is â€” Developer\nSuccess Engineer, Application Infrastructure Startup\n\n\nThe founders and DevRel folks I spoke to agreed: these core characteristics are\nmore critical to success in the role than prior experience or social media\nfollowing. You likely have engineers in your team today with these traits. Maybe\nit's worth having a conversation about DevRel?\n\nAcres of DevRel diamonds\nConstraints drive creativity\n[https://www.fastcompany.com/3067925/how-constraints-force-your-brain-to-be-more-creative] \nand innovation [https://hbr.org/2019/11/why-constraints-are-good-for-innovation]\n. The market for developer relations talent is certainly constrained, and we\nneed to get creative in response. Expanding your perspective for what DevRel\n\"looks like\" beyond social media following and title will help you find acres\nof\nDevRel diamonds\n[https://www.amazon.com/Acres-Diamonds-Life-Changing-Classics-Audio/dp/0937539783] \nwhere you least expect.\n\nAgain, remember this simple logic:\n\n * IF most current DevRel professionals were past engineers,\n * THEN most future DevRel professionals are current engineers.","feature_image":"__GHOST_URL__/content/images/2021/05/header-1.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2021-05-25T13:23:33.000Z","updated_at":"2022-01-30T07:47:33.000Z","published_at":"2021-05-25T14:20:40.000Z","custom_excerpt":"Why you shouldnâ€™t filter for social media following or prior experience","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"60e5cd58c1d1894be7adc8f7","uuid":"aa2af07f-c643-43c1-8771-dc22573294b8","title":"PhDs Aren't Starting Companies Like They Used To","slug":"phd-founders","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"The burden of scientific knowledge and managerial complexity is crushing our best and brightest.\\n\\nSTEM PhDs aren't starting companies like they used to. Meanwhile, fresh PhD founders earn *less* than they did 20 years ago.\\n\\nCushy tech jobs are looking better and better to our most highly-educated as entrepreneurship loses its relative attractiveness.\\n\\nHere's why.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: PhDs Aren't Starting Companies Like They Used To\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## Two decades of declining PhD entrepreneurship\\n\\n[STEM PhDs are creating fewer startups than they used to](https://www.nber.org/papers/w27787):\\n\\n> \\\"**We... show a decline over the past 20 years in both the rate of startups founded and the share of employment at startups by the highest-educated science and engineering portion of the U.S. workforce.** The declines are wide-ranging and not driven by any particular founder demographic category or geographic region or scientific discipline.\\\"\\n\\nHere's what the data shows: today, of STEM PhDs working in the private sector, only ~20% start companies, down from 30%+ in the late 90s:\\n\\n![izoe3lP-QH](https://res-1.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/izoe3lP-QH.png)\\n\\n> \\\"Figure 1 displays the large decline over the past two decades in the share of founders among PhDs in science and engineering. **In 1997, 34 percent reported being a founder of a startup, but by 2017 this rate had declined to 21 percent, a decline of 38 percent.**\\\"\\n\\nFurther, STEM PhDs are joining startups at lower rates in general, even outside of founder roles. **Startups are much less attractive to PhDs than they used to be.** This is true across demographic groups (gender, race, location, citizenship, etc.):\\n\\n> \\\"Since 1997, the share of founders in these startups has declined by around 38 percent, not limited to any particular founder demographic or ethnic group or occupation, and this decline is widespread across regions of the United States. The share of workers at startups has followed the same path of decline.\\\"\\n\\n> \\\"**the employment share of science and engineering PhDs at startups is also falling over time.** The downward trend is not driven by any particular category of PhDs. For example, figures similar to Figure 1 for males versus females, whites versus non-whites, California versus the rest of the U.S., and for U.S. versus non-U.S. born PhDs differ in levels but their dynamics are almost exactly the same as those in Figure 1... **The dramatically falling share of founders and employment at startups raises the prospect of a drying up of high-tech, high-opportunity startups.**\\\"\\n\\nWhy the change of heart among our PhD graduates? As the study authors speculate:\\n\\n> \\\"A potential source of this decline is the exponential increase in the amount of scientific knowledge.\\\"\\n\\nAs the fields from which these PhDs come have become increasingly complex and extensive over time, the amount of scientific knowledge one must cram in to operate at the cutting edge of the field has exploded. Take any field and you see the same trend â€” becoming an \\\"expert\\\" is much, much harder than it used to be, and this burden of scientific knowledge weighs on potential founders.\\n\\nNot only are fewer PhDs starting or joining startups, they're also waiting longer after completing their graduate coursework to found companies:\\n\\n> \\\"Consistent with the burden of knowledge increasing for founders, **the years of work experience among founders shows a steady increase.** The regression results imply that **the average founder had about 14 percent longer post-PhD work experience in 2017 than in 1997.**\\\"\\n\\nHere again we see the impact of the burden of scientific knowledge. With so much existing research and scientific knowledge out there to assimilate, PhD graduates are delaying entrepreneurship, taking more time to gather work experience before setting off on their own.\\n\\n## Learn to earn\\n\\nEven worse, relative to their more experienced peers, newly minted PhDs who do found startups earn much less than they used to, making founding a company an even less appealing proposition:\\n\\n![Jy9Ww_-fUd](https://res-5.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/Jy9Ww_-fUd.png)\\n\\n> \\\"Figure 2 illustrates **a pronounced decline over time in the earnings of less experienced founders relative to their more experienced peers.** Here, we separate less and more experienced founders by the median number of years after PhD (13 years), although other reasonable cut-offs lead to similar results. Between 1997 and 2001, founders with post-PhD experience at or below the median earned more... but by the 2010s, the situation is reversed, with **less experienced founders earning on average 30-40 percent less than other founders. Prior work experience apparently is becoming much more valuable for founders over time.**\\\"\\n\\nThe figure compares the earnings of PhD founders with below-median and above-median work experience and demonstrates that this ratio has fallen meaningfully over the past two decades. Whereas the groups used to have earnings parity, today young PhD founders suffer a significant earnings disadvantage relative to their more experienced peers, making 30-40% less.\\n\\nAbsolute earnings for the highly-educated in general have risen over the same period, so this might not be terrible news. Young PhD founders could still earn more than they used to in absolute terms.\\n\\n**Not so.** Earnings for PhD founders with below-median work experience **declined** in real (inflation-adjusted) terms, from \\\\$73K in 1997 to only â€‹\\\\$58K in 2017, **a 20%+ pay cut**:\\n\\n> \\\"**The earnings of less experienced founders declined not just in relative but also in absolute terms.** The average inflation-adjusted earnings of founders with below the median post-PhD experience were \\\\$72,616 in 1997, whereas 20 years later their earnings were â€‹\\\\$57,517, **a decline of more than 20 percent**\\\"\\n\\nThe earnings of young STEM PhD founders are their *lowest level* in more than 20 years.\\n\\nWhat if we combine both inexperienced and experienced founders and look at the overall trend in PhD founder earnings? Surely this has trended positively?\\n\\nNope:\\n\\n> \\\"Founders' earnings decline on average by about 1.6 percent per year (column 1). However, this is offset by an opposite time trend in returns to experience. The mean number of years after founders receive a PhD is 15.9 years; hence... at the mean work experience, the negative baseline time trend is completely offset.\\\"\\n\\nOK, this takes a bit of unpacking. Earnings for less experienced PhD founders have fallen, while more experienced founders have seen rising earnings. The breakeven point is ~15 years, which is to say founders with fewer than 15 years of post-PhD experience have seen declining real earnings over time, while founders with more than 15 years of experience have seen earnings growth. It just so happens the average PhD founder in the survey had 15.9 years of post-PhD experience, so the two stories roughly balance out.\\n\\n*The good news:* overall PhD founder earnings aren't declining! *The bad news:* PhD founder earnings aren't rising either!\\n\\n![Real-Earnings-of-PhD-Founders--1619555660589](https://res-1.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/Real-Earnings-of-PhD-Founders--1619555660589.svg)\\n\\nThe craziest thing about all this? PhD *employees* are doing much better: \\n\\n> \\\"In stark contrast to founders, **workers' real earnings grow over time**, although the increase is relatively small, 0.4 percent per year... The trend toward increasing returns to experience is much weaker among workers than among founders...\\\"\\n\\nAgain, let's unpack. STEM PhDs who work at established companies rather than startups have seen their earnings rise across the board, regardless of experience level:\\n\\n![Real-Earnings-of-PhD-Workers-1619555855360](https://res-4.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/Real-Earnings-of-PhD-Workers-1619555855360.svg)\\n\\nAs discussed earlier, founding a company as a young PhD is less attractive than it used to be. While young PhD founders used to make slightly more than young PhDs at established firms, this relationship has completely reversed, with inexperienced PhD founders now earning significantly less than their less entrepreneurial associates:\\n\\n![Real-Earnings-of-Inexperienced-PhDs-1619556012742](https://res-4.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/Real-Earnings-of-Inexperienced-PhDs-1619556012742.svg)\\n\\nIn summary, **new PhD founders get the worst deal**, earning less than both their equally and more experienced peers:\\n\\n![Real-Earnings-of-PhDs-1619556257369](https://res-1.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/Real-Earnings-of-PhDs-1619556257369.svg)\\n\\nThat was all a bit complicated, so before moving on, let's summarize the trends.\\n\\n* Previously, experience mattered most within established companies, but over time the \\\"gains from experience\\\" grew much more for founders than workers\\n* Experienced PhD founders went from being no better off than their less experienced peers to earning significantly more, whereas the gap between experienced and inexperienced PhD employees stayed relatively stable.\\n* Inexperienced PhD founders used to make more than inexperienced PhD workers, but this relationship has flipped\\n* Inexperienced PhD founders are now the worst-paid PhDs\\n\\n## The division of tasks\\n\\nSo far we've established:\\n\\n1. PhDs are founding far *fewer* companies, and \\n\\n2. When they do found companies, young PhD graduates earn *much less* than they used to and significantly less than peers working at established companies\\n\\nNot good. But it couldn't get any worse for our youthful, bright, wide-eyed PhDs could it?\\n\\nTurns out, it can.\\n\\n> \\\"**established firms have an advantage over startups in creating a division of labor in R&D**... by introducing more hierarchical layers, reducing knowledge workers' span of control, and allocating more experienced workers to positions with greater managerial responsibility. Further, established firms compensate workers for performing more R&D tasks and supervising more individuals. These developments are not seen among founders. **The differences follow from the natural limits imposed by running a small firm with less division of labor and a high amount of multitasking by the founder.** The largest firms are even more active in reorganizing job tasks, increasing the depth of hierarchy at twice the rate of all established firms.\\\"\\n\\nBig Tech and other large companies have become more attractive places to innovate for our most well-educated workers. Large companies have better dealt with the accumulated burden of scientific knowledge by enforcing a \\\"division of labor\\\" among employees. Large companies form *\\\"knowledge hierarchies\\\"*, such that no one person needs to know everything, and information can be aggregated up the chain in a rationale fashion. This lets organizations to scale to meet the needs of cutting edge scientific research and development, which increasingly incorporates impossibly vast sums of knowledge.\\n\\nOn the other hand, startup founders do not have armies of willing cadets to offload and delegate to. They are the captain of the ship and also it's most valuable crewmember, so as the burdens of both scientific knowledge and management complex grow, it all gets placed on their shoulders.\\n\\nThe job of a founder has gotten harder â€” running a startup today requires more management and R&D activities than it did 20 years ago. Quantified, this is about 15% more \\\"tasks\\\", with **R&D tasks growing by about 50% and management tasks growing 5%**:\\n\\n![fig3a](https://res-2.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/fig3a.png)\\n\\n> \\\"The average number of all tasks for founders increased by about 15 percent from the beginning to the end of our sample, a statistically significant difference... Furthermore, although the number of both R&D and management tasks increased, the increase is more pronounced in **R&D, for which it rose by more than 50 percent from 1997 to 2017**... As a result, R&D tasks that comprised about 25 percent of all tasks conducted by founders in 1997 increased to 34 percent of all tasks in 2017. As can be seen in Figure 3, this was not accompanied by any decline in management tasks, so the founders had to shoulder the burden of doing more R&D tasks while also running the same or more administrative tasks.\\\"\\n\\nPhD workers at established firms also saw their total tasks grow, but to a lesser degree. **R&D tasks for workers only grew 12% over the same 20 year period, and management tasks did not increase at all**:\\n\\n![fig3b](https://res-4.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/fig3b.png)\\n\\n> \\\"Workers were also affected by the need to perform more R&D tasks, as the increase in the number of R&D tasks from 1997 to 2017 is about 12 percent. Notably, however, as the figure reveals, workers did not need to handle more management tasks, which remained relatively flat for them.\\\"\\n\\nWhat gives? It goes back to the division of labor point I mentioned earlier. Let's start with R&D:\\n\\n> \\\"The number of R&D tasks is rising, but **established firms take advantage of a division of labor and knowledge hierarchies**\\\"\\n\\nThe growing burden of scientific knowledge increases the number of R&D tasks that founder must occupy themselves with. With little hierarchy or staff to offload this work, **founders have no operating leverage**. Conversely, large, established firms can shift much of the burden to armies of researchers, more efficiently dealing with the growing stack of research output.\\n\\n> \\\"**We find that the number of different R&D tasks has increased more for founders than for workers.** And the returns to experience have increased over time for founders but not for workers, **highlighting the increasing need for a single personâ€”the founderâ€”to cope with the burden of knowledge in startups.** Workers at established firms have, instead, comfortably narrowed their span of control, employed more people indirectly under their control to support their work, and kept administrative duties low. They are also better rewarded for taking on more diverse work and managerial responsibilities than founders. ...**established firms have coped more effectively with the increasing burden of knowledge in science by better utilizing the division of labor in innovative work through reorganizing tasks and hierarchies.**\\\"\\n\\nIndividual workers at established firms have limited scope, while the remaining load gets shared with other team members and subordinates. Further, the firm captures the gains from the successful division of labor and then shares this with employees in the form of better pay for the managers who corral these efforts internally.\\n\\n> \\\"Running a startup might constrain founders' ability to organize its hierarchy efficiently, at least until it has succeeded in growing well beyond its initial size. As science accumulates more knowledge, we would therefore expect PhD founders to have to take on more R&D tasks.\\\"\\n\\nFounders have no ability to pull off similar organizational tricks until their startups reach meaningful scale. Thus, as scientific knowledge has accumulated, they've taken on the additional R&D work themselves.\\n\\nThis has implications for startup management too:\\n\\n> \\\"Also, **founders had to deal with significantly more management tasks than workers** in terms of levels: about 30-40 percent more at the beginning of the study period, **increasing to 50 percent more at the end**. The explanation for this difference likely lies in how the two types of firms differ in their organization of work...\\\"\\n\\nFounders and startups cannot afford the overhead that comes with increasing layers of professional management. This is why startup's delay building executive teams until at least a few years into a startup's lifecycle. Large organizations can and do invest in these management layers, gladly taking on the extra expense:\\n\\n> \\\"... the firm responds by increasing the number of layers... and... [allowing] greater job specialization. Increasing the number of layers of management adds a fixed cost of operations... **[Larger] firms are more likely to become hierarchically taller by adding more layers of management... as they can more easily absorb the added fixed cost.** Founders at startups appear not to have recourse to this mitigation strategy.\\\"\\n\\nThe study's authors quantify these additional layers by tracking two metrics:\\n\\n* the number of individuals *directly* supervised by PhD founders and workers, and\\n* the number of individuals *indirectly* supervised (i.e. supervised by one's own direct reports)\\n\\nThe directly supervised corresponds to the **managerial burden** that each PhD-holder has (their span of control), while the indirectly supervised tells us how much **managerial leverage** each person has (the depth of hierarchy). The theory would suggest that workers within organizations should have fewer direct reports over time and more indirect reports, as organizations build out these knowledge hierarchies.\\n\\nAnd that's exactly what we see:\\n\\n![managerial](https://res-3.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/managerial.png)\\n\\n* Workers with PhDs saw the number of employees directly managed *decline* over time while the number of employees indirectly managed *increased* over time. In others words, **the proliferation of middle management reduces the management burden for any individual worker but increases overall managerial leverage.**\\n\\n* Founders on the other hand saw no statistically significant trend in their span of control or depth of hierarchy. **The organizational structure of startups has not evolved to keep up with the increased burden of scientific knowledge.**\\n\\n> \\\"workers [perform] fewer R&D tasks as they age... the span of control decreases for workers at established firms... However... hierarchies deepen over time for workers at established firms... Together, the results suggest that **established firms cope with the increasing burden of knowledge on their workers by introducing additional layers of hierarchy, while simultaneously reducing the number of employees who report directly to managers**\\\"\\n\\n## Doing \\\\*too many\\\\* things that don't scale\\n\\nWe need to think harder about making knowledge work... work.\\n\\nIn summary:\\n\\n> \\\"Our findings suggest that if the goal is to restore business dynamism in the high-tech sector, **alleviating the burden of knowledge should be front and center** in the strategy to attain it.\\\"\\n\\nThe declining in PhD entrepreneurship mimics a broader drop in startup formation chronicled elsewhere. But PhD founders are special... and so these trends are especially worrying.\\n\\nSTEM PhDs have founded some of the world's most successful and impactful enterprises. Among them: Google, Intel, VMware, and others.\\n\\nIronically, however, today these same companies gobble up the brightest minds we have, discouraging or delaying their own entrepreneurial pursuits.\\n\\nIn Silicon Valley we talk a lot about management practices to help founders and executives \\\"scale.\\\" But deeply technical founders face a separate but equally important problem: scaling *knowledge*.\\n\"}],[\"embed\",{\"url\":\"https://twitter.com/whoisnnamdi/status/1413250293786021889\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">PhDs aren&#39;t starting companies like they used to<br><br>Cushy tech jobs are more and more attractive to STEM PhDs<br><br>The burden of scientific knowledge and managerial complexity is crushing our best and brightest<br><br>I explore the precipitous decline in PhD founders:<a href=\\\"https://t.co/NxpFn3NrZv\\\">https://t.co/NxpFn3NrZv</a></p>&mdash; Nnamdi Iregbulem (@whoisnnamdi) <a href=\\\"https://twitter.com/whoisnnamdi/status/1413250293786021889?ref_src=twsrc%5Etfw\\\">July 8, 2021</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\",\"metadata\":{\"url\":\"https://twitter.com/whoisnnamdi/status/1413250293786021889\",\"author_name\":\"Nnamdi Iregbulem\",\"author_url\":\"https://twitter.com/whoisnnamdi\",\"width\":550,\"height\":null,\"cache_age\":\"3153600000\",\"provider_name\":\"Twitter\",\"provider_url\":\"http://www.twitter.com/\",\"version\":\"1.0\"}}],[\"markdown\",{\"markdown\":\"*Thanks to [Thomas Astebro](https://www.hec.edu/en/faculty-research/faculty-directory/faculty-member/astebro-thomas), [Serguey Braguinsky](https://www.rhsmith.umd.edu/directory/serguey-braguinsky), and [Yuheng Ding](https://www.rhsmith.umd.edu/directory/yuheng-gavin-ding), the authors of [the study](https://www.nber.org/papers/w27787) from which much of this essay is derived.*\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: PhDs Aren't Starting Companies Like They Used To\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>The burden of scientific knowledge and managerial complexity is crushing our best and brightest.</p>\n<p>STEM PhDs aren't starting companies like they used to. Meanwhile, fresh PhD founders earn <em>less</em> than they did 20 years ago.</p>\n<p>Cushy tech jobs are looking better and better to our most highly-educated as entrepreneurship loses its relative attractiveness.</p>\n<p>Here's why.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: PhDs Aren't Starting Companies Like They Used To\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"two-decades-of-declining-phd-entrepreneurship\">Two decades of declining PhD entrepreneurship</h2>\n<p><a href=\"https://www.nber.org/papers/w27787\">STEM PhDs are creating fewer startups than they used to</a>:</p>\n<blockquote>\n<p>&quot;<strong>We... show a decline over the past 20 years in both the rate of startups founded and the share of employment at startups by the highest-educated science and engineering portion of the U.S. workforce.</strong> The declines are wide-ranging and not driven by any particular founder demographic category or geographic region or scientific discipline.&quot;</p>\n</blockquote>\n<p>Here's what the data shows: today, of STEM PhDs working in the private sector, only ~20% start companies, down from 30%+ in the late 90s:</p>\n<p><img src=\"https://res-1.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/izoe3lP-QH.png\" alt=\"izoe3lP-QH\" loading=\"lazy\"></p>\n<blockquote>\n<p>&quot;Figure 1 displays the large decline over the past two decades in the share of founders among PhDs in science and engineering. <strong>In 1997, 34 percent reported being a founder of a startup, but by 2017 this rate had declined to 21 percent, a decline of 38 percent.</strong>&quot;</p>\n</blockquote>\n<p>Further, STEM PhDs are joining startups at lower rates in general, even outside of founder roles. <strong>Startups are much less attractive to PhDs than they used to be.</strong> This is true across demographic groups (gender, race, location, citizenship, etc.):</p>\n<blockquote>\n<p>&quot;Since 1997, the share of founders in these startups has declined by around 38 percent, not limited to any particular founder demographic or ethnic group or occupation, and this decline is widespread across regions of the United States. The share of workers at startups has followed the same path of decline.&quot;</p>\n</blockquote>\n<blockquote>\n<p>&quot;<strong>the employment share of science and engineering PhDs at startups is also falling over time.</strong> The downward trend is not driven by any particular category of PhDs. For example, figures similar to Figure 1 for males versus females, whites versus non-whites, California versus the rest of the U.S., and for U.S. versus non-U.S. born PhDs differ in levels but their dynamics are almost exactly the same as those in Figure 1... <strong>The dramatically falling share of founders and employment at startups raises the prospect of a drying up of high-tech, high-opportunity startups.</strong>&quot;</p>\n</blockquote>\n<p>Why the change of heart among our PhD graduates? As the study authors speculate:</p>\n<blockquote>\n<p>&quot;A potential source of this decline is the exponential increase in the amount of scientific knowledge.&quot;</p>\n</blockquote>\n<p>As the fields from which these PhDs come have become increasingly complex and extensive over time, the amount of scientific knowledge one must cram in to operate at the cutting edge of the field has exploded. Take any field and you see the same trend â€” becoming an &quot;expert&quot; is much, much harder than it used to be, and this burden of scientific knowledge weighs on potential founders.</p>\n<p>Not only are fewer PhDs starting or joining startups, they're also waiting longer after completing their graduate coursework to found companies:</p>\n<blockquote>\n<p>&quot;Consistent with the burden of knowledge increasing for founders, <strong>the years of work experience among founders shows a steady increase.</strong> The regression results imply that <strong>the average founder had about 14 percent longer post-PhD work experience in 2017 than in 1997.</strong>&quot;</p>\n</blockquote>\n<p>Here again we see the impact of the burden of scientific knowledge. With so much existing research and scientific knowledge out there to assimilate, PhD graduates are delaying entrepreneurship, taking more time to gather work experience before setting off on their own.</p>\n<h2 id=\"learn-to-earn\">Learn to earn</h2>\n<p>Even worse, relative to their more experienced peers, newly minted PhDs who do found startups earn much less than they used to, making founding a company an even less appealing proposition:</p>\n<p><img src=\"https://res-5.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/Jy9Ww_-fUd.png\" alt=\"Jy9Ww_-fUd\" loading=\"lazy\"></p>\n<blockquote>\n<p>&quot;Figure 2 illustrates <strong>a pronounced decline over time in the earnings of less experienced founders relative to their more experienced peers.</strong> Here, we separate less and more experienced founders by the median number of years after PhD (13 years), although other reasonable cut-offs lead to similar results. Between 1997 and 2001, founders with post-PhD experience at or below the median earned more... but by the 2010s, the situation is reversed, with <strong>less experienced founders earning on average 30-40 percent less than other founders. Prior work experience apparently is becoming much more valuable for founders over time.</strong>&quot;</p>\n</blockquote>\n<p>The figure compares the earnings of PhD founders with below-median and above-median work experience and demonstrates that this ratio has fallen meaningfully over the past two decades. Whereas the groups used to have earnings parity, today young PhD founders suffer a significant earnings disadvantage relative to their more experienced peers, making 30-40% less.</p>\n<p>Absolute earnings for the highly-educated in general have risen over the same period, so this might not be terrible news. Young PhD founders could still earn more than they used to in absolute terms.</p>\n<p><strong>Not so.</strong> Earnings for PhD founders with below-median work experience <strong>declined</strong> in real (inflation-adjusted) terms, from $73K in 1997 to only â€‹$58K in 2017, <strong>a 20%+ pay cut</strong>:</p>\n<blockquote>\n<p>&quot;<strong>The earnings of less experienced founders declined not just in relative but also in absolute terms.</strong> The average inflation-adjusted earnings of founders with below the median post-PhD experience were $72,616 in 1997, whereas 20 years later their earnings were â€‹$57,517, <strong>a decline of more than 20 percent</strong>&quot;</p>\n</blockquote>\n<p>The earnings of young STEM PhD founders are their <em>lowest level</em> in more than 20 years.</p>\n<p>What if we combine both inexperienced and experienced founders and look at the overall trend in PhD founder earnings? Surely this has trended positively?</p>\n<p>Nope:</p>\n<blockquote>\n<p>&quot;Founders' earnings decline on average by about 1.6 percent per year (column 1). However, this is offset by an opposite time trend in returns to experience. The mean number of years after founders receive a PhD is 15.9 years; hence... at the mean work experience, the negative baseline time trend is completely offset.&quot;</p>\n</blockquote>\n<p>OK, this takes a bit of unpacking. Earnings for less experienced PhD founders have fallen, while more experienced founders have seen rising earnings. The breakeven point is ~15 years, which is to say founders with fewer than 15 years of post-PhD experience have seen declining real earnings over time, while founders with more than 15 years of experience have seen earnings growth. It just so happens the average PhD founder in the survey had 15.9 years of post-PhD experience, so the two stories roughly balance out.</p>\n<p><em>The good news:</em> overall PhD founder earnings aren't declining! <em>The bad news:</em> PhD founder earnings aren't rising either!</p>\n<p><img src=\"https://res-1.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/Real-Earnings-of-PhD-Founders--1619555660589.svg\" alt=\"Real-Earnings-of-PhD-Founders--1619555660589\" loading=\"lazy\"></p>\n<p>The craziest thing about all this? PhD <em>employees</em> are doing much better:</p>\n<blockquote>\n<p>&quot;In stark contrast to founders, <strong>workers' real earnings grow over time</strong>, although the increase is relatively small, 0.4 percent per year... The trend toward increasing returns to experience is much weaker among workers than among founders...&quot;</p>\n</blockquote>\n<p>Again, let's unpack. STEM PhDs who work at established companies rather than startups have seen their earnings rise across the board, regardless of experience level:</p>\n<p><img src=\"https://res-4.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/Real-Earnings-of-PhD-Workers-1619555855360.svg\" alt=\"Real-Earnings-of-PhD-Workers-1619555855360\" loading=\"lazy\"></p>\n<p>As discussed earlier, founding a company as a young PhD is less attractive than it used to be. While young PhD founders used to make slightly more than young PhDs at established firms, this relationship has completely reversed, with inexperienced PhD founders now earning significantly less than their less entrepreneurial associates:</p>\n<p><img src=\"https://res-4.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/Real-Earnings-of-Inexperienced-PhDs-1619556012742.svg\" alt=\"Real-Earnings-of-Inexperienced-PhDs-1619556012742\" loading=\"lazy\"></p>\n<p>In summary, <strong>new PhD founders get the worst deal</strong>, earning less than both their equally and more experienced peers:</p>\n<p><img src=\"https://res-1.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/Real-Earnings-of-PhDs-1619556257369.svg\" alt=\"Real-Earnings-of-PhDs-1619556257369\" loading=\"lazy\"></p>\n<p>That was all a bit complicated, so before moving on, let's summarize the trends.</p>\n<ul>\n<li>Previously, experience mattered most within established companies, but over time the &quot;gains from experience&quot; grew much more for founders than workers</li>\n<li>Experienced PhD founders went from being no better off than their less experienced peers to earning significantly more, whereas the gap between experienced and inexperienced PhD employees stayed relatively stable.</li>\n<li>Inexperienced PhD founders used to make more than inexperienced PhD workers, but this relationship has flipped</li>\n<li>Inexperienced PhD founders are now the worst-paid PhDs</li>\n</ul>\n<h2 id=\"the-division-of-tasks\">The division of tasks</h2>\n<p>So far we've established:</p>\n<ol>\n<li>\n<p>PhDs are founding far <em>fewer</em> companies, and</p>\n</li>\n<li>\n<p>When they do found companies, young PhD graduates earn <em>much less</em> than they used to and significantly less than peers working at established companies</p>\n</li>\n</ol>\n<p>Not good. But it couldn't get any worse for our youthful, bright, wide-eyed PhDs could it?</p>\n<p>Turns out, it can.</p>\n<blockquote>\n<p>&quot;<strong>established firms have an advantage over startups in creating a division of labor in R&amp;D</strong>... by introducing more hierarchical layers, reducing knowledge workers' span of control, and allocating more experienced workers to positions with greater managerial responsibility. Further, established firms compensate workers for performing more R&amp;D tasks and supervising more individuals. These developments are not seen among founders. <strong>The differences follow from the natural limits imposed by running a small firm with less division of labor and a high amount of multitasking by the founder.</strong> The largest firms are even more active in reorganizing job tasks, increasing the depth of hierarchy at twice the rate of all established firms.&quot;</p>\n</blockquote>\n<p>Big Tech and other large companies have become more attractive places to innovate for our most well-educated workers. Large companies have better dealt with the accumulated burden of scientific knowledge by enforcing a &quot;division of labor&quot; among employees. Large companies form <em>&quot;knowledge hierarchies&quot;</em>, such that no one person needs to know everything, and information can be aggregated up the chain in a rationale fashion. This lets organizations to scale to meet the needs of cutting edge scientific research and development, which increasingly incorporates impossibly vast sums of knowledge.</p>\n<p>On the other hand, startup founders do not have armies of willing cadets to offload and delegate to. They are the captain of the ship and also it's most valuable crewmember, so as the burdens of both scientific knowledge and management complex grow, it all gets placed on their shoulders.</p>\n<p>The job of a founder has gotten harder â€” running a startup today requires more management and R&amp;D activities than it did 20 years ago. Quantified, this is about 15% more &quot;tasks&quot;, with <strong>R&amp;D tasks growing by about 50% and management tasks growing 5%</strong>:</p>\n<p><img src=\"https://res-2.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/fig3a.png\" alt=\"fig3a\" loading=\"lazy\"></p>\n<blockquote>\n<p>&quot;The average number of all tasks for founders increased by about 15 percent from the beginning to the end of our sample, a statistically significant difference... Furthermore, although the number of both R&amp;D and management tasks increased, the increase is more pronounced in <strong>R&amp;D, for which it rose by more than 50 percent from 1997 to 2017</strong>... As a result, R&amp;D tasks that comprised about 25 percent of all tasks conducted by founders in 1997 increased to 34 percent of all tasks in 2017. As can be seen in Figure 3, this was not accompanied by any decline in management tasks, so the founders had to shoulder the burden of doing more R&amp;D tasks while also running the same or more administrative tasks.&quot;</p>\n</blockquote>\n<p>PhD workers at established firms also saw their total tasks grow, but to a lesser degree. <strong>R&amp;D tasks for workers only grew 12% over the same 20 year period, and management tasks did not increase at all</strong>:</p>\n<p><img src=\"https://res-4.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/fig3b.png\" alt=\"fig3b\" loading=\"lazy\"></p>\n<blockquote>\n<p>&quot;Workers were also affected by the need to perform more R&amp;D tasks, as the increase in the number of R&amp;D tasks from 1997 to 2017 is about 12 percent. Notably, however, as the figure reveals, workers did not need to handle more management tasks, which remained relatively flat for them.&quot;</p>\n</blockquote>\n<p>What gives? It goes back to the division of labor point I mentioned earlier. Let's start with R&amp;D:</p>\n<blockquote>\n<p>&quot;The number of R&amp;D tasks is rising, but <strong>established firms take advantage of a division of labor and knowledge hierarchies</strong>&quot;</p>\n</blockquote>\n<p>The growing burden of scientific knowledge increases the number of R&amp;D tasks that founder must occupy themselves with. With little hierarchy or staff to offload this work, <strong>founders have no operating leverage</strong>. Conversely, large, established firms can shift much of the burden to armies of researchers, more efficiently dealing with the growing stack of research output.</p>\n<blockquote>\n<p>&quot;<strong>We find that the number of different R&amp;D tasks has increased more for founders than for workers.</strong> And the returns to experience have increased over time for founders but not for workers, <strong>highlighting the increasing need for a single personâ€”the founderâ€”to cope with the burden of knowledge in startups.</strong> Workers at established firms have, instead, comfortably narrowed their span of control, employed more people indirectly under their control to support their work, and kept administrative duties low. They are also better rewarded for taking on more diverse work and managerial responsibilities than founders. ...<strong>established firms have coped more effectively with the increasing burden of knowledge in science by better utilizing the division of labor in innovative work through reorganizing tasks and hierarchies.</strong>&quot;</p>\n</blockquote>\n<p>Individual workers at established firms have limited scope, while the remaining load gets shared with other team members and subordinates. Further, the firm captures the gains from the successful division of labor and then shares this with employees in the form of better pay for the managers who corral these efforts internally.</p>\n<blockquote>\n<p>&quot;Running a startup might constrain founders' ability to organize its hierarchy efficiently, at least until it has succeeded in growing well beyond its initial size. As science accumulates more knowledge, we would therefore expect PhD founders to have to take on more R&amp;D tasks.&quot;</p>\n</blockquote>\n<p>Founders have no ability to pull off similar organizational tricks until their startups reach meaningful scale. Thus, as scientific knowledge has accumulated, they've taken on the additional R&amp;D work themselves.</p>\n<p>This has implications for startup management too:</p>\n<blockquote>\n<p>&quot;Also, <strong>founders had to deal with significantly more management tasks than workers</strong> in terms of levels: about 30-40 percent more at the beginning of the study period, <strong>increasing to 50 percent more at the end</strong>. The explanation for this difference likely lies in how the two types of firms differ in their organization of work...&quot;</p>\n</blockquote>\n<p>Founders and startups cannot afford the overhead that comes with increasing layers of professional management. This is why startup's delay building executive teams until at least a few years into a startup's lifecycle. Large organizations can and do invest in these management layers, gladly taking on the extra expense:</p>\n<blockquote>\n<p>&quot;... the firm responds by increasing the number of layers... and... [allowing] greater job specialization. Increasing the number of layers of management adds a fixed cost of operations... <strong>[Larger] firms are more likely to become hierarchically taller by adding more layers of management... as they can more easily absorb the added fixed cost.</strong> Founders at startups appear not to have recourse to this mitigation strategy.&quot;</p>\n</blockquote>\n<p>The study's authors quantify these additional layers by tracking two metrics:</p>\n<ul>\n<li>the number of individuals <em>directly</em> supervised by PhD founders and workers, and</li>\n<li>the number of individuals <em>indirectly</em> supervised (i.e. supervised by one's own direct reports)</li>\n</ul>\n<p>The directly supervised corresponds to the <strong>managerial burden</strong> that each PhD-holder has (their span of control), while the indirectly supervised tells us how much <strong>managerial leverage</strong> each person has (the depth of hierarchy). The theory would suggest that workers within organizations should have fewer direct reports over time and more indirect reports, as organizations build out these knowledge hierarchies.</p>\n<p>And that's exactly what we see:</p>\n<p><img src=\"https://res-3.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/managerial.png\" alt=\"managerial\" loading=\"lazy\"></p>\n<ul>\n<li>\n<p>Workers with PhDs saw the number of employees directly managed <em>decline</em> over time while the number of employees indirectly managed <em>increased</em> over time. In others words, <strong>the proliferation of middle management reduces the management burden for any individual worker but increases overall managerial leverage.</strong></p>\n</li>\n<li>\n<p>Founders on the other hand saw no statistically significant trend in their span of control or depth of hierarchy. <strong>The organizational structure of startups has not evolved to keep up with the increased burden of scientific knowledge.</strong></p>\n</li>\n</ul>\n<blockquote>\n<p>&quot;workers [perform] fewer R&amp;D tasks as they age... the span of control decreases for workers at established firms... However... hierarchies deepen over time for workers at established firms... Together, the results suggest that <strong>established firms cope with the increasing burden of knowledge on their workers by introducing additional layers of hierarchy, while simultaneously reducing the number of employees who report directly to managers</strong>&quot;</p>\n</blockquote>\n<h2 id=\"doing-too-many-things-that-dont-scale\">Doing *too many* things that don't scale</h2>\n<p>We need to think harder about making knowledge work... work.</p>\n<p>In summary:</p>\n<blockquote>\n<p>&quot;Our findings suggest that if the goal is to restore business dynamism in the high-tech sector, <strong>alleviating the burden of knowledge should be front and center</strong> in the strategy to attain it.&quot;</p>\n</blockquote>\n<p>The declining in PhD entrepreneurship mimics a broader drop in startup formation chronicled elsewhere. But PhD founders are special... and so these trends are especially worrying.</p>\n<p>STEM PhDs have founded some of the world's most successful and impactful enterprises. Among them: Google, Intel, VMware, and others.</p>\n<p>Ironically, however, today these same companies gobble up the brightest minds we have, discouraging or delaying their own entrepreneurial pursuits.</p>\n<p>In Silicon Valley we talk a lot about management practices to help founders and executives &quot;scale.&quot; But deeply technical founders face a separate but equally important problem: scaling <em>knowledge</em>.</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">PhDs aren&#39;t starting companies like they used to<br><br>Cushy tech jobs are more and more attractive to STEM PhDs<br><br>The burden of scientific knowledge and managerial complexity is crushing our best and brightest<br><br>I explore the precipitous decline in PhD founders:<a href=\"https://t.co/NxpFn3NrZv\">https://t.co/NxpFn3NrZv</a></p>&mdash; Nnamdi Iregbulem (@whoisnnamdi) <a href=\"https://twitter.com/whoisnnamdi/status/1413250293786021889?ref_src=twsrc%5Etfw\">July 8, 2021</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><!--kg-card-begin: markdown--><p><em>Thanks to <a href=\"https://www.hec.edu/en/faculty-research/faculty-directory/faculty-member/astebro-thomas\">Thomas Astebro</a>, <a href=\"https://www.rhsmith.umd.edu/directory/serguey-braguinsky\">Serguey Braguinsky</a>, and <a href=\"https://www.rhsmith.umd.edu/directory/yuheng-gavin-ding\">Yuheng Ding</a>, the authors of <a href=\"https://www.nber.org/papers/w27787\">the study</a> from which much of this essay is derived.</em></p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: PhDs Aren't Starting Companies Like They Used To\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"60e5cd58c1d1894be7adc8f7","plaintext":"The burden of scientific knowledge and managerial complexity is crushing our\nbest and brightest.\n\nSTEM PhDs aren't starting companies like they used to. Meanwhile, fresh PhD\nfounders earn less than they did 20 years ago.\n\nCushy tech jobs are looking better and better to our most highly-educated as\nentrepreneurship loses its relative attractiveness.\n\nHere's why.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Two decades of declining PhD entrepreneurship\nSTEM PhDs are creating fewer startups than they used to\n[https://www.nber.org/papers/w27787]:\n\n> \"We... show a decline over the past 20 years in both the rate of startups\nfounded and the share of employment at startups by the highest-educated science\nand engineering portion of the U.S. workforce. The declines are wide-ranging and\nnot driven by any particular founder demographic category or geographic region\nor scientific discipline.\"\n\n\nHere's what the data shows: today, of STEM PhDs working in the private sector,\nonly ~20% start companies, down from 30%+ in the late 90s:\n\n\n\n> \"Figure 1 displays the large decline over the past two decades in the share of\nfounders among PhDs in science and engineering. In 1997, 34 percent reported\nbeing a founder of a startup, but by 2017 this rate had declined to 21 percent,\na decline of 38 percent.\"\n\n\nFurther, STEM PhDs are joining startups at lower rates in general, even outside\nof founder roles. Startups are much less attractive to PhDs than they used to\nbe. This is true across demographic groups (gender, race, location, citizenship,\netc.):\n\n> \"Since 1997, the share of founders in these startups has declined by around 38\npercent, not limited to any particular founder demographic or ethnic group or\noccupation, and this decline is widespread across regions of the United States.\nThe share of workers at startups has followed the same path of decline.\"\n\n\n> \"the employment share of science and engineering PhDs at startups is also\nfalling over time. The downward trend is not driven by any particular category\nof PhDs. For example, figures similar to Figure 1 for males versus females,\nwhites versus non-whites, California versus the rest of the U.S., and for U.S.\nversus non-U.S. born PhDs differ in levels but their dynamics are almost exactly\nthe same as those in Figure 1... The dramatically falling share of founders and\nemployment at startups raises the prospect of a drying up of high-tech,\nhigh-opportunity startups.\"\n\n\nWhy the change of heart among our PhD graduates? As the study authors speculate:\n\n> \"A potential source of this decline is the exponential increase in the amount of\nscientific knowledge.\"\n\n\nAs the fields from which these PhDs come have become increasingly complex and\nextensive over time, the amount of scientific knowledge one must cram in to\noperate at the cutting edge of the field has exploded. Take any field and you\nsee the same trend â€” becoming an \"expert\" is much, much harder than it used to\nbe, and this burden of scientific knowledge weighs on potential founders.\n\nNot only are fewer PhDs starting or joining startups, they're also waiting\nlonger after completing their graduate coursework to found companies:\n\n> \"Consistent with the burden of knowledge increasing for founders, the years of\nwork experience among founders shows a steady increase. The regression results\nimply that the average founder had about 14 percent longer post-PhD work\nexperience in 2017 than in 1997.\"\n\n\nHere again we see the impact of the burden of scientific knowledge. With so much\nexisting research and scientific knowledge out there to assimilate, PhD\ngraduates are delaying entrepreneurship, taking more time to gather work\nexperience before setting off on their own.\n\nLearn to earn\nEven worse, relative to their more experienced peers, newly minted PhDs who do\nfound startups earn much less than they used to, making founding a company an\neven less appealing proposition:\n\n\n\n> \"Figure 2 illustrates a pronounced decline over time in the earnings of less\nexperienced founders relative to their more experienced peers. Here, we separate\nless and more experienced founders by the median number of years after PhD (13\nyears), although other reasonable cut-offs lead to similar results. Between 1997\nand 2001, founders with post-PhD experience at or below the median earned\nmore... but by the 2010s, the situation is reversed, with less experienced\nfounders earning on average 30-40 percent less than other founders. Prior work\nexperience apparently is becoming much more valuable for founders over time.\"\n\n\nThe figure compares the earnings of PhD founders with below-median and\nabove-median work experience and demonstrates that this ratio has fallen\nmeaningfully over the past two decades. Whereas the groups used to have earnings\nparity, today young PhD founders suffer a significant earnings disadvantage\nrelative to their more experienced peers, making 30-40% less.\n\nAbsolute earnings for the highly-educated in general have risen over the same\nperiod, so this might not be terrible news. Young PhD founders could still earn\nmore than they used to in absolute terms.\n\nNot so. Earnings for PhD founders with below-median work experience declined in\nreal (inflation-adjusted) terms, from $73K in 1997 to only â€‹$58K in 2017, a 20%+\npay cut:\n\n> \"The earnings of less experienced founders declined not just in relative but\nalso in absolute terms. The average inflation-adjusted earnings of founders with\nbelow the median post-PhD experience were $72,616 in 1997, whereas 20 years\nlater their earnings were â€‹$57,517, a decline of more than 20 percent\"\n\n\nThe earnings of young STEM PhD founders are their lowest level in more than 20\nyears.\n\nWhat if we combine both inexperienced and experienced founders and look at the\noverall trend in PhD founder earnings? Surely this has trended positively?\n\nNope:\n\n> \"Founders' earnings decline on average by about 1.6 percent per year (column 1).\nHowever, this is offset by an opposite time trend in returns to experience. The\nmean number of years after founders receive a PhD is 15.9 years; hence... at the\nmean work experience, the negative baseline time trend is completely offset.\"\n\n\nOK, this takes a bit of unpacking. Earnings for less experienced PhD founders\nhave fallen, while more experienced founders have seen rising earnings. The\nbreakeven point is ~15 years, which is to say founders with fewer than 15 years\nof post-PhD experience have seen declining real earnings over time, while\nfounders with more than 15 years of experience have seen earnings growth. It\njust so happens the average PhD founder in the survey had 15.9 years of post-PhD\nexperience, so the two stories roughly balance out.\n\nThe good news: overall PhD founder earnings aren't declining! The bad news: PhD\nfounder earnings aren't rising either!\n\n\n\nThe craziest thing about all this? PhD employees are doing much better:\n\n> \"In stark contrast to founders, workers' real earnings grow over time, although\nthe increase is relatively small, 0.4 percent per year... The trend toward\nincreasing returns to experience is much weaker among workers than among\nfounders...\"\n\n\nAgain, let's unpack. STEM PhDs who work at established companies rather than\nstartups have seen their earnings rise across the board, regardless of\nexperience level:\n\n\n\nAs discussed earlier, founding a company as a young PhD is less attractive than\nit used to be. While young PhD founders used to make slightly more than young\nPhDs at established firms, this relationship has completely reversed, with\ninexperienced PhD founders now earning significantly less than their less\nentrepreneurial associates:\n\n\n\nIn summary, new PhD founders get the worst deal, earning less than both their\nequally and more experienced peers:\n\n\n\nThat was all a bit complicated, so before moving on, let's summarize the trends.\n\n * Previously, experience mattered most within established companies, but over\n   time the \"gains from experience\" grew much more for founders than workers\n * Experienced PhD founders went from being no better off than their less\n   experienced peers to earning significantly more, whereas the gap between\n   experienced and inexperienced PhD employees stayed relatively stable.\n * Inexperienced PhD founders used to make more than inexperienced PhD workers,\n   but this relationship has flipped\n * Inexperienced PhD founders are now the worst-paid PhDs\n\nThe division of tasks\nSo far we've established:\n\n 1. PhDs are founding far fewer companies, and\n    \n    \n 2. When they do found companies, young PhD graduates earn much less than they\n    used to and significantly less than peers working at established companies\n    \n    \n\nNot good. But it couldn't get any worse for our youthful, bright, wide-eyed PhDs\ncould it?\n\nTurns out, it can.\n\n> \"established firms have an advantage over startups in creating a division of\nlabor in R&D... by introducing more hierarchical layers, reducing knowledge\nworkers' span of control, and allocating more experienced workers to positions\nwith greater managerial responsibility. Further, established firms compensate\nworkers for performing more R&D tasks and supervising more individuals. These\ndevelopments are not seen among founders. The differences follow from the\nnatural limits imposed by running a small firm with less division of labor and a\nhigh amount of multitasking by the founder. The largest firms are even more\nactive in reorganizing job tasks, increasing the depth of hierarchy at twice the\nrate of all established firms.\"\n\n\nBig Tech and other large companies have become more attractive places to\ninnovate for our most well-educated workers. Large companies have better dealt\nwith the accumulated burden of scientific knowledge by enforcing a \"division of\nlabor\" among employees. Large companies form \"knowledge hierarchies\", such that\nno one person needs to know everything, and information can be aggregated up the\nchain in a rationale fashion. This lets organizations to scale to meet the needs\nof cutting edge scientific research and development, which increasingly\nincorporates impossibly vast sums of knowledge.\n\nOn the other hand, startup founders do not have armies of willing cadets to\noffload and delegate to. They are the captain of the ship and also it's most\nvaluable crewmember, so as the burdens of both scientific knowledge and\nmanagement complex grow, it all gets placed on their shoulders.\n\nThe job of a founder has gotten harder â€” running a startup today requires more\nmanagement and R&D activities than it did 20 years ago. Quantified, this is\nabout 15% more \"tasks\", with R&D tasks growing by about 50% and management tasks\ngrowing 5%:\n\n\n\n> \"The average number of all tasks for founders increased by about 15 percent from\nthe beginning to the end of our sample, a statistically significant\ndifference... Furthermore, although the number of both R&D and management tasks\nincreased, the increase is more pronounced in R&D, for which it rose by more\nthan 50 percent from 1997 to 2017... As a result, R&D tasks that comprised about\n25 percent of all tasks conducted by founders in 1997 increased to 34 percent of\nall tasks in 2017. As can be seen in Figure 3, this was not accompanied by any\ndecline in management tasks, so the founders had to shoulder the burden of doing\nmore R&D tasks while also running the same or more administrative tasks.\"\n\n\nPhD workers at established firms also saw their total tasks grow, but to a\nlesser degree. R&D tasks for workers only grew 12% over the same 20 year period,\nand management tasks did not increase at all:\n\n\n\n> \"Workers were also affected by the need to perform more R&D tasks, as the\nincrease in the number of R&D tasks from 1997 to 2017 is about 12 percent.\nNotably, however, as the figure reveals, workers did not need to handle more\nmanagement tasks, which remained relatively flat for them.\"\n\n\nWhat gives? It goes back to the division of labor point I mentioned earlier.\nLet's start with R&D:\n\n> \"The number of R&D tasks is rising, but established firms take advantage of a\ndivision of labor and knowledge hierarchies\"\n\n\nThe growing burden of scientific knowledge increases the number of R&D tasks\nthat founder must occupy themselves with. With little hierarchy or staff to\noffload this work, founders have no operating leverage. Conversely, large,\nestablished firms can shift much of the burden to armies of researchers, more\nefficiently dealing with the growing stack of research output.\n\n> \"We find that the number of different R&D tasks has increased more for founders\nthan for workers. And the returns to experience have increased over time for\nfounders but not for workers, highlighting the increasing need for a single\npersonâ€”the founderâ€”to cope with the burden of knowledge in startups. Workers at\nestablished firms have, instead, comfortably narrowed their span of control,\nemployed more people indirectly under their control to support their work, and\nkept administrative duties low. They are also better rewarded for taking on more\ndiverse work and managerial responsibilities than founders. ...established firms\nhave coped more effectively with the increasing burden of knowledge in science\nby better utilizing the division of labor in innovative work through\nreorganizing tasks and hierarchies.\"\n\n\nIndividual workers at established firms have limited scope, while the remaining\nload gets shared with other team members and subordinates. Further, the firm\ncaptures the gains from the successful division of labor and then shares this\nwith employees in the form of better pay for the managers who corral these\nefforts internally.\n\n> \"Running a startup might constrain founders' ability to organize its hierarchy\nefficiently, at least until it has succeeded in growing well beyond its initial\nsize. As science accumulates more knowledge, we would therefore expect PhD\nfounders to have to take on more R&D tasks.\"\n\n\nFounders have no ability to pull off similar organizational tricks until their\nstartups reach meaningful scale. Thus, as scientific knowledge has accumulated,\nthey've taken on the additional R&D work themselves.\n\nThis has implications for startup management too:\n\n> \"Also, founders had to deal with significantly more management tasks than\nworkers in terms of levels: about 30-40 percent more at the beginning of the\nstudy period, increasing to 50 percent more at the end. The explanation for this\ndifference likely lies in how the two types of firms differ in their\norganization of work...\"\n\n\nFounders and startups cannot afford the overhead that comes with increasing\nlayers of professional management. This is why startup's delay building\nexecutive teams until at least a few years into a startup's lifecycle. Large\norganizations can and do invest in these management layers, gladly taking on the\nextra expense:\n\n> \"... the firm responds by increasing the number of layers... and... [allowing]\ngreater job specialization. Increasing the number of layers of management adds a\nfixed cost of operations... [Larger] firms are more likely to become\nhierarchically taller by adding more layers of management... as they can more\neasily absorb the added fixed cost. Founders at startups appear not to have\nrecourse to this mitigation strategy.\"\n\n\nThe study's authors quantify these additional layers by tracking two metrics:\n\n * the number of individuals directly supervised by PhD founders and workers,\n   and\n * the number of individuals indirectly supervised (i.e. supervised by one's own\n   direct reports)\n\nThe directly supervised corresponds to the managerial burden that each\nPhD-holder has (their span of control), while the indirectly supervised tells us\nhow much managerial leverage each person has (the depth of hierarchy). The\ntheory would suggest that workers within organizations should have fewer direct\nreports over time and more indirect reports, as organizations build out these\nknowledge hierarchies.\n\nAnd that's exactly what we see:\n\n\n\n * Workers with PhDs saw the number of employees directly managed decline over\n   time while the number of employees indirectly managed increased over time. In\n   others words, the proliferation of middle management reduces the management\n   burden for any individual worker but increases overall managerial leverage.\n   \n   \n * Founders on the other hand saw no statistically significant trend in their\n   span of control or depth of hierarchy. The organizational structure of\n   startups has not evolved to keep up with the increased burden of scientific\n   knowledge.\n   \n   \n\n> \"workers [perform] fewer R&D tasks as they age... the span of control decreases\nfor workers at established firms... However... hierarchies deepen over time for\nworkers at established firms... Together, the results suggest that established\nfirms cope with the increasing burden of knowledge on their workers by\nintroducing additional layers of hierarchy, while simultaneously reducing the\nnumber of employees who report directly to managers\"\n\n\nDoing *too many* things that don't scale\nWe need to think harder about making knowledge work... work.\n\nIn summary:\n\n> \"Our findings suggest that if the goal is to restore business dynamism in the\nhigh-tech sector, alleviating the burden of knowledge should be front and center \nin the strategy to attain it.\"\n\n\nThe declining in PhD entrepreneurship mimics a broader drop in startup formation\nchronicled elsewhere. But PhD founders are special... and so these trends are\nespecially worrying.\n\nSTEM PhDs have founded some of the world's most successful and impactful\nenterprises. Among them: Google, Intel, VMware, and others.\n\nIronically, however, today these same companies gobble up the brightest minds we\nhave, discouraging or delaying their own entrepreneurial pursuits.\n\nIn Silicon Valley we talk a lot about management practices to help founders and\nexecutives \"scale.\" But deeply technical founders face a separate but equally\nimportant problem: scaling knowledge.\n\n> PhDs aren't starting companies like they used to\n\nCushy tech jobs are more and more attractive to STEM PhDs\n\nThe burden of scientific knowledge and managerial complexity is crushing our\nbest and brightest\n\nI explore the precipitous decline in PhD founders:https://t.co/NxpFn3NrZv\n\nâ€” Nnamdi Iregbulem (@whoisnnamdi) July 8, 2021\n[https://twitter.com/whoisnnamdi/status/1413250293786021889?ref_src=twsrc%5Etfw]\nThanks to Thomas Astebro\n[https://www.hec.edu/en/faculty-research/faculty-directory/faculty-member/astebro-thomas]\n, Serguey Braguinsky [https://www.rhsmith.umd.edu/directory/serguey-braguinsky],\nand Yuheng Ding [https://www.rhsmith.umd.edu/directory/yuheng-gavin-ding], the\nauthors of the study [https://www.nber.org/papers/w27787] from which much of\nthis essay is derived.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"https://res-4.cloudinary.com/whoisnnamdi/image/upload/q_auto/v1/whoisnnamdi/header.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2021-07-07T15:50:48.000Z","updated_at":"2022-01-01T20:10:00.000Z","published_at":"2021-07-08T07:01:00.000Z","custom_excerpt":"The burden of scientific knowledge and managerial complexity is crushing our best and brightest.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"611cb8f616c7fe4443b14021","uuid":"c9606551-7df1-4eb4-b318-066da06a1b8b","title":"Do Wealthy Investors Have an Edge?","slug":"wealthy-investors-edge","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"The super-rich earn more on their investments than the rest of us. \\n\\nSomething nefarious, or something else?\\n\\n## The rich get richer, faster\\n\\nWealth and financial returns are positively correlated. Here's a plot of average annualized portfolio returns against ([log](https://en.wikipedia.org/wiki/Logarithm)) wealth, coming from a [study](https://conference.nber.org/conf_papers/f155140/f155140.pdf) using data from [Addepar](https://addepar.com/), a wealth management technology company:\\n\\n![Pasted-image-20210725110126](__GHOST_URL__/content/images/2021/08/Pasted-image-20210725110126.png)\\n\\nThere's a strong positive relationship between wealth and financial returns. To translate the range on the x-axis into something a bit more meaningful, you can think of the left side as representing investors with less than \\\\$3 million in assets and the right side representing investors with more than \\\\$100M in wealth.\\n\\nHere are the exact returns at various levels of wealth:\\n\\n![Pasted-image-20210725105724](__GHOST_URL__/content/images/2021/08/Pasted-image-20210725105724.png)\\n\\nComparing the <\\\\$3M group to the >\\\\$300M group, **the richest investors earn roughly 2 percentage points more on their investment portfolios annually**, a sizable advantage.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Do Wealthy Investors Have an Edge?\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## High class asset classes?\\n\\nRicher investors could be allocating their capital to different asset classes than other investors, and that could be driving the return differential.\\n\\nIs it true that asset allocations differ meaningfully across wealth groups? **Yes**:\\n\\n![Pasted-image-20210815202907](__GHOST_URL__/content/images/2021/08/Pasted-image-20210815202907.png)\\n\\nRicher investors put more of their money to work in [alternative investments](https://money.usnews.com/investing/investing-101/articles/a-beginners-guide-to-alternative-investments) (venture capital, private equity, hedge funds, etc.), private companies (owned directly, not via venture capital or private equity funds), and housing.\\n\\nHowever, it turns out that while asset allocations do tend to correlate with wealth levels, the differences in returns cannot be fully or even mostly explained by high-level asset allocation decisions.\\n\\nTo test for this, the authors calculated the expected returns of various wealth groupings based purely on the typical asset allocation of those groups. So stocks are assumed to get the returns of the S&P 500, bonds are expected to earn the returns of the US Aggregate Bond Index, and so on.\\n\\nWhen they do this, they find that the expected returns are not divergent enough to explain the rich investor advantage:\\n\\n![Pasted-image-20210725110742](__GHOST_URL__/content/images/2021/08/Pasted-image-20210725110742.png)\\n\\nUsing this approach, the gap between investors with less than \\\\$3M in assets and those with \\\\$100M+ is only **0.35 percentage points**, whereas the difference in raw returns was a full *2 percentage points*. **So asset mix does not even come close to explaining the differences.**\\n\\nWe can also look at returns across wealth levels within each asset class. The table below shows the results of a regression of realized returns of individual investors on various wealth buckets, repeated for different asset classes. Interpret the numbers as the annualized returns of that group relative to the returns of investors with less than $3M in assets. For now, focus on panel A at the top:\\n\\n![Pasted-image-20210725110838](__GHOST_URL__/content/images/2021/08/Pasted-image-20210725110838.png)\\n\\n**Richer investors earn significantly higher returns in public equities, alternatives, and privately held companies.** The only major category they don't dominate is fixed income, which perhaps makes some sense given the spread of returns at the individual bonds tends to be much more compressed that other assets.\\n\\n## You have to risk money to make money\\n\\nSo what gives? Why do the super rich earn so much more on their investments than everyone else, even after controlling for asset class?\\n\\nHere's a thought: **is raw, realized returns even the right metric to compare?** (Hint: No)\\n\\nRisk vs. reward is a classic dynamic in finance. Financial returns compensate investors for risks they take, with riskier investments generating higher returns, which encourages investors to buy them in the first place.\\n\\nThe [Sharpe Ratio](https://www.investopedia.com/terms/s/sharperatio.asp) quantifies the degree to which a portfolio earns excess returns relative to the risk undertaken. The Sharpe Ratio divides the excess returns of a portfolio relative to some risk-free asset by the standard deviation of the portfolios excess returns, which represents volatility and risk, yielding \\\"risk-adjusted\\\" returns.\\n\\nWhen the researchers do this, the relationship between wealth and returns completely breaks down:\\n\\n![Pasted-image-20210725110133](__GHOST_URL__/content/images/2021/08/Pasted-image-20210725110133.png)\\n\\nThe Sharpe Ratios of wealthier investor portfolios are no better than those of less wealthy investors:\\n> â€œhaving controlled for risk, the point estimates of the Sharpe ratio for very wealthy investors is not higher, and **the relationship between returns and wealth remains statistically insignificant**â€\\n\\nSo wealthy investors earn more but those earnings are explained by more risk-taking.\\n\\nRemember, this risk-taking is happening within asset classes rather merely than across, so this result implies that the rich are investing in riskier individual assets (e.g. companies) within each category. For example, the wealthiest investors hold a much larger share of their public equity portfolio in individual stocks (vs. ETFs or mutual funds) relative to other investors, leading to more volatile portfolios:\\n\\n![Pasted-image-20210815223154](__GHOST_URL__/content/images/2021/08/Pasted-image-20210815223154.png)\\n\\nHigh net worth investors also tend to invest in smaller, higher growth companies, naturally riskier. Interestingly, this behavior generates a lower market \\\"beta\\\" for rich investors in the [CAPM model](https://www.investopedia.com/terms/c/capm.asp), as their portfolios correlate less well with the overall equity market than do those of less wealthy investors, who have betas close to 1:\\n\\n![Pasted-image-20210815224634](__GHOST_URL__/content/images/2021/08/Pasted-image-20210815224634.png)\\n\\n> â€œHigher-wealth households load more heavily on the SMB factor, reflecting an **increased focus on small-cap companies**. High net worth portfolios also load more negatively on the HML factor, meaning that they have **more exposure to growth companies** than lower wealth investors.â€\\n\\n## Looking at all the alternatives\\n\\nThere's one more wrinkle though. Here's that last table again, showing returns across wealth groups and asset classes. This time focus on panel B, which focuses on risk-adjusted returns:\\n\\n![Pasted-image-20210725110838-1](__GHOST_URL__/content/images/2021/08/Pasted-image-20210725110838-1.png)\\n\\n**For public equities and privately-held companies, controlling for risk largely eliminates / accounts for the return premium earned by wealth investors.** However, accounting for risk doesn't totally do the trick for alternative investments, where richer investors do better even taking risk into account. In fact, less wealthy investors do *so* badly in alternatives that the average investor with less than $3M in assets only earned an annualized return of 1.75%, which is not much higher than the risk-free rate during the same period of 1.33%, despite taking on significant risk.\\n\\nWe can dive a layer deeper by examining the returns across subgroups within alternatives, primarily hedge funds, venture capital and private equity, and real estate. **Richer investors earn higher raw and risk-adjusted returns in hedge funds and VC/PE** but do no better in real estate, where they actually earn *lower* risk-adjusted returns:\\n\\n![Pasted-image-20210725113425](__GHOST_URL__/content/images/2021/08/Pasted-image-20210725113425.png)\\n\\n**The least wealthy earn less than 1% annually on their hedge fund, venture capital, and private equity investments**, which is stunning.\\n\\nIt's hard to pinpoint the exact drivers of the alternative investments advantage of the richest investors. What we do know is that the alternative investment portfolios of the richest investors differ quite substantially from those of less wealthy investors:\\n\\n![Pasted-image-20210815213652](__GHOST_URL__/content/images/2021/08/Pasted-image-20210815213652.png)\\n\\nFor example, investors in the sub-\\\\$3M group have only two alternative investments on average, while the \\\\$100M+ group has **35**. On that basis alone we would expect the better diversification to generate lower volatility for the richest investors and potentially even higher returns based on my argument in \\\"[Why Don't VCs Index Invest?](https://whoisnnamdi.com/vcs-index-invest/)\\\" (citing [Abe Othman](https://angel.co/blog/venture-returns)):\\n\\n> ... investors increase their expected return by indexing as broadly as possible at the seed stage (i.e., by putting money into every credible deal), because any selective policy for seed-stage investingâ€”absent perfect foresightâ€”will eventually be outperformed by an indexing approach.\\n\\nAnother quirk: **the alternatives positions of richer investors are updated much less frequently**, meaning the valuations at which the companies are held are updated less often. This makes the portfolios of richer investors appear less volatile. Further, as folks in the industry know, companies that are doing well will typically see their valuations rise faster and their carrying values updated more frequently. So less updating means less volatility, and any volatility they do see is largely to the upside:\\n\\n> **The smoothed returns of private equity understate the true economic risk** and are an artifact of the lack of mark-to-market for illiquid assets â€” [Demystifying Illiquid Assets: Expected Returns for Private Equity](https://www.aqr.com/Insights/Research/White-Papers/Demystifying-Illiquid-Assets-Expected-Returns-for-Private-Equity)\\n\\nStill, having stared at the data for a while, my sense is the alternative advantage represents a real returns premium and isn't merely an artifact of mark-to-market gamesmanship. Let's keep digging.\\n\\n## Real estate: location, location, location. Alternatives: access, access, access\\n\\nWe've crossed out anything nefarious in all the other asset classes. In all asset classes outside of alternatives, wealthier investors earn higher returns in the same way anyone earns them â€” by taking more risk. But alternatives remain a mystery. What's going on there?\\n\\n**Is it skill?** Probably not, at least not in traditional sense of \\\"stock picking\\\". Most investments in alternatives are intermediated by managers â€” hedge, venture capital, and private equity funds â€” who make the actual investments. Therefore, it's unlikely that better stock picking ability on the part of the wealthy investors themselves explains their enhanced returns.\\n\\nBut that's also why the returns gap is *so strange*. If the individual investor is not actually making the investments, then why should their personal net worth correlate so highly with their portfolio returns in alternatives? The only explanation is differences in skill at picking great managers or access to those managers across wealth levels:\\n> \\\"Higher-wealth investors may receive preferential access to better-performing managers because they can offer larger amounts of funds at once, which reduces marketing and related overhead costs to the fund manager... In contrast, lower-wealth investors may only receive access to hedge fund and private equity solutions that are distributed through advanced marketing networks and are originated by large platform operators. However, **funds that provide more accessibility may deliver worse performance**\\\"\\n\\nFor example, the authors find that [fund-of-funds](https://www.investopedia.com/terms/f/fundsoffunds.asp), investment funds that invest in other funds rather than in securities directly, earn \\\"almost exactly two percentage points lower\\\" returns on an annualized basis \\\"evidence for fees imposed by additional layers of management.\\\" Another piece of evidence â€” the fewer investors who hold the same alternatives security, the higher than returns, and vice versa: \\\"assets with limited investor participation are significantly related to higher investment returns.\\\" In other words, **exclusivity generates better returns**. This points to the importance of access.\\n\\nOne highly suggestive piece of evidence comes from the returns of investors whose funds are managed by a single family office (SFO), which is an investment firm setup solely to manage the wealth and investments of a single family or person. **Portfolios managed by family offices earn significantly higher returns** than portfolios of investors in the same wealth bracket who do not have a family office. Not only that, the return differential across wealth groups disappears when we look only at portfolios managed by family offices:\\n\\n![Pasted-image-20210725112023](__GHOST_URL__/content/images/2021/08/Pasted-image-20210725112023.png)\\n\\nDepending on the asset class, among portfolios managed by family offices, investors with less than \\\\$3M in assets earn **more** than investors with over \\\\$100M in assets:\\n\\n> \\\"While lower-wealth investors earn substantially lower returns on their hedge fund and private equity investments than ultra-high net worth investors, **this does not apply to investors with smaller portfolios that are managed by an SFO**. Even SFO investors with less than three million, or 3-10 million earn roughly the same return as those with more than 100 million on their investments in hedge funds and private equity, and **substantially more than investors in the same wealth brackets but without SFO management.**\\\"\\n\\nSomething about the nature of family offices and their influence on manager selection causes the wealth-returns relationship to disappear entirely. The study's authors speculate that this \\\"likely [relates] to the difficulty of identifying and **accessing** high-performing alternative investment funds.\\\"\\n\\n**Access to assets matters.** In the public markets, access is effectively democratized, so we can completely explain the advantage of richer investors in the public markets via differential risk-taking. However, the advantage in alternative assets reflects more than mere risk tolerance or preference. Ironically, family offices, which likely *exacerbate* inequality between the rich and the rest, **level the playing field \\\\*among\\\\* the rich**.\\n\\n## The 1% vs. the 0.1%\\n\\nSo do wealthy investors have an edge? Relative to non-wealthy, not really. It's risk-loving turtles all the way down.\\n\\nBut do the wealthiest have an edge versus their somewhat less wealthy peers? Yes, though I won't lose much sleep over it. It's an **access advantage**, and it's limited to the assets where access remains important: the relatively opaque and exclusive worlds of hedge funds, venture capital, and private equity.\\n\\nCandidly, I'm more focused on expanding access to these alternative asset classes in general than on helping already well-off investors get access to the best funds. That said, the excess returns of alternatives are quite low for investors with only a few million in assets. On that basis, they aren't much better than public equities except for the extremely wealthy.\\n\\nIf these new investors only receive access to the worst-performing funds, the effort will be worthless. Worth pondering further.\"}],[\"embed\",{\"url\":\"https://twitter.com/whoisnnamdi/status/1428770455414992899\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">The super-rich earn more on their investments than the rest of us.<br><br>In the battle between the 1% and the 0.1%, the richest get richer, faster.<br><br>Something nefarious? Or something else?<a href=\\\"https://t.co/Mc8imZTiH3\\\">https://t.co/Mc8imZTiH3</a></p>&mdash; Nnamdi Iregbulem (@whoisnnamdi) <a href=\\\"https://twitter.com/whoisnnamdi/status/1428770455414992899?ref_src=twsrc%5Etfw\\\">August 20, 2021</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\",\"metadata\":{\"url\":\"https://twitter.com/whoisnnamdi/status/1428770455414992899\",\"author_name\":\"Nnamdi Iregbulem\",\"author_url\":\"https://twitter.com/whoisnnamdi\",\"width\":550,\"height\":null,\"cache_age\":\"3153600000\",\"provider_name\":\"Twitter\",\"provider_url\":\"http://www.twitter.com/\",\"version\":\"1.0\"}}],[\"markdown\",{\"markdown\":\"*Thanks to [Cynthia Balloch](https://www.lse.ac.uk/finance/people/faculty/Balloch) and [Julian Richers](https://sites.google.com/site/julianrichers/home), the authors of the study from which much of this essay is derived.*\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: Do Wealthy Investors Have an Edge?\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>The super-rich earn more on their investments than the rest of us.</p>\n<p>Something nefarious, or something else?</p>\n<h2 id=\"the-rich-get-richer-faster\">The rich get richer, faster</h2>\n<p>Wealth and financial returns are positively correlated. Here's a plot of average annualized portfolio returns against (<a href=\"https://en.wikipedia.org/wiki/Logarithm\">log</a>) wealth, coming from a <a href=\"https://conference.nber.org/conf_papers/f155140/f155140.pdf\">study</a> using data from <a href=\"https://addepar.com/\">Addepar</a>, a wealth management technology company:</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/08/Pasted-image-20210725110126.png\" alt=\"Pasted-image-20210725110126\" loading=\"lazy\"></p>\n<p>There's a strong positive relationship between wealth and financial returns. To translate the range on the x-axis into something a bit more meaningful, you can think of the left side as representing investors with less than $3 million in assets and the right side representing investors with more than $100M in wealth.</p>\n<p>Here are the exact returns at various levels of wealth:</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/08/Pasted-image-20210725105724.png\" alt=\"Pasted-image-20210725105724\" loading=\"lazy\"></p>\n<p>Comparing the &lt;$3M group to the &gt;$300M group, <strong>the richest investors earn roughly 2 percentage points more on their investment portfolios annually</strong>, a sizable advantage.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Do Wealthy Investors Have an Edge?\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"high-class-asset-classes\">High class asset classes?</h2>\n<p>Richer investors could be allocating their capital to different asset classes than other investors, and that could be driving the return differential.</p>\n<p>Is it true that asset allocations differ meaningfully across wealth groups? <strong>Yes</strong>:</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/08/Pasted-image-20210815202907.png\" alt=\"Pasted-image-20210815202907\" loading=\"lazy\"></p>\n<p>Richer investors put more of their money to work in <a href=\"https://money.usnews.com/investing/investing-101/articles/a-beginners-guide-to-alternative-investments\">alternative investments</a> (venture capital, private equity, hedge funds, etc.), private companies (owned directly, not via venture capital or private equity funds), and housing.</p>\n<p>However, it turns out that while asset allocations do tend to correlate with wealth levels, the differences in returns cannot be fully or even mostly explained by high-level asset allocation decisions.</p>\n<p>To test for this, the authors calculated the expected returns of various wealth groupings based purely on the typical asset allocation of those groups. So stocks are assumed to get the returns of the S&amp;P 500, bonds are expected to earn the returns of the US Aggregate Bond Index, and so on.</p>\n<p>When they do this, they find that the expected returns are not divergent enough to explain the rich investor advantage:</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/08/Pasted-image-20210725110742.png\" alt=\"Pasted-image-20210725110742\" loading=\"lazy\"></p>\n<p>Using this approach, the gap between investors with less than $3M in assets and those with $100M+ is only <strong>0.35 percentage points</strong>, whereas the difference in raw returns was a full <em>2 percentage points</em>. <strong>So asset mix does not even come close to explaining the differences.</strong></p>\n<p>We can also look at returns across wealth levels within each asset class. The table below shows the results of a regression of realized returns of individual investors on various wealth buckets, repeated for different asset classes. Interpret the numbers as the annualized returns of that group relative to the returns of investors with less than $3M in assets. For now, focus on panel A at the top:</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/08/Pasted-image-20210725110838.png\" alt=\"Pasted-image-20210725110838\" loading=\"lazy\"></p>\n<p><strong>Richer investors earn significantly higher returns in public equities, alternatives, and privately held companies.</strong> The only major category they don't dominate is fixed income, which perhaps makes some sense given the spread of returns at the individual bonds tends to be much more compressed that other assets.</p>\n<h2 id=\"you-have-to-risk-money-to-make-money\">You have to risk money to make money</h2>\n<p>So what gives? Why do the super rich earn so much more on their investments than everyone else, even after controlling for asset class?</p>\n<p>Here's a thought: <strong>is raw, realized returns even the right metric to compare?</strong> (Hint: No)</p>\n<p>Risk vs. reward is a classic dynamic in finance. Financial returns compensate investors for risks they take, with riskier investments generating higher returns, which encourages investors to buy them in the first place.</p>\n<p>The <a href=\"https://www.investopedia.com/terms/s/sharperatio.asp\">Sharpe Ratio</a> quantifies the degree to which a portfolio earns excess returns relative to the risk undertaken. The Sharpe Ratio divides the excess returns of a portfolio relative to some risk-free asset by the standard deviation of the portfolios excess returns, which represents volatility and risk, yielding &quot;risk-adjusted&quot; returns.</p>\n<p>When the researchers do this, the relationship between wealth and returns completely breaks down:</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/08/Pasted-image-20210725110133.png\" alt=\"Pasted-image-20210725110133\" loading=\"lazy\"></p>\n<p>The Sharpe Ratios of wealthier investor portfolios are no better than those of less wealthy investors:</p>\n<blockquote>\n<p>â€œhaving controlled for risk, the point estimates of the Sharpe ratio for very wealthy investors is not higher, and <strong>the relationship between returns and wealth remains statistically insignificant</strong>â€</p>\n</blockquote>\n<p>So wealthy investors earn more but those earnings are explained by more risk-taking.</p>\n<p>Remember, this risk-taking is happening within asset classes rather merely than across, so this result implies that the rich are investing in riskier individual assets (e.g. companies) within each category. For example, the wealthiest investors hold a much larger share of their public equity portfolio in individual stocks (vs. ETFs or mutual funds) relative to other investors, leading to more volatile portfolios:</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/08/Pasted-image-20210815223154.png\" alt=\"Pasted-image-20210815223154\" loading=\"lazy\"></p>\n<p>High net worth investors also tend to invest in smaller, higher growth companies, naturally riskier. Interestingly, this behavior generates a lower market &quot;beta&quot; for rich investors in the <a href=\"https://www.investopedia.com/terms/c/capm.asp\">CAPM model</a>, as their portfolios correlate less well with the overall equity market than do those of less wealthy investors, who have betas close to 1:</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/08/Pasted-image-20210815224634.png\" alt=\"Pasted-image-20210815224634\" loading=\"lazy\"></p>\n<blockquote>\n<p>â€œHigher-wealth households load more heavily on the SMB factor, reflecting an <strong>increased focus on small-cap companies</strong>. High net worth portfolios also load more negatively on the HML factor, meaning that they have <strong>more exposure to growth companies</strong> than lower wealth investors.â€</p>\n</blockquote>\n<h2 id=\"looking-at-all-the-alternatives\">Looking at all the alternatives</h2>\n<p>There's one more wrinkle though. Here's that last table again, showing returns across wealth groups and asset classes. This time focus on panel B, which focuses on risk-adjusted returns:</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/08/Pasted-image-20210725110838-1.png\" alt=\"Pasted-image-20210725110838-1\" loading=\"lazy\"></p>\n<p><strong>For public equities and privately-held companies, controlling for risk largely eliminates / accounts for the return premium earned by wealth investors.</strong> However, accounting for risk doesn't totally do the trick for alternative investments, where richer investors do better even taking risk into account. In fact, less wealthy investors do <em>so</em> badly in alternatives that the average investor with less than $3M in assets only earned an annualized return of 1.75%, which is not much higher than the risk-free rate during the same period of 1.33%, despite taking on significant risk.</p>\n<p>We can dive a layer deeper by examining the returns across subgroups within alternatives, primarily hedge funds, venture capital and private equity, and real estate. <strong>Richer investors earn higher raw and risk-adjusted returns in hedge funds and VC/PE</strong> but do no better in real estate, where they actually earn <em>lower</em> risk-adjusted returns:</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/08/Pasted-image-20210725113425.png\" alt=\"Pasted-image-20210725113425\" loading=\"lazy\"></p>\n<p><strong>The least wealthy earn less than 1% annually on their hedge fund, venture capital, and private equity investments</strong>, which is stunning.</p>\n<p>It's hard to pinpoint the exact drivers of the alternative investments advantage of the richest investors. What we do know is that the alternative investment portfolios of the richest investors differ quite substantially from those of less wealthy investors:</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/08/Pasted-image-20210815213652.png\" alt=\"Pasted-image-20210815213652\" loading=\"lazy\"></p>\n<p>For example, investors in the sub-$3M group have only two alternative investments on average, while the $100M+ group has <strong>35</strong>. On that basis alone we would expect the better diversification to generate lower volatility for the richest investors and potentially even higher returns based on my argument in &quot;<a href=\"https://whoisnnamdi.com/vcs-index-invest/\">Why Don't VCs Index Invest?</a>&quot; (citing <a href=\"https://angel.co/blog/venture-returns\">Abe Othman</a>):</p>\n<blockquote>\n<p>... investors increase their expected return by indexing as broadly as possible at the seed stage (i.e., by putting money into every credible deal), because any selective policy for seed-stage investingâ€”absent perfect foresightâ€”will eventually be outperformed by an indexing approach.</p>\n</blockquote>\n<p>Another quirk: <strong>the alternatives positions of richer investors are updated much less frequently</strong>, meaning the valuations at which the companies are held are updated less often. This makes the portfolios of richer investors appear less volatile. Further, as folks in the industry know, companies that are doing well will typically see their valuations rise faster and their carrying values updated more frequently. So less updating means less volatility, and any volatility they do see is largely to the upside:</p>\n<blockquote>\n<p><strong>The smoothed returns of private equity understate the true economic risk</strong> and are an artifact of the lack of mark-to-market for illiquid assets â€” <a href=\"https://www.aqr.com/Insights/Research/White-Papers/Demystifying-Illiquid-Assets-Expected-Returns-for-Private-Equity\">Demystifying Illiquid Assets: Expected Returns for Private Equity</a></p>\n</blockquote>\n<p>Still, having stared at the data for a while, my sense is the alternative advantage represents a real returns premium and isn't merely an artifact of mark-to-market gamesmanship. Let's keep digging.</p>\n<h2 id=\"real-estate-location-location-location-alternatives-access-access-access\">Real estate: location, location, location. Alternatives: access, access, access</h2>\n<p>We've crossed out anything nefarious in all the other asset classes. In all asset classes outside of alternatives, wealthier investors earn higher returns in the same way anyone earns them â€” by taking more risk. But alternatives remain a mystery. What's going on there?</p>\n<p><strong>Is it skill?</strong> Probably not, at least not in traditional sense of &quot;stock picking&quot;. Most investments in alternatives are intermediated by managers â€” hedge, venture capital, and private equity funds â€” who make the actual investments. Therefore, it's unlikely that better stock picking ability on the part of the wealthy investors themselves explains their enhanced returns.</p>\n<p>But that's also why the returns gap is <em>so strange</em>. If the individual investor is not actually making the investments, then why should their personal net worth correlate so highly with their portfolio returns in alternatives? The only explanation is differences in skill at picking great managers or access to those managers across wealth levels:</p>\n<blockquote>\n<p>&quot;Higher-wealth investors may receive preferential access to better-performing managers because they can offer larger amounts of funds at once, which reduces marketing and related overhead costs to the fund manager... In contrast, lower-wealth investors may only receive access to hedge fund and private equity solutions that are distributed through advanced marketing networks and are originated by large platform operators. However, <strong>funds that provide more accessibility may deliver worse performance</strong>&quot;</p>\n</blockquote>\n<p>For example, the authors find that <a href=\"https://www.investopedia.com/terms/f/fundsoffunds.asp\">fund-of-funds</a>, investment funds that invest in other funds rather than in securities directly, earn &quot;almost exactly two percentage points lower&quot; returns on an annualized basis &quot;evidence for fees imposed by additional layers of management.&quot; Another piece of evidence â€” the fewer investors who hold the same alternatives security, the higher than returns, and vice versa: &quot;assets with limited investor participation are significantly related to higher investment returns.&quot; In other words, <strong>exclusivity generates better returns</strong>. This points to the importance of access.</p>\n<p>One highly suggestive piece of evidence comes from the returns of investors whose funds are managed by a single family office (SFO), which is an investment firm setup solely to manage the wealth and investments of a single family or person. <strong>Portfolios managed by family offices earn significantly higher returns</strong> than portfolios of investors in the same wealth bracket who do not have a family office. Not only that, the return differential across wealth groups disappears when we look only at portfolios managed by family offices:</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/08/Pasted-image-20210725112023.png\" alt=\"Pasted-image-20210725112023\" loading=\"lazy\"></p>\n<p>Depending on the asset class, among portfolios managed by family offices, investors with less than $3M in assets earn <strong>more</strong> than investors with over $100M in assets:</p>\n<blockquote>\n<p>&quot;While lower-wealth investors earn substantially lower returns on their hedge fund and private equity investments than ultra-high net worth investors, <strong>this does not apply to investors with smaller portfolios that are managed by an SFO</strong>. Even SFO investors with less than three million, or 3-10 million earn roughly the same return as those with more than 100 million on their investments in hedge funds and private equity, and <strong>substantially more than investors in the same wealth brackets but without SFO management.</strong>&quot;</p>\n</blockquote>\n<p>Something about the nature of family offices and their influence on manager selection causes the wealth-returns relationship to disappear entirely. The study's authors speculate that this &quot;likely [relates] to the difficulty of identifying and <strong>accessing</strong> high-performing alternative investment funds.&quot;</p>\n<p><strong>Access to assets matters.</strong> In the public markets, access is effectively democratized, so we can completely explain the advantage of richer investors in the public markets via differential risk-taking. However, the advantage in alternative assets reflects more than mere risk tolerance or preference. Ironically, family offices, which likely <em>exacerbate</em> inequality between the rich and the rest, <strong>level the playing field *among* the rich</strong>.</p>\n<h2 id=\"the-1-vs-the-01\">The 1% vs. the 0.1%</h2>\n<p>So do wealthy investors have an edge? Relative to non-wealthy, not really. It's risk-loving turtles all the way down.</p>\n<p>But do the wealthiest have an edge versus their somewhat less wealthy peers? Yes, though I won't lose much sleep over it. It's an <strong>access advantage</strong>, and it's limited to the assets where access remains important: the relatively opaque and exclusive worlds of hedge funds, venture capital, and private equity.</p>\n<p>Candidly, I'm more focused on expanding access to these alternative asset classes in general than on helping already well-off investors get access to the best funds. That said, the excess returns of alternatives are quite low for investors with only a few million in assets. On that basis, they aren't much better than public equities except for the extremely wealthy.</p>\n<p>If these new investors only receive access to the worst-performing funds, the effort will be worthless. Worth pondering further.</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">The super-rich earn more on their investments than the rest of us.<br><br>In the battle between the 1% and the 0.1%, the richest get richer, faster.<br><br>Something nefarious? Or something else?<a href=\"https://t.co/Mc8imZTiH3\">https://t.co/Mc8imZTiH3</a></p>&mdash; Nnamdi Iregbulem (@whoisnnamdi) <a href=\"https://twitter.com/whoisnnamdi/status/1428770455414992899?ref_src=twsrc%5Etfw\">August 20, 2021</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><!--kg-card-begin: markdown--><p><em>Thanks to <a href=\"https://www.lse.ac.uk/finance/people/faculty/Balloch\">Cynthia Balloch</a> and <a href=\"https://sites.google.com/site/julianrichers/home\">Julian Richers</a>, the authors of the study from which much of this essay is derived.</em></p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: Do Wealthy Investors Have an Edge?\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"611cb8f616c7fe4443b14021","plaintext":"The super-rich earn more on their investments than the rest of us.\n\nSomething nefarious, or something else?\n\nThe rich get richer, faster\nWealth and financial returns are positively correlated. Here's a plot of average\nannualized portfolio returns against (log\n[https://en.wikipedia.org/wiki/Logarithm]) wealth, coming from a study\n[https://conference.nber.org/conf_papers/f155140/f155140.pdf] using data from \nAddepar [https://addepar.com/], a wealth management technology company:\n\n\n\nThere's a strong positive relationship between wealth and financial returns. To\ntranslate the range on the x-axis into something a bit more meaningful, you can\nthink of the left side as representing investors with less than $3 million in\nassets and the right side representing investors with more than $100M in wealth.\n\nHere are the exact returns at various levels of wealth:\n\n\n\nComparing the <$3M group to the >$300M group, the richest investors earn roughly\n2 percentage points more on their investment portfolios annually, a sizable\nadvantage.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡High class asset classes?\nRicher investors could be allocating their capital to different asset classes\nthan other investors, and that could be driving the return differential.\n\nIs it true that asset allocations differ meaningfully across wealth groups? Yes:\n\n\n\nRicher investors put more of their money to work in alternative investments\n[https://money.usnews.com/investing/investing-101/articles/a-beginners-guide-to-alternative-investments] \n(venture capital, private equity, hedge funds, etc.), private companies (owned\ndirectly, not via venture capital or private equity funds), and housing.\n\nHowever, it turns out that while asset allocations do tend to correlate with\nwealth levels, the differences in returns cannot be fully or even mostly\nexplained by high-level asset allocation decisions.\n\nTo test for this, the authors calculated the expected returns of various wealth\ngroupings based purely on the typical asset allocation of those groups. So\nstocks are assumed to get the returns of the S&P 500, bonds are expected to earn\nthe returns of the US Aggregate Bond Index, and so on.\n\nWhen they do this, they find that the expected returns are not divergent enough\nto explain the rich investor advantage:\n\n\n\nUsing this approach, the gap between investors with less than $3M in assets and\nthose with $100M+ is only 0.35 percentage points, whereas the difference in raw\nreturns was a full 2 percentage points. So asset mix does not even come close to\nexplaining the differences.\n\nWe can also look at returns across wealth levels within each asset class. The\ntable below shows the results of a regression of realized returns of individual\ninvestors on various wealth buckets, repeated for different asset classes.\nInterpret the numbers as the annualized returns of that group relative to the\nreturns of investors with less than $3M in assets. For now, focus on panel A at\nthe top:\n\n\n\nRicher investors earn significantly higher returns in public equities,\nalternatives, and privately held companies. The only major category they don't\ndominate is fixed income, which perhaps makes some sense given the spread of\nreturns at the individual bonds tends to be much more compressed that other\nassets.\n\nYou have to risk money to make money\nSo what gives? Why do the super rich earn so much more on their investments than\neveryone else, even after controlling for asset class?\n\nHere's a thought: is raw, realized returns even the right metric to compare? \n(Hint: No)\n\nRisk vs. reward is a classic dynamic in finance. Financial returns compensate\ninvestors for risks they take, with riskier investments generating higher\nreturns, which encourages investors to buy them in the first place.\n\nThe Sharpe Ratio [https://www.investopedia.com/terms/s/sharperatio.asp] \nquantifies the degree to which a portfolio earns excess returns relative to the\nrisk undertaken. The Sharpe Ratio divides the excess returns of a portfolio\nrelative to some risk-free asset by the standard deviation of the portfolios\nexcess returns, which represents volatility and risk, yielding \"risk-adjusted\"\nreturns.\n\nWhen the researchers do this, the relationship between wealth and returns\ncompletely breaks down:\n\n\n\nThe Sharpe Ratios of wealthier investor portfolios are no better than those of\nless wealthy investors:\n\n> â€œhaving controlled for risk, the point estimates of the Sharpe ratio for very\nwealthy investors is not higher, and the relationship between returns and wealth\nremains statistically insignificantâ€\n\n\nSo wealthy investors earn more but those earnings are explained by more\nrisk-taking.\n\nRemember, this risk-taking is happening within asset classes rather merely than\nacross, so this result implies that the rich are investing in riskier individual\nassets (e.g. companies) within each category. For example, the wealthiest\ninvestors hold a much larger share of their public equity portfolio in\nindividual stocks (vs. ETFs or mutual funds) relative to other investors,\nleading to more volatile portfolios:\n\n\n\nHigh net worth investors also tend to invest in smaller, higher growth\ncompanies, naturally riskier. Interestingly, this behavior generates a lower\nmarket \"beta\" for rich investors in the CAPM model\n[https://www.investopedia.com/terms/c/capm.asp], as their portfolios correlate\nless well with the overall equity market than do those of less wealthy\ninvestors, who have betas close to 1:\n\n\n\n> â€œHigher-wealth households load more heavily on the SMB factor, reflecting an \nincreased focus on small-cap companies. High net worth portfolios also load more\nnegatively on the HML factor, meaning that they have more exposure to growth\ncompanies than lower wealth investors.â€\n\n\nLooking at all the alternatives\nThere's one more wrinkle though. Here's that last table again, showing returns\nacross wealth groups and asset classes. This time focus on panel B, which\nfocuses on risk-adjusted returns:\n\n\n\nFor public equities and privately-held companies, controlling for risk largely\neliminates / accounts for the return premium earned by wealth investors. \nHowever, accounting for risk doesn't totally do the trick for alternative\ninvestments, where richer investors do better even taking risk into account. In\nfact, less wealthy investors do so badly in alternatives that the average\ninvestor with less than $3M in assets only earned an annualized return of 1.75%,\nwhich is not much higher than the risk-free rate during the same period of\n1.33%, despite taking on significant risk.\n\nWe can dive a layer deeper by examining the returns across subgroups within\nalternatives, primarily hedge funds, venture capital and private equity, and\nreal estate. Richer investors earn higher raw and risk-adjusted returns in hedge\nfunds and VC/PE but do no better in real estate, where they actually earn lower \nrisk-adjusted returns:\n\n\n\nThe least wealthy earn less than 1% annually on their hedge fund, venture\ncapital, and private equity investments, which is stunning.\n\nIt's hard to pinpoint the exact drivers of the alternative investments advantage\nof the richest investors. What we do know is that the alternative investment\nportfolios of the richest investors differ quite substantially from those of\nless wealthy investors:\n\n\n\nFor example, investors in the sub-$3M group have only two alternative\ninvestments on average, while the $100M+ group has 35. On that basis alone we\nwould expect the better diversification to generate lower volatility for the\nrichest investors and potentially even higher returns based on my argument in \"\nWhy Don't VCs Index Invest? [https://whoisnnamdi.com/vcs-index-invest/]\" (citing \nAbe Othman [https://angel.co/blog/venture-returns]):\n\n> ... investors increase their expected return by indexing as broadly as possible\nat the seed stage (i.e., by putting money into every credible deal), because any\nselective policy for seed-stage investingâ€”absent perfect foresightâ€”will\neventually be outperformed by an indexing approach.\n\n\nAnother quirk: the alternatives positions of richer investors are updated much\nless frequently, meaning the valuations at which the companies are held are\nupdated less often. This makes the portfolios of richer investors appear less\nvolatile. Further, as folks in the industry know, companies that are doing well\nwill typically see their valuations rise faster and their carrying values\nupdated more frequently. So less updating means less volatility, and any\nvolatility they do see is largely to the upside:\n\n> The smoothed returns of private equity understate the true economic risk and are\nan artifact of the lack of mark-to-market for illiquid assets â€” Demystifying\nIlliquid Assets: Expected Returns for Private Equity\n[https://www.aqr.com/Insights/Research/White-Papers/Demystifying-Illiquid-Assets-Expected-Returns-for-Private-Equity]\n\n\nStill, having stared at the data for a while, my sense is the alternative\nadvantage represents a real returns premium and isn't merely an artifact of\nmark-to-market gamesmanship. Let's keep digging.\n\nReal estate: location, location, location. Alternatives: access, access, access\nWe've crossed out anything nefarious in all the other asset classes. In all\nasset classes outside of alternatives, wealthier investors earn higher returns\nin the same way anyone earns them â€” by taking more risk. But alternatives remain\na mystery. What's going on there?\n\nIs it skill? Probably not, at least not in traditional sense of \"stock picking\".\nMost investments in alternatives are intermediated by managers â€” hedge, venture\ncapital, and private equity funds â€” who make the actual investments. Therefore,\nit's unlikely that better stock picking ability on the part of the wealthy\ninvestors themselves explains their enhanced returns.\n\nBut that's also why the returns gap is so strange. If the individual investor is\nnot actually making the investments, then why should their personal net worth\ncorrelate so highly with their portfolio returns in alternatives? The only\nexplanation is differences in skill at picking great managers or access to those\nmanagers across wealth levels:\n\n> \"Higher-wealth investors may receive preferential access to better-performing\nmanagers because they can offer larger amounts of funds at once, which reduces\nmarketing and related overhead costs to the fund manager... In contrast,\nlower-wealth investors may only receive access to hedge fund and private equity\nsolutions that are distributed through advanced marketing networks and are\noriginated by large platform operators. However, funds that provide more\naccessibility may deliver worse performance\"\n\n\nFor example, the authors find that fund-of-funds\n[https://www.investopedia.com/terms/f/fundsoffunds.asp], investment funds that\ninvest in other funds rather than in securities directly, earn \"almost exactly\ntwo percentage points lower\" returns on an annualized basis \"evidence for fees\nimposed by additional layers of management.\" Another piece of evidence â€” the\nfewer investors who hold the same alternatives security, the higher than\nreturns, and vice versa: \"assets with limited investor participation are\nsignificantly related to higher investment returns.\" In other words, exclusivity\ngenerates better returns. This points to the importance of access.\n\nOne highly suggestive piece of evidence comes from the returns of investors\nwhose funds are managed by a single family office (SFO), which is an investment\nfirm setup solely to manage the wealth and investments of a single family or\nperson. Portfolios managed by family offices earn significantly higher returns \nthan portfolios of investors in the same wealth bracket who do not have a family\noffice. Not only that, the return differential across wealth groups disappears\nwhen we look only at portfolios managed by family offices:\n\n\n\nDepending on the asset class, among portfolios managed by family offices,\ninvestors with less than $3M in assets earn more than investors with over $100M\nin assets:\n\n> \"While lower-wealth investors earn substantially lower returns on their hedge\nfund and private equity investments than ultra-high net worth investors, this\ndoes not apply to investors with smaller portfolios that are managed by an SFO.\nEven SFO investors with less than three million, or 3-10 million earn roughly\nthe same return as those with more than 100 million on their investments in\nhedge funds and private equity, and substantially more than investors in the\nsame wealth brackets but without SFO management.\"\n\n\nSomething about the nature of family offices and their influence on manager\nselection causes the wealth-returns relationship to disappear entirely. The\nstudy's authors speculate that this \"likely [relates] to the difficulty of\nidentifying and accessing high-performing alternative investment funds.\"\n\nAccess to assets matters. In the public markets, access is effectively\ndemocratized, so we can completely explain the advantage of richer investors in\nthe public markets via differential risk-taking. However, the advantage in\nalternative assets reflects more than mere risk tolerance or preference.\nIronically, family offices, which likely exacerbate inequality between the rich\nand the rest, level the playing field *among* the rich.\n\nThe 1% vs. the 0.1%\nSo do wealthy investors have an edge? Relative to non-wealthy, not really. It's\nrisk-loving turtles all the way down.\n\nBut do the wealthiest have an edge versus their somewhat less wealthy peers?\nYes, though I won't lose much sleep over it. It's an access advantage, and it's\nlimited to the assets where access remains important: the relatively opaque and\nexclusive worlds of hedge funds, venture capital, and private equity.\n\nCandidly, I'm more focused on expanding access to these alternative asset\nclasses in general than on helping already well-off investors get access to the\nbest funds. That said, the excess returns of alternatives are quite low for\ninvestors with only a few million in assets. On that basis, they aren't much\nbetter than public equities except for the extremely wealthy.\n\nIf these new investors only receive access to the worst-performing funds, the\neffort will be worthless. Worth pondering further.\n\n> The super-rich earn more on their investments than the rest of us.\n\nIn the battle between the 1% and the 0.1%, the richest get richer, faster.\n\nSomething nefarious? Or something else?https://t.co/Mc8imZTiH3\n\nâ€” Nnamdi Iregbulem (@whoisnnamdi) August 20, 2021\n[https://twitter.com/whoisnnamdi/status/1428770455414992899?ref_src=twsrc%5Etfw]\nThanks to Cynthia Balloch [https://www.lse.ac.uk/finance/people/faculty/Balloch] \nand Julian Richers [https://sites.google.com/site/julianrichers/home], the\nauthors of the study from which much of this essay is derived.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2021/08/header.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2021-08-18T07:38:30.000Z","updated_at":"2022-01-01T20:07:45.000Z","published_at":"2021-08-18T07:47:55.000Z","custom_excerpt":"The super-rich earn more on their investments than the rest of us. \n\nSomething nefarious, or something else?","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"614bd8c316c7fe4443b1406f","uuid":"e69def79-9482-4e44-a077-f9cca44ac4e0","title":"You Can't Eat Relative Growth","slug":"relative-growth","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"In 2006, Howard Marks, co-founder of Oaktree Capital Management, published a memo titled \\\"[You Can't Eat IRR](https://www.oaktreecapital.com/docs/default-source/memos/2006-07-12-you-cant-eat-irr.pdf).\\\" In doing so, he popularized the idea that [IRR](https://www.investopedia.com/terms/i/irr.asp), or internal rate of return, is a misleading measure of fund performance, as it gives no sense for the amount of capital put to work or the absolute dollars returned to investors:\\n> \\\"A high internal rate of return does not in and of itself put money in oneâ€™s pocket. Only when itâ€™s applied to a material amount of invested capital for a significant period of time does IRR produce wealth\\\"\\n\\nI've noticed a similar problem in how we measure and evaluate startup success, particularly **growth rates**.\\n\\nThere are two kinds of growth: **absolute** and **relative**:\\n- Absolute growth is the *absolute* increase in a metric, like dollars of revenue added or customers acquired in a given period. The metric this period minus its value last period gives you the absolute growth:\\n\\n$$\\\\text{Absolute Growth}\\\\_t = \\\\text{Metric}\\\\_t - \\\\text{Metric}\\\\_{t-1}$$\\n\\n- Relative growth is measured *relative* to what came before: \\\"We ended the year with 150% more customers\\\", or \\\"We grew revenue 3X this year.\\\" It's effectively unitless, but we tend to measure it in percentages, as in \\\"percentage points of growth.\\\" It's the absolute growth divided by the metric's value last period\\n\\n$$\\\\text{Relative Growth}\\\\_t = \\\\frac{\\\\text{Metric}\\\\_t - \\\\text{Metric}\\\\_{t-1}}{\\\\text{Metric}\\\\_{t-1}}$$\\n\\n**In startup land, we talk way too much about relative growth.** It muddles our thinking and makes compound, exponential growth seem easier than it really is. **We'd do better to ground our thinking in absolute growth.**\\n\\nObsessing too much over relative growth injects a number of \\\"bugs\\\" into our thinking:\\n- It screws up our language\\n- It makes us forget what startups actually do\\n- It sets up unrealistic expectations\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: You Can't Eat Relative Growth\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## No sense, this makes\\n![Pasted-image-20210906134123](__GHOST_URL__/content/images/2021/09/Pasted-image-20210906134123.png)\\n\\nThe first problem with the concept of relative growth is that it warps our language in nonsensical ways.\\n\\nA common scenario: a startup previously growing 100% Y/Y \\\"slows\\\" to 50% the subsequent year.\\n\\nThe board of directors asks \\\"why did growth slow so much?\\\" External investors evaluating the company think, \\\"Wow, they really hit a wall.\\\"\\n\\n**But they did no such thing.** Yes the growth rate measured in *percentage terms* has declined, but the growth measured in terms of *dollars of revenue added* hasn't slowed at all.\\n\\nFor example, let's say revenue went from $5M to $10M to $15M, which corresponds to 100% growth followed by 50%. Technically, the company added $5M in revenue each year, so growth hasn't slowed, per se. The problem isn't so much that growth \\\"slowed\\\" so much as it is that absolute growth *didn't increase*, hence the fall in the relative growth rate.\\n\\nThink back to your high school physics class. Imagine we have an object, say a car, traveling in some direction. That car has a position, x, and a velocity, v. In business terms, imagine the level of revenue (or whatever metric) is the position of that car and it's absolute growth maps to the velocity.\\n\\n![drawing-2021-09-22-17.21.13.excalidraw](__GHOST_URL__/content/images/2021/09/drawing-2021-09-22-17.21.13.excalidraw.png)\\n\\nAs long as that car keeps moving at the same velocity, we would say it neither accelerates nor decelerates. In startup land however, a business growing at constant absolute growth is said to to somehow be *decelerating* because its relative growth is declining.\\n\\n![drawing-2021-09-22-17.30.35.excalidraw](__GHOST_URL__/content/images/2021/09/drawing-2021-09-22-17.30.35.excalidraw.png)\\n\\nThis is super strange.\\n\\nIn fact, the only way to make sense of this thinking is to measure the size of the business on a logarithmic scale. As I discuss in \\\"[You Don't Understand Compound Growth](https://whoisnnamdi.com/you-dont-understand-compound-growth/)\\\", a constant slope (velocity, effectively) on a log scale implies constant relative growth. In this view, adding a constant $5M in revenue annually is in fact a declining amount of *log revenue* added, thus matching the language of deceleration we tend to use.\\n\\nOK fine, but this subtle rescaling goes completely unsaid. Further, as I'll discuss later on, constant relative growth is fairly unrealistic, yet it is effectively implied by our language on the topic.\\n\\nWe talk as if a reduction in relative growth implies something fundamentally changed about a business. And it would, if that's what companies actually did â€” that is, grow \\\"relatively\\\". However, more often than not, a decline in relative growth in fact suggests that **not enough changed** about the business.\\n\\n## As Yoda said, \\\"Grow absolutely. There is no relative\\\"\\n![Pasted-image-20210906134610](__GHOST_URL__/content/images/2021/09/Pasted-image-20210906134610.png)\\n\\nThe second problem with relative growth is that it misleads us about what businesses fundamentally do.\\n\\nThe fundamental unit of growth is a dollar of additional revenue, not an additional *percentage point* of growth. In other words, absolute growth is the more fundamental concept. We can calculate a relative growth rate after the fact if we want, but the core result is absolute growth.\\n\\nRelative growth is merely a derived concept, a way to normalize absolute growth into a metric that can be compared across companies. That's great, and it's a valuable tool. But we seriously pervert the concept when we go from using it as an *ex post* calculation to thinking that the primary activity of companies is to generate \\\"percentage points of relative growth\\\". That is putting the cart before the horse, the percentage points before the dollars.\\n\\n**Relative growth is not what literally happens.** It's a way to benchmark what happened. **Absolute growth is what actually happened**, what was actually accomplished.\\n\\n**Absolute growth is the \\\"[hard thing](https://www.amazon.com/gp/product/0062273205/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0062273205&linkCode=as2&tag=whoisnn-20&linkId=e0d8ea2cb4b222b0461b55b48ca46c06)\\\" that startups must do each and every day.** Relative growth imperfectly normalizes those efforts in order to make them comparable across scales of companies. It falls well short of its own goal. Further, the choice to normalize absolute growth by the previous level of revenue is simply a convention and a somewhat arbitrary choice. Hypothetically we could normalize growth by *anything*.\\n\\nThe job of the business is to generate absolute growth, to bring in more dollars this year than last year. The most informative information about the team's ability to do that comes from how much they were able to add in the past. Knowing that revenue tripled last year is not in fact informative about the likelihood of revenue tripling this year, because \\\"tripling\\\" is not what the company is in the business of doing. **It's in the business of generating more absolute dollars of revenue each year.** That it tripled last year doesn't really tell you whether it can triple this year. That it added $5M in revenue last year tells you A LOT about the likelihood of generating $5M in additional revenue this year.\\n\\nThinking in relative growth terms causes you to lose your sense of scale. Conversely, thinking in absolute growth makes things quite vivid. \\\"How exactly are we going to find $5M in additional revenue next year\\\" is a much more tangible and precise discussion than \\\"How do we grow 80% next year\\\" even if they mean the exact same thing.\\n\\nThe same relative growth rate can describe many different situations. For example, you hear that a company has grown 3X year-over-year, a relative growth metric. That single number is consistent with all of the following scenarios:\\n- $300K to $900K\\n- $1M to $3M\\n- $3M to $9M\\n\\nYet there is nothing similar about any of these growth stories. It is a fundamentally different task (and therefore, accomplishment) to go from $300K in revenue to $900K than to go from $3M to $9M. To describe these in the same terms (\\\"3X growth\\\") is a complete misnomer that obfuscates an incredible amount of context. *These are nothing alike.* In this way, relative growth represents a **loss of information** compared to absolute growth.\\n\\nIt's seductive to think that, \\\"well, we grew 100% last year so we should expect to grow similarly this year\\\" when in fact the two tasks are completely different. Constant relative growth of 100% two years in a row in fact requires *doubling* your growth rate in absolute terms because your existing revenue base is now twice as large. Absolute growth is the \\\"real\\\" growth target you need to hit, and for most companies that won't be easy. This is sobering.\\n\\nSaid differently, you can't eat *percentage points* of growth, you can only eat **dollars** of growth.\\n\\n## Rational expectations\\n![Pasted-image-20210906133733](__GHOST_URL__/content/images/2021/09/Pasted-image-20210906133733.png)\\n\\nIt's cliche to point out that [humans don't understand compound, exponential growth](https://whoisnnamdi.com/you-dont-understand-compound-growth/). In startups we have the opposite problem â€” people are so familiar with the concept that they apply it everywhere, in situations where exponential growth isn't likely or even plausible.\\n\\nExponential growth implies *constant relative growth*. Rather than seeing relative growth fall off, the business continues to grow at nearly the same rate for multiple periods.\\n\\nExponential growth is a great aspirational target to set for companies. Y Combinator does this and it works fantastically for focusing the minds of startup founders. When exponential growth is the goal, one realizes there are really very few ways to achieve it, and most growth hacks won't get the job done.\\n\\nHowever, exponential growth is not a rational *expectation* to have or *prediction* to make. Few phenomena exhibit this sort of behavior outside of the natural world, like bacteria growing in a petri dish. Modern economies are often modeled as perpetual, exponential growth machines, but for most of human history, economies did not grow exponentially at all. Perhaps it's a fine approximation for a large economy, which aggregates an uncountable set of activities that sum up to something approximating constant exponential growth. But it's certainly not a good model for a single company.\\n\\nOnly at low growth rates is past relative growth predictive of future relative growth. At high growth rates the two are not very correlated at all. A business (or an economy for that matter) that grew 2% last year has a very good chance of growing roughly 2% this year. For a business that grew 200% last year... this year's growth is anyone's guess.\\n\\nThere's nothing inherent about startups that makes them grow exponentially other than the fact that it is easier to pull off for small companies than it is for larger ones. Any other correlation between startups and exponential growth is aspirational and attitudinal: startups grow exponentially because **we will them to**. It is not otherwise a reasonable expectation.\\n\\nFor forecasting purposes, constant absolute growth is a much better \\\"baseline\\\" or \\\"base case\\\" than constant relative growth. Constant relative growth may be a great target for setting the tone in the organization, raising ambitions, etc., but mark my words: it probably won't happen.\\n\\nConstant growth in absolute terms is totally normal and unremarkable: startups often add similar amounts of revenue as they did the previous year. Constant _relative_ growth is totally *abnormal*. The idea that a startup growing 100% should somehow manage to grow close to that the subsequent year is a mental bias we tend to have in Silicon Valley that doesn't properly reflect reality. It rarely happens.\\n\\nIt is much more common to see a company go from $5 to 10 to 15 to 20 (constant absolute growth of $5M per year) than go from $5 to 10 to 20 to 40 (constant relative growth of 100% per year). Doing the latter requires a fundamental re-architecture of the company and go-to-market motion every 6 months. Going from $5-10M looks very different than going from $20-40M, even though they both involve a doubling of the business.\\n\\nI find that founders and operators tend to understand this all too well, while investors consistently underappreciate and underestimate the difficulty of scaling at a constant relative rate.\\n\\nOperators, by dint of living in the real world, viscerally understand that what got them *here* won't necessarily get them *there*. Investors on the other hand like to think of companies \\\"2X-ing year-over-year,\\\" as if the 2X relative growth is some fundamental property of the business, like its mass or electric charge. It is not, as they often discover 12 months later.\\n\\nThe investor mentality is in part driven by their relationship with the business. They invest at a certain valuation, and returns are measured relative to that entry price. Founders on the other hand start from **zero** â€” so they don't really measure themselves \\\"relative\\\" to anything. What matters is building as large a business as they possibly can in absolute terms.\\n\\n## Deal in absolutes\\n![Pasted-image-20210906133514](__GHOST_URL__/content/images/2021/09/Pasted-image-20210906133514.png)\\n\\nTo close, I want to make sure I'm not misunderstood in my diatribe against relative growth.\\n\\nThere are actually very good theoretical reasons to focus on relative growth. For example, when relative growth is predictable and easy to pin down, we can use it to calculate the net present value of an asset, which is a direct function of the relative growth of cash flows. This is how discounted cash flow analysis works, for example.\\n\\nSpeaking of assets, the relative growth of asset prices (in other words, returns) is a fundamental building block of modern finance theory and is one of the primary traits that determines how attractive an asset is to potential investors (and the other is the risk or volatility of those returns).\\n\\nSo investors' focus on relative growth is not totally unfounded. That said, these notions all rely on either precisely knowing the relevant parameters (growth, discount rate, etc) or knowing precisely the variability of those metrics (their volatility, variance, etc). This is the world of quantifiable risk, and upon its core principles rests trillions of assets and millions of pages of academic finance research.\\n\\nBut startups do not live in the world of risk, they are squarely domiciled in the world of uncertainty (and the state of Delaware). Here, we barely know what we think we know and reliable invariants are hard to come by. Nothing can be taken for granted, certainly not growth.\\n\\nSo in our board rooms, pitch decks, and quarterly business reviews, let's ground ourselves in the harsh, brutal world of absolutes rather than the theoretically and mathematically convenient domain of relatives. We'll likely do better on both metrics, that way.\"}],[\"embed\",{\"url\":\"https://twitter.com/whoisnnamdi/status/1441460616917504008\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">This month I wrote about the difference between absolute and relative growth and the fact that Silicon Valley (esp. VC) focuses WAY too much on the latter<br><br>Inspired by an old <a href=\\\"https://twitter.com/HowardMarksBook?ref_src=twsrc%5Etfw\\\">@HowardMarksBook</a> memo...<a href=\\\"https://t.co/JlIT9T60Y4\\\">https://t.co/JlIT9T60Y4</a></p>&mdash; Nnamdi Iregbulem (@whoisnnamdi) <a href=\\\"https://twitter.com/whoisnnamdi/status/1441460616917504008?ref_src=twsrc%5Etfw\\\">September 24, 2021</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\",\"metadata\":{\"url\":\"https://twitter.com/whoisnnamdi/status/1441460616917504008\",\"author_name\":\"Nnamdi Iregbulem\",\"author_url\":\"https://twitter.com/whoisnnamdi\",\"width\":550,\"height\":null,\"cache_age\":\"3153600000\",\"provider_name\":\"Twitter\",\"provider_url\":\"http://www.twitter.com/\",\"version\":\"1.0\"}}],[\"markdown\",{\"markdown\":\"<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: You Can't Eat Relative Growth\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>In 2006, Howard Marks, co-founder of Oaktree Capital Management, published a memo titled &quot;<a href=\"https://www.oaktreecapital.com/docs/default-source/memos/2006-07-12-you-cant-eat-irr.pdf\">You Can't Eat IRR</a>.&quot; In doing so, he popularized the idea that <a href=\"https://www.investopedia.com/terms/i/irr.asp\">IRR</a>, or internal rate of return, is a misleading measure of fund performance, as it gives no sense for the amount of capital put to work or the absolute dollars returned to investors:</p>\n<blockquote>\n<p>&quot;A high internal rate of return does not in and of itself put money in oneâ€™s pocket. Only when itâ€™s applied to a material amount of invested capital for a significant period of time does IRR produce wealth&quot;</p>\n</blockquote>\n<p>I've noticed a similar problem in how we measure and evaluate startup success, particularly <strong>growth rates</strong>.</p>\n<p>There are two kinds of growth: <strong>absolute</strong> and <strong>relative</strong>:</p>\n<ul>\n<li>Absolute growth is the <em>absolute</em> increase in a metric, like dollars of revenue added or customers acquired in a given period. The metric this period minus its value last period gives you the absolute growth:</li>\n</ul>\n<p>$$\\text{Absolute Growth}_t = \\text{Metric}_t - \\text{Metric}_{t-1}$$</p>\n<ul>\n<li>Relative growth is measured <em>relative</em> to what came before: &quot;We ended the year with 150% more customers&quot;, or &quot;We grew revenue 3X this year.&quot; It's effectively unitless, but we tend to measure it in percentages, as in &quot;percentage points of growth.&quot; It's the absolute growth divided by the metric's value last period</li>\n</ul>\n<p>$$\\text{Relative Growth}_t = \\frac{\\text{Metric}_t - \\text{Metric}_{t-1}}{\\text{Metric}_{t-1}}$$</p>\n<p><strong>In startup land, we talk way too much about relative growth.</strong> It muddles our thinking and makes compound, exponential growth seem easier than it really is. <strong>We'd do better to ground our thinking in absolute growth.</strong></p>\n<p>Obsessing too much over relative growth injects a number of &quot;bugs&quot; into our thinking:</p>\n<ul>\n<li>It screws up our language</li>\n<li>It makes us forget what startups actually do</li>\n<li>It sets up unrealistic expectations</li>\n</ul>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: You Can't Eat Relative Growth\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"no-sense-this-makes\">No sense, this makes</h2>\n<p><img src=\"__GHOST_URL__/content/images/2021/09/Pasted-image-20210906134123.png\" alt=\"Pasted-image-20210906134123\" loading=\"lazy\"></p>\n<p>The first problem with the concept of relative growth is that it warps our language in nonsensical ways.</p>\n<p>A common scenario: a startup previously growing 100% Y/Y &quot;slows&quot; to 50% the subsequent year.</p>\n<p>The board of directors asks &quot;why did growth slow so much?&quot; External investors evaluating the company think, &quot;Wow, they really hit a wall.&quot;</p>\n<p><strong>But they did no such thing.</strong> Yes the growth rate measured in <em>percentage terms</em> has declined, but the growth measured in terms of <em>dollars of revenue added</em> hasn't slowed at all.</p>\n<p>For example, let's say revenue went from $5M to $10M to $15M, which corresponds to 100% growth followed by 50%. Technically, the company added $5M in revenue each year, so growth hasn't slowed, per se. The problem isn't so much that growth &quot;slowed&quot; so much as it is that absolute growth <em>didn't increase</em>, hence the fall in the relative growth rate.</p>\n<p>Think back to your high school physics class. Imagine we have an object, say a car, traveling in some direction. That car has a position, x, and a velocity, v. In business terms, imagine the level of revenue (or whatever metric) is the position of that car and it's absolute growth maps to the velocity.</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/09/drawing-2021-09-22-17.21.13.excalidraw.png\" alt=\"drawing-2021-09-22-17.21.13.excalidraw\" loading=\"lazy\"></p>\n<p>As long as that car keeps moving at the same velocity, we would say it neither accelerates nor decelerates. In startup land however, a business growing at constant absolute growth is said to to somehow be <em>decelerating</em> because its relative growth is declining.</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/09/drawing-2021-09-22-17.30.35.excalidraw.png\" alt=\"drawing-2021-09-22-17.30.35.excalidraw\" loading=\"lazy\"></p>\n<p>This is super strange.</p>\n<p>In fact, the only way to make sense of this thinking is to measure the size of the business on a logarithmic scale. As I discuss in &quot;<a href=\"https://whoisnnamdi.com/you-dont-understand-compound-growth/\">You Don't Understand Compound Growth</a>&quot;, a constant slope (velocity, effectively) on a log scale implies constant relative growth. In this view, adding a constant $5M in revenue annually is in fact a declining amount of <em>log revenue</em> added, thus matching the language of deceleration we tend to use.</p>\n<p>OK fine, but this subtle rescaling goes completely unsaid. Further, as I'll discuss later on, constant relative growth is fairly unrealistic, yet it is effectively implied by our language on the topic.</p>\n<p>We talk as if a reduction in relative growth implies something fundamentally changed about a business. And it would, if that's what companies actually did â€” that is, grow &quot;relatively&quot;. However, more often than not, a decline in relative growth in fact suggests that <strong>not enough changed</strong> about the business.</p>\n<h2 id=\"as-yoda-said-grow-absolutely-there-is-no-relative\">As Yoda said, &quot;Grow absolutely. There is no relative&quot;</h2>\n<p><img src=\"__GHOST_URL__/content/images/2021/09/Pasted-image-20210906134610.png\" alt=\"Pasted-image-20210906134610\" loading=\"lazy\"></p>\n<p>The second problem with relative growth is that it misleads us about what businesses fundamentally do.</p>\n<p>The fundamental unit of growth is a dollar of additional revenue, not an additional <em>percentage point</em> of growth. In other words, absolute growth is the more fundamental concept. We can calculate a relative growth rate after the fact if we want, but the core result is absolute growth.</p>\n<p>Relative growth is merely a derived concept, a way to normalize absolute growth into a metric that can be compared across companies. That's great, and it's a valuable tool. But we seriously pervert the concept when we go from using it as an <em>ex post</em> calculation to thinking that the primary activity of companies is to generate &quot;percentage points of relative growth&quot;. That is putting the cart before the horse, the percentage points before the dollars.</p>\n<p><strong>Relative growth is not what literally happens.</strong> It's a way to benchmark what happened. <strong>Absolute growth is what actually happened</strong>, what was actually accomplished.</p>\n<p><strong>Absolute growth is the &quot;<a href=\"https://www.amazon.com/gp/product/0062273205/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0062273205&amp;linkCode=as2&amp;tag=whoisnn-20&amp;linkId=e0d8ea2cb4b222b0461b55b48ca46c06\">hard thing</a>&quot; that startups must do each and every day.</strong> Relative growth imperfectly normalizes those efforts in order to make them comparable across scales of companies. It falls well short of its own goal. Further, the choice to normalize absolute growth by the previous level of revenue is simply a convention and a somewhat arbitrary choice. Hypothetically we could normalize growth by <em>anything</em>.</p>\n<p>The job of the business is to generate absolute growth, to bring in more dollars this year than last year. The most informative information about the team's ability to do that comes from how much they were able to add in the past. Knowing that revenue tripled last year is not in fact informative about the likelihood of revenue tripling this year, because &quot;tripling&quot; is not what the company is in the business of doing. <strong>It's in the business of generating more absolute dollars of revenue each year.</strong> That it tripled last year doesn't really tell you whether it can triple this year. That it added $5M in revenue last year tells you A LOT about the likelihood of generating $5M in additional revenue this year.</p>\n<p>Thinking in relative growth terms causes you to lose your sense of scale. Conversely, thinking in absolute growth makes things quite vivid. &quot;How exactly are we going to find $5M in additional revenue next year&quot; is a much more tangible and precise discussion than &quot;How do we grow 80% next year&quot; even if they mean the exact same thing.</p>\n<p>The same relative growth rate can describe many different situations. For example, you hear that a company has grown 3X year-over-year, a relative growth metric. That single number is consistent with all of the following scenarios:</p>\n<ul>\n<li>$300K to $900K</li>\n<li>$1M to $3M</li>\n<li>$3M to $9M</li>\n</ul>\n<p>Yet there is nothing similar about any of these growth stories. It is a fundamentally different task (and therefore, accomplishment) to go from $300K in revenue to $900K than to go from $3M to $9M. To describe these in the same terms (&quot;3X growth&quot;) is a complete misnomer that obfuscates an incredible amount of context. <em>These are nothing alike.</em> In this way, relative growth represents a <strong>loss of information</strong> compared to absolute growth.</p>\n<p>It's seductive to think that, &quot;well, we grew 100% last year so we should expect to grow similarly this year&quot; when in fact the two tasks are completely different. Constant relative growth of 100% two years in a row in fact requires <em>doubling</em> your growth rate in absolute terms because your existing revenue base is now twice as large. Absolute growth is the &quot;real&quot; growth target you need to hit, and for most companies that won't be easy. This is sobering.</p>\n<p>Said differently, you can't eat <em>percentage points</em> of growth, you can only eat <strong>dollars</strong> of growth.</p>\n<h2 id=\"rational-expectations\">Rational expectations</h2>\n<p><img src=\"__GHOST_URL__/content/images/2021/09/Pasted-image-20210906133733.png\" alt=\"Pasted-image-20210906133733\" loading=\"lazy\"></p>\n<p>It's cliche to point out that <a href=\"https://whoisnnamdi.com/you-dont-understand-compound-growth/\">humans don't understand compound, exponential growth</a>. In startups we have the opposite problem â€” people are so familiar with the concept that they apply it everywhere, in situations where exponential growth isn't likely or even plausible.</p>\n<p>Exponential growth implies <em>constant relative growth</em>. Rather than seeing relative growth fall off, the business continues to grow at nearly the same rate for multiple periods.</p>\n<p>Exponential growth is a great aspirational target to set for companies. Y Combinator does this and it works fantastically for focusing the minds of startup founders. When exponential growth is the goal, one realizes there are really very few ways to achieve it, and most growth hacks won't get the job done.</p>\n<p>However, exponential growth is not a rational <em>expectation</em> to have or <em>prediction</em> to make. Few phenomena exhibit this sort of behavior outside of the natural world, like bacteria growing in a petri dish. Modern economies are often modeled as perpetual, exponential growth machines, but for most of human history, economies did not grow exponentially at all. Perhaps it's a fine approximation for a large economy, which aggregates an uncountable set of activities that sum up to something approximating constant exponential growth. But it's certainly not a good model for a single company.</p>\n<p>Only at low growth rates is past relative growth predictive of future relative growth. At high growth rates the two are not very correlated at all. A business (or an economy for that matter) that grew 2% last year has a very good chance of growing roughly 2% this year. For a business that grew 200% last year... this year's growth is anyone's guess.</p>\n<p>There's nothing inherent about startups that makes them grow exponentially other than the fact that it is easier to pull off for small companies than it is for larger ones. Any other correlation between startups and exponential growth is aspirational and attitudinal: startups grow exponentially because <strong>we will them to</strong>. It is not otherwise a reasonable expectation.</p>\n<p>For forecasting purposes, constant absolute growth is a much better &quot;baseline&quot; or &quot;base case&quot; than constant relative growth. Constant relative growth may be a great target for setting the tone in the organization, raising ambitions, etc., but mark my words: it probably won't happen.</p>\n<p>Constant growth in absolute terms is totally normal and unremarkable: startups often add similar amounts of revenue as they did the previous year. Constant <em>relative</em> growth is totally <em>abnormal</em>. The idea that a startup growing 100% should somehow manage to grow close to that the subsequent year is a mental bias we tend to have in Silicon Valley that doesn't properly reflect reality. It rarely happens.</p>\n<p>It is much more common to see a company go from $5 to 10 to 15 to 20 (constant absolute growth of $5M per year) than go from $5 to 10 to 20 to 40 (constant relative growth of 100% per year). Doing the latter requires a fundamental re-architecture of the company and go-to-market motion every 6 months. Going from $5-10M looks very different than going from $20-40M, even though they both involve a doubling of the business.</p>\n<p>I find that founders and operators tend to understand this all too well, while investors consistently underappreciate and underestimate the difficulty of scaling at a constant relative rate.</p>\n<p>Operators, by dint of living in the real world, viscerally understand that what got them <em>here</em> won't necessarily get them <em>there</em>. Investors on the other hand like to think of companies &quot;2X-ing year-over-year,&quot; as if the 2X relative growth is some fundamental property of the business, like its mass or electric charge. It is not, as they often discover 12 months later.</p>\n<p>The investor mentality is in part driven by their relationship with the business. They invest at a certain valuation, and returns are measured relative to that entry price. Founders on the other hand start from <strong>zero</strong> â€” so they don't really measure themselves &quot;relative&quot; to anything. What matters is building as large a business as they possibly can in absolute terms.</p>\n<h2 id=\"deal-in-absolutes\">Deal in absolutes</h2>\n<p><img src=\"__GHOST_URL__/content/images/2021/09/Pasted-image-20210906133514.png\" alt=\"Pasted-image-20210906133514\" loading=\"lazy\"></p>\n<p>To close, I want to make sure I'm not misunderstood in my diatribe against relative growth.</p>\n<p>There are actually very good theoretical reasons to focus on relative growth. For example, when relative growth is predictable and easy to pin down, we can use it to calculate the net present value of an asset, which is a direct function of the relative growth of cash flows. This is how discounted cash flow analysis works, for example.</p>\n<p>Speaking of assets, the relative growth of asset prices (in other words, returns) is a fundamental building block of modern finance theory and is one of the primary traits that determines how attractive an asset is to potential investors (and the other is the risk or volatility of those returns).</p>\n<p>So investors' focus on relative growth is not totally unfounded. That said, these notions all rely on either precisely knowing the relevant parameters (growth, discount rate, etc) or knowing precisely the variability of those metrics (their volatility, variance, etc). This is the world of quantifiable risk, and upon its core principles rests trillions of assets and millions of pages of academic finance research.</p>\n<p>But startups do not live in the world of risk, they are squarely domiciled in the world of uncertainty (and the state of Delaware). Here, we barely know what we think we know and reliable invariants are hard to come by. Nothing can be taken for granted, certainly not growth.</p>\n<p>So in our board rooms, pitch decks, and quarterly business reviews, let's ground ourselves in the harsh, brutal world of absolutes rather than the theoretically and mathematically convenient domain of relatives. We'll likely do better on both metrics, that way.</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">This month I wrote about the difference between absolute and relative growth and the fact that Silicon Valley (esp. VC) focuses WAY too much on the latter<br><br>Inspired by an old <a href=\"https://twitter.com/HowardMarksBook?ref_src=twsrc%5Etfw\">@HowardMarksBook</a> memo...<a href=\"https://t.co/JlIT9T60Y4\">https://t.co/JlIT9T60Y4</a></p>&mdash; Nnamdi Iregbulem (@whoisnnamdi) <a href=\"https://twitter.com/whoisnnamdi/status/1441460616917504008?ref_src=twsrc%5Etfw\">September 24, 2021</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><!--kg-card-begin: markdown--><section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: You Can't Eat Relative Growth\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"614bd8c316c7fe4443b1406f","plaintext":"In 2006, Howard Marks, co-founder of Oaktree Capital Management, published a\nmemo titled \"You Can't Eat IRR\n[https://www.oaktreecapital.com/docs/default-source/memos/2006-07-12-you-cant-eat-irr.pdf]\n.\" In doing so, he popularized the idea that IRR\n[https://www.investopedia.com/terms/i/irr.asp], or internal rate of return, is a\nmisleading measure of fund performance, as it gives no sense for the amount of\ncapital put to work or the absolute dollars returned to investors:\n\n> \"A high internal rate of return does not in and of itself put money in oneâ€™s\npocket. Only when itâ€™s applied to a material amount of invested capital for a\nsignificant period of time does IRR produce wealth\"\n\n\nI've noticed a similar problem in how we measure and evaluate startup success,\nparticularly growth rates.\n\nThere are two kinds of growth: absolute and relative:\n\n * Absolute growth is the absolute increase in a metric, like dollars of revenue\n   added or customers acquired in a given period. The metric this period minus\n   its value last period gives you the absolute growth:\n\n$$\\text{Absolute Growth}_t = \\text{Metric}_t - \\text{Metric}_{t-1}$$\n\n * Relative growth is measured relative to what came before: \"We ended the year\n   with 150% more customers\", or \"We grew revenue 3X this year.\" It's\n   effectively unitless, but we tend to measure it in percentages, as in\n   \"percentage points of growth.\" It's the absolute growth divided by the\n   metric's value last period\n\n$$\\text{Relative Growth}_t = \\frac{\\text{Metric}_t -\n\\text{Metric}_{t-1}}{\\text{Metric}_{t-1}}$$\n\nIn startup land, we talk way too much about relative growth. It muddles our\nthinking and makes compound, exponential growth seem easier than it really is. \nWe'd do better to ground our thinking in absolute growth.\n\nObsessing too much over relative growth injects a number of \"bugs\" into our\nthinking:\n\n * It screws up our language\n * It makes us forget what startups actually do\n * It sets up unrealistic expectations\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡No sense, this makes\n\n\nThe first problem with the concept of relative growth is that it warps our\nlanguage in nonsensical ways.\n\nA common scenario: a startup previously growing 100% Y/Y \"slows\" to 50% the\nsubsequent year.\n\nThe board of directors asks \"why did growth slow so much?\" External investors\nevaluating the company think, \"Wow, they really hit a wall.\"\n\nBut they did no such thing. Yes the growth rate measured in percentage terms has\ndeclined, but the growth measured in terms of dollars of revenue added hasn't\nslowed at all.\n\nFor example, let's say revenue went from $5M to $10M to $15M, which corresponds\nto 100% growth followed by 50%. Technically, the company added $5M in revenue\neach year, so growth hasn't slowed, per se. The problem isn't so much that\ngrowth \"slowed\" so much as it is that absolute growth didn't increase, hence the\nfall in the relative growth rate.\n\nThink back to your high school physics class. Imagine we have an object, say a\ncar, traveling in some direction. That car has a position, x, and a velocity, v.\nIn business terms, imagine the level of revenue (or whatever metric) is the\nposition of that car and it's absolute growth maps to the velocity.\n\n\n\nAs long as that car keeps moving at the same velocity, we would say it neither\naccelerates nor decelerates. In startup land however, a business growing at\nconstant absolute growth is said to to somehow be decelerating because its\nrelative growth is declining.\n\n\n\nThis is super strange.\n\nIn fact, the only way to make sense of this thinking is to measure the size of\nthe business on a logarithmic scale. As I discuss in \"You Don't Understand\nCompound Growth [https://whoisnnamdi.com/you-dont-understand-compound-growth/]\",\na constant slope (velocity, effectively) on a log scale implies constant\nrelative growth. In this view, adding a constant $5M in revenue annually is in\nfact a declining amount of log revenue added, thus matching the language of\ndeceleration we tend to use.\n\nOK fine, but this subtle rescaling goes completely unsaid. Further, as I'll\ndiscuss later on, constant relative growth is fairly unrealistic, yet it is\neffectively implied by our language on the topic.\n\nWe talk as if a reduction in relative growth implies something fundamentally\nchanged about a business. And it would, if that's what companies actually did â€”\nthat is, grow \"relatively\". However, more often than not, a decline in relative\ngrowth in fact suggests that not enough changed about the business.\n\nAs Yoda said, \"Grow absolutely. There is no relative\"\n\n\nThe second problem with relative growth is that it misleads us about what\nbusinesses fundamentally do.\n\nThe fundamental unit of growth is a dollar of additional revenue, not an\nadditional percentage point of growth. In other words, absolute growth is the\nmore fundamental concept. We can calculate a relative growth rate after the fact\nif we want, but the core result is absolute growth.\n\nRelative growth is merely a derived concept, a way to normalize absolute growth\ninto a metric that can be compared across companies. That's great, and it's a\nvaluable tool. But we seriously pervert the concept when we go from using it as\nan ex post calculation to thinking that the primary activity of companies is to\ngenerate \"percentage points of relative growth\". That is putting the cart before\nthe horse, the percentage points before the dollars.\n\nRelative growth is not what literally happens. It's a way to benchmark what\nhappened. Absolute growth is what actually happened, what was actually\naccomplished.\n\nAbsolute growth is the \"hard thing\n[https://www.amazon.com/gp/product/0062273205/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0062273205&linkCode=as2&tag=whoisnn-20&linkId=e0d8ea2cb4b222b0461b55b48ca46c06]\n\" that startups must do each and every day. Relative growth imperfectly\nnormalizes those efforts in order to make them comparable across scales of\ncompanies. It falls well short of its own goal. Further, the choice to normalize\nabsolute growth by the previous level of revenue is simply a convention and a\nsomewhat arbitrary choice. Hypothetically we could normalize growth by anything.\n\nThe job of the business is to generate absolute growth, to bring in more dollars\nthis year than last year. The most informative information about the team's\nability to do that comes from how much they were able to add in the past.\nKnowing that revenue tripled last year is not in fact informative about the\nlikelihood of revenue tripling this year, because \"tripling\" is not what the\ncompany is in the business of doing. It's in the business of generating more\nabsolute dollars of revenue each year. That it tripled last year doesn't really\ntell you whether it can triple this year. That it added $5M in revenue last year\ntells you A LOT about the likelihood of generating $5M in additional revenue\nthis year.\n\nThinking in relative growth terms causes you to lose your sense of scale.\nConversely, thinking in absolute growth makes things quite vivid. \"How exactly\nare we going to find $5M in additional revenue next year\" is a much more\ntangible and precise discussion than \"How do we grow 80% next year\" even if they\nmean the exact same thing.\n\nThe same relative growth rate can describe many different situations. For\nexample, you hear that a company has grown 3X year-over-year, a relative growth\nmetric. That single number is consistent with all of the following scenarios:\n\n * $300K to $900K\n * $1M to $3M\n * $3M to $9M\n\nYet there is nothing similar about any of these growth stories. It is a\nfundamentally different task (and therefore, accomplishment) to go from $300K in\nrevenue to $900K than to go from $3M to $9M. To describe these in the same terms\n(\"3X growth\") is a complete misnomer that obfuscates an incredible amount of\ncontext. These are nothing alike. In this way, relative growth represents a loss\nof information compared to absolute growth.\n\nIt's seductive to think that, \"well, we grew 100% last year so we should expect\nto grow similarly this year\" when in fact the two tasks are completely\ndifferent. Constant relative growth of 100% two years in a row in fact requires \ndoubling your growth rate in absolute terms because your existing revenue base\nis now twice as large. Absolute growth is the \"real\" growth target you need to\nhit, and for most companies that won't be easy. This is sobering.\n\nSaid differently, you can't eat percentage points of growth, you can only eat \ndollars of growth.\n\nRational expectations\n\n\nIt's cliche to point out that humans don't understand compound, exponential\ngrowth [https://whoisnnamdi.com/you-dont-understand-compound-growth/]. In\nstartups we have the opposite problem â€” people are so familiar with the concept\nthat they apply it everywhere, in situations where exponential growth isn't\nlikely or even plausible.\n\nExponential growth implies constant relative growth. Rather than seeing relative\ngrowth fall off, the business continues to grow at nearly the same rate for\nmultiple periods.\n\nExponential growth is a great aspirational target to set for companies. Y\nCombinator does this and it works fantastically for focusing the minds of\nstartup founders. When exponential growth is the goal, one realizes there are\nreally very few ways to achieve it, and most growth hacks won't get the job\ndone.\n\nHowever, exponential growth is not a rational expectation to have or prediction \nto make. Few phenomena exhibit this sort of behavior outside of the natural\nworld, like bacteria growing in a petri dish. Modern economies are often modeled\nas perpetual, exponential growth machines, but for most of human history,\neconomies did not grow exponentially at all. Perhaps it's a fine approximation\nfor a large economy, which aggregates an uncountable set of activities that sum\nup to something approximating constant exponential growth. But it's certainly\nnot a good model for a single company.\n\nOnly at low growth rates is past relative growth predictive of future relative\ngrowth. At high growth rates the two are not very correlated at all. A business\n(or an economy for that matter) that grew 2% last year has a very good chance of\ngrowing roughly 2% this year. For a business that grew 200% last year... this\nyear's growth is anyone's guess.\n\nThere's nothing inherent about startups that makes them grow exponentially other\nthan the fact that it is easier to pull off for small companies than it is for\nlarger ones. Any other correlation between startups and exponential growth is\naspirational and attitudinal: startups grow exponentially because we will them\nto. It is not otherwise a reasonable expectation.\n\nFor forecasting purposes, constant absolute growth is a much better \"baseline\"\nor \"base case\" than constant relative growth. Constant relative growth may be a\ngreat target for setting the tone in the organization, raising ambitions, etc.,\nbut mark my words: it probably won't happen.\n\nConstant growth in absolute terms is totally normal and unremarkable: startups\noften add similar amounts of revenue as they did the previous year. Constant \nrelative growth is totally abnormal. The idea that a startup growing 100% should\nsomehow manage to grow close to that the subsequent year is a mental bias we\ntend to have in Silicon Valley that doesn't properly reflect reality. It rarely\nhappens.\n\nIt is much more common to see a company go from $5 to 10 to 15 to 20 (constant\nabsolute growth of $5M per year) than go from $5 to 10 to 20 to 40 (constant\nrelative growth of 100% per year). Doing the latter requires a fundamental\nre-architecture of the company and go-to-market motion every 6 months. Going\nfrom $5-10M looks very different than going from $20-40M, even though they both\ninvolve a doubling of the business.\n\nI find that founders and operators tend to understand this all too well, while\ninvestors consistently underappreciate and underestimate the difficulty of\nscaling at a constant relative rate.\n\nOperators, by dint of living in the real world, viscerally understand that what\ngot them here won't necessarily get them there. Investors on the other hand like\nto think of companies \"2X-ing year-over-year,\" as if the 2X relative growth is\nsome fundamental property of the business, like its mass or electric charge. It\nis not, as they often discover 12 months later.\n\nThe investor mentality is in part driven by their relationship with the\nbusiness. They invest at a certain valuation, and returns are measured relative\nto that entry price. Founders on the other hand start from zero â€” so they don't\nreally measure themselves \"relative\" to anything. What matters is building as\nlarge a business as they possibly can in absolute terms.\n\nDeal in absolutes\n\n\nTo close, I want to make sure I'm not misunderstood in my diatribe against\nrelative growth.\n\nThere are actually very good theoretical reasons to focus on relative growth.\nFor example, when relative growth is predictable and easy to pin down, we can\nuse it to calculate the net present value of an asset, which is a direct\nfunction of the relative growth of cash flows. This is how discounted cash flow\nanalysis works, for example.\n\nSpeaking of assets, the relative growth of asset prices (in other words,\nreturns) is a fundamental building block of modern finance theory and is one of\nthe primary traits that determines how attractive an asset is to potential\ninvestors (and the other is the risk or volatility of those returns).\n\nSo investors' focus on relative growth is not totally unfounded. That said,\nthese notions all rely on either precisely knowing the relevant parameters\n(growth, discount rate, etc) or knowing precisely the variability of those\nmetrics (their volatility, variance, etc). This is the world of quantifiable\nrisk, and upon its core principles rests trillions of assets and millions of\npages of academic finance research.\n\nBut startups do not live in the world of risk, they are squarely domiciled in\nthe world of uncertainty (and the state of Delaware). Here, we barely know what\nwe think we know and reliable invariants are hard to come by. Nothing can be\ntaken for granted, certainly not growth.\n\nSo in our board rooms, pitch decks, and quarterly business reviews, let's ground\nourselves in the harsh, brutal world of absolutes rather than the theoretically\nand mathematically convenient domain of relatives. We'll likely do better on\nboth metrics, that way.\n\n> This month I wrote about the difference between absolute and relative growth and\nthe fact that Silicon Valley (esp. VC) focuses WAY too much on the latter\n\nInspired by an old @HowardMarksBook\n[https://twitter.com/HowardMarksBook?ref_src=twsrc%5Etfw] memo...\nhttps://t.co/JlIT9T60Y4\n\nâ€” Nnamdi Iregbulem (@whoisnnamdi) September 24, 2021\n[https://twitter.com/whoisnnamdi/status/1441460616917504008?ref_src=twsrc%5Etfw]\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2021/09/Pasted-image-20210922213513.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2021-09-23T01:30:43.000Z","updated_at":"2022-01-01T20:08:17.000Z","published_at":"2021-09-23T09:07:29.000Z","custom_excerpt":"In startup land, we talk way too much about relative growth. We'd do better to ground our thinking in absolute growth.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"618a976bfec7d1542d1d29ae","uuid":"bb42c460-e869-45fd-9d45-bced99565281","title":"Companies Rarely Grow Into Their Valuations","slug":"grow-valuation","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Investors often justify high valuation multiples with the claim that the companies \\\"will grow into their valuations.\\\"\\n\\nIt turns out **this rarely happens**.\\n\\nMost often, companies don't grow fast enough to compensate for rising valuation multiples. Instead, high valuations today imply slower value appreciation in the future, i.e. lower returns.\\n\\nThus, companies don't catch up to their valuations; **their valuations catch up to *them*.**\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Companies Rarely Grow Into Their Valuations\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n### Expanding on multiple expansion\\nInvestors can justify rising [valuation multiples](https://en.wikipedia.org/wiki/Valuation_using_multiples) with a belief that:\\n* growth will be better than expected (\\\"they will grow into their valuation\\\"),\\n* returns will be lower than expected (the valuation will appreciate more slowly), or\\n* multiples will be even higher in the future (\\\"someone else will pay more for this thing\\\")\\n\\nIf growth accelerates, valuation multiples fall due to the denominator growing faster than the numerator (revenue or cash flow grows faster than valuation). \\n\\nOn the other hand, if future returns decline, the numerator grows more slowly (valuations grow slower than revenue or cash flow), also causing multiples to fall. Either outcome leads to declining valuation multiples:\\n\\n$$\\\\frac{\\\\text{Valuation} \\\\uparrow}{\\\\text{Revenue or Cash Flow} \\\\uparrow \\\\uparrow \\\\uparrow} \\\\rightarrow \\\\text{Declining Valuation Multiples}$$\\n\\nThink of the \\\"multiples are higher today because multiples will be higher tomorrow\\\" justification as a sort of \\\"bubble mentality\\\" or \\\"[greater fools](https://en.wikipedia.org/wiki/Greater_fool_theory)\\\" explanation. Someone else will pay more for this later, so I'm OK paying more today. This of course can't go on for long: bubbles eventually pop; manias eventually subside. So, here too, multiples return to \\\"normal.\\\"\\n\\nThese three explanations for valuation multiples are collectively called the  [Campbell-Shiller Decomposition](https://www.youtube.com/watch?v=CIMMkDWiqRE), originally conceived in the late 1980s. It lets us cleanly account for changing valuation multiples with changing beliefs about growth, returns, and future multiples. We can even make an equation out of it (\\\\\\\\(\\\\Delta\\\\\\\\) = Change):\\n$$\\\\Delta \\\\text{Valuation Multiples Today} = \\\\Delta \\\\text{Future Growth} - \\\\Delta\\\\text{Future Returns} + \\\\Delta\\\\text{Future Valuation Multiples}$$\\n\\nTherefore, higher multiples today imply (1) faster growth in the future, (2) lower future returns, or (3) even higher multiples going forward.\\n\\nImportantly, this works for both forward and backward-looking analysis: changing *expectations* of future growth, returns, or multiples affect valuations today and changing valuation multiples today also *forecast* future growth, returns, and multiples. In other words, investors' **subjective** expectations about the future influence valuations today and those valuations also predict the **objective** future itself.\\n\\nRegardless of the specific cause, valuation multiples eventually [mean-revert](https://www.investopedia.com/terms/m/meanreversion.asp); subjective expectations eventually collide with objective reality.\\n\\n### Subjective expectations\\nLet's start with *subjective expectations*. When [researchers](https://onlinelibrary.wiley.com/doi/10.1111/jofi.13016) decompose variation in price-earnings (PE) ratios into changing expectations about cash flows, discount rates (e.g. expected returns), and future PE ratios using the Campbell-Shiller Decomposition, they find fluctuating cash flow expectations (CF in the table below) explain more than 90% of all movement in valuations ratios, while expected returns (DR) explain little:\\n\\n![Pasted-image-20211105145313](__GHOST_URL__/content/images/2021/11/Pasted-image-20211105145313.png)\\n\\n> â€œIn the 2003 to 2015 sample, **one-year subjective earnings growth expectations account for virtually all (94%) price-earnings ratio movements.**â€ \\n> ...\\n> â€œ**high prices can largely be accounted for by high expectations for future cash flows.** Cash flow growth expectations are volatile and significantly correlated with prices. In comparison, return expectations are much less volatile and positively correlate with prices, meaning that **high prices cannot come from low discount rates**â€ â€” [Subjective Cash Flow and Discount Rate Expectations](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3841696)\\n\\n[Another paper](https://www.ssrn.com/abstract=3740792) breaks down the expected returns vs growth dynamic between different classes of market participants, finding that sell-side analysts, institutional investors, and corporate CFOs all use growth expectations to explain fluctuating valuations (\\\\\\\\(g_t\\\\\\\\) in the table below) rather than expected returns (\\\\\\\\(\\\\mu_t\\\\\\\\)):\\n\\n![Pasted-image-20211105145501](__GHOST_URL__/content/images/2021/11/Pasted-image-20211105145501.png)\\n\\n> â€œ**both Wall Street and Main Street believe... the expected cash flow process is the main economic force driving asset price variations**â€\\n> ...\\n> â€œ**cash flow expectations alone explain 99% of the price-dividend ratio variation**, while return expectations only explain about 10%.â€ â€” [Subjective Return Expectations](https://www.ssrn.com/abstract=3740792)\\n\\nInvestors see valuations move and ascribe these gyrations to changing expectations for future business growth. But does the growth ever materialize?\\n\\n### Objective reality\\n**Not really:**\\n\\n> â€œthe variance decomposition results reveal that **all three types of investors seem to overestimate how much cash flow variation contributes to the variation in asset prices** when compared to objective measures of return expectations, which show that **discount rate variation should contribute the most to asset price variation**â€ â€” [Subjective Return Expectations](https://www.ssrn.com/abstract=3740792)\\n\\nNow we turn to *objective reality*. The chart below plots expected (solid blue) and realized (dotted green) 1-year earnings growth of the S&P 500 over the last 40 years. Expected earnings growth consistently exceeds actual growth, implying investors tend to overestimate earnings growth. Notice as well how expected earnings growth tend to show \\\"upside volatility\\\", whereas actual earnings show more downside volatility.\\n\\n![Pasted-image-20211031150624](__GHOST_URL__/content/images/2021/11/Pasted-image-20211031150624.png)\\n\\n> â€œ**Earnings growth expectations typically fail to predict the change in earnings during busts**, but they do tend to predict recoveries and track future earnings growth reasonably well during normal times.â€ â€” [Subjective Cash Flow and Discount Rate Expectations](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3841696)\\n\\nInvestors rarely predict poor earnings growth in advance. They often correctly predict strong earnings growth after recessions, but that's kind of cheating isn't it? Quick bounce-backs follow recessions almost universally.\\n\\nWhen financial researchers do look-backs, they find that **high valuation multiples precede low returns**. In fact, they literally *predict* lower returns. Per finance legend [John Cochrane](https://www.johnhcochrane.com/)'s [2011 Presidential Address at the American Finance Association](https://www.youtube.com/watch?v=ZDsOiftolUI) (apologies for the pixelated 360p screenshot, YouTube was less generous back then):\\n\\n![Pasted-image-20211105153730](__GHOST_URL__/content/images/2021/11/Pasted-image-20211105153730.png)\\n\\n> \\\"These regressions are telling us that **all variation in price-dividend ratios, all of that volatility, corresponds to variations in expected returns.** None of it corresponds to variation in expected dividend growth and none to rational bubbles or prices that are ever higher.\\\"\\n> ...\\n> \\\"**The valuation ratio translates one to one to expected returns** and doesn't forecast the cash flows or price change that we might have expected.\\\" â€” John Cochrane\\n\\nHigh valuation multiples correspond to lower returns, and vice versa. After periods of frothy valuations, returns end up lower than expected, bringing lofty valuation multiples back down to reality.\\n\\nDespite this sobering reality, **investors are extremely stubborn about future return expectations**, even in the face of rising prices. Undeterred by nose-bleed valuations, they continue to expect roughly the same return in all periods, leading actual returns (dotted green) to be much more volatile than expected returns (solid blue), which look nearly constant in comparison (right-hand chart):\\n\\n![Pasted-image-20211031153941](__GHOST_URL__/content/images/2021/11/Pasted-image-20211031153941.png)\\n\\nEquity investors always expect the same rate of return, regardless of how high or low valuations multiples are today, which doesn't make a ton of sense.\\n\\n### Waiting for ~~Godot~~ growth\\nThe data from the public markets is clear: **valuations rise, returns fall.**\\n\\nInvestors don't like to think this way, and thus they continue to expect the same return in all periods, leading to inevitable disappointment. Meanwhile, they justify their stubbornness about returns by convincing themselves that growth will save the day. It typically does not.\\n\\nThis data only covers public equity investors. It'd be fair to point out that growth among startups is much more variable than that for public companies, so much so that variation in startup growth could explain much more valuation variation.\\n\\nThat said, I find it hard to believe the future for startups could brighten so dramatically, practically overnight:\\n\\n![Pasted-image-20211013191138](__GHOST_URL__/content/images/2021/11/Pasted-image-20211013191138.png)\\n\\nIf anything, the high variability of startup growth may be a cognitive trap, seducing us to think that herculean growth alone can shoulder weighty valuations.\\n\\nI think it's past time we in the venture world get serious about the valuation craze. Do we really think the future is so much brighter? Are we merely accepting lower future returns, and if so, do our LPs know this? Is it all just a bubble?\\n\\nInvestors rely too much on growth to justify current valuations and underestimate the risk that higher multiples portend poor returns. Investors like to think companies will grow into their valuations, but more often than not, the stock simply underperforms.\\n\\nThe burden is on venture investors to prove there's something special about the asset class that will help it escape the fateful relationship between valuations and returns we see in public equities.\\n\\nUntil then, growth is just a cop out.\"}],[\"embed\",{\"url\":\"https://twitter.com/whoisnnamdi/status/1458872942960398346\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">1/ How investors justify high valuation multiples: &quot;they will grow into their valuation&quot;<br><br>Pay it, and growth will come<br><br>This rarely happens<br><br>Companies don&#39;t catch up to their valuations; their valuations catch up to *them* ðŸ¤¯ <a href=\\\"https://t.co/PRbaj8xskc\\\">pic.twitter.com/PRbaj8xskc</a></p>&mdash; Nnamdi Iregbulem (@whoisnnamdi) <a href=\\\"https://twitter.com/whoisnnamdi/status/1458872942960398346?ref_src=twsrc%5Etfw\\\">November 11, 2021</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\",\"metadata\":{\"url\":\"https://twitter.com/whoisnnamdi/status/1458872942960398346\",\"author_name\":\"Nnamdi Iregbulem\",\"author_url\":\"https://twitter.com/whoisnnamdi\",\"width\":550,\"height\":null,\"cache_age\":\"3153600000\",\"provider_name\":\"Twitter\",\"provider_url\":\"http://www.twitter.com/\",\"version\":\"1.0\"}}],[\"markdown\",{\"markdown\":\"<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: Companies Rarely Grow Into Their Valuations\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>Investors often justify high valuation multiples with the claim that the companies &quot;will grow into their valuations.&quot;</p>\n<p>It turns out <strong>this rarely happens</strong>.</p>\n<p>Most often, companies don't grow fast enough to compensate for rising valuation multiples. Instead, high valuations today imply slower value appreciation in the future, i.e. lower returns.</p>\n<p>Thus, companies don't catch up to their valuations; <strong>their valuations catch up to <em>them</em>.</strong></p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Companies Rarely Grow Into Their Valuations\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h3 id=\"expanding-on-multiple-expansion\">Expanding on multiple expansion</h3>\n<p>Investors can justify rising <a href=\"https://en.wikipedia.org/wiki/Valuation_using_multiples\">valuation multiples</a> with a belief that:</p>\n<ul>\n<li>growth will be better than expected (&quot;they will grow into their valuation&quot;),</li>\n<li>returns will be lower than expected (the valuation will appreciate more slowly), or</li>\n<li>multiples will be even higher in the future (&quot;someone else will pay more for this thing&quot;)</li>\n</ul>\n<p>If growth accelerates, valuation multiples fall due to the denominator growing faster than the numerator (revenue or cash flow grows faster than valuation).</p>\n<p>On the other hand, if future returns decline, the numerator grows more slowly (valuations grow slower than revenue or cash flow), also causing multiples to fall. Either outcome leads to declining valuation multiples:</p>\n<p>$$\\frac{\\text{Valuation} \\uparrow}{\\text{Revenue or Cash Flow} \\uparrow \\uparrow \\uparrow} \\rightarrow \\text{Declining Valuation Multiples}$$</p>\n<p>Think of the &quot;multiples are higher today because multiples will be higher tomorrow&quot; justification as a sort of &quot;bubble mentality&quot; or &quot;<a href=\"https://en.wikipedia.org/wiki/Greater_fool_theory\">greater fools</a>&quot; explanation. Someone else will pay more for this later, so I'm OK paying more today. This of course can't go on for long: bubbles eventually pop; manias eventually subside. So, here too, multiples return to &quot;normal.&quot;</p>\n<p>These three explanations for valuation multiples are collectively called the  <a href=\"https://www.youtube.com/watch?v=CIMMkDWiqRE\">Campbell-Shiller Decomposition</a>, originally conceived in the late 1980s. It lets us cleanly account for changing valuation multiples with changing beliefs about growth, returns, and future multiples. We can even make an equation out of it (\\(\\Delta\\) = Change):<br>\n$$\\Delta \\text{Valuation Multiples Today} = \\Delta \\text{Future Growth} - \\Delta\\text{Future Returns} + \\Delta\\text{Future Valuation Multiples}$$</p>\n<p>Therefore, higher multiples today imply (1) faster growth in the future, (2) lower future returns, or (3) even higher multiples going forward.</p>\n<p>Importantly, this works for both forward and backward-looking analysis: changing <em>expectations</em> of future growth, returns, or multiples affect valuations today and changing valuation multiples today also <em>forecast</em> future growth, returns, and multiples. In other words, investors' <strong>subjective</strong> expectations about the future influence valuations today and those valuations also predict the <strong>objective</strong> future itself.</p>\n<p>Regardless of the specific cause, valuation multiples eventually <a href=\"https://www.investopedia.com/terms/m/meanreversion.asp\">mean-revert</a>; subjective expectations eventually collide with objective reality.</p>\n<h3 id=\"subjective-expectations\">Subjective expectations</h3>\n<p>Let's start with <em>subjective expectations</em>. When <a href=\"https://onlinelibrary.wiley.com/doi/10.1111/jofi.13016\">researchers</a> decompose variation in price-earnings (PE) ratios into changing expectations about cash flows, discount rates (e.g. expected returns), and future PE ratios using the Campbell-Shiller Decomposition, they find fluctuating cash flow expectations (CF in the table below) explain more than 90% of all movement in valuations ratios, while expected returns (DR) explain little:</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/11/Pasted-image-20211105145313.png\" alt=\"Pasted-image-20211105145313\" loading=\"lazy\"></p>\n<blockquote>\n<p>â€œIn the 2003 to 2015 sample, <strong>one-year subjective earnings growth expectations account for virtually all (94%) price-earnings ratio movements.</strong>â€<br>\n...<br>\nâ€œ<strong>high prices can largely be accounted for by high expectations for future cash flows.</strong> Cash flow growth expectations are volatile and significantly correlated with prices. In comparison, return expectations are much less volatile and positively correlate with prices, meaning that <strong>high prices cannot come from low discount rates</strong>â€ â€” <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3841696\">Subjective Cash Flow and Discount Rate Expectations</a></p>\n</blockquote>\n<p><a href=\"https://www.ssrn.com/abstract=3740792\">Another paper</a> breaks down the expected returns vs growth dynamic between different classes of market participants, finding that sell-side analysts, institutional investors, and corporate CFOs all use growth expectations to explain fluctuating valuations (\\(g_t\\) in the table below) rather than expected returns (\\(\\mu_t\\)):</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/11/Pasted-image-20211105145501.png\" alt=\"Pasted-image-20211105145501\" loading=\"lazy\"></p>\n<blockquote>\n<p>â€œ<strong>both Wall Street and Main Street believe... the expected cash flow process is the main economic force driving asset price variations</strong>â€<br>\n...<br>\nâ€œ<strong>cash flow expectations alone explain 99% of the price-dividend ratio variation</strong>, while return expectations only explain about 10%.â€ â€” <a href=\"https://www.ssrn.com/abstract=3740792\">Subjective Return Expectations</a></p>\n</blockquote>\n<p>Investors see valuations move and ascribe these gyrations to changing expectations for future business growth. But does the growth ever materialize?</p>\n<h3 id=\"objective-reality\">Objective reality</h3>\n<p><strong>Not really:</strong></p>\n<blockquote>\n<p>â€œthe variance decomposition results reveal that <strong>all three types of investors seem to overestimate how much cash flow variation contributes to the variation in asset prices</strong> when compared to objective measures of return expectations, which show that <strong>discount rate variation should contribute the most to asset price variation</strong>â€ â€” <a href=\"https://www.ssrn.com/abstract=3740792\">Subjective Return Expectations</a></p>\n</blockquote>\n<p>Now we turn to <em>objective reality</em>. The chart below plots expected (solid blue) and realized (dotted green) 1-year earnings growth of the S&amp;P 500 over the last 40 years. Expected earnings growth consistently exceeds actual growth, implying investors tend to overestimate earnings growth. Notice as well how expected earnings growth tend to show &quot;upside volatility&quot;, whereas actual earnings show more downside volatility.</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/11/Pasted-image-20211031150624.png\" alt=\"Pasted-image-20211031150624\" loading=\"lazy\"></p>\n<blockquote>\n<p>â€œ<strong>Earnings growth expectations typically fail to predict the change in earnings during busts</strong>, but they do tend to predict recoveries and track future earnings growth reasonably well during normal times.â€ â€” <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3841696\">Subjective Cash Flow and Discount Rate Expectations</a></p>\n</blockquote>\n<p>Investors rarely predict poor earnings growth in advance. They often correctly predict strong earnings growth after recessions, but that's kind of cheating isn't it? Quick bounce-backs follow recessions almost universally.</p>\n<p>When financial researchers do look-backs, they find that <strong>high valuation multiples precede low returns</strong>. In fact, they literally <em>predict</em> lower returns. Per finance legend <a href=\"https://www.johnhcochrane.com/\">John Cochrane</a>'s <a href=\"https://www.youtube.com/watch?v=ZDsOiftolUI\">2011 Presidential Address at the American Finance Association</a> (apologies for the pixelated 360p screenshot, YouTube was less generous back then):</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/11/Pasted-image-20211105153730.png\" alt=\"Pasted-image-20211105153730\" loading=\"lazy\"></p>\n<blockquote>\n<p>&quot;These regressions are telling us that <strong>all variation in price-dividend ratios, all of that volatility, corresponds to variations in expected returns.</strong> None of it corresponds to variation in expected dividend growth and none to rational bubbles or prices that are ever higher.&quot;<br>\n...<br>\n&quot;<strong>The valuation ratio translates one to one to expected returns</strong> and doesn't forecast the cash flows or price change that we might have expected.&quot; â€” John Cochrane</p>\n</blockquote>\n<p>High valuation multiples correspond to lower returns, and vice versa. After periods of frothy valuations, returns end up lower than expected, bringing lofty valuation multiples back down to reality.</p>\n<p>Despite this sobering reality, <strong>investors are extremely stubborn about future return expectations</strong>, even in the face of rising prices. Undeterred by nose-bleed valuations, they continue to expect roughly the same return in all periods, leading actual returns (dotted green) to be much more volatile than expected returns (solid blue), which look nearly constant in comparison (right-hand chart):</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/11/Pasted-image-20211031153941.png\" alt=\"Pasted-image-20211031153941\" loading=\"lazy\"></p>\n<p>Equity investors always expect the same rate of return, regardless of how high or low valuations multiples are today, which doesn't make a ton of sense.</p>\n<h3 id=\"waiting-for-godot-growth\">Waiting for <s>Godot</s> growth</h3>\n<p>The data from the public markets is clear: <strong>valuations rise, returns fall.</strong></p>\n<p>Investors don't like to think this way, and thus they continue to expect the same return in all periods, leading to inevitable disappointment. Meanwhile, they justify their stubbornness about returns by convincing themselves that growth will save the day. It typically does not.</p>\n<p>This data only covers public equity investors. It'd be fair to point out that growth among startups is much more variable than that for public companies, so much so that variation in startup growth could explain much more valuation variation.</p>\n<p>That said, I find it hard to believe the future for startups could brighten so dramatically, practically overnight:</p>\n<p><img src=\"__GHOST_URL__/content/images/2021/11/Pasted-image-20211013191138.png\" alt=\"Pasted-image-20211013191138\" loading=\"lazy\"></p>\n<p>If anything, the high variability of startup growth may be a cognitive trap, seducing us to think that herculean growth alone can shoulder weighty valuations.</p>\n<p>I think it's past time we in the venture world get serious about the valuation craze. Do we really think the future is so much brighter? Are we merely accepting lower future returns, and if so, do our LPs know this? Is it all just a bubble?</p>\n<p>Investors rely too much on growth to justify current valuations and underestimate the risk that higher multiples portend poor returns. Investors like to think companies will grow into their valuations, but more often than not, the stock simply underperforms.</p>\n<p>The burden is on venture investors to prove there's something special about the asset class that will help it escape the fateful relationship between valuations and returns we see in public equities.</p>\n<p>Until then, growth is just a cop out.</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">1/ How investors justify high valuation multiples: &quot;they will grow into their valuation&quot;<br><br>Pay it, and growth will come<br><br>This rarely happens<br><br>Companies don&#39;t catch up to their valuations; their valuations catch up to *them* ðŸ¤¯ <a href=\"https://t.co/PRbaj8xskc\">pic.twitter.com/PRbaj8xskc</a></p>&mdash; Nnamdi Iregbulem (@whoisnnamdi) <a href=\"https://twitter.com/whoisnnamdi/status/1458872942960398346?ref_src=twsrc%5Etfw\">November 11, 2021</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><!--kg-card-begin: markdown--><section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: Companies Rarely Grow Into Their Valuations\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"618a976bfec7d1542d1d29ae","plaintext":"Investors often justify high valuation multiples with the claim that the\ncompanies \"will grow into their valuations.\"\n\nIt turns out this rarely happens.\n\nMost often, companies don't grow fast enough to compensate for rising valuation\nmultiples. Instead, high valuations today imply slower value appreciation in the\nfuture, i.e. lower returns.\n\nThus, companies don't catch up to their valuations; their valuations catch up to \nthem.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Expanding on multiple expansion\nInvestors can justify rising valuation multiples\n[https://en.wikipedia.org/wiki/Valuation_using_multiples] with a belief that:\n\n * growth will be better than expected (\"they will grow into their valuation\"),\n * returns will be lower than expected (the valuation will appreciate more\n   slowly), or\n * multiples will be even higher in the future (\"someone else will pay more for\n   this thing\")\n\nIf growth accelerates, valuation multiples fall due to the denominator growing\nfaster than the numerator (revenue or cash flow grows faster than valuation).\n\nOn the other hand, if future returns decline, the numerator grows more slowly\n(valuations grow slower than revenue or cash flow), also causing multiples to\nfall. Either outcome leads to declining valuation multiples:\n\n$$\\frac{\\text{Valuation} \\uparrow}{\\text{Revenue or Cash Flow} \\uparrow \\uparrow\n\\uparrow} \\rightarrow \\text{Declining Valuation Multiples}$$\n\nThink of the \"multiples are higher today because multiples will be higher\ntomorrow\" justification as a sort of \"bubble mentality\" or \"greater fools\n[https://en.wikipedia.org/wiki/Greater_fool_theory]\" explanation. Someone else\nwill pay more for this later, so I'm OK paying more today. This of course can't\ngo on for long: bubbles eventually pop; manias eventually subside. So, here too,\nmultiples return to \"normal.\"\n\nThese three explanations for valuation multiples are collectively called the \nCampbell-Shiller Decomposition [https://www.youtube.com/watch?v=CIMMkDWiqRE],\noriginally conceived in the late 1980s. It lets us cleanly account for changing\nvaluation multiples with changing beliefs about growth, returns, and future\nmultiples. We can even make an equation out of it (\\(\\Delta\\) = Change):\n$$\\Delta \\text{Valuation Multiples Today} = \\Delta \\text{Future Growth} -\n\\Delta\\text{Future Returns} + \\Delta\\text{Future Valuation Multiples}$$\n\nTherefore, higher multiples today imply (1) faster growth in the future, (2)\nlower future returns, or (3) even higher multiples going forward.\n\nImportantly, this works for both forward and backward-looking analysis: changing \nexpectations of future growth, returns, or multiples affect valuations today and\nchanging valuation multiples today also forecast future growth, returns, and\nmultiples. In other words, investors' subjective expectations about the future\ninfluence valuations today and those valuations also predict the objective \nfuture itself.\n\nRegardless of the specific cause, valuation multiples eventually mean-revert\n[https://www.investopedia.com/terms/m/meanreversion.asp]; subjective\nexpectations eventually collide with objective reality.\n\nSubjective expectations\nLet's start with subjective expectations. When researchers\n[https://onlinelibrary.wiley.com/doi/10.1111/jofi.13016] decompose variation in\nprice-earnings (PE) ratios into changing expectations about cash flows, discount\nrates (e.g. expected returns), and future PE ratios using the Campbell-Shiller\nDecomposition, they find fluctuating cash flow expectations (CF in the table\nbelow) explain more than 90% of all movement in valuations ratios, while\nexpected returns (DR) explain little:\n\n\n\n> â€œIn the 2003 to 2015 sample, one-year subjective earnings growth expectations\naccount for virtually all (94%) price-earnings ratio movements.â€\n...\nâ€œhigh prices can largely be accounted for by high expectations for future cash\nflows. Cash flow growth expectations are volatile and significantly correlated\nwith prices. In comparison, return expectations are much less volatile and\npositively correlate with prices, meaning that high prices cannot come from low\ndiscount ratesâ€ â€” Subjective Cash Flow and Discount Rate Expectations\n[https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3841696]\n\n\nAnother paper [https://www.ssrn.com/abstract=3740792] breaks down the expected\nreturns vs growth dynamic between different classes of market participants,\nfinding that sell-side analysts, institutional investors, and corporate CFOs all\nuse growth expectations to explain fluctuating valuations (\\(g_t\\) in the table\nbelow) rather than expected returns (\\(\\mu_t\\)):\n\n\n\n> â€œboth Wall Street and Main Street believe... the expected cash flow process is\nthe main economic force driving asset price variationsâ€\n...\nâ€œcash flow expectations alone explain 99% of the price-dividend ratio variation,\nwhile return expectations only explain about 10%.â€ â€” Subjective Return\nExpectations [https://www.ssrn.com/abstract=3740792]\n\n\nInvestors see valuations move and ascribe these gyrations to changing\nexpectations for future business growth. But does the growth ever materialize?\n\nObjective reality\nNot really:\n\n> â€œthe variance decomposition results reveal that all three types of investors\nseem to overestimate how much cash flow variation contributes to the variation\nin asset prices when compared to objective measures of return expectations,\nwhich show that discount rate variation should contribute the most to asset\nprice variationâ€ â€” Subjective Return Expectations\n[https://www.ssrn.com/abstract=3740792]\n\n\nNow we turn to objective reality. The chart below plots expected (solid blue)\nand realized (dotted green) 1-year earnings growth of the S&P 500 over the last\n40 years. Expected earnings growth consistently exceeds actual growth, implying\ninvestors tend to overestimate earnings growth. Notice as well how expected\nearnings growth tend to show \"upside volatility\", whereas actual earnings show\nmore downside volatility.\n\n\n\n> â€œEarnings growth expectations typically fail to predict the change in earnings\nduring busts, but they do tend to predict recoveries and track future earnings\ngrowth reasonably well during normal times.â€ â€” Subjective Cash Flow and\nDiscount\nRate Expectations [https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3841696]\n\n\nInvestors rarely predict poor earnings growth in advance. They often correctly\npredict strong earnings growth after recessions, but that's kind of cheating\nisn't it? Quick bounce-backs follow recessions almost universally.\n\nWhen financial researchers do look-backs, they find that high valuation\nmultiples precede low returns. In fact, they literally predict lower returns.\nPer finance legend John Cochrane [https://www.johnhcochrane.com/]'s 2011\nPresidential Address at the American Finance Association\n[https://www.youtube.com/watch?v=ZDsOiftolUI] (apologies for the pixelated 360p\nscreenshot, YouTube was less generous back then):\n\n\n\n> \"These regressions are telling us that all variation in price-dividend ratios,\nall of that volatility, corresponds to variations in expected returns. None of\nit corresponds to variation in expected dividend growth and none to rational\nbubbles or prices that are ever higher.\"\n...\n\"The valuation ratio translates one to one to expected returns and doesn't\nforecast the cash flows or price change that we might have expected.\" â€” John\nCochrane\n\n\nHigh valuation multiples correspond to lower returns, and vice versa. After\nperiods of frothy valuations, returns end up lower than expected, bringing lofty\nvaluation multiples back down to reality.\n\nDespite this sobering reality, investors are extremely stubborn about future\nreturn expectations, even in the face of rising prices. Undeterred by nose-bleed\nvaluations, they continue to expect roughly the same return in all periods,\nleading actual returns (dotted green) to be much more volatile than expected\nreturns (solid blue), which look nearly constant in comparison (right-hand\nchart):\n\n\n\nEquity investors always expect the same rate of return, regardless of how high\nor low valuations multiples are today, which doesn't make a ton of sense.\n\nWaiting for Godot growth\nThe data from the public markets is clear: valuations rise, returns fall.\n\nInvestors don't like to think this way, and thus they continue to expect the\nsame return in all periods, leading to inevitable disappointment. Meanwhile,\nthey justify their stubbornness about returns by convincing themselves that\ngrowth will save the day. It typically does not.\n\nThis data only covers public equity investors. It'd be fair to point out that\ngrowth among startups is much more variable than that for public companies, so\nmuch so that variation in startup growth could explain much more valuation\nvariation.\n\nThat said, I find it hard to believe the future for startups could brighten so\ndramatically, practically overnight:\n\n\n\nIf anything, the high variability of startup growth may be a cognitive trap,\nseducing us to think that herculean growth alone can shoulder weighty\nvaluations.\n\nI think it's past time we in the venture world get serious about the valuation\ncraze. Do we really think the future is so much brighter? Are we merely\naccepting lower future returns, and if so, do our LPs know this? Is it all just\na bubble?\n\nInvestors rely too much on growth to justify current valuations and\nunderestimate the risk that higher multiples portend poor returns. Investors\nlike to think companies will grow into their valuations, but more often than\nnot, the stock simply underperforms.\n\nThe burden is on venture investors to prove there's something special about the\nasset class that will help it escape the fateful relationship between valuations\nand returns we see in public equities.\n\nUntil then, growth is just a cop out.\n\n> 1/ How investors justify high valuation multiples: \"they will grow into their\nvaluation\"\n\nPay it, and growth will come\n\nThis rarely happens\n\nCompanies don't catch up to their valuations; their valuations catch up to\n*them* ðŸ¤¯ pic.twitter.com/PRbaj8xskc [https://t.co/PRbaj8xskc]\n\nâ€” Nnamdi Iregbulem (@whoisnnamdi) November 11, 2021\n[https://twitter.com/whoisnnamdi/status/1458872942960398346?ref_src=twsrc%5Etfw]\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2021/11/header-2.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2021-11-09T15:44:43.000Z","updated_at":"2022-05-29T18:57:54.000Z","published_at":"2021-11-09T16:28:00.000Z","custom_excerpt":"Companies don't catch up to their valuations; their valuations catch up to them.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"6192052ffec7d1542d1d2a17","uuid":"3f2800bc-cd8c-494c-a7c4-12e97795600b","title":"WebAssembly-ing the Pieces: Vectorizedâ€™s Data Policy Engine","slug":"data-policy-engine","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}]],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/classical_scrubbing_vectorized_redpanda_graph.png\",\"width\":1600,\"height\":854}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/galaxy.png\",\"width\":1752,\"height\":697}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/Uppercase_filter.png\",\"width\":4714,\"height\":2432}],[\"code\",{\"code\":\"import { InlineTransform } from â€œ@vectorizedio/InlineTransformâ€;\\nconst transform = new InlineTransform();\\ntransform.topics([{â€œinputâ€: â€œlowercaseâ€, â€œoutputâ€: â€uppercaseâ€}]):\\nâ€¦\\nconst uppercase = async (record) => {\\n    const newRecord = {\\n        ...record,\\n        value: record.value.map((char) => {\\n            return char.toUpperCase();\\n        }),\\n    };\\n    return newRecord;\\n}\\n\",\"language\":\"javascript\"}],[\"code\",{\"code\":\"> bin/kafka-topics.sh \\\\\\nâ€” alter â€” topic my_topic_name \\\\\\nâ€” config x-data-policy={â€¦}\\n(redpanda has a tool called `rpk` that is similar to kafka-topics.sh)\",\"language\":\"bash\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/11/Uppercase_filter_2.png\",\"width\":4714,\"height\":2600}],[\"embed\",{\"url\":\"https://twitter.com/emaxerrno/status/1438214386124873728\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">I&#39;m about to show a sneak preview of on the most anticipated features by the community here, as a sponsored talk. <br><br>tl;dr - take an *unmodified spark app* and use a push-down predicate in <a href=\\\"https://twitter.com/hashtag/wasm?src=hash&amp;ref_src=twsrc%5Etfw\\\">#wasm</a> ðŸ¤¯ðŸ¤¯ðŸ¤¯<br><br>Demo at the end. <br> <a href=\\\"https://twitter.com/hashtag/redpanda?src=hash&amp;ref_src=twsrc%5Etfw\\\">#redpanda</a> <a href=\\\"https://twitter.com/hashtag/kafka?src=hash&amp;ref_src=twsrc%5Etfw\\\">#kafka</a> <a href=\\\"https://twitter.com/hashtag/KafkaSummit?src=hash&amp;ref_src=twsrc%5Etfw\\\">#KafkaSummit</a> <a href=\\\"https://t.co/NiL2SNHrvq\\\">https://t.co/NiL2SNHrvq</a></p>&mdash; ðŸ•ºðŸ’ƒðŸ¤Ÿ Alexander Gallego (@emaxerrno) <a href=\\\"https://twitter.com/emaxerrno/status/1438214386124873728?ref_src=twsrc%5Etfw\\\">September 15, 2021</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\",\"metadata\":{\"url\":\"https://twitter.com/emaxerrno/status/1438214386124873728\",\"author_name\":\"ðŸ•ºðŸ’ƒðŸ¤Ÿ Alexander Gallego\",\"author_url\":\"https://twitter.com/emaxerrno\",\"width\":550,\"height\":null,\"cache_age\":\"3153600000\",\"provider_name\":\"Twitter\",\"provider_url\":\"http://www.twitter.com/\",\"version\":\"1.0\"}}]],\"markups\":[[\"a\",[\"href\",\"https://whoisnnamdi.com/why-developers-love-redpanda/\"]],[\"a\",[\"href\",\"https://vectorized.io/\",\"rel\",\"noopener ugc nofollow\"]],[\"a\",[\"href\",\"https://github.com/vectorizedio/redpanda\",\"rel\",\"noopener ugc nofollow\"]],[\"a\",[\"href\",\"https://webassembly.org/\",\"rel\",\"noopener ugc nofollow\"]],[\"em\"],[\"a\",[\"href\",\"https://lsvp.com/\",\"rel\",\"noopener ugc nofollow\"]],[\"a\",[\"href\",\"https://vectorized.io/blog/wasm-architecture/\",\"rel\",\"noopener ugc nofollow\"]],[\"a\",[\"href\",\"https://v8.dev/\",\"rel\",\"noopener ugc nofollow\"]],[\"a\",[\"href\",\"https://medium.com/microsoftazure/data-at-scale-learn-how-predicate-pushdown-will-save-you-money-7063b80878d7\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://v8docs.nodesource.com/node-0.8/df/d69/classv8_1_1_context.html\",\"rel\",\"noopener ugc nofollow\"]],[\"a\",[\"href\",\"https://medium.com/lightspeed-venture-partners/why-developers-love-redpanda-30bf2f3b8231\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://twitter.com/emaxerrno/\",\"rel\",\"noopener ugc nofollow\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"In \"],[0,[0],1,\"Why Developers Love Redpanda\"],[0,[],0,\", I talked about the exciting developments around WebAssembly and how \"],[0,[1],1,\"Vectorized\"],[0,[],0,\" is leveraging the technology to build itâ€™s Intelligent Data API, \"],[0,[2],1,\"Redpanda\"],[0,[],0,\":\"]]],[1,\"blockquote\",[[0,[3,4],2,\"WebAssembly\"],[0,[4],1,\", or WASM, is one of the most exciting up-and-coming technologies in software development today. WebAssembly lets developers write code in any major language, translate that code to the compact WASM format, and run it on the web with the high performance of a native application.\"],[1,[],0,0],[1,[],0,1],[0,[4],1,\"Redpanda is one of the first infrastructure technologies to take advantage of WASM, enabling developers to â€œwrite and edit code in their favorite programming language to perform one-shot transformations, like guaranteeing GDPR compliance by removing personal information or to provide filtering and simple aggregation functions.â€\"],[1,[],0,2],[1,[],0,3],[0,[4],1,\"JavaScript, Python, Rust, Go â€” anything that compiles to WebAssembly (basically everything at this point) can be used to transform data. Again the key is accessibility â€” inline WASM transforms in Redpanda represent just that.\"]]],[1,\"p\",[[0,[],0,\"Ever since partnering with Vectorized, we at \"],[0,[5],1,\"Lightspeed\"],[0,[],0,\" knew that Redpanda was much more than a streaming engine. Redpanda truly is an Intelligent Data API, and itâ€™s \"],[0,[6],1,\"Data Policy Engine\"],[0,[],0,\" unlocks one more piece of that puzzle.\"]]],[1,\"p\",[[0,[],0,\"Today, I want to expand on this and talk a bit more about the exciting developments coming down the pipe at Vectorized.\"]]],[1,\"p\",[[0,[],0,\"Hereâ€™s the big idea: rather than ship data to code, which is expensive and latency-prone, why not ship code to the data?\"]]],[1,\"h2\",[[0,[],0,\"The keystone problem in streaming\"]]],[1,\"p\",[[0,[],0,\"Streaming has seen a ton of innovation over the last few years, but one area that remains painful today is stream processing. While a full explanation of these difficulties probably warrants its own article, Iâ€™ll cover the most salient points here.\"]]],[1,\"p\",[[0,[],0,\"The great thing about streaming is the immutable message queue. The not so good thing about streaming is, also, the immutable message queue.\"]]],[1,\"p\",[[0,[],0,\"What do I mean by this? The immutability of the message queue is great because it guarantees that data produced to the topic can be replicated one-to-one by simply consuming the whole queue from the start. This lets you effectively â€œreplayâ€ data like a VHS tape and also gives you built-in auditing, since you know the ordering hasnâ€™t changed. It also decouples producers of data from the consumers of that data, letting the two operate independently without significant coordination work.\"]]],[1,\"p\",[[0,[],0,\"However, there are some problems. Immutability not only means you *can* consume the data in the same order it was produced â€” it means you must (at least as implemented today in the Kafka-API world). Further, immutability means one must consume at least as much as was produced, often many times as much, leading to additional costs in the form of network traffic and other resources. These issues can be avoided to some extent by being very diligent in setting up your architecture \"],[0,[4,4],2,\"a priori\"],[0,[],0,\", careful in segregating your use cases, etc., but few do this in practice.\"]]],[1,\"p\",[[0,[],0,\"In summary, the things that make streaming great also make stream processing complex and difficult.\"]]],[1,\"h2\",[[0,[],0,\"Shipping code to data\"]]],[1,\"p\",[[0,[],0,\"Hereâ€™s where WebAssembly comes in. WebAssembly lets us do a small amount of extra compute work to save us a ton of cost in the form of network utilization and latency. Mission critical streams can stay as large as they want without saturating the network.\"]]],[1,\"p\",[[0,[],0,\"Weâ€™re excited about the power and promise of WebAssembly, and we think it has the potential to do for server-side compute today what JavaScript did for the web in the late 90s. Like JavaScript enabled the shipping of code to the userâ€™s client, WebAssembly lets engineers ship code to the storage engine.\"]]],[1,\"p\",[[0,[],0,\"Hereâ€™s how.\"]]],[1,\"p\",[[0,[],0,\"The Redpanda Data Policies Engine simultaneously extends the Kafka API and what you can do with server-side compute. Itâ€™s a server-side compute API for Redpanda thatâ€™s compatible with all existing Kafka tooling and the broader ecosystem, including Spark Streaming, Kafka Streams, Flink, and more.\"]]],[1,\"p\",[[0,[],0,\"With Data Policies, all your favorite tools can benefit from server-side WebAssembly filters, allowing for easy and simple data scrubbing, cleaning, filtering, normalization and more. As a runtime, WebAssembly allows code to execute inside Redpanda, allowing code to be injected into an active cluster at runtime.\"]]],[10,0],[1,\"p\",[[0,[],0,\"Redpanda Transforms enable extremely low-latency transformations by avoiding the â€œdata ping-pongâ€ that happens in many systems and stream processors today, where data gets sent back and forth between storage and compute, even for very minor operations. Further, Redpanda Transform is built on the \"],[0,[7],1,\"V8 engine\"],[0,[],0,\", the high-performance JavaScript and WebAssembly engine that also powers Chrome and NodeJS.\"]]],[1,\"p\",[[0,[],0,\"Transforms in Redpanda are effectively a stateless \"],[0,[8],1,\"predicate pushdown\"],[0,[],0,\". In simple terms, that means performance is massively improved by â€œpushing downâ€ code to the data, only touching the relevant data (and ignoring the rest), cutting down on wasteful network traffic, I/O, and latency.\"]]],[10,1],[1,\"p\",[[0,[],0,\"Redpanda Transforms are also completely auditable. The controller can report on which specific piece of code is touching which specific piece of data, on which machines, at which topic offsets.\"]]],[1,\"h2\",[[0,[],0,\"As easy as one, two, THREE\"]]],[10,2],[1,\"p\",[[0,[],0,\"Few things are simple in data engineering, but, as usual, Vectorized is changing the game. For all the cool things happening under the hood, getting started with Data Policies is shockingly easy.\"]]],[1,\"p\",[[0,[],0,\"First, write your policy/transform in a WebAssembly compatible language (read: everything). To make this even easier, Redpanda provides native plugins for inline transforms. In the end, you end up with something that looks like fairly standard (JavaScript in this case) code. Hereâ€™s a simple proof of concept: transforming all lowercase alphabetic characters in a record to uppercase:\"]]],[10,3],[1,\"p\",[[0,[],0,\"Next, apply the policy to a Kafka topic. Again this is incredibly straightforward. All it takes is a single terminal command:\"]]],[10,4],[1,\"p\",[[0,[],0,\"Now, Redpanda handles the rest.\"]]],[3,\"ul\",[[[0,[],0,\"Upon a TCP connection to consume from the topic, Redpanda initiates a \"],[0,[9],1,\"V8 context\"]],[[0,[],0,\"Bytes are read from disk\"]],[[0,[],0,\"Payload is transformed and re-checksumed (ensures Kafka protocol remains unchanged)\"]],[[0,[],0,\"Redpanda returns the transformed record\"]]]],[10,5],[1,\"p\",[[0,[],0,\"Pretty slick.\"]]],[1,\"h2\",[[0,[],0,\"Simplicity is the ultimate sophistication\"]]],[1,\"p\",[[0,[],0,\"Iâ€™ve \"],[0,[10],1,\"talked before\"],[0,[],0,\" about Vectorizedâ€™s deep understanding and appreciation for the power of simplicity:\"]]],[1,\"blockquote\",[[0,[4,4,4],3,\"Redpanda abstracts away the complexity that often prevents the typical developer from adopting real-time streaming.\"]]],[1,\"p\",[[0,[],0,\"The Data Policy Engine continues that tradition.\"]]],[1,\"p\",[[0,[],0,\"This was just an example use case, but they only get more interesting from here. GDPR compliance via masking rules. Encryption at-rest, on-disk. All at runtime, with near-native performance.\"]]],[1,\"p\",[[0,[],0,\"Curious to learn more after this quick introduction? \"],[0,[11],1,\"Alex Gallego\"],[0,[],0,\", founder of Vectorized, gave a sneak preview of the Data Policy Engine at this yearâ€™s Kafka Summit, which you can check out here:\"]]],[10,6],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<p>In <a href=\"https://whoisnnamdi.com/why-developers-love-redpanda/\">Why Developers Love Redpanda</a>, I talked about the exciting developments around WebAssembly and how <a href=\"https://vectorized.io/\" rel=\"noopener ugc nofollow\">Vectorized</a> is leveraging the technology to build itâ€™s Intelligent Data API, <a href=\"https://github.com/vectorizedio/redpanda\" rel=\"noopener ugc nofollow\">Redpanda</a>:</p><blockquote><a href=\"https://webassembly.org/\" rel=\"noopener ugc nofollow\"><em>WebAssembly</em></a><em>, or WASM, is one of the most exciting up-and-coming technologies in software development today. WebAssembly lets developers write code in any major language, translate that code to the compact WASM format, and run it on the web with the high performance of a native application.</em><br><br><em>Redpanda is one of the first infrastructure technologies to take advantage of WASM, enabling developers to â€œwrite and edit code in their favorite programming language to perform one-shot transformations, like guaranteeing GDPR compliance by removing personal information or to provide filtering and simple aggregation functions.â€</em><br><br><em>JavaScript, Python, Rust, Go â€” anything that compiles to WebAssembly (basically everything at this point) can be used to transform data. Again the key is accessibility â€” inline WASM transforms in Redpanda represent just that.</em></blockquote><p>Ever since partnering with Vectorized, we at <a href=\"https://lsvp.com/\" rel=\"noopener ugc nofollow\">Lightspeed</a> knew that Redpanda was much more than a streaming engine. Redpanda truly is an Intelligent Data API, and itâ€™s <a href=\"https://vectorized.io/blog/wasm-architecture/\" rel=\"noopener ugc nofollow\">Data Policy Engine</a> unlocks one more piece of that puzzle.</p><p>Today, I want to expand on this and talk a bit more about the exciting developments coming down the pipe at Vectorized.</p><p>Hereâ€™s the big idea: rather than ship data to code, which is expensive and latency-prone, why not ship code to the data?</p><h2 id=\"the-keystone-problem-in-streaming\">The keystone problem in streaming</h2><p>Streaming has seen a ton of innovation over the last few years, but one area that remains painful today is stream processing. While a full explanation of these difficulties probably warrants its own article, Iâ€™ll cover the most salient points here.</p><p>The great thing about streaming is the immutable message queue. The not so good thing about streaming is, also, the immutable message queue.</p><p>What do I mean by this? The immutability of the message queue is great because it guarantees that data produced to the topic can be replicated one-to-one by simply consuming the whole queue from the start. This lets you effectively â€œreplayâ€ data like a VHS tape and also gives you built-in auditing, since you know the ordering hasnâ€™t changed. It also decouples producers of data from the consumers of that data, letting the two operate independently without significant coordination work.</p><p>However, there are some problems. Immutability not only means you *can* consume the data in the same order it was produced â€” it means you must (at least as implemented today in the Kafka-API world). Further, immutability means one must consume at least as much as was produced, often many times as much, leading to additional costs in the form of network traffic and other resources. These issues can be avoided to some extent by being very diligent in setting up your architecture <em><em>a priori</em></em>, careful in segregating your use cases, etc., but few do this in practice.</p><p>In summary, the things that make streaming great also make stream processing complex and difficult.</p><h2 id=\"shipping-code-to-data\">Shipping code to data</h2><p>Hereâ€™s where WebAssembly comes in. WebAssembly lets us do a small amount of extra compute work to save us a ton of cost in the form of network utilization and latency. Mission critical streams can stay as large as they want without saturating the network.</p><p>Weâ€™re excited about the power and promise of WebAssembly, and we think it has the potential to do for server-side compute today what JavaScript did for the web in the late 90s. Like JavaScript enabled the shipping of code to the userâ€™s client, WebAssembly lets engineers ship code to the storage engine.</p><p>Hereâ€™s how.</p><p>The Redpanda Data Policies Engine simultaneously extends the Kafka API and what you can do with server-side compute. Itâ€™s a server-side compute API for Redpanda thatâ€™s compatible with all existing Kafka tooling and the broader ecosystem, including Spark Streaming, Kafka Streams, Flink, and more.</p><p>With Data Policies, all your favorite tools can benefit from server-side WebAssembly filters, allowing for easy and simple data scrubbing, cleaning, filtering, normalization and more. As a runtime, WebAssembly allows code to execute inside Redpanda, allowing code to be injected into an active cluster at runtime.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/classical_scrubbing_vectorized_redpanda_graph.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1600\" height=\"854\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/classical_scrubbing_vectorized_redpanda_graph.png 600w, __GHOST_URL__/content/images/size/w1000/2021/11/classical_scrubbing_vectorized_redpanda_graph.png 1000w, __GHOST_URL__/content/images/2021/11/classical_scrubbing_vectorized_redpanda_graph.png 1600w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Redpanda Transforms enable extremely low-latency transformations by avoiding the â€œdata ping-pongâ€ that happens in many systems and stream processors today, where data gets sent back and forth between storage and compute, even for very minor operations. Further, Redpanda Transform is built on the <a href=\"https://v8.dev/\" rel=\"noopener ugc nofollow\">V8 engine</a>, the high-performance JavaScript and WebAssembly engine that also powers Chrome and NodeJS.</p><p>Transforms in Redpanda are effectively a stateless <a href=\"https://medium.com/microsoftazure/data-at-scale-learn-how-predicate-pushdown-will-save-you-money-7063b80878d7\" rel=\"noopener\">predicate pushdown</a>. In simple terms, that means performance is massively improved by â€œpushing downâ€ code to the data, only touching the relevant data (and ignoring the rest), cutting down on wasteful network traffic, I/O, and latency.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/galaxy.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1752\" height=\"697\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/galaxy.png 600w, __GHOST_URL__/content/images/size/w1000/2021/11/galaxy.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/11/galaxy.png 1600w, __GHOST_URL__/content/images/2021/11/galaxy.png 1752w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Redpanda Transforms are also completely auditable. The controller can report on which specific piece of code is touching which specific piece of data, on which machines, at which topic offsets.</p><h2 id=\"as-easy-as-one-two-three\">As easy as one, two, THREE</h2><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/Uppercase_filter.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1032\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/Uppercase_filter.png 600w, __GHOST_URL__/content/images/size/w1000/2021/11/Uppercase_filter.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/11/Uppercase_filter.png 1600w, __GHOST_URL__/content/images/size/w2400/2021/11/Uppercase_filter.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Few things are simple in data engineering, but, as usual, Vectorized is changing the game. For all the cool things happening under the hood, getting started with Data Policies is shockingly easy.</p><p>First, write your policy/transform in a WebAssembly compatible language (read: everything). To make this even easier, Redpanda provides native plugins for inline transforms. In the end, you end up with something that looks like fairly standard (JavaScript in this case) code. Hereâ€™s a simple proof of concept: transforming all lowercase alphabetic characters in a record to uppercase:</p><pre><code class=\"language-javascript\">import { InlineTransform } from â€œ@vectorizedio/InlineTransformâ€;\nconst transform = new InlineTransform();\ntransform.topics([{â€œinputâ€: â€œlowercaseâ€, â€œoutputâ€: â€uppercaseâ€}]):\nâ€¦\nconst uppercase = async (record) =&gt; {\n    const newRecord = {\n        ...record,\n        value: record.value.map((char) =&gt; {\n            return char.toUpperCase();\n        }),\n    };\n    return newRecord;\n}\n</code></pre><p>Next, apply the policy to a Kafka topic. Again this is incredibly straightforward. All it takes is a single terminal command:</p><pre><code class=\"language-bash\">&gt; bin/kafka-topics.sh \\\nâ€” alter â€” topic my_topic_name \\\nâ€” config x-data-policy={â€¦}\n(redpanda has a tool called `rpk` that is similar to kafka-topics.sh)</code></pre><p>Now, Redpanda handles the rest.</p><ul><li>Upon a TCP connection to consume from the topic, Redpanda initiates a <a href=\"https://v8docs.nodesource.com/node-0.8/df/d69/classv8_1_1_context.html\" rel=\"noopener ugc nofollow\">V8 context</a></li><li>Bytes are read from disk</li><li>Payload is transformed and re-checksumed (ensures Kafka protocol remains unchanged)</li><li>Redpanda returns the transformed record</li></ul><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/11/Uppercase_filter_2.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1103\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/11/Uppercase_filter_2.png 600w, __GHOST_URL__/content/images/size/w1000/2021/11/Uppercase_filter_2.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/11/Uppercase_filter_2.png 1600w, __GHOST_URL__/content/images/size/w2400/2021/11/Uppercase_filter_2.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Pretty slick.</p><h2 id=\"simplicity-is-the-ultimate-sophistication\">Simplicity is the ultimate sophistication</h2><p>Iâ€™ve <a href=\"https://medium.com/lightspeed-venture-partners/why-developers-love-redpanda-30bf2f3b8231\" rel=\"noopener\">talked before</a> about Vectorizedâ€™s deep understanding and appreciation for the power of simplicity:</p><blockquote><em><em><em>Redpanda abstracts away the complexity that often prevents the typical developer from adopting real-time streaming.</em></em></em></blockquote><p>The Data Policy Engine continues that tradition.</p><p>This was just an example use case, but they only get more interesting from here. GDPR compliance via masking rules. Encryption at-rest, on-disk. All at runtime, with near-native performance.</p><p>Curious to learn more after this quick introduction? <a href=\"https://twitter.com/emaxerrno/\" rel=\"noopener ugc nofollow\">Alex Gallego</a>, founder of Vectorized, gave a sneak preview of the Data Policy Engine at this yearâ€™s Kafka Summit, which you can check out here:</p><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">I&#39;m about to show a sneak preview of on the most anticipated features by the community here, as a sponsored talk. <br><br>tl;dr - take an *unmodified spark app* and use a push-down predicate in <a href=\"https://twitter.com/hashtag/wasm?src=hash&amp;ref_src=twsrc%5Etfw\">#wasm</a> ðŸ¤¯ðŸ¤¯ðŸ¤¯<br><br>Demo at the end. <br> <a href=\"https://twitter.com/hashtag/redpanda?src=hash&amp;ref_src=twsrc%5Etfw\">#redpanda</a> <a href=\"https://twitter.com/hashtag/kafka?src=hash&amp;ref_src=twsrc%5Etfw\">#kafka</a> <a href=\"https://twitter.com/hashtag/KafkaSummit?src=hash&amp;ref_src=twsrc%5Etfw\">#KafkaSummit</a> <a href=\"https://t.co/NiL2SNHrvq\">https://t.co/NiL2SNHrvq</a></p>&mdash; ðŸ•ºðŸ’ƒðŸ¤Ÿ Alexander Gallego (@emaxerrno) <a href=\"https://twitter.com/emaxerrno/status/1438214386124873728?ref_src=twsrc%5Etfw\">September 15, 2021</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure>","comment_id":"6192052ffec7d1542d1d2a17","plaintext":"In Why Developers Love Redpanda\n[https://whoisnnamdi.com/why-developers-love-redpanda/], I talked about the\nexciting developments around WebAssembly and how Vectorized\n[https://vectorized.io/] is leveraging the technology to build itâ€™s Intelligent\nData API, Redpanda [https://github.com/vectorizedio/redpanda]:\n\n> WebAssembly [https://webassembly.org/], or WASM, is one of the most exciting\nup-and-coming technologies in software development today. WebAssembly lets\ndevelopers write code in any major language, translate that code to the compact\nWASM format, and run it on the web with the high performance of a native\napplication.\n\nRedpanda is one of the first infrastructure technologies to take advantage of\nWASM, enabling developers to â€œwrite and edit code in their favorite programming\nlanguage to perform one-shot transformations, like guaranteeing GDPR compliance\nby removing personal information or to provide filtering and simple aggregation\nfunctions.â€\n\nJavaScript, Python, Rust, Go â€” anything that compiles to WebAssembly (basically\neverything at this point) can be used to transform data. Again the key is\naccessibility â€” inline WASM transforms in Redpanda represent just that.\nEver since partnering with Vectorized, we at Lightspeed [https://lsvp.com/] knew\nthat Redpanda was much more than a streaming engine. Redpanda truly is an\nIntelligent Data API, and itâ€™s Data Policy Engine\n[https://vectorized.io/blog/wasm-architecture/] unlocks one more piece of that\npuzzle.\n\nToday, I want to expand on this and talk a bit more about the exciting\ndevelopments coming down the pipe at Vectorized.\n\nHereâ€™s the big idea: rather than ship data to code, which is expensive and\nlatency-prone, why not ship code to the data?\n\nThe keystone problem in streaming\nStreaming has seen a ton of innovation over the last few years, but one area\nthat remains painful today is stream processing. While a full explanation of\nthese difficulties probably warrants its own article, Iâ€™ll cover the most\nsalient points here.\n\nThe great thing about streaming is the immutable message queue. The not so good\nthing about streaming is, also, the immutable message queue.\n\nWhat do I mean by this? The immutability of the message queue is great because\nit guarantees that data produced to the topic can be replicated one-to-one by\nsimply consuming the whole queue from the start. This lets you effectively\nâ€œreplayâ€ data like a VHS tape and also gives you built-in auditing, since you\nknow the ordering hasnâ€™t changed. It also decouples producers of data from the\nconsumers of that data, letting the two operate independently without\nsignificant coordination work.\n\nHowever, there are some problems. Immutability not only means you *can* consume\nthe data in the same order it was produced â€” it means you must (at least as\nimplemented today in the Kafka-API world). Further, immutability means one must\nconsume at least as much as was produced, often many times as much, leading to\nadditional costs in the form of network traffic and other resources. These\nissues can be avoided to some extent by being very diligent in setting up your\narchitecture a priori, careful in segregating your use cases, etc., but few do\nthis in practice.\n\nIn summary, the things that make streaming great also make stream processing\ncomplex and difficult.\n\nShipping code to data\nHereâ€™s where WebAssembly comes in. WebAssembly lets us do a small amount of\nextra compute work to save us a ton of cost in the form of network utilization\nand latency. Mission critical streams can stay as large as they want without\nsaturating the network.\n\nWeâ€™re excited about the power and promise of WebAssembly, and we think it has\nthe potential to do for server-side compute today what JavaScript did for the\nweb in the late 90s. Like JavaScript enabled the shipping of code to the userâ€™s\nclient, WebAssembly lets engineers ship code to the storage engine.\n\nHereâ€™s how.\n\nThe Redpanda Data Policies Engine simultaneously extends the Kafka API and what\nyou can do with server-side compute. Itâ€™s a server-side compute API for Redpanda\nthatâ€™s compatible with all existing Kafka tooling and the broader ecosystem,\nincluding Spark Streaming, Kafka Streams, Flink, and more.\n\nWith Data Policies, all your favorite tools can benefit from server-side\nWebAssembly filters, allowing for easy and simple data scrubbing, cleaning,\nfiltering, normalization and more. As a runtime, WebAssembly allows code to\nexecute inside Redpanda, allowing code to be injected into an active cluster at\nruntime.\n\nRedpanda Transforms enable extremely low-latency transformations by avoiding the\nâ€œdata ping-pongâ€ that happens in many systems and stream processors today, where\ndata gets sent back and forth between storage and compute, even for very minor\noperations. Further, Redpanda Transform is built on the V8 engine\n[https://v8.dev/], the high-performance JavaScript and WebAssembly engine that\nalso powers Chrome and NodeJS.\n\nTransforms in Redpanda are effectively a stateless predicate pushdown\n[https://medium.com/microsoftazure/data-at-scale-learn-how-predicate-pushdown-will-save-you-money-7063b80878d7]\n. In simple terms, that means performance is massively improved by â€œpushing\ndownâ€ code to the data, only touching the relevant data (and ignoring the rest),\ncutting down on wasteful network traffic, I/O, and latency.\n\nRedpanda Transforms are also completely auditable. The controller can report on\nwhich specific piece of code is touching which specific piece of data, on which\nmachines, at which topic offsets.\n\nAs easy as one, two, THREE\nFew things are simple in data engineering, but, as usual, Vectorized is changing\nthe game. For all the cool things happening under the hood, getting started with\nData Policies is shockingly easy.\n\nFirst, write your policy/transform in a WebAssembly compatible language (read:\neverything). To make this even easier, Redpanda provides native plugins for\ninline transforms. In the end, you end up with something that looks like fairly\nstandard (JavaScript in this case) code. Hereâ€™s a simple proof of concept:\ntransforming all lowercase alphabetic characters in a record to uppercase:\n\nimport { InlineTransform } from â€œ@vectorizedio/InlineTransformâ€;\nconst transform = new InlineTransform();\ntransform.topics([{â€œinputâ€: â€œlowercaseâ€, â€œoutputâ€: â€uppercaseâ€}]):\nâ€¦\nconst uppercase = async (record) => {\n    const newRecord = {\n        ...record,\n        value: record.value.map((char) => {\n            return char.toUpperCase();\n        }),\n    };\n    return newRecord;\n}\n\n\nNext, apply the policy to a Kafka topic. Again this is incredibly\nstraightforward. All it takes is a single terminal command:\n\n> bin/kafka-topics.sh \\\nâ€” alter â€” topic my_topic_name \\\nâ€” config x-data-policy={â€¦}\n(redpanda has a tool called `rpk` that is similar to kafka-topics.sh)\n\nNow, Redpanda handles the rest.\n\n * Upon a TCP connection to consume from the topic, Redpanda initiates a V8\n   context\n   [https://v8docs.nodesource.com/node-0.8/df/d69/classv8_1_1_context.html]\n * Bytes are read from disk\n * Payload is transformed and re-checksumed (ensures Kafka protocol remains\n   unchanged)\n * Redpanda returns the transformed record\n\nPretty slick.\n\nSimplicity is the ultimate sophistication\nIâ€™ve talked before\n[https://medium.com/lightspeed-venture-partners/why-developers-love-redpanda-30bf2f3b8231] \nabout Vectorizedâ€™s deep understanding and appreciation for the power of\nsimplicity:\n\n> Redpanda abstracts away the complexity that often prevents the typical developer\nfrom adopting real-time streaming.\nThe Data Policy Engine continues that tradition.\n\nThis was just an example use case, but they only get more interesting from here.\nGDPR compliance via masking rules. Encryption at-rest, on-disk. All at runtime,\nwith near-native performance.\n\nCurious to learn more after this quick introduction? Alex Gallego\n[https://twitter.com/emaxerrno/], founder of Vectorized, gave a sneak preview of\nthe Data Policy Engine at this yearâ€™s Kafka Summit, which you can check out\nhere:\n\n> I'm about to show a sneak preview of on the most anticipated features by the\ncommunity here, as a sponsored talk. \n\ntl;dr - take an *unmodified spark app* and use a push-down predicate in #wasm\n[https://twitter.com/hashtag/wasm?src=hash&ref_src=twsrc%5Etfw] ðŸ¤¯ðŸ¤¯ðŸ¤¯\n\nDemo at the end. \n#redpanda [https://twitter.com/hashtag/redpanda?src=hash&ref_src=twsrc%5Etfw] \n#kafka [https://twitter.com/hashtag/kafka?src=hash&ref_src=twsrc%5Etfw] \n#KafkaSummit\n[https://twitter.com/hashtag/KafkaSummit?src=hash&ref_src=twsrc%5Etfw] \nhttps://t.co/NiL2SNHrvq\n\nâ€” ðŸ•ºðŸ’ƒðŸ¤Ÿ Alexander Gallego (@emaxerrno) September 15, 2021\n[https://twitter.com/emaxerrno/status/1438214386124873728?ref_src=twsrc%5Etfw]","feature_image":"__GHOST_URL__/content/images/2021/11/header-1.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2021-11-15T06:58:55.000Z","updated_at":"2022-04-24T22:16:55.000Z","published_at":"2021-10-09T13:00:00.000Z","custom_excerpt":"Rather than ship data to code, which is expensive and latency-prone, why not ship code to the data?","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"61d40a02fec7d1542d1d2a76","uuid":"95ba8747-832f-4bd8-8979-c3de2333e70a","title":"Introducing a New and Improved SaaS Metric: Weighted ACV","slug":"weighted-acv","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"ACV, or average/annual contract value, isn't as useful a concept as people think.\\n\\nThough it's easy to forget, ACV is a *customer-weighted* metric: it tells us something about the customers of the business. However, despite its name, it doesn't tell us much about the *revenue profile* of the business, which is arguably more important.\\n\\nFurther, the standard ACV metric obscures valuable information about the skewness of monetization / revenue. Thus, we can't use it to compare companies with differing customer concentration.\\n\\nWe need a different SaaS monetization metric.\\n\\nI present to you: **weighted ACV (WACV)**.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Introducing a New and Improved SaaS Metric: Weighted ACV\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## Customer-centric or dollar-centric?\\nIn [Enterprise Software Monetization is Fat-Tailed](https://whoisnnamdi.com/software-fat-tailed/), I talked about the follies of focusing on simple averages, especially in enterprise software:\\n> In enterprise software, the \\\"average\\\" customer is a meaningless concept.\\n> \\n> Paying too much attention to the \\\"average\\\" customer leads many founders and investors astray.\\n\\n[Average/annual contract value](https://blog.hubspot.com/sales/annual-contract-value-acv), or ACV, is one such misleading metric.\\n\\n$$\\\\text{ACV} = \\\\frac{\\\\text{Total Annual Contract Value}}{\\\\text{Total Customers}}$$\\n\\nACV tells you something about the typical *customer*. Products with small ACVs tend to serve smaller, more fickle customers with a high probability of churning, like small businesses and startups. High ACV products address the needs of larger companies with more mission critical use cases, leading to less churn.\\n\\nHowever, while ACV tells you something about how the typical customer might behave, it doesn't tell you much about how the typical *dollar of revenue* behaves. If 70% of the revenue comes from 20% of the customers, then for the purposes of analyzing revenues at a point in time, it's really only that subset of customers that matter. Such [extreme concentration](https://whoisnnamdi.com/software-fat-tailed/#the-evidence) is not unusual for public software companies:\\n![Pasted image 20211113192246](__GHOST_URL__/content/images/2020/10/share.png)\\n> The implied top-20% and top-1% revenue concentration are quite large for most companies (blue = top 20%, red = top 1%)\\n> \\n> So, **the top 20% typically represent ~70% of revenue**, while **the top 1% represent ~40%**. Not quite Pareto 80/20, but pretty close!\\n\\nThis distinction between **customer behavior** and **revenue behavior** is critical, as the behavior of the typical dollar of revenue is much more informative about the quality of revenue and the likelihood that revenue will be retained or expanded. **For companies with high revenue concentration, simple averages are largely useless.**\"}],[\"embed\",{\"url\":\"https://twitter.com/masterly_in/status/1476610484371660812\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">This is largely true to this day - for many public enterprise SAAS, a very small # of customers contributes a huge chunk of total rev.  <br>e.g. ~0.95% of <a href=\\\"https://twitter.com/search?q=%24NET&amp;src=ctag&amp;ref_src=twsrc%5Etfw\\\">$NET</a> paying customers rep &gt;50% of rev in Q3/21<br><br>So why do some analysts still use metrics like ARPU/AARPU for enterprise saas? <a href=\\\"https://t.co/WXSpWJYfNA\\\">pic.twitter.com/WXSpWJYfNA</a></p>&mdash; Masterly Inactive (@masterly_in) <a href=\\\"https://twitter.com/masterly_in/status/1476610484371660812?ref_src=twsrc%5Etfw\\\">December 30, 2021</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\",\"metadata\":{\"url\":\"https://twitter.com/masterly_in/status/1476610484371660812\",\"author_name\":\"Masterly Inactive\",\"author_url\":\"https://twitter.com/masterly_in\",\"width\":550,\"height\":null,\"cache_age\":\"3153600000\",\"provider_name\":\"Twitter\",\"provider_url\":\"http://www.twitter.com/\",\"version\":\"1.0\"}}],[\"markdown\",{\"markdown\":\"Rather than the exception, high concentration is the *norm* in certain verticals (e.g. cloud infrastructure) or pricing models (consumption/pay-as-you-go) where a \\\"customer\\\" can be as small as tens of dollars per month:\\n> Interestingly, many companies tied to infrastructure in some way like Datadog, Fastly, and Twilio... have 80/20 monetization distributions, at least in some years.\\n\\nUnfortunately, the standard ACV metric is incomparable across companies with vastly different customer concentration. A company with many small or \\\"free tier\\\" customers will have an artificially low ACV metric, even if contract sizes are reasonably high among its paying customers. You can't naively compare such a skewed company to another business where every customer is small.\\n\\nThis is why you see public software companies with tons of bottom up but low-paying usage report ACV or other customer metrics including only the customers larger than some nominal spending level, like $5,000 (screenshot from the [GitLab S-1](https://sec.report/Document/0001628280-21-019932/gitlab-sx1a2.htm)):\\n![Pasted-image-20211114131342](__GHOST_URL__/content/images/2022/01/Pasted-image-20211114131342.png)\\n\\nUsing arbitrary thresholds is a clunky way of dealing with this problem, as companies can pick any value they want. **ACV calculations with different thresholds are effectively incomparable.**\\n\\n## Weighing in\\nA customer-weighed metric helps you understand customers. ACV is a *customer* or *equal-weighted* metric, which is to say every customer is weighted equally. So if there are 1000 customers, the contract value of each customer is \\\"weighted\\\" or multiplied by 1/1000 and then summed up. Because each *customer* is weighted equally, the resulting metric tells us something about the typical *customer*. Thus we can rewrite ACV as:\\n\\n$$\\\\text{ACV} = \\\\sum_n \\\\text{\\\\% of Total Customers}_n \\\\times \\\\text{Contract Value}_n$$\\n\\n**However, if you want to understand revenue, you need to use a revenue-weighted metric.**\\n\\nJust like the [market capitalization-weighting](https://www.investopedia.com/terms/c/capitalizationweightedindex.asp) of the S&P 500 index signals the changing value of the overall equity market (but not of the individual *companies* in the index), a revenue or contract value-weighted metric tells us much about the overall revenue of the business (rather than the individual customers).\\n\\nIntroducing: **weighted ACV (WACV)**.\\n\\nRevenue-weighting the revenue each customer generates might sound like double counting, but we need to weight individual customer revenues by *something*. Nothing limits us to equal-weighting. Revenue-weighting is not only perfectly reasonable, it's the more appropriate methodology when analyzing quality of revenues.\\n\\nA perfect example is [net dollar retention](https://whoisnnamdi.com/high-retention-high-volatility/), a common tool for understanding the quality and behavior of software revenues:\\n- Believe it or not, *net dollar retention is also a revenue-weighted metric*: it weights the individual dollar retention of each customer by the revenue that customer represents. That's not how the calculation is typically conceptualized, but that is the underlying math (grab some data and prove this to yourself)\\n- Thus, larger customers matter more for net dollar retention; the churning of a tiny customer has infinitesimal impact.\\n\\nTo calculate weighted ACV:\\n- Take the contract value of each customer and multiply it by the proportion of revenue that customer represents. A customer representing 1% of revenue gets a 1/100 weight, a customer representing 3% of revenue receives a weight of 3/100, and so on.\\n- Then sum all those numbers (i.e. SUMPRODUCT, for all you spreadsheet monkeys out there)\\n\\n$$\\\\text{Weighted ACV} = \\\\sum_n \\\\text{\\\\% of Total Contract Value}_n \\\\times \\\\text{Contract Value}_n$$\\n\\n**Weighted ACV tells you where to look if you want to best understand the revenue of the business.** For example, a WACV of $25,000 tells us roughly that the typical dollar of revenue is generated by a $25,000 customer. Thus, revenue retention/churn and other revenue dynamics of the business will tend toward what we'd expect for those kinds of customers. Revenue-weighting is especially helpful if the company in question has a large number of customers spending little or zero, contaminating the equal-weighted ACV calculation.\\n\\nMeanwhile, changes in WACV correspond to changing monetization among the largest chunk of the revenue base. Customers with the biggest revenue impact will have the largest influence on WACV, as with net dollar retention.\\n\\nIf we think about a company as a sort of physical object, its \\\"center of mass\\\" is concentrated at its WACV. Logically, if we want to do physics on this thing or model its movement, what matters most is its center of mass (its weighted ACV), not necessarily its literal \\\"center\\\" (equal-weighted ACV). That's where revenue is most \\\"densely\\\" concentrated.\\n\\nThis concept flips standard monetization logic on its head. Instead of saying \\\"the average customer generates X revenue,\\\" as if all revenue comes from a single type of customer, WACV says \\\"Y-size customers generate the average dollar of revenue,\\\" respecting the fact that certain customers are disproportionately impactful. ACV asks \\\"what's the expected value of a randomly selected *customer*\\\" while WACV asks \\\"what's the expected contract size associated with a randomly selected *dollar of revenue*.\\\"\\n\\nAs I'll demonstrate in a second, *this is really powerful*. In a single number, we capture much more information than the equal-weighted ACV metric by accounting for the skew and concentration of the customer base. In statistics parlance, WACV gives us some sense of the [variance](https://www.scribbr.com/statistics/variance/) of revenues across customers, rather than merely the mean.\\n\\nNote: this essay focuses on enterprise SaaS monetization, but you can apply the same concept to B2C and other models. E.g. Average Revenue Per User (ARPU) becomes Weighted ARPU (WARPU), and so on.\\n\\n### An example worth its weight in revenue\\nTwo businesses could have the same equal-weighted ACV but wildly different weighted ACVs.\\n\\nHere's an example to make this vivid.\\n\\nImagine two, $50K revenue companies with five customers each, equivalent equal-weighted ACVs, but very different revenue distributions. Company 1 has five equal-sized customers, while Company 2 has a fairly typical skewed distribution, with 20% of customers representing 80% of revenue:\\n\\n| | Company 1 | Company 2 |\\n| --- | --- | --- |\\n| Customer 1 | $10,000 | $40,000 |\\n| Customer 2 | $10,000 | $2,500 |\\n| Customer 3 | $10,000 | $2,500 |\\n| Customer 4 | $10,000 | $2,500 |\\n| Customer 5 | $10,000 | $2,500 |\\n| **ACV** | **$10,000** | **$10,000** |\\n| **Weighted ACV** | **$10,000** | **$32,500** |\\n\\n**Notice how sensitive WACV is to the more skewed revenue distribution of the second company.** It's telling us Company 2's large $40K customer is really dictating the revenue dynamics of the company. For Company 2, the typical dollar of revenue will behave like it's coming from a $32.5K customer, not a $10K customer. The standard ACV metric totally misses this.\\n\\nNow that we've seen how WACV helps us at a single point in time, let's see what happens to the metric *over time*. Next month, both companies land a large, $100K deal with a new customer:\\n\\n| | Company 1 | Company 2 |\\n| --- | --- | --- |\\n| Customer 1 | $10,000 | $40,000 |\\n| Customer 2 | $10,000 | $2,500 |\\n| Customer 3 | $10,000 | $2,500 |\\n| Customer 4 | $10,000 | $2,500 |\\n| Customer 5 | $10,000 | $2,500 |\\n| Customer 6 | $100,000 | $100,000 |\\n| **ACV** | **$25,000** | **$25,000** |\\n| **Weighted ACV** | **$70,000** | **$77,500** |\\n\\nBoth metrics increase, but weighted ACV increases by a lot more, reflecting the dominance of the new large customer within the revenue base. The standard ACV calculation unwittingly discounts the effect of large customers, muting their impact.\\n\\nAgain, the weighted version of ACV correctly points us towards the largest customers. The \\\"typical\\\" dollar of revenue for both companies will now behave like it's coming from a roughly $70-80K customer, *not* a $25K customer.\\n\\nLastly, the fact that WACV across the companies has converged suggests their revenue concentration is now much more similar, which is exactly right.\\n\\n### VICs: Very Important Customers\\nOne last trick.\\n\\nJust like dividing total revenue or contract value by ACV yields the total customer count, dividing by weighted ACV tells us something about the customer base. The calculation tells us, on a revenue basis, **how many customers really matter**. In other words, what minority of customers effectively determines overall revenue?\\n\\nLet's call them **very important customers (VICs)**:\\n\\n$$\\\\text{Very Important Customers} = \\\\text{Total Contract Value } / \\\\text{ Weighted ACV} $$\\n\\nIt turns out, this will be a small fraction of the overall customer count for the typical enterprise software company.\\n\\nReturning to the first example, total revenue was $50K, while weighted ACV was $10K for Company 1 and $32.5K for Company 2. Thus, Company 1 has 5 VICs while Company 2 has 1.5. This tells us that while Company 1 has five relevant and discernibly important customers, Company 2 only has one or two. This accords with the data â€“ in terms of revenue risk or quality of revenue, Company 2 is effectively a one (point five) trick pony:\\n\\n| | Company 1 | Company 2 |\\n| --- | --- | --- |\\n| Total Contract Value | $50,000 | $50,000 |\\n| Weighted ACV | $10,000 | $32,500 |\\n| **Very Important Customers** | **5** | **1.54** |\\n\\nIn the second example, total revenue is now $150K, with weighted ACV of $70K for Company 1 and $77.5K for Company 2. Some quick math yields ~2 very important customers for each company, reflecting their respective revenue concentration. Said differently, you can summarize the entire revenue profile of each company by looking at the two largest customers:\\n\\n| | Company 1 | Company 2 |\\n| --- | --- | --- |\\n| Total Contract Value | $150,000 | $150,000 |\\n| Weighted ACV | $70,000 | $77,500 |\\n| **Very Important Customers** | **2.14** | **1.94** |\\n\\nFrankly, I find this much more representative of the volatility of revenue. These companies have serious concentration risk, and from a diversification perspective really only have two customers each.\\n\\nPublic software companies have similar concentration, so the same logic applies: very important customers will only be 30-40% of the overall customer base.\\n\\nWith WACV and VICs, founders with high revenue concentration can now rigorously quantify the number and magnitude of meaningful customer relationships they have while avoiding awkward conversations that go something like, \\\"well... we have X total customers, but only Y many are paying us more than Z per year, so if you remove those then our business is really...\\\"\\n\\n### Conclusion\\nAre there any downsides to weighted ACV?\\n\\nNo, none at all.\\n\\nJust kidding! The negatives of WACV mirror those of other size-weighting schemes like the S&P 500: it's extremely sensitive to idiosyncratic fluctuations in your largest customers that may not be representative of the broader customer base or long-lasting in nature.\\n\\nThese are fair critiques. However, all can be easily addressed by calculating **both** weighted and equal-weighted ACV. Coincidently, the difference between the two is a nice measure of customer concentration and the [fat-tailedness of monetization](https://whoisnnamdi.com/software-fat-tailed/): the further apart they are, the more revenue is concentrated among a few customers, and vice versa:\\n\\n$$\\\\text{Weighted ACV} - \\\\text{Equal-weighted ACV} \\\\approx \\\\text{Customer Concentration}$$\\n\\nIn fact, the main disadvantage of revenue-weighting is that it requires knowing the revenue or contract value of **each and every customer**. So an outsider can't calculate the metric; it must be reported by the company. You can often approximate it with just data of the top 30-40% of customers, but that won't be perfect.\\n\\nIf you *do* have enough information to calculate weighted ACV, you should *always* do it. WACV contains more information than the standard ACV metric, and by definition you can always calculate the latter if you can calculate the former.\\n\\n*If you found this helpful, need help with the calculation, or end up implementing this in your analytics, do let me know!*\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: Introducing a New and Improved SaaS Metric: Weighted ACV\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>ACV, or average/annual contract value, isn't as useful a concept as people think.</p>\n<p>Though it's easy to forget, ACV is a <em>customer-weighted</em> metric: it tells us something about the customers of the business. However, despite its name, it doesn't tell us much about the <em>revenue profile</em> of the business, which is arguably more important.</p>\n<p>Further, the standard ACV metric obscures valuable information about the skewness of monetization / revenue. Thus, we can't use it to compare companies with differing customer concentration.</p>\n<p>We need a different SaaS monetization metric.</p>\n<p>I present to you: <strong>weighted ACV (WACV)</strong>.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Introducing a New and Improved SaaS Metric: Weighted ACV\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"customer-centric-or-dollar-centric\">Customer-centric or dollar-centric?</h2>\n<p>In <a href=\"https://whoisnnamdi.com/software-fat-tailed/\">Enterprise Software Monetization is Fat-Tailed</a>, I talked about the follies of focusing on simple averages, especially in enterprise software:</p>\n<blockquote>\n<p>In enterprise software, the &quot;average&quot; customer is a meaningless concept.</p>\n<p>Paying too much attention to the &quot;average&quot; customer leads many founders and investors astray.</p>\n</blockquote>\n<p><a href=\"https://blog.hubspot.com/sales/annual-contract-value-acv\">Average/annual contract value</a>, or ACV, is one such misleading metric.</p>\n<p>$$\\text{ACV} = \\frac{\\text{Total Annual Contract Value}}{\\text{Total Customers}}$$</p>\n<p>ACV tells you something about the typical <em>customer</em>. Products with small ACVs tend to serve smaller, more fickle customers with a high probability of churning, like small businesses and startups. High ACV products address the needs of larger companies with more mission critical use cases, leading to less churn.</p>\n<p>However, while ACV tells you something about how the typical customer might behave, it doesn't tell you much about how the typical <em>dollar of revenue</em> behaves. If 70% of the revenue comes from 20% of the customers, then for the purposes of analyzing revenues at a point in time, it's really only that subset of customers that matter. Such <a href=\"https://whoisnnamdi.com/software-fat-tailed/#the-evidence\">extreme concentration</a> is not unusual for public software companies:<br>\n<img src=\"__GHOST_URL__/content/images/2020/10/share.png\" alt=\"Pasted image 20211113192246\" loading=\"lazy\"></p>\n<blockquote>\n<p>The implied top-20% and top-1% revenue concentration are quite large for most companies (blue = top 20%, red = top 1%)</p>\n<p>So, <strong>the top 20% typically represent ~70% of revenue</strong>, while <strong>the top 1% represent ~40%</strong>. Not quite Pareto 80/20, but pretty close!</p>\n</blockquote>\n<p>This distinction between <strong>customer behavior</strong> and <strong>revenue behavior</strong> is critical, as the behavior of the typical dollar of revenue is much more informative about the quality of revenue and the likelihood that revenue will be retained or expanded. <strong>For companies with high revenue concentration, simple averages are largely useless.</strong></p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">This is largely true to this day - for many public enterprise SAAS, a very small # of customers contributes a huge chunk of total rev.  <br>e.g. ~0.95% of <a href=\"https://twitter.com/search?q=%24NET&amp;src=ctag&amp;ref_src=twsrc%5Etfw\">$NET</a> paying customers rep &gt;50% of rev in Q3/21<br><br>So why do some analysts still use metrics like ARPU/AARPU for enterprise saas? <a href=\"https://t.co/WXSpWJYfNA\">pic.twitter.com/WXSpWJYfNA</a></p>&mdash; Masterly Inactive (@masterly_in) <a href=\"https://twitter.com/masterly_in/status/1476610484371660812?ref_src=twsrc%5Etfw\">December 30, 2021</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><!--kg-card-begin: markdown--><p>Rather than the exception, high concentration is the <em>norm</em> in certain verticals (e.g. cloud infrastructure) or pricing models (consumption/pay-as-you-go) where a &quot;customer&quot; can be as small as tens of dollars per month:</p>\n<blockquote>\n<p>Interestingly, many companies tied to infrastructure in some way like Datadog, Fastly, and Twilio... have 80/20 monetization distributions, at least in some years.</p>\n</blockquote>\n<p>Unfortunately, the standard ACV metric is incomparable across companies with vastly different customer concentration. A company with many small or &quot;free tier&quot; customers will have an artificially low ACV metric, even if contract sizes are reasonably high among its paying customers. You can't naively compare such a skewed company to another business where every customer is small.</p>\n<p>This is why you see public software companies with tons of bottom up but low-paying usage report ACV or other customer metrics including only the customers larger than some nominal spending level, like $5,000 (screenshot from the <a href=\"https://sec.report/Document/0001628280-21-019932/gitlab-sx1a2.htm\">GitLab S-1</a>):<br>\n<img src=\"__GHOST_URL__/content/images/2022/01/Pasted-image-20211114131342.png\" alt=\"Pasted-image-20211114131342\" loading=\"lazy\"></p>\n<p>Using arbitrary thresholds is a clunky way of dealing with this problem, as companies can pick any value they want. <strong>ACV calculations with different thresholds are effectively incomparable.</strong></p>\n<h2 id=\"weighing-in\">Weighing in</h2>\n<p>A customer-weighed metric helps you understand customers. ACV is a <em>customer</em> or <em>equal-weighted</em> metric, which is to say every customer is weighted equally. So if there are 1000 customers, the contract value of each customer is &quot;weighted&quot; or multiplied by 1/1000 and then summed up. Because each <em>customer</em> is weighted equally, the resulting metric tells us something about the typical <em>customer</em>. Thus we can rewrite ACV as:</p>\n<p>$$\\text{ACV} = \\sum_n \\text{% of Total Customers}_n \\times \\text{Contract Value}_n$$</p>\n<p><strong>However, if you want to understand revenue, you need to use a revenue-weighted metric.</strong></p>\n<p>Just like the <a href=\"https://www.investopedia.com/terms/c/capitalizationweightedindex.asp\">market capitalization-weighting</a> of the S&amp;P 500 index signals the changing value of the overall equity market (but not of the individual <em>companies</em> in the index), a revenue or contract value-weighted metric tells us much about the overall revenue of the business (rather than the individual customers).</p>\n<p>Introducing: <strong>weighted ACV (WACV)</strong>.</p>\n<p>Revenue-weighting the revenue each customer generates might sound like double counting, but we need to weight individual customer revenues by <em>something</em>. Nothing limits us to equal-weighting. Revenue-weighting is not only perfectly reasonable, it's the more appropriate methodology when analyzing quality of revenues.</p>\n<p>A perfect example is <a href=\"https://whoisnnamdi.com/high-retention-high-volatility/\">net dollar retention</a>, a common tool for understanding the quality and behavior of software revenues:</p>\n<ul>\n<li>Believe it or not, <em>net dollar retention is also a revenue-weighted metric</em>: it weights the individual dollar retention of each customer by the revenue that customer represents. That's not how the calculation is typically conceptualized, but that is the underlying math (grab some data and prove this to yourself)</li>\n<li>Thus, larger customers matter more for net dollar retention; the churning of a tiny customer has infinitesimal impact.</li>\n</ul>\n<p>To calculate weighted ACV:</p>\n<ul>\n<li>Take the contract value of each customer and multiply it by the proportion of revenue that customer represents. A customer representing 1% of revenue gets a 1/100 weight, a customer representing 3% of revenue receives a weight of 3/100, and so on.</li>\n<li>Then sum all those numbers (i.e. SUMPRODUCT, for all you spreadsheet monkeys out there)</li>\n</ul>\n<p>$$\\text{Weighted ACV} = \\sum_n \\text{% of Total Contract Value}_n \\times \\text{Contract Value}_n$$</p>\n<p><strong>Weighted ACV tells you where to look if you want to best understand the revenue of the business.</strong> For example, a WACV of $25,000 tells us roughly that the typical dollar of revenue is generated by a $25,000 customer. Thus, revenue retention/churn and other revenue dynamics of the business will tend toward what we'd expect for those kinds of customers. Revenue-weighting is especially helpful if the company in question has a large number of customers spending little or zero, contaminating the equal-weighted ACV calculation.</p>\n<p>Meanwhile, changes in WACV correspond to changing monetization among the largest chunk of the revenue base. Customers with the biggest revenue impact will have the largest influence on WACV, as with net dollar retention.</p>\n<p>If we think about a company as a sort of physical object, its &quot;center of mass&quot; is concentrated at its WACV. Logically, if we want to do physics on this thing or model its movement, what matters most is its center of mass (its weighted ACV), not necessarily its literal &quot;center&quot; (equal-weighted ACV). That's where revenue is most &quot;densely&quot; concentrated.</p>\n<p>This concept flips standard monetization logic on its head. Instead of saying &quot;the average customer generates X revenue,&quot; as if all revenue comes from a single type of customer, WACV says &quot;Y-size customers generate the average dollar of revenue,&quot; respecting the fact that certain customers are disproportionately impactful. ACV asks &quot;what's the expected value of a randomly selected <em>customer</em>&quot; while WACV asks &quot;what's the expected contract size associated with a randomly selected <em>dollar of revenue</em>.&quot;</p>\n<p>As I'll demonstrate in a second, <em>this is really powerful</em>. In a single number, we capture much more information than the equal-weighted ACV metric by accounting for the skew and concentration of the customer base. In statistics parlance, WACV gives us some sense of the <a href=\"https://www.scribbr.com/statistics/variance/\">variance</a> of revenues across customers, rather than merely the mean.</p>\n<p>Note: this essay focuses on enterprise SaaS monetization, but you can apply the same concept to B2C and other models. E.g. Average Revenue Per User (ARPU) becomes Weighted ARPU (WARPU), and so on.</p>\n<h3 id=\"an-example-worth-its-weight-in-revenue\">An example worth its weight in revenue</h3>\n<p>Two businesses could have the same equal-weighted ACV but wildly different weighted ACVs.</p>\n<p>Here's an example to make this vivid.</p>\n<p>Imagine two, $50K revenue companies with five customers each, equivalent equal-weighted ACVs, but very different revenue distributions. Company 1 has five equal-sized customers, while Company 2 has a fairly typical skewed distribution, with 20% of customers representing 80% of revenue:</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Company 1</th>\n<th>Company 2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Customer 1</td>\n<td>$10,000</td>\n<td>$40,000</td>\n</tr>\n<tr>\n<td>Customer 2</td>\n<td>$10,000</td>\n<td>$2,500</td>\n</tr>\n<tr>\n<td>Customer 3</td>\n<td>$10,000</td>\n<td>$2,500</td>\n</tr>\n<tr>\n<td>Customer 4</td>\n<td>$10,000</td>\n<td>$2,500</td>\n</tr>\n<tr>\n<td>Customer 5</td>\n<td>$10,000</td>\n<td>$2,500</td>\n</tr>\n<tr>\n<td><strong>ACV</strong></td>\n<td><strong>$10,000</strong></td>\n<td><strong>$10,000</strong></td>\n</tr>\n<tr>\n<td><strong>Weighted ACV</strong></td>\n<td><strong>$10,000</strong></td>\n<td><strong>$32,500</strong></td>\n</tr>\n</tbody>\n</table>\n<p><strong>Notice how sensitive WACV is to the more skewed revenue distribution of the second company.</strong> It's telling us Company 2's large $40K customer is really dictating the revenue dynamics of the company. For Company 2, the typical dollar of revenue will behave like it's coming from a $32.5K customer, not a $10K customer. The standard ACV metric totally misses this.</p>\n<p>Now that we've seen how WACV helps us at a single point in time, let's see what happens to the metric <em>over time</em>. Next month, both companies land a large, $100K deal with a new customer:</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Company 1</th>\n<th>Company 2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Customer 1</td>\n<td>$10,000</td>\n<td>$40,000</td>\n</tr>\n<tr>\n<td>Customer 2</td>\n<td>$10,000</td>\n<td>$2,500</td>\n</tr>\n<tr>\n<td>Customer 3</td>\n<td>$10,000</td>\n<td>$2,500</td>\n</tr>\n<tr>\n<td>Customer 4</td>\n<td>$10,000</td>\n<td>$2,500</td>\n</tr>\n<tr>\n<td>Customer 5</td>\n<td>$10,000</td>\n<td>$2,500</td>\n</tr>\n<tr>\n<td>Customer 6</td>\n<td>$100,000</td>\n<td>$100,000</td>\n</tr>\n<tr>\n<td><strong>ACV</strong></td>\n<td><strong>$25,000</strong></td>\n<td><strong>$25,000</strong></td>\n</tr>\n<tr>\n<td><strong>Weighted ACV</strong></td>\n<td><strong>$70,000</strong></td>\n<td><strong>$77,500</strong></td>\n</tr>\n</tbody>\n</table>\n<p>Both metrics increase, but weighted ACV increases by a lot more, reflecting the dominance of the new large customer within the revenue base. The standard ACV calculation unwittingly discounts the effect of large customers, muting their impact.</p>\n<p>Again, the weighted version of ACV correctly points us towards the largest customers. The &quot;typical&quot; dollar of revenue for both companies will now behave like it's coming from a roughly $70-80K customer, <em>not</em> a $25K customer.</p>\n<p>Lastly, the fact that WACV across the companies has converged suggests their revenue concentration is now much more similar, which is exactly right.</p>\n<h3 id=\"vics-very-important-customers\">VICs: Very Important Customers</h3>\n<p>One last trick.</p>\n<p>Just like dividing total revenue or contract value by ACV yields the total customer count, dividing by weighted ACV tells us something about the customer base. The calculation tells us, on a revenue basis, <strong>how many customers really matter</strong>. In other words, what minority of customers effectively determines overall revenue?</p>\n<p>Let's call them <strong>very important customers (VICs)</strong>:</p>\n<p>$$\\text{Very Important Customers} = \\text{Total Contract Value } / \\text{ Weighted ACV} $$</p>\n<p>It turns out, this will be a small fraction of the overall customer count for the typical enterprise software company.</p>\n<p>Returning to the first example, total revenue was $50K, while weighted ACV was $10K for Company 1 and $32.5K for Company 2. Thus, Company 1 has 5 VICs while Company 2 has 1.5. This tells us that while Company 1 has five relevant and discernibly important customers, Company 2 only has one or two. This accords with the data â€“ in terms of revenue risk or quality of revenue, Company 2 is effectively a one (point five) trick pony:</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Company 1</th>\n<th>Company 2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Total Contract Value</td>\n<td>$50,000</td>\n<td>$50,000</td>\n</tr>\n<tr>\n<td>Weighted ACV</td>\n<td>$10,000</td>\n<td>$32,500</td>\n</tr>\n<tr>\n<td><strong>Very Important Customers</strong></td>\n<td><strong>5</strong></td>\n<td><strong>1.54</strong></td>\n</tr>\n</tbody>\n</table>\n<p>In the second example, total revenue is now $150K, with weighted ACV of $70K for Company 1 and $77.5K for Company 2. Some quick math yields ~2 very important customers for each company, reflecting their respective revenue concentration. Said differently, you can summarize the entire revenue profile of each company by looking at the two largest customers:</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Company 1</th>\n<th>Company 2</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Total Contract Value</td>\n<td>$150,000</td>\n<td>$150,000</td>\n</tr>\n<tr>\n<td>Weighted ACV</td>\n<td>$70,000</td>\n<td>$77,500</td>\n</tr>\n<tr>\n<td><strong>Very Important Customers</strong></td>\n<td><strong>2.14</strong></td>\n<td><strong>1.94</strong></td>\n</tr>\n</tbody>\n</table>\n<p>Frankly, I find this much more representative of the volatility of revenue. These companies have serious concentration risk, and from a diversification perspective really only have two customers each.</p>\n<p>Public software companies have similar concentration, so the same logic applies: very important customers will only be 30-40% of the overall customer base.</p>\n<p>With WACV and VICs, founders with high revenue concentration can now rigorously quantify the number and magnitude of meaningful customer relationships they have while avoiding awkward conversations that go something like, &quot;well... we have X total customers, but only Y many are paying us more than Z per year, so if you remove those then our business is really...&quot;</p>\n<h3 id=\"conclusion\">Conclusion</h3>\n<p>Are there any downsides to weighted ACV?</p>\n<p>No, none at all.</p>\n<p>Just kidding! The negatives of WACV mirror those of other size-weighting schemes like the S&amp;P 500: it's extremely sensitive to idiosyncratic fluctuations in your largest customers that may not be representative of the broader customer base or long-lasting in nature.</p>\n<p>These are fair critiques. However, all can be easily addressed by calculating <strong>both</strong> weighted and equal-weighted ACV. Coincidently, the difference between the two is a nice measure of customer concentration and the <a href=\"https://whoisnnamdi.com/software-fat-tailed/\">fat-tailedness of monetization</a>: the further apart they are, the more revenue is concentrated among a few customers, and vice versa:</p>\n<p>$$\\text{Weighted ACV} - \\text{Equal-weighted ACV} \\approx \\text{Customer Concentration}$$</p>\n<p>In fact, the main disadvantage of revenue-weighting is that it requires knowing the revenue or contract value of <strong>each and every customer</strong>. So an outsider can't calculate the metric; it must be reported by the company. You can often approximate it with just data of the top 30-40% of customers, but that won't be perfect.</p>\n<p>If you <em>do</em> have enough information to calculate weighted ACV, you should <em>always</em> do it. WACV contains more information than the standard ACV metric, and by definition you can always calculate the latter if you can calculate the former.</p>\n<p><em>If you found this helpful, need help with the calculation, or end up implementing this in your analytics, do let me know!</em></p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: Introducing a New and Improved SaaS Metric: Weighted ACV\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"61d40a02fec7d1542d1d2a76","plaintext":"ACV, or average/annual contract value, isn't as useful a concept as people\nthink.\n\nThough it's easy to forget, ACV is a customer-weighted metric: it tells us\nsomething about the customers of the business. However, despite its name, it\ndoesn't tell us much about the revenue profile of the business, which is\narguably more important.\n\nFurther, the standard ACV metric obscures valuable information about the\nskewness of monetization / revenue. Thus, we can't use it to compare companies\nwith differing customer concentration.\n\nWe need a different SaaS monetization metric.\n\nI present to you: weighted ACV (WACV).\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Customer-centric or dollar-centric?\nIn Enterprise Software Monetization is Fat-Tailed\n[https://whoisnnamdi.com/software-fat-tailed/], I talked about the follies of\nfocusing on simple averages, especially in enterprise software:\n\n> In enterprise software, the \"average\" customer is a meaningless concept.\n\nPaying too much attention to the \"average\" customer leads many founders and\ninvestors astray.\n\n\nAverage/annual contract value\n[https://blog.hubspot.com/sales/annual-contract-value-acv], or ACV, is one such\nmisleading metric.\n\n$$\\text{ACV} = \\frac{\\text{Total Annual Contract Value}}{\\text{Total\nCustomers}}$$\n\nACV tells you something about the typical customer. Products with small ACVs\ntend to serve smaller, more fickle customers with a high probability of\nchurning, like small businesses and startups. High ACV products address the\nneeds of larger companies with more mission critical use cases, leading to less\nchurn.\n\nHowever, while ACV tells you something about how the typical customer might\nbehave, it doesn't tell you much about how the typical dollar of revenue \nbehaves. If 70% of the revenue comes from 20% of the customers, then for the\npurposes of analyzing revenues at a point in time, it's really only that subset\nof customers that matter. Such extreme concentration\n[https://whoisnnamdi.com/software-fat-tailed/#the-evidence] is not unusual for\npublic software companies:\n\n\n> The implied top-20% and top-1% revenue concentration are quite large for most\ncompanies (blue = top 20%, red = top 1%)\n\nSo, the top 20% typically represent ~70% of revenue, while the top 1% represent\n~40%. Not quite Pareto 80/20, but pretty close!\n\n\nThis distinction between customer behavior and revenue behavior is critical, as\nthe behavior of the typical dollar of revenue is much more informative about the\nquality of revenue and the likelihood that revenue will be retained or expanded. \nFor companies with high revenue concentration, simple averages are largely\nuseless.\n\n> This is largely true to this day - for many public enterprise SAAS, a very small\n# of customers contributes a huge chunk of total rev. \ne.g. ~0.95% of $NET\n[https://twitter.com/search?q=%24NET&src=ctag&ref_src=twsrc%5Etfw] paying\ncustomers rep >50% of rev in Q3/21\n\nSo why do some analysts still use metrics like ARPU/AARPU for enterprise saas? \npic.twitter.com/WXSpWJYfNA [https://t.co/WXSpWJYfNA]\n\nâ€” Masterly Inactive (@masterly_in) December 30, 2021\n[https://twitter.com/masterly_in/status/1476610484371660812?ref_src=twsrc%5Etfw]\nRather than the exception, high concentration is the norm in certain verticals\n(e.g. cloud infrastructure) or pricing models (consumption/pay-as-you-go) where\na \"customer\" can be as small as tens of dollars per month:\n\n> Interestingly, many companies tied to infrastructure in some way like Datadog,\nFastly, and Twilio... have 80/20 monetization distributions, at least in some\nyears.\n\n\nUnfortunately, the standard ACV metric is incomparable across companies with\nvastly different customer concentration. A company with many small or \"free\ntier\" customers will have an artificially low ACV metric, even if contract sizes\nare reasonably high among its paying customers. You can't naively compare such a\nskewed company to another business where every customer is small.\n\nThis is why you see public software companies with tons of bottom up but\nlow-paying usage report ACV or other customer metrics including only the\ncustomers larger than some nominal spending level, like $5,000 (screenshot from\nthe GitLab S-1\n[https://sec.report/Document/0001628280-21-019932/gitlab-sx1a2.htm]):\n\n\nUsing arbitrary thresholds is a clunky way of dealing with this problem, as\ncompanies can pick any value they want. ACV calculations with different\nthresholds are effectively incomparable.\n\nWeighing in\nA customer-weighed metric helps you understand customers. ACV is a customer or \nequal-weighted metric, which is to say every customer is weighted equally. So if\nthere are 1000 customers, the contract value of each customer is \"weighted\" or\nmultiplied by 1/1000 and then summed up. Because each customer is weighted\nequally, the resulting metric tells us something about the typical customer.\nThus we can rewrite ACV as:\n\n$$\\text{ACV} = \\sum_n \\text{% of Total Customers}_n \\times \\text{Contract\nValue}_n$$\n\nHowever, if you want to understand revenue, you need to use a revenue-weighted\nmetric.\n\nJust like the market capitalization-weighting\n[https://www.investopedia.com/terms/c/capitalizationweightedindex.asp] of the\nS&P 500 index signals the changing value of the overall equity market (but not\nof the individual companies in the index), a revenue or contract value-weighted\nmetric tells us much about the overall revenue of the business (rather than the\nindividual customers).\n\nIntroducing: weighted ACV (WACV).\n\nRevenue-weighting the revenue each customer generates might sound like double\ncounting, but we need to weight individual customer revenues by something.\nNothing limits us to equal-weighting. Revenue-weighting is not only perfectly\nreasonable, it's the more appropriate methodology when analyzing quality of\nrevenues.\n\nA perfect example is net dollar retention\n[https://whoisnnamdi.com/high-retention-high-volatility/], a common tool for\nunderstanding the quality and behavior of software revenues:\n\n * Believe it or not, net dollar retention is also a revenue-weighted metric: it\n   weights the individual dollar retention of each customer by the revenue that\n   customer represents. That's not how the calculation is typically\n   conceptualized, but that is the underlying math (grab some data and prove\n   this to yourself)\n * Thus, larger customers matter more for net dollar retention; the churning of\n   a tiny customer has infinitesimal impact.\n\nTo calculate weighted ACV:\n\n * Take the contract value of each customer and multiply it by the proportion of\n   revenue that customer represents. A customer representing 1% of revenue gets\n   a 1/100 weight, a customer representing 3% of revenue receives a weight of\n   3/100, and so on.\n * Then sum all those numbers (i.e. SUMPRODUCT, for all you spreadsheet monkeys\n   out there)\n\n$$\\text{Weighted ACV} = \\sum_n \\text{% of Total Contract Value}_n \\times\n\\text{Contract Value}_n$$\n\nWeighted ACV tells you where to look if you want to best understand the revenue\nof the business. For example, a WACV of $25,000 tells us roughly that the\ntypical dollar of revenue is generated by a $25,000 customer. Thus, revenue\nretention/churn and other revenue dynamics of the business will tend toward what\nwe'd expect for those kinds of customers. Revenue-weighting is especially\nhelpful if the company in question has a large number of customers spending\nlittle or zero, contaminating the equal-weighted ACV calculation.\n\nMeanwhile, changes in WACV correspond to changing monetization among the largest\nchunk of the revenue base. Customers with the biggest revenue impact will have\nthe largest influence on WACV, as with net dollar retention.\n\nIf we think about a company as a sort of physical object, its \"center of mass\"\nis concentrated at its WACV. Logically, if we want to do physics on this thing\nor model its movement, what matters most is its center of mass (its weighted\nACV), not necessarily its literal \"center\" (equal-weighted ACV). That's where\nrevenue is most \"densely\" concentrated.\n\nThis concept flips standard monetization logic on its head. Instead of saying\n\"the average customer generates X revenue,\" as if all revenue comes from a\nsingle type of customer, WACV says \"Y-size customers generate the average dollar\nof revenue,\" respecting the fact that certain customers are disproportionately\nimpactful. ACV asks \"what's the expected value of a randomly selected customer\"\nwhile WACV asks \"what's the expected contract size associated with a randomly\nselected dollar of revenue.\"\n\nAs I'll demonstrate in a second, this is really powerful. In a single number, we\ncapture much more information than the equal-weighted ACV metric by accounting\nfor the skew and concentration of the customer base. In statistics parlance,\nWACV gives us some sense of the variance\n[https://www.scribbr.com/statistics/variance/] of revenues across customers,\nrather than merely the mean.\n\nNote: this essay focuses on enterprise SaaS monetization, but you can apply the\nsame concept to B2C and other models. E.g. Average Revenue Per User (ARPU)\nbecomes Weighted ARPU (WARPU), and so on.\n\nAn example worth its weight in revenue\nTwo businesses could have the same equal-weighted ACV but wildly different\nweighted ACVs.\n\nHere's an example to make this vivid.\n\nImagine two, $50K revenue companies with five customers each, equivalent\nequal-weighted ACVs, but very different revenue distributions. Company 1 has\nfive equal-sized customers, while Company 2 has a fairly typical skewed\ndistribution, with 20% of customers representing 80% of revenue:\n\nCompany 1Company 2Customer 1$10,000$40,000Customer 2$10,000$2,500Customer 3\n$10,000$2,500Customer 4$10,000$2,500Customer 5$10,000$2,500ACV$10,000$10,000\nWeighted ACV$10,000$32,500Notice how sensitive WACV is to the more skewed\nrevenue distribution of the second company. It's telling us Company 2's large\n$40K customer is really dictating the revenue dynamics of the company. For\nCompany 2, the typical dollar of revenue will behave like it's coming from a\n$32.5K customer, not a $10K customer. The standard ACV metric totally misses\nthis.\n\nNow that we've seen how WACV helps us at a single point in time, let's see what\nhappens to the metric over time. Next month, both companies land a large, $100K\ndeal with a new customer:\n\nCompany 1Company 2Customer 1$10,000$40,000Customer 2$10,000$2,500Customer 3\n$10,000$2,500Customer 4$10,000$2,500Customer 5$10,000$2,500Customer 6$100,000\n$100,000ACV$25,000$25,000Weighted ACV$70,000$77,500Both metrics increase, but\nweighted ACV increases by a lot more, reflecting the dominance of the new large\ncustomer within the revenue base. The standard ACV calculation unwittingly\ndiscounts the effect of large customers, muting their impact.\n\nAgain, the weighted version of ACV correctly points us towards the largest\ncustomers. The \"typical\" dollar of revenue for both companies will now behave\nlike it's coming from a roughly $70-80K customer, not a $25K customer.\n\nLastly, the fact that WACV across the companies has converged suggests their\nrevenue concentration is now much more similar, which is exactly right.\n\nVICs: Very Important Customers\nOne last trick.\n\nJust like dividing total revenue or contract value by ACV yields the total\ncustomer count, dividing by weighted ACV tells us something about the customer\nbase. The calculation tells us, on a revenue basis, how many customers really\nmatter. In other words, what minority of customers effectively determines\noverall revenue?\n\nLet's call them very important customers (VICs):\n\n$$\\text{Very Important Customers} = \\text{Total Contract Value } / \\text{\nWeighted ACV} $$\n\nIt turns out, this will be a small fraction of the overall customer count for\nthe typical enterprise software company.\n\nReturning to the first example, total revenue was $50K, while weighted ACV was\n$10K for Company 1 and $32.5K for Company 2. Thus, Company 1 has 5 VICs while\nCompany 2 has 1.5. This tells us that while Company 1 has five relevant and\ndiscernibly important customers, Company 2 only has one or two. This accords\nwith the data â€“ in terms of revenue risk or quality of revenue, Company 2 is\neffectively a one (point five) trick pony:\n\nCompany 1Company 2Total Contract Value$50,000$50,000Weighted ACV$10,000$32,500\nVery Important Customers51.54In the second example, total revenue is now $150K,\nwith weighted ACV of $70K for Company 1 and $77.5K for Company 2. Some quick\nmath yields ~2 very important customers for each company, reflecting their\nrespective revenue concentration. Said differently, you can summarize the entire\nrevenue profile of each company by looking at the two largest customers:\n\nCompany 1Company 2Total Contract Value$150,000$150,000Weighted ACV$70,000$77,500\nVery Important Customers2.141.94Frankly, I find this much more representative of\nthe volatility of revenue. These companies have serious concentration risk, and\nfrom a diversification perspective really only have two customers each.\n\nPublic software companies have similar concentration, so the same logic applies:\nvery important customers will only be 30-40% of the overall customer base.\n\nWith WACV and VICs, founders with high revenue concentration can now rigorously\nquantify the number and magnitude of meaningful customer relationships they have\nwhile avoiding awkward conversations that go something like, \"well... we have X\ntotal customers, but only Y many are paying us more than Z per year, so if you\nremove those then our business is really...\"\n\nConclusion\nAre there any downsides to weighted ACV?\n\nNo, none at all.\n\nJust kidding! The negatives of WACV mirror those of other size-weighting schemes\nlike the S&P 500: it's extremely sensitive to idiosyncratic fluctuations in your\nlargest customers that may not be representative of the broader customer base or\nlong-lasting in nature.\n\nThese are fair critiques. However, all can be easily addressed by calculating \nboth weighted and equal-weighted ACV. Coincidently, the difference between the\ntwo is a nice measure of customer concentration and the fat-tailedness of\nmonetization [https://whoisnnamdi.com/software-fat-tailed/]: the further apart\nthey are, the more revenue is concentrated among a few customers, and vice\nversa:\n\n$$\\text{Weighted ACV} - \\text{Equal-weighted ACV} \\approx \\text{Customer\nConcentration}$$\n\nIn fact, the main disadvantage of revenue-weighting is that it requires knowing\nthe revenue or contract value of each and every customer. So an outsider can't\ncalculate the metric; it must be reported by the company. You can often\napproximate it with just data of the top 30-40% of customers, but that won't be\nperfect.\n\nIf you do have enough information to calculate weighted ACV, you should always \ndo it. WACV contains more information than the standard ACV metric, and by\ndefinition you can always calculate the latter if you can calculate the former.\n\nIf you found this helpful, need help with the calculation, or end up\nimplementing this in your analytics, do let me know!\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2022/01/weighted_ACV.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2022-01-04T08:49:06.000Z","updated_at":"2022-02-07T03:23:12.000Z","published_at":"2022-01-11T18:23:10.000Z","custom_excerpt":"ACV isn't as useful a concept as people think. We need a different SaaS monetization metric.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"62008a02fec7d1542d1d2af2","uuid":"7202b265-8591-4cce-9d3f-b7991b14f43c","title":"Schrodinger's Balance Sheet: When Equity Becomes a Liability","slug":"schrodingers-balance-sheet","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"[Preferred equity](https://www.svb.com/blogs/lewis-hower/startup-founders-should-know-preferred-stock) is synthetic leverage.\\n\\nIt combines an equity-like security with a debt-like security. Which one it is depends on the success of the business:\\n* When things go well, preferred stock converts to standard common equity. \\n* When things go poorly, preferred stock turns into debt.\\n\\nIn this way, preferred equity exists in a constant state of [**quantum superposition**](https://scienceexchange.caltech.edu/topics/quantum-science-explained/quantum-superposition). It's neither equity nor debt, until it is.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Schrodinger's Balance Sheet: When Equity Becomes a Liability\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## SchrÃ¶dinger's balance sheet\\n![Schrodingers_cat](__GHOST_URL__/content/images/2022/02/Schrodingers_cat.svg)\\n\\n[Erwin SchrÃ¶dinger](https://en.wikipedia.org/wiki/Erwin_Schr%C3%B6dinger) was a renowned physicist and one of the first to study the strange world of quantum theory. Among us mortals, he is most known for his famous thought experiment, eponymously called \\\"[SchrÃ¶dinger's cat](https://en.wikipedia.org/wiki/Schr%C3%B6dinger%27s_cat).\\\" In it, he posited that a cat sitting in a box along with a flask of poison could be considered to be both dead \\\\*and\\\\* alive until we open the box to find out if the flask has shattered, killing the poor kitty.\\n\\n**Preferred equity is like SchrÃ¶dinger's cat.** Open the box: if a startup is very valuable, preferred stock all becomes normal equity. If the box contains a dead or slow growing startup that hasn't created much value, preferred stock becomes debt instead.\\n\\nYou can think about preferred equity as debt combined with a deeply out of the money [call option](https://www.investopedia.com/terms/c/calloption.asp). \\\"[*Out of the money*](https://www.investopedia.com/terms/o/outofthemoney.asp)\\\" is just a fancy way of saying the investor won't make much of a return unless the company gains significant value. If the company creates no value from that point forward, the option component is worthless, and the equity merely becomes debt. If the company creates significant value, the importance of the debt element wanes and the option component dominates the return profile.\\n\\nStrangely enough, this is the exact *reverse* of what you'd want to have happen as a founder.\\n\\nThis point has been made by [John Cochrane and others](https://www.gsb.stanford.edu/healthy-banking-system-goal) in the context of bank capitalization:\\n>Ensuring that banks are funded with significantly more equity should be a key element of effective bank regulatory reform. Much more equity funding would permit banks to perform all their useful functions and support growth without endangering the financial system by systemic fragility.\\n\\nThings go very wrong when banks are overly-funded with debt, as debt tends not to \\\"fail gracefully\\\" the way equity does. In financial crises, banks \\\"break\\\" in a very *hard* way due to the significant debt they carry, which must be paid back, necessitating government bailouts in the worst case scenarios. On the other hand, equity tends to break in a *soft* way: if the company isn't worth anything, nothing is owed. Thus a sudden decline in the value of the company doesn't cause a severe panic.\\n\\nCochrane goes so far as to advocate that in times of financial distress, debt on the balance sheet of struggling banks should simply [convert to equity](https://static1.squarespace.com/static/5e6033a4ea02d801f37e15bb/t/5ee802f76e77d94cab19b981/1592263416691/across-the-great-divide-ch10.pdf) rather than be bailed out by the government. Notice what he's proposing â€“ debt on the *upside* and equity on the *downside*.\\n\\nLikewise, as a founder, you'd want your capital structure to be equity when things go badly, making it a variable cost that declines gracefully as your business success declines, and you'd want it to be debt in the upside case, effectively acting as a fixed cost over which you get leverage.\\n\\nIn startup land, however, we do the opposite â€“ *we convert equity to debt in times of distress.*\\n\\n## Spin up\\n\\nPreferred equity is more valuable to investors than common equity, so they're willing to pay more for it, necessitating the issuance of fewer shares and leading to less dilution for the company. Thus, *relative to raising common equity*, preferred equity has a similar benefit as debt, in that it allows you to raise more capital with less dilution.\\n\\nIn this way, startups become **synthetically levered**. No debt appears on the balance sheet, yet the returns of the common equity (really anyone below the most senior preferred stock) get juiced by the lower cost of capital achieved via preferred equity.\\n\\nThe value of preferred stock can be inferred from its cost, i.e. its premium relative to common equity. The preferred equity premium is rarely laid out explicitly, but researchers at Stanford and the University of British Columbia estimate that these days [**preferred equity is 50% more valuable than common equity**](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3725240) and was even more valuable in the past:\\n![Pasted-image-20211201152745](__GHOST_URL__/content/images/2022/02/Pasted-image-20211201152745.png)\\n> This paper develops the first option pricing model of venture capital-backed companies and their security values that incorporates the dilutive future financing rounds prevalent in the industry. Applying our model to 19,000 companies raising 37,000 rounds shows that preferred contractual features make **the most recently issued preferred shares worth on average 56% more than common shares** â€“ [A Valuation Model of Venture Capital-Backed Companies with Multiple Financing Rounds](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3725240)\\n\\nA quick illustration: you're a founder, and you know you need to raise roughly $60M to achieve a meaningful outcome. Because preferred equity is worth 50% more to investors than common, you could either raise $60M in preferred stock with some level of dilution, or raise it all in common stock for 50% more dilution. Let's say the common approach would dilute you by 60%. Then raising the same amount via preferred would only dilute you by 40%:\\n\\n|  | Preferred | Common|\\n| --- | --- | --- |\\n| Capital raised | $60M | $60M |\\n| Total shares | 100 | 100 |\\n| Blended price/share | $1.50 | $1.00 |\\n| Shares purchased | 40 | 60 |\\n| **Dilution** | **40%** | **60%** |\\n\\nThis obviously makes a massive difference in an upside scenario. Simply put, **you get to keep much, much more of your company.** When things work out, preferred equity has a higher cost to investors, and a lower cost to startups.\\n\\nThis is obviously great in a bull market. Cheap, bountiful leverage, available oftentimes for a fraction of the painful diligence associated with raising real debt.\\n\\nThe availability of preferred equity drives companies to raise more than they otherwise would. We'll look at such a scenario next.\\n\\n## Spin down\\n\\nWhen rates of return are sufficiently low, preferred equity begins to look eerily like debt. When are rates of return lowest? [When valuations are highest](https://whoisnnamdi.com/grow-valuation/):\\n> **High valuation multiples corresponds to lower returns**, and vice versa. After periods of frothy valuations, returns end up lower than expected, bringing lofty valuations multiples back down to reality â€“ [Companies Rarely Grow Into Their Valuations](https://whoisnnamdi.com/grow-valuation/)\\n\\nThe mountains of preferred equity being layered into private companies follows the same behavioral vein typically seen during the peak of a market cycle, that is, **massive overuse and abuse of debt that juices returns.** This has predictably disastrous consequences when things go south.\\n\\nAs is common in finance, **the problems with debt reveal themselves only once it blows up.** In a downside scenario, the returns of common equity holders get crushed by the weight of the liquidation preference attached to preferred equity.\\n\\nRemember, venture capital investors are willing to pay $1.50 for preferred equity granting *the same ownership* they could get for $1 of common equity. In an upside scenario, they effectively pay $1.50 for $1's worth of equity. What happens in a downside scenario?\\n\\nLet's return to our previous example. This time, the company chooses a certain, fixed level of dilution that it's willing to endure, 60%, and raises money up to that point. Since preferred stock can be issued at a premium, the company can raise $90M of it for the same dilution as $60M of common:\\n\\n|  | Preferred | Common|\\n| --- | --- | --- |\\n| Capital raised | $90M | $60M |\\n| Total shares | 100 | 100 |\\n| Blended price/share | $1.50 | $1.00 |\\n| Shares purchased | 60 | 60 |\\n| **Dilution** | **60%** | **60%** |\\n\\nSo far so good. The preferred approach gives you $30M more to put to work in the business. But let's say [you never quite achieve product-market fit](https://whoisnnamdi.com/product-market-fit-is-lindy/) (not uncommon, even among companies that have raised tens of millions of dollars) and you woefully underperform expectations. You never become a unicorn, and the business is sold for only $100M:\\n- If you only raised common equity, the founders and employees walk away with $40M. Not as much as hoped for, but not bad!\\n- If you raised preferred however, founders and employees walk away with only $10M, since the equity is now debt, and the investors must receive their \\\"1x [liquidation preference](https://www.seedinvest.com/blog/angel-investing/liquidation-preferences)\\\" (their \\\"principal\\\" effectively). Brutal.\\n\\nThis may offer a clue into why the hedge funds of the world have moved so swiftly into venture. As sophisticated, multi-asset investors, they are quite used to lower-returning, low-risk credit investing combined with potentially high-returning, high-risk derivatives. Rather than \\\"fish out of water\\\", as they are often portrayed by traditional venture investors, could they in fact be quite shrewd [(tiger)sharks](https://randle.substack.com/p/playing-different-games)?\\n\\nThe rabbit hole goes further. Define \\\"overvaluation\\\" as the premium at which preferred stock is valued relative to common equity. Analysis shows **overvaluation predicts poor exit outcomes**, measured in terms of (1) exit value and (2) the probability of going public or being bought out (note: [low R^2 implies exit outcomes are difficult to predict](https://blog.minitab.com/en/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit), not that the relationships aren't statistically significant):\\n![Pasted-image-20220206175842](__GHOST_URL__/content/images/2022/02/Pasted-image-20220206175842.png)\\n> â€¦ **overvaluation predicts low exit outcomes**â€¦ The extent of this overstatement predicts poor subsequent performance â€“ [A Valuation Model of Venture Capital-Backed Companies with Multiple Financing Rounds](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3725240)\\n\\n**Abuse of preferred equity predicts worse outcomes, fewer exits, and lower returns.**\\n\\nSynthetic leverage, as with all forms of financial leverage, makes bad situations *even worse* **AND** *more likely*.\\n\\n## Superposition\\n\\nNow, let's finally explore the quirky quantum world of superposition. \\n\\nPreferred equity starts as neither debt nor equity: you have to \\\"open the box\\\" to see if the company is successful. Unfortunately, actions that make your upside better (raising a ton of money and putting it to work in the business) also make your downside worse. Things that look smart in the upside scenario (raising a \\\"war chest\\\") look disastrous in retrospect on the downside. Gain and pain are entangled; success and failure are superimposed on one another.\\n\\n**Perversely, the Silicon Valley ecosystem creates more synthetic debt (i.e. preferred equity) exactly as returns fall:**\\n1. Valuations rise\\n2. Companies take advantage by issuing more preferred stock\\n3. Returns fall due to inflated valuations\\n4. Preferred stock converges toward debt\\n\\nLet's return to financial crises. The capital stack of a company is very similar to that of a home. From the perspective of the founder, common stock is the \\\"equity\\\" in the home and preferred stock is the debt or mortgage. If value of home falls below the principal on the mortgage, the homeowner is \\\"[underwater](https://www.investopedia.com/terms/u/underwater-mortgage.asp)\\\", destroying the value of their equity.\\n\\nLikewise, when a startup's valuation falls too low, the value comes out of the common shareholders; they get squeezed first. This is most severe in a down round where [anti-dilution provisions](https://www.dlapiperaccelerate.com/knowledge/2017/what-is-anti-dilution-and-why-does-it-matter-to-me-as-a-company-founder.html) come into play. This is the Silicon Valley version of a good ol' Wall Street bailout: **the debt (preferred) holders get saved, and the equity holders get wrecked.**\\n\\nWhat tends to happen when homeowners go underwater? We know this from history â€“ [they abandon the home](https://www.abi.org/newsroom/chart-of-the-day/serious-delinquency-rates-on-single-family-mortgages-decreased-slightly-in):\\n![Pasted-image-20220130120610](__GHOST_URL__/content/images/2022/02/Pasted-image-20220130120610.png)\\n\\nNow I ask: **what might founders and employees do once they are underwater on the preferred equity they've raised?**\\n\\nEquity value motivates founders and employees. If there's no hope for their equity to be worth anything, could we see discouraged founders and employees abandon ship in droves? Even if they don't leave the company entirely, could they effectively go \\\"delinquent\\\" and \\\"check out,\\\" significantly reducing their company-focused effort and output?\\n\\nIn startups, we see acceleration of value impairment: as things get worse, they get even worse. Not a great underwriting scenario for a debt-like instrument huh?\\n\\nPoor performance alone doesn't create a \\\"[zombie startup](http://www.daniellemorrill.com/2013/03/zombie-startups/).\\\"  Zombification requires *the total evisceration of team vitality and morale*. Thus, SchrÃ¶dinger's cat becomes SchrÃ¶dinger's zombie:\\n> \\\"â€¦ it's very easy to get into this 'zombie mode,' where your startup is **neither truly succeeding nor dying**â€¦ This is actually worse than failing.\\\" â€“ [Drew Houston, Founder of Dropbox](https://www.businessinsider.com/drew-houston-dropbox-startup-advice-2018-12)\\n\\n## ~~Schrodinger's~~ Pandora's box\\n\\nImagine you're selling your home and the buyer offers to pay you 50% above the asking price as long as they can get \\\"preferred equity\\\" in your home. You'd be ecstatic about the richer sale price, but you'd also be really curious to know what in the world \\\"preferred equity\\\" is and why it's so valuable to them!\\n\\nLikewise, as a founder or startup employee, even if corporate finance isn't your favorite topic, you should wonder why investors value preferred equity so highly.\\n\\nWhat could investors be so concerned about that they would willingly overpay by 50%? And if they're so concerned, do you think, maybe, you should be too?\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: Schrodinger's Balance Sheet: When Equity Becomes a Liability\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p><a href=\"https://www.svb.com/blogs/lewis-hower/startup-founders-should-know-preferred-stock\">Preferred equity</a> is synthetic leverage.</p>\n<p>It combines an equity-like security with a debt-like security. Which one it is depends on the success of the business:</p>\n<ul>\n<li>When things go well, preferred stock converts to standard common equity.</li>\n<li>When things go poorly, preferred stock turns into debt.</li>\n</ul>\n<p>In this way, preferred equity exists in a constant state of <a href=\"https://scienceexchange.caltech.edu/topics/quantum-science-explained/quantum-superposition\"><strong>quantum superposition</strong></a>. It's neither equity nor debt, until it is.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Schrodinger's Balance Sheet: When Equity Becomes a Liability\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"schr%C3%B6dingers-balance-sheet\">SchrÃ¶dinger's balance sheet</h2>\n<p><img src=\"__GHOST_URL__/content/images/2022/02/Schrodingers_cat.svg\" alt=\"Schrodingers_cat\" loading=\"lazy\"></p>\n<p><a href=\"https://en.wikipedia.org/wiki/Erwin_Schr%C3%B6dinger\">Erwin SchrÃ¶dinger</a> was a renowned physicist and one of the first to study the strange world of quantum theory. Among us mortals, he is most known for his famous thought experiment, eponymously called &quot;<a href=\"https://en.wikipedia.org/wiki/Schr%C3%B6dinger%27s_cat\">SchrÃ¶dinger's cat</a>.&quot; In it, he posited that a cat sitting in a box along with a flask of poison could be considered to be both dead *and* alive until we open the box to find out if the flask has shattered, killing the poor kitty.</p>\n<p><strong>Preferred equity is like SchrÃ¶dinger's cat.</strong> Open the box: if a startup is very valuable, preferred stock all becomes normal equity. If the box contains a dead or slow growing startup that hasn't created much value, preferred stock becomes debt instead.</p>\n<p>You can think about preferred equity as debt combined with a deeply out of the money <a href=\"https://www.investopedia.com/terms/c/calloption.asp\">call option</a>. &quot;<a href=\"https://www.investopedia.com/terms/o/outofthemoney.asp\"><em>Out of the money</em></a>&quot; is just a fancy way of saying the investor won't make much of a return unless the company gains significant value. If the company creates no value from that point forward, the option component is worthless, and the equity merely becomes debt. If the company creates significant value, the importance of the debt element wanes and the option component dominates the return profile.</p>\n<p>Strangely enough, this is the exact <em>reverse</em> of what you'd want to have happen as a founder.</p>\n<p>This point has been made by <a href=\"https://www.gsb.stanford.edu/healthy-banking-system-goal\">John Cochrane and others</a> in the context of bank capitalization:</p>\n<blockquote>\n<p>Ensuring that banks are funded with significantly more equity should be a key element of effective bank regulatory reform. Much more equity funding would permit banks to perform all their useful functions and support growth without endangering the financial system by systemic fragility.</p>\n</blockquote>\n<p>Things go very wrong when banks are overly-funded with debt, as debt tends not to &quot;fail gracefully&quot; the way equity does. In financial crises, banks &quot;break&quot; in a very <em>hard</em> way due to the significant debt they carry, which must be paid back, necessitating government bailouts in the worst case scenarios. On the other hand, equity tends to break in a <em>soft</em> way: if the company isn't worth anything, nothing is owed. Thus a sudden decline in the value of the company doesn't cause a severe panic.</p>\n<p>Cochrane goes so far as to advocate that in times of financial distress, debt on the balance sheet of struggling banks should simply <a href=\"https://static1.squarespace.com/static/5e6033a4ea02d801f37e15bb/t/5ee802f76e77d94cab19b981/1592263416691/across-the-great-divide-ch10.pdf\">convert to equity</a> rather than be bailed out by the government. Notice what he's proposing â€“ debt on the <em>upside</em> and equity on the <em>downside</em>.</p>\n<p>Likewise, as a founder, you'd want your capital structure to be equity when things go badly, making it a variable cost that declines gracefully as your business success declines, and you'd want it to be debt in the upside case, effectively acting as a fixed cost over which you get leverage.</p>\n<p>In startup land, however, we do the opposite â€“ <em>we convert equity to debt in times of distress.</em></p>\n<h2 id=\"spin-up\">Spin up</h2>\n<p>Preferred equity is more valuable to investors than common equity, so they're willing to pay more for it, necessitating the issuance of fewer shares and leading to less dilution for the company. Thus, <em>relative to raising common equity</em>, preferred equity has a similar benefit as debt, in that it allows you to raise more capital with less dilution.</p>\n<p>In this way, startups become <strong>synthetically levered</strong>. No debt appears on the balance sheet, yet the returns of the common equity (really anyone below the most senior preferred stock) get juiced by the lower cost of capital achieved via preferred equity.</p>\n<p>The value of preferred stock can be inferred from its cost, i.e. its premium relative to common equity. The preferred equity premium is rarely laid out explicitly, but researchers at Stanford and the University of British Columbia estimate that these days <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3725240\"><strong>preferred equity is 50% more valuable than common equity</strong></a> and was even more valuable in the past:<br>\n<img src=\"__GHOST_URL__/content/images/2022/02/Pasted-image-20211201152745.png\" alt=\"Pasted-image-20211201152745\" loading=\"lazy\"></p>\n<blockquote>\n<p>This paper develops the first option pricing model of venture capital-backed companies and their security values that incorporates the dilutive future financing rounds prevalent in the industry. Applying our model to 19,000 companies raising 37,000 rounds shows that preferred contractual features make <strong>the most recently issued preferred shares worth on average 56% more than common shares</strong> â€“ <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3725240\">A Valuation Model of Venture Capital-Backed Companies with Multiple Financing Rounds</a></p>\n</blockquote>\n<p>A quick illustration: you're a founder, and you know you need to raise roughly $60M to achieve a meaningful outcome. Because preferred equity is worth 50% more to investors than common, you could either raise $60M in preferred stock with some level of dilution, or raise it all in common stock for 50% more dilution. Let's say the common approach would dilute you by 60%. Then raising the same amount via preferred would only dilute you by 40%:</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Preferred</th>\n<th>Common</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Capital raised</td>\n<td>$60M</td>\n<td>$60M</td>\n</tr>\n<tr>\n<td>Total shares</td>\n<td>100</td>\n<td>100</td>\n</tr>\n<tr>\n<td>Blended price/share</td>\n<td>$1.50</td>\n<td>$1.00</td>\n</tr>\n<tr>\n<td>Shares purchased</td>\n<td>40</td>\n<td>60</td>\n</tr>\n<tr>\n<td><strong>Dilution</strong></td>\n<td><strong>40%</strong></td>\n<td><strong>60%</strong></td>\n</tr>\n</tbody>\n</table>\n<p>This obviously makes a massive difference in an upside scenario. Simply put, <strong>you get to keep much, much more of your company.</strong> When things work out, preferred equity has a higher cost to investors, and a lower cost to startups.</p>\n<p>This is obviously great in a bull market. Cheap, bountiful leverage, available oftentimes for a fraction of the painful diligence associated with raising real debt.</p>\n<p>The availability of preferred equity drives companies to raise more than they otherwise would. We'll look at such a scenario next.</p>\n<h2 id=\"spin-down\">Spin down</h2>\n<p>When rates of return are sufficiently low, preferred equity begins to look eerily like debt. When are rates of return lowest? <a href=\"https://whoisnnamdi.com/grow-valuation/\">When valuations are highest</a>:</p>\n<blockquote>\n<p><strong>High valuation multiples corresponds to lower returns</strong>, and vice versa. After periods of frothy valuations, returns end up lower than expected, bringing lofty valuations multiples back down to reality â€“ <a href=\"https://whoisnnamdi.com/grow-valuation/\">Companies Rarely Grow Into Their Valuations</a></p>\n</blockquote>\n<p>The mountains of preferred equity being layered into private companies follows the same behavioral vein typically seen during the peak of a market cycle, that is, <strong>massive overuse and abuse of debt that juices returns.</strong> This has predictably disastrous consequences when things go south.</p>\n<p>As is common in finance, <strong>the problems with debt reveal themselves only once it blows up.</strong> In a downside scenario, the returns of common equity holders get crushed by the weight of the liquidation preference attached to preferred equity.</p>\n<p>Remember, venture capital investors are willing to pay $1.50 for preferred equity granting <em>the same ownership</em> they could get for $1 of common equity. In an upside scenario, they effectively pay $1.50 for $1's worth of equity. What happens in a downside scenario?</p>\n<p>Let's return to our previous example. This time, the company chooses a certain, fixed level of dilution that it's willing to endure, 60%, and raises money up to that point. Since preferred stock can be issued at a premium, the company can raise $90M of it for the same dilution as $60M of common:</p>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>Preferred</th>\n<th>Common</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Capital raised</td>\n<td>$90M</td>\n<td>$60M</td>\n</tr>\n<tr>\n<td>Total shares</td>\n<td>100</td>\n<td>100</td>\n</tr>\n<tr>\n<td>Blended price/share</td>\n<td>$1.50</td>\n<td>$1.00</td>\n</tr>\n<tr>\n<td>Shares purchased</td>\n<td>60</td>\n<td>60</td>\n</tr>\n<tr>\n<td><strong>Dilution</strong></td>\n<td><strong>60%</strong></td>\n<td><strong>60%</strong></td>\n</tr>\n</tbody>\n</table>\n<p>So far so good. The preferred approach gives you $30M more to put to work in the business. But let's say <a href=\"https://whoisnnamdi.com/product-market-fit-is-lindy/\">you never quite achieve product-market fit</a> (not uncommon, even among companies that have raised tens of millions of dollars) and you woefully underperform expectations. You never become a unicorn, and the business is sold for only $100M:</p>\n<ul>\n<li>If you only raised common equity, the founders and employees walk away with $40M. Not as much as hoped for, but not bad!</li>\n<li>If you raised preferred however, founders and employees walk away with only $10M, since the equity is now debt, and the investors must receive their &quot;1x <a href=\"https://www.seedinvest.com/blog/angel-investing/liquidation-preferences\">liquidation preference</a>&quot; (their &quot;principal&quot; effectively). Brutal.</li>\n</ul>\n<p>This may offer a clue into why the hedge funds of the world have moved so swiftly into venture. As sophisticated, multi-asset investors, they are quite used to lower-returning, low-risk credit investing combined with potentially high-returning, high-risk derivatives. Rather than &quot;fish out of water&quot;, as they are often portrayed by traditional venture investors, could they in fact be quite shrewd <a href=\"https://randle.substack.com/p/playing-different-games\">(tiger)sharks</a>?</p>\n<p>The rabbit hole goes further. Define &quot;overvaluation&quot; as the premium at which preferred stock is valued relative to common equity. Analysis shows <strong>overvaluation predicts poor exit outcomes</strong>, measured in terms of (1) exit value and (2) the probability of going public or being bought out (note: <a href=\"https://blog.minitab.com/en/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit\">low R^2 implies exit outcomes are difficult to predict</a>, not that the relationships aren't statistically significant):<br>\n<img src=\"__GHOST_URL__/content/images/2022/02/Pasted-image-20220206175842.png\" alt=\"Pasted-image-20220206175842\" loading=\"lazy\"></p>\n<blockquote>\n<p>â€¦ <strong>overvaluation predicts low exit outcomes</strong>â€¦ The extent of this overstatement predicts poor subsequent performance â€“ <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3725240\">A Valuation Model of Venture Capital-Backed Companies with Multiple Financing Rounds</a></p>\n</blockquote>\n<p><strong>Abuse of preferred equity predicts worse outcomes, fewer exits, and lower returns.</strong></p>\n<p>Synthetic leverage, as with all forms of financial leverage, makes bad situations <em>even worse</em> <strong>AND</strong> <em>more likely</em>.</p>\n<h2 id=\"superposition\">Superposition</h2>\n<p>Now, let's finally explore the quirky quantum world of superposition.</p>\n<p>Preferred equity starts as neither debt nor equity: you have to &quot;open the box&quot; to see if the company is successful. Unfortunately, actions that make your upside better (raising a ton of money and putting it to work in the business) also make your downside worse. Things that look smart in the upside scenario (raising a &quot;war chest&quot;) look disastrous in retrospect on the downside. Gain and pain are entangled; success and failure are superimposed on one another.</p>\n<p><strong>Perversely, the Silicon Valley ecosystem creates more synthetic debt (i.e. preferred equity) exactly as returns fall:</strong></p>\n<ol>\n<li>Valuations rise</li>\n<li>Companies take advantage by issuing more preferred stock</li>\n<li>Returns fall due to inflated valuations</li>\n<li>Preferred stock converges toward debt</li>\n</ol>\n<p>Let's return to financial crises. The capital stack of a company is very similar to that of a home. From the perspective of the founder, common stock is the &quot;equity&quot; in the home and preferred stock is the debt or mortgage. If value of home falls below the principal on the mortgage, the homeowner is &quot;<a href=\"https://www.investopedia.com/terms/u/underwater-mortgage.asp\">underwater</a>&quot;, destroying the value of their equity.</p>\n<p>Likewise, when a startup's valuation falls too low, the value comes out of the common shareholders; they get squeezed first. This is most severe in a down round where <a href=\"https://www.dlapiperaccelerate.com/knowledge/2017/what-is-anti-dilution-and-why-does-it-matter-to-me-as-a-company-founder.html\">anti-dilution provisions</a> come into play. This is the Silicon Valley version of a good ol' Wall Street bailout: <strong>the debt (preferred) holders get saved, and the equity holders get wrecked.</strong></p>\n<p>What tends to happen when homeowners go underwater? We know this from history â€“ <a href=\"https://www.abi.org/newsroom/chart-of-the-day/serious-delinquency-rates-on-single-family-mortgages-decreased-slightly-in\">they abandon the home</a>:<br>\n<img src=\"__GHOST_URL__/content/images/2022/02/Pasted-image-20220130120610.png\" alt=\"Pasted-image-20220130120610\" loading=\"lazy\"></p>\n<p>Now I ask: <strong>what might founders and employees do once they are underwater on the preferred equity they've raised?</strong></p>\n<p>Equity value motivates founders and employees. If there's no hope for their equity to be worth anything, could we see discouraged founders and employees abandon ship in droves? Even if they don't leave the company entirely, could they effectively go &quot;delinquent&quot; and &quot;check out,&quot; significantly reducing their company-focused effort and output?</p>\n<p>In startups, we see acceleration of value impairment: as things get worse, they get even worse. Not a great underwriting scenario for a debt-like instrument huh?</p>\n<p>Poor performance alone doesn't create a &quot;<a href=\"http://www.daniellemorrill.com/2013/03/zombie-startups/\">zombie startup</a>.&quot;  Zombification requires <em>the total evisceration of team vitality and morale</em>. Thus, SchrÃ¶dinger's cat becomes SchrÃ¶dinger's zombie:</p>\n<blockquote>\n<p>&quot;â€¦ it's very easy to get into this 'zombie mode,' where your startup is <strong>neither truly succeeding nor dying</strong>â€¦ This is actually worse than failing.&quot; â€“ <a href=\"https://www.businessinsider.com/drew-houston-dropbox-startup-advice-2018-12\">Drew Houston, Founder of Dropbox</a></p>\n</blockquote>\n<h2 id=\"schrodingers-pandoras-box\"><s>Schrodinger's</s> Pandora's box</h2>\n<p>Imagine you're selling your home and the buyer offers to pay you 50% above the asking price as long as they can get &quot;preferred equity&quot; in your home. You'd be ecstatic about the richer sale price, but you'd also be really curious to know what in the world &quot;preferred equity&quot; is and why it's so valuable to them!</p>\n<p>Likewise, as a founder or startup employee, even if corporate finance isn't your favorite topic, you should wonder why investors value preferred equity so highly.</p>\n<p>What could investors be so concerned about that they would willingly overpay by 50%? And if they're so concerned, do you think, maybe, you should be too?</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: Schrodinger's Balance Sheet: When Equity Becomes a Liability\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"62008a02fec7d1542d1d2af2","plaintext":"Preferred equity\n[https://www.svb.com/blogs/lewis-hower/startup-founders-should-know-preferred-stock] \nis synthetic leverage.\n\nIt combines an equity-like security with a debt-like security. Which one it is\ndepends on the success of the business:\n\n * When things go well, preferred stock converts to standard common equity.\n * When things go poorly, preferred stock turns into debt.\n\nIn this way, preferred equity exists in a constant state of quantum\nsuperposition\n[https://scienceexchange.caltech.edu/topics/quantum-science-explained/quantum-superposition]\n. It's neither equity nor debt, until it is.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡SchrÃ¶dinger's balance sheet\n\n\nErwin SchrÃ¶dinger [https://en.wikipedia.org/wiki/Erwin_Schr%C3%B6dinger] was a\nrenowned physicist and one of the first to study the strange world of quantum\ntheory. Among us mortals, he is most known for his famous thought experiment,\neponymously called \"SchrÃ¶dinger's cat\n[https://en.wikipedia.org/wiki/Schr%C3%B6dinger%27s_cat].\" In it, he posited\nthat a cat sitting in a box along with a flask of poison could be considered to\nbe both dead *and* alive until we open the box to find out if the flask has\nshattered, killing the poor kitty.\n\nPreferred equity is like SchrÃ¶dinger's cat. Open the box: if a startup is very\nvaluable, preferred stock all becomes normal equity. If the box contains a dead\nor slow growing startup that hasn't created much value, preferred stock becomes\ndebt instead.\n\nYou can think about preferred equity as debt combined with a deeply out of the\nmoney call option [https://www.investopedia.com/terms/c/calloption.asp]. \"Out\nof\nthe money [https://www.investopedia.com/terms/o/outofthemoney.asp]\" is just a\nfancy way of saying the investor won't make much of a return unless the company\ngains significant value. If the company creates no value from that point\nforward, the option component is worthless, and the equity merely becomes debt.\nIf the company creates significant value, the importance of the debt element\nwanes and the option component dominates the return profile.\n\nStrangely enough, this is the exact reverse of what you'd want to have happen as\na founder.\n\nThis point has been made by John Cochrane and others\n[https://www.gsb.stanford.edu/healthy-banking-system-goal] in the context of\nbank capitalization:\n\n> Ensuring that banks are funded with significantly more equity should be a key\nelement of effective bank regulatory reform. Much more equity funding would\npermit banks to perform all their useful functions and support growth without\nendangering the financial system by systemic fragility.\n\n\nThings go very wrong when banks are overly-funded with debt, as debt tends not\nto \"fail gracefully\" the way equity does. In financial crises, banks \"break\" in\na very hard way due to the significant debt they carry, which must be paid back,\nnecessitating government bailouts in the worst case scenarios. On the other\nhand, equity tends to break in a soft way: if the company isn't worth anything,\nnothing is owed. Thus a sudden decline in the value of the company doesn't cause\na severe panic.\n\nCochrane goes so far as to advocate that in times of financial distress, debt on\nthe balance sheet of struggling banks should simply convert to equity\n[https://static1.squarespace.com/static/5e6033a4ea02d801f37e15bb/t/5ee802f76e77d94cab19b981/1592263416691/across-the-great-divide-ch10.pdf] \nrather than be bailed out by the government. Notice what he's proposing â€“ debt\non the upside and equity on the downside.\n\nLikewise, as a founder, you'd want your capital structure to be equity when\nthings go badly, making it a variable cost that declines gracefully as your\nbusiness success declines, and you'd want it to be debt in the upside case,\neffectively acting as a fixed cost over which you get leverage.\n\nIn startup land, however, we do the opposite â€“ we convert equity to debt in\ntimes of distress.\n\nSpin up\nPreferred equity is more valuable to investors than common equity, so they're\nwilling to pay more for it, necessitating the issuance of fewer shares and\nleading to less dilution for the company. Thus, relative to raising common\nequity, preferred equity has a similar benefit as debt, in that it allows you to\nraise more capital with less dilution.\n\nIn this way, startups become synthetically levered. No debt appears on the\nbalance sheet, yet the returns of the common equity (really anyone below the\nmost senior preferred stock) get juiced by the lower cost of capital achieved\nvia preferred equity.\n\nThe value of preferred stock can be inferred from its cost, i.e. its premium\nrelative to common equity. The preferred equity premium is rarely laid out\nexplicitly, but researchers at Stanford and the University of British Columbia\nestimate that these days preferred equity is 50% more valuable than common\nequity [https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3725240] and was\neven more valuable in the past:\n\n\n> This paper develops the first option pricing model of venture capital-backed\ncompanies and their security values that incorporates the dilutive future\nfinancing rounds prevalent in the industry. Applying our model to 19,000\ncompanies raising 37,000 rounds shows that preferred contractual features make \nthe most recently issued preferred shares worth on average 56% more than common\nshares â€“ A Valuation Model of Venture Capital-Backed Companies with Multiple\nFinancing Rounds [https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3725240]\n\n\nA quick illustration: you're a founder, and you know you need to raise roughly\n$60M to achieve a meaningful outcome. Because preferred equity is worth 50% more\nto investors than common, you could either raise $60M in preferred stock with\nsome level of dilution, or raise it all in common stock for 50% more dilution.\nLet's say the common approach would dilute you by 60%. Then raising the same\namount via preferred would only dilute you by 40%:\n\nPreferredCommonCapital raised$60M$60MTotal shares100100Blended price/share$1.50\n$1.00Shares purchased4060Dilution40%60%This obviously makes a massive difference\nin an upside scenario. Simply put, you get to keep much, much more of your\ncompany. When things work out, preferred equity has a higher cost to investors,\nand a lower cost to startups.\n\nThis is obviously great in a bull market. Cheap, bountiful leverage, available\noftentimes for a fraction of the painful diligence associated with raising real\ndebt.\n\nThe availability of preferred equity drives companies to raise more than they\notherwise would. We'll look at such a scenario next.\n\nSpin down\nWhen rates of return are sufficiently low, preferred equity begins to look\neerily like debt. When are rates of return lowest? When valuations are highest\n[https://whoisnnamdi.com/grow-valuation/]:\n\n> High valuation multiples corresponds to lower returns, and vice versa. After\nperiods of frothy valuations, returns end up lower than expected, bringing lofty\nvaluations multiples back down to reality â€“ Companies Rarely Grow Into Their\nValuations [https://whoisnnamdi.com/grow-valuation/]\n\n\nThe mountains of preferred equity being layered into private companies follows\nthe same behavioral vein typically seen during the peak of a market cycle, that\nis, massive overuse and abuse of debt that juices returns. This has predictably\ndisastrous consequences when things go south.\n\nAs is common in finance, the problems with debt reveal themselves only once it\nblows up. In a downside scenario, the returns of common equity holders get\ncrushed by the weight of the liquidation preference attached to preferred\nequity.\n\nRemember, venture capital investors are willing to pay $1.50 for preferred\nequity granting the same ownership they could get for $1 of common equity. In an\nupside scenario, they effectively pay $1.50 for $1's worth of equity. What\nhappens in a downside scenario?\n\nLet's return to our previous example. This time, the company chooses a certain,\nfixed level of dilution that it's willing to endure, 60%, and raises money up to\nthat point. Since preferred stock can be issued at a premium, the company can\nraise $90M of it for the same dilution as $60M of common:\n\nPreferredCommonCapital raised$90M$60MTotal shares100100Blended price/share$1.50\n$1.00Shares purchased6060Dilution60%60%So far so good. The preferred approach\ngives you $30M more to put to work in the business. But let's say you never\nquite achieve product-market fit\n[https://whoisnnamdi.com/product-market-fit-is-lindy/] (not uncommon, even among\ncompanies that have raised tens of millions of dollars) and you woefully\nunderperform expectations. You never become a unicorn, and the business is sold\nfor only $100M:\n\n * If you only raised common equity, the founders and employees walk away with\n   $40M. Not as much as hoped for, but not bad!\n * If you raised preferred however, founders and employees walk away with only\n   $10M, since the equity is now debt, and the investors must receive their \"1x \n   liquidation preference\n   [https://www.seedinvest.com/blog/angel-investing/liquidation-preferences]\"\n   (their \"principal\" effectively). Brutal.\n\nThis may offer a clue into why the hedge funds of the world have moved so\nswiftly into venture. As sophisticated, multi-asset investors, they are quite\nused to lower-returning, low-risk credit investing combined with potentially\nhigh-returning, high-risk derivatives. Rather than \"fish out of water\", as they\nare often portrayed by traditional venture investors, could they in fact be\nquite shrewd (tiger)sharks\n[https://randle.substack.com/p/playing-different-games]?\n\nThe rabbit hole goes further. Define \"overvaluation\" as the premium at which\npreferred stock is valued relative to common equity. Analysis shows \novervaluation predicts poor exit outcomes, measured in terms of (1) exit value\nand (2) the probability of going public or being bought out (note: low R^2\nimplies exit outcomes are difficult to predict\n[https://blog.minitab.com/en/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit]\n, not that the relationships aren't statistically significant):\n\n\n> â€¦ overvaluation predicts low exit outcomesâ€¦ The extent of this overstatement\npredicts poor subsequent performance â€“ A Valuation Model of Venture\nCapital-Backed Companies with Multiple Financing Rounds\n[https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3725240]\n\n\nAbuse of preferred equity predicts worse outcomes, fewer exits, and lower\nreturns.\n\nSynthetic leverage, as with all forms of financial leverage, makes bad\nsituations even worse AND more likely.\n\nSuperposition\nNow, let's finally explore the quirky quantum world of superposition.\n\nPreferred equity starts as neither debt nor equity: you have to \"open the box\"\nto see if the company is successful. Unfortunately, actions that make your\nupside better (raising a ton of money and putting it to work in the business)\nalso make your downside worse. Things that look smart in the upside scenario\n(raising a \"war chest\") look disastrous in retrospect on the downside. Gain and\npain are entangled; success and failure are superimposed on one another.\n\nPerversely, the Silicon Valley ecosystem creates more synthetic debt (i.e.\npreferred equity) exactly as returns fall:\n\n 1. Valuations rise\n 2. Companies take advantage by issuing more preferred stock\n 3. Returns fall due to inflated valuations\n 4. Preferred stock converges toward debt\n\nLet's return to financial crises. The capital stack of a company is very similar\nto that of a home. From the perspective of the founder, common stock is the\n\"equity\" in the home and preferred stock is the debt or mortgage. If value of\nhome falls below the principal on the mortgage, the homeowner is \"underwater\n[https://www.investopedia.com/terms/u/underwater-mortgage.asp]\", destroying the\nvalue of their equity.\n\nLikewise, when a startup's valuation falls too low, the value comes out of the\ncommon shareholders; they get squeezed first. This is most severe in a down\nround where anti-dilution provisions\n[https://www.dlapiperaccelerate.com/knowledge/2017/what-is-anti-dilution-and-why-does-it-matter-to-me-as-a-company-founder.html] \ncome into play. This is the Silicon Valley version of a good ol' Wall Street\nbailout: the debt (preferred) holders get saved, and the equity holders get\nwrecked.\n\nWhat tends to happen when homeowners go underwater? We know this from history â€“ \nthey abandon the home\n[https://www.abi.org/newsroom/chart-of-the-day/serious-delinquency-rates-on-single-family-mortgages-decreased-slightly-in]\n:\n\n\nNow I ask: what might founders and employees do once they are underwater on the\npreferred equity they've raised?\n\nEquity value motivates founders and employees. If there's no hope for their\nequity to be worth anything, could we see discouraged founders and employees\nabandon ship in droves? Even if they don't leave the company entirely, could\nthey effectively go \"delinquent\" and \"check out,\" significantly reducing their\ncompany-focused effort and output?\n\nIn startups, we see acceleration of value impairment: as things get worse, they\nget even worse. Not a great underwriting scenario for a debt-like instrument\nhuh?\n\nPoor performance alone doesn't create a \"zombie startup\n[http://www.daniellemorrill.com/2013/03/zombie-startups/].\" Zombification\nrequires the total evisceration of team vitality and morale. Thus, SchrÃ¶dinger's\ncat becomes SchrÃ¶dinger's zombie:\n\n> \"â€¦ it's very easy to get into this 'zombie mode,' where your startup is neither\ntruly succeeding nor dyingâ€¦ This is actually worse than failing.\" â€“ Drew\nHouston, Founder of Dropbox\n[https://www.businessinsider.com/drew-houston-dropbox-startup-advice-2018-12]\n\n\nSchrodinger's Pandora's box\nImagine you're selling your home and the buyer offers to pay you 50% above the\nasking price as long as they can get \"preferred equity\" in your home. You'd be\necstatic about the richer sale price, but you'd also be really curious to know\nwhat in the world \"preferred equity\" is and why it's so valuable to them!\n\nLikewise, as a founder or startup employee, even if corporate finance isn't your\nfavorite topic, you should wonder why investors value preferred equity so\nhighly.\n\nWhat could investors be so concerned about that they would willingly overpay by\n50%? And if they're so concerned, do you think, maybe, you should be too?\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2022/02/header.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2022-02-07T02:54:58.000Z","updated_at":"2022-02-13T22:01:57.000Z","published_at":"2022-02-07T14:55:54.000Z","custom_excerpt":"Preferred equity exists in a constant state of quantum superposition. It's neither equity nor debt, until it is.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"621fdf62fec7d1542d1d2b2e","uuid":"8ce9de25-3da1-44ef-b00a-d5995d88143a","title":"Breaking Apart the Rule of 40","slug":"rule-40","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Rules are meant to be broken, and the Rule of 40 is no exception.\\n\\nThe Rule of 40 is a popular heuristic for evaluating financial performance and predicting valuation multiples.\\n\\nBut it's got ~~99~~ 3 problems:\\n- It's too rigid\\n- It's too short-term\\n- It's too narrowly focused\\n\\nIn this essay, I break apart the Rule of 40, fix it, and put it back together again.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Breaking Apart the Rule of 40\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## Laying down the rules\\n\\nAfter flying high for some time, software valuation multiples have come back down to Earth (Note: LTM multiples used throughout this article):\\n![rev_mul](__GHOST_URL__/content/images/2022/03/rev_mul.png)\\n\\nWhile there are [all sorts](https://whoisnnamdi.com/grow-valuation/) of [explanations](https://whoisnnamdi.com/high-retention-high-volatility/) for the recent tech correction, the [Rule of 40](https://feld.com/archives/2015/02/rule-40-healthy-saas-company/) concerns itself not so much with the ebbs and flows of software valuations but rather their determinants at *a single point-in-time*. It provides a simple rule of thumb for evaluating the performance of software companies and estimating their likely valuation multiples:\\n\\n$$\\\\text{Rule of 40} = \\\\text{Growth} + \\\\text{Profitability}$$\\n\\nThe Rule of 40 states that the sum of annual revenue growth and profitability (either EBITDA or free cash flow margin) should equal 40 or more for the best performing companies, as in the following slide from [Battery Ventures' Software 2021 deck](https://www.scribd.com/document/497410287/Battery-Ventures-Software-2021-Report):\\n![Pasted-image-20220222124207](__GHOST_URL__/content/images/2022/03/Pasted-image-20220222124207.png)\\n\\nIn general though, the \\\"40\\\" isn't particularly important. Higher is better; that's it.\\n\\n## \\\"Houston, we have three problems\\\"\\n\\nI see three problems with standard Rule of 40 analysis.\\n\\n### Problem #1: Revenue and margin may not be equally important\\n\\nBecause the Rule of 40 adds revenue and margin together with no particular weighting of each (it's analogous to a simple average), in a subtle way it implies they are of equal importance.\\n\\nThis isn't necessarily true of course. An additional point of revenue growth could be worth more, the same, or less than an additional point of profitability.\\n\\n**Fix #1: include revenue and margin separately in our regressions.**\\n\\n### Problem #2: The long-run may look quite different\\n\\nEven if revenue and margin were equally important on average, their relative importance could change over time.\\n\\nFolks tend to run Rule of 40 regressions at a particular point in time, revealing how the market values growth and margin today, and today alone, saying nothing about how those relationships change over the long-run.\\n\\nIn a bull market, where growth is highly valued, our regressions fool us into thinking growth will be forever important. When the market subsequently turns, growth gets crushed, needlessly surprising many analysts and investors.\\n\\n**Fix #2: pool data from multiple time periods.**\\n\\n### Problem #3: Growth and margin aren't the only factors\\n\\nSimple regressions inflate the importance of the Rule of 40 by misattributing the influence of other factors to growth and margin.\\n\\nFor example: Snowflake is a high flying company, both in terms of it's growth rate and revenue multiple. But Snowflake really is a special snowflake â€“ it has a lot of other things going for it too, like the massive market for data warehouse solutions.\\n\\nThus, naively comparing Snowflake and other companies with smaller markets in the same regression will tend to overstate the value of revenue growth, leading to the false impression that, \\\"if only we grow as fast as Snowflake, we'll be valued just as highly.\\\" This is wrong.\\n\\n**Fix #3: control for the average influence of unobserved factors.**\\n\\n## If it's broken, fix it\\n\\nLet's implement each of these fixes one-by-one to see how they influence the results.\\n\\nHere's the impact of revenue growth and free cash flow margin on valuation multiples with each of the three fixes implemented sequentially:\\n![regs](__GHOST_URL__/content/images/2022/03/regs.png)\\n\\n**First**, let's split up growth and margin to see how they separately impact valuations. To start, we pick a random date, June 30th 2021:\\n- According to this simple analysis, a single additional percentage point of revenue growth increases valuation multiples by 3%, while an additional percentage point of free cash flow margin only adds 0.5%.\\n- By this measure, growth is six times as important as margin.\\n\\n**Second**, we'll pool together two years of trading data, excluding any companies that went public or got acquired during this time so we maintain a balanced sample throughout. The regression reveals the *average* importance of growth and profitability over *the entire period*:\\n- An additional point of revenue growth leads to a 2.7% higher revenue multiple (down from 3%) while an additional point of free cash flow margin yields 1.1% higher valuation (up from 0.5%).\\n- Growth matters only ~2.5x as much as margin.\\n\\n**Lastly**, the results still suffer from the fact that we're attempting to explain all the complexities of valuation with only two variables (the \\\"Snowflake problem\\\"), giving credit to growth and margin where credit isn't due. The final regression controls for the average impact of these unobserved factors ([fixed effects](https://www.youtube.com/watch?v=sFvV9b1cGFc) for the econometrics nerds):\\n- 1 point of either revenue growth or free cash flow margin increases valuation multiples by 1%.\\n- **Growth and margin matter equally.**\\n\\nSo it turns out growth and margin are equally important after all!\\n\\nNote: it may be much easier to increase growth or margin by one percentage point, so we have to be a little careful in saying they \\\"matter equally.\\\"\\n\\nStill, we've much more rigorously confirmed that growth and margin have similar effects on valuation. Very cool.\\n\\n## How the rules have changed\\n\\nHere's how the market value of growth and profitability have evolved over time:\\n![fe](__GHOST_URL__/content/images/2022/03/fe.png)\\n\\nWe can see a number of interesting features:\\n- The market value of profitability temporarily spiked in the early days of the pandemic but then fell significantly, bottoming out at almost zero in Q1 2021\\n- Meanwhile, the market's thirst for growth surged from only 0.5% per percentage point of growth to 1.5% at the peak in late 2020\\n- Beginning in early 2021, margin began a steady comeback, and **profitability is now as important as it was in the most uncertain days of the pandemic**\\n- The value of growth fell in early 2021, recovered somewhat, and crashed even more spectacularly later in the year, **returning growth to its pre-pandemic value**\\n\\nWe can also plot the \\\"spread\\\" between the value of growth vs. margin, an interesting chart in its own right:\\n![spread](__GHOST_URL__/content/images/2022/03/spread.png)\\n- Growth and margin start off fairly close, with a slight market preference toward margin\\n- After a brief period of uncertainty, the value of software growth relative to profitability roars back, peaking at a ~1% premium at the end of 2020\\n- Again, we see the first blow to growth in the first half of 2021 and a second blow landing in late 2021\\n- **Relative to profitability, growth is even less valuable than it was pre-COVID**\\n\\n## Rewriting the rules\\n\\nA few conclusions:\\n- On average, **growth and profitability are equally impactful to valuation**, but one may win out over the other at various periods\\n- Growth matters *much less* than simple cross-sectional regressions imply\\n- As of early 2022, **the market has turned decisively against growth in favor of profitability**\\n\\nIn a way, these results affirm the utility of the Rule of 40: growth and margin are similarly important. However it adds a wrinkle: the *degree* of similarity varies over the market cycle.\\n\\nThough the days of \\\"growth at *all* costs\\\" are clearly over, it's still fair to ask: growth at *what* cost? In other words, **how should companies trade off growth and margin?**\\n\\nI'll leave that to a future post. ðŸ‘€\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: Breaking Apart the Rule of 40\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>Rules are meant to be broken, and the Rule of 40 is no exception.</p>\n<p>The Rule of 40 is a popular heuristic for evaluating financial performance and predicting valuation multiples.</p>\n<p>But it's got <s>99</s> 3 problems:</p>\n<ul>\n<li>It's too rigid</li>\n<li>It's too short-term</li>\n<li>It's too narrowly focused</li>\n</ul>\n<p>In this essay, I break apart the Rule of 40, fix it, and put it back together again.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Breaking Apart the Rule of 40\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"laying-down-the-rules\">Laying down the rules</h2>\n<p>After flying high for some time, software valuation multiples have come back down to Earth (Note: LTM multiples used throughout this article):<br>\n<img src=\"__GHOST_URL__/content/images/2022/03/rev_mul.png\" alt=\"rev_mul\" loading=\"lazy\"></p>\n<p>While there are <a href=\"https://whoisnnamdi.com/grow-valuation/\">all sorts</a> of <a href=\"https://whoisnnamdi.com/high-retention-high-volatility/\">explanations</a> for the recent tech correction, the <a href=\"https://feld.com/archives/2015/02/rule-40-healthy-saas-company/\">Rule of 40</a> concerns itself not so much with the ebbs and flows of software valuations but rather their determinants at <em>a single point-in-time</em>. It provides a simple rule of thumb for evaluating the performance of software companies and estimating their likely valuation multiples:</p>\n<p>$$\\text{Rule of 40} = \\text{Growth} + \\text{Profitability}$$</p>\n<p>The Rule of 40 states that the sum of annual revenue growth and profitability (either EBITDA or free cash flow margin) should equal 40 or more for the best performing companies, as in the following slide from <a href=\"https://www.scribd.com/document/497410287/Battery-Ventures-Software-2021-Report\">Battery Ventures' Software 2021 deck</a>:<br>\n<img src=\"__GHOST_URL__/content/images/2022/03/Pasted-image-20220222124207.png\" alt=\"Pasted-image-20220222124207\" loading=\"lazy\"></p>\n<p>In general though, the &quot;40&quot; isn't particularly important. Higher is better; that's it.</p>\n<h2 id=\"houston-we-have-three-problems\">&quot;Houston, we have three problems&quot;</h2>\n<p>I see three problems with standard Rule of 40 analysis.</p>\n<h3 id=\"problem-1-revenue-and-margin-may-not-be-equally-important\">Problem #1: Revenue and margin may not be equally important</h3>\n<p>Because the Rule of 40 adds revenue and margin together with no particular weighting of each (it's analogous to a simple average), in a subtle way it implies they are of equal importance.</p>\n<p>This isn't necessarily true of course. An additional point of revenue growth could be worth more, the same, or less than an additional point of profitability.</p>\n<p><strong>Fix #1: include revenue and margin separately in our regressions.</strong></p>\n<h3 id=\"problem-2-the-long-run-may-look-quite-different\">Problem #2: The long-run may look quite different</h3>\n<p>Even if revenue and margin were equally important on average, their relative importance could change over time.</p>\n<p>Folks tend to run Rule of 40 regressions at a particular point in time, revealing how the market values growth and margin today, and today alone, saying nothing about how those relationships change over the long-run.</p>\n<p>In a bull market, where growth is highly valued, our regressions fool us into thinking growth will be forever important. When the market subsequently turns, growth gets crushed, needlessly surprising many analysts and investors.</p>\n<p><strong>Fix #2: pool data from multiple time periods.</strong></p>\n<h3 id=\"problem-3-growth-and-margin-arent-the-only-factors\">Problem #3: Growth and margin aren't the only factors</h3>\n<p>Simple regressions inflate the importance of the Rule of 40 by misattributing the influence of other factors to growth and margin.</p>\n<p>For example: Snowflake is a high flying company, both in terms of it's growth rate and revenue multiple. But Snowflake really is a special snowflake â€“ it has a lot of other things going for it too, like the massive market for data warehouse solutions.</p>\n<p>Thus, naively comparing Snowflake and other companies with smaller markets in the same regression will tend to overstate the value of revenue growth, leading to the false impression that, &quot;if only we grow as fast as Snowflake, we'll be valued just as highly.&quot; This is wrong.</p>\n<p><strong>Fix #3: control for the average influence of unobserved factors.</strong></p>\n<h2 id=\"if-its-broken-fix-it\">If it's broken, fix it</h2>\n<p>Let's implement each of these fixes one-by-one to see how they influence the results.</p>\n<p>Here's the impact of revenue growth and free cash flow margin on valuation multiples with each of the three fixes implemented sequentially:<br>\n<img src=\"__GHOST_URL__/content/images/2022/03/regs.png\" alt=\"regs\" loading=\"lazy\"></p>\n<p><strong>First</strong>, let's split up growth and margin to see how they separately impact valuations. To start, we pick a random date, June 30th 2021:</p>\n<ul>\n<li>According to this simple analysis, a single additional percentage point of revenue growth increases valuation multiples by 3%, while an additional percentage point of free cash flow margin only adds 0.5%.</li>\n<li>By this measure, growth is six times as important as margin.</li>\n</ul>\n<p><strong>Second</strong>, we'll pool together two years of trading data, excluding any companies that went public or got acquired during this time so we maintain a balanced sample throughout. The regression reveals the <em>average</em> importance of growth and profitability over <em>the entire period</em>:</p>\n<ul>\n<li>An additional point of revenue growth leads to a 2.7% higher revenue multiple (down from 3%) while an additional point of free cash flow margin yields 1.1% higher valuation (up from 0.5%).</li>\n<li>Growth matters only ~2.5x as much as margin.</li>\n</ul>\n<p><strong>Lastly</strong>, the results still suffer from the fact that we're attempting to explain all the complexities of valuation with only two variables (the &quot;Snowflake problem&quot;), giving credit to growth and margin where credit isn't due. The final regression controls for the average impact of these unobserved factors (<a href=\"https://www.youtube.com/watch?v=sFvV9b1cGFc\">fixed effects</a> for the econometrics nerds):</p>\n<ul>\n<li>1 point of either revenue growth or free cash flow margin increases valuation multiples by 1%.</li>\n<li><strong>Growth and margin matter equally.</strong></li>\n</ul>\n<p>So it turns out growth and margin are equally important after all!</p>\n<p>Note: it may be much easier to increase growth or margin by one percentage point, so we have to be a little careful in saying they &quot;matter equally.&quot;</p>\n<p>Still, we've much more rigorously confirmed that growth and margin have similar effects on valuation. Very cool.</p>\n<h2 id=\"how-the-rules-have-changed\">How the rules have changed</h2>\n<p>Here's how the market value of growth and profitability have evolved over time:<br>\n<img src=\"__GHOST_URL__/content/images/2022/03/fe.png\" alt=\"fe\" loading=\"lazy\"></p>\n<p>We can see a number of interesting features:</p>\n<ul>\n<li>The market value of profitability temporarily spiked in the early days of the pandemic but then fell significantly, bottoming out at almost zero in Q1 2021</li>\n<li>Meanwhile, the market's thirst for growth surged from only 0.5% per percentage point of growth to 1.5% at the peak in late 2020</li>\n<li>Beginning in early 2021, margin began a steady comeback, and <strong>profitability is now as important as it was in the most uncertain days of the pandemic</strong></li>\n<li>The value of growth fell in early 2021, recovered somewhat, and crashed even more spectacularly later in the year, <strong>returning growth to its pre-pandemic value</strong></li>\n</ul>\n<p>We can also plot the &quot;spread&quot; between the value of growth vs. margin, an interesting chart in its own right:<br>\n<img src=\"__GHOST_URL__/content/images/2022/03/spread.png\" alt=\"spread\" loading=\"lazy\"></p>\n<ul>\n<li>Growth and margin start off fairly close, with a slight market preference toward margin</li>\n<li>After a brief period of uncertainty, the value of software growth relative to profitability roars back, peaking at a ~1% premium at the end of 2020</li>\n<li>Again, we see the first blow to growth in the first half of 2021 and a second blow landing in late 2021</li>\n<li><strong>Relative to profitability, growth is even less valuable than it was pre-COVID</strong></li>\n</ul>\n<h2 id=\"rewriting-the-rules\">Rewriting the rules</h2>\n<p>A few conclusions:</p>\n<ul>\n<li>On average, <strong>growth and profitability are equally impactful to valuation</strong>, but one may win out over the other at various periods</li>\n<li>Growth matters <em>much less</em> than simple cross-sectional regressions imply</li>\n<li>As of early 2022, <strong>the market has turned decisively against growth in favor of profitability</strong></li>\n</ul>\n<p>In a way, these results affirm the utility of the Rule of 40: growth and margin are similarly important. However it adds a wrinkle: the <em>degree</em> of similarity varies over the market cycle.</p>\n<p>Though the days of &quot;growth at <em>all</em> costs&quot; are clearly over, it's still fair to ask: growth at <em>what</em> cost? In other words, <strong>how should companies trade off growth and margin?</strong></p>\n<p>I'll leave that to a future post. ðŸ‘€</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: Breaking Apart the Rule of 40\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"621fdf62fec7d1542d1d2b2e","plaintext":"Rules are meant to be broken, and the Rule of 40 is no exception.\n\nThe Rule of 40 is a popular heuristic for evaluating financial performance and\npredicting valuation multiples.\n\nBut it's got 99 3 problems:\n\n * It's too rigid\n * It's too short-term\n * It's too narrowly focused\n\nIn this essay, I break apart the Rule of 40, fix it, and put it back together\nagain.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Laying down the rules\nAfter flying high for some time, software valuation multiples have come back\ndown to Earth (Note: LTM multiples used throughout this article):\n\n\nWhile there are all sorts [https://whoisnnamdi.com/grow-valuation/] of \nexplanations [https://whoisnnamdi.com/high-retention-high-volatility/] for the\nrecent tech correction, the Rule of 40\n[https://feld.com/archives/2015/02/rule-40-healthy-saas-company/] concerns\nitself not so much with the ebbs and flows of software valuations but rather\ntheir determinants at a single point-in-time. It provides a simple rule of thumb\nfor evaluating the performance of software companies and estimating their likely\nvaluation multiples:\n\n$$\\text{Rule of 40} = \\text{Growth} + \\text{Profitability}$$\n\nThe Rule of 40 states that the sum of annual revenue growth and profitability\n(either EBITDA or free cash flow margin) should equal 40 or more for the best\nperforming companies, as in the following slide from Battery Ventures' Software\n2021 deck\n[https://www.scribd.com/document/497410287/Battery-Ventures-Software-2021-Report]\n:\n\n\nIn general though, the \"40\" isn't particularly important. Higher is better;\nthat's it.\n\n\"Houston, we have three problems\"\nI see three problems with standard Rule of 40 analysis.\n\nProblem #1: Revenue and margin may not be equally important\nBecause the Rule of 40 adds revenue and margin together with no particular\nweighting of each (it's analogous to a simple average), in a subtle way it\nimplies they are of equal importance.\n\nThis isn't necessarily true of course. An additional point of revenue growth\ncould be worth more, the same, or less than an additional point of\nprofitability.\n\nFix #1: include revenue and margin separately in our regressions.\n\nProblem #2: The long-run may look quite different\nEven if revenue and margin were equally important on average, their relative\nimportance could change over time.\n\nFolks tend to run Rule of 40 regressions at a particular point in time,\nrevealing how the market values growth and margin today, and today alone, saying\nnothing about how those relationships change over the long-run.\n\nIn a bull market, where growth is highly valued, our regressions fool us into\nthinking growth will be forever important. When the market subsequently turns,\ngrowth gets crushed, needlessly surprising many analysts and investors.\n\nFix #2: pool data from multiple time periods.\n\nProblem #3: Growth and margin aren't the only factors\nSimple regressions inflate the importance of the Rule of 40 by misattributing\nthe influence of other factors to growth and margin.\n\nFor example: Snowflake is a high flying company, both in terms of it's growth\nrate and revenue multiple. But Snowflake really is a special snowflake â€“ it has\na lot of other things going for it too, like the massive market for data\nwarehouse solutions.\n\nThus, naively comparing Snowflake and other companies with smaller markets in\nthe same regression will tend to overstate the value of revenue growth, leading\nto the false impression that, \"if only we grow as fast as Snowflake, we'll be\nvalued just as highly.\" This is wrong.\n\nFix #3: control for the average influence of unobserved factors.\n\nIf it's broken, fix it\nLet's implement each of these fixes one-by-one to see how they influence the\nresults.\n\nHere's the impact of revenue growth and free cash flow margin on valuation\nmultiples with each of the three fixes implemented sequentially:\n\n\nFirst, let's split up growth and margin to see how they separately impact\nvaluations. To start, we pick a random date, June 30th 2021:\n\n * According to this simple analysis, a single additional percentage point of\n   revenue growth increases valuation multiples by 3%, while an additional\n   percentage point of free cash flow margin only adds 0.5%.\n * By this measure, growth is six times as important as margin.\n\nSecond, we'll pool together two years of trading data, excluding any companies\nthat went public or got acquired during this time so we maintain a balanced\nsample throughout. The regression reveals the average importance of growth and\nprofitability over the entire period:\n\n * An additional point of revenue growth leads to a 2.7% higher revenue multiple\n   (down from 3%) while an additional point of free cash flow margin yields 1.1%\n   higher valuation (up from 0.5%).\n * Growth matters only ~2.5x as much as margin.\n\nLastly, the results still suffer from the fact that we're attempting to explain\nall the complexities of valuation with only two variables (the \"Snowflake\nproblem\"), giving credit to growth and margin where credit isn't due. The final\nregression controls for the average impact of these unobserved factors (fixed\neffects [https://www.youtube.com/watch?v=sFvV9b1cGFc] for the econometrics\nnerds):\n\n * 1 point of either revenue growth or free cash flow margin increases valuation\n   multiples by 1%.\n * Growth and margin matter equally.\n\nSo it turns out growth and margin are equally important after all!\n\nNote: it may be much easier to increase growth or margin by one percentage\npoint, so we have to be a little careful in saying they \"matter equally.\"\n\nStill, we've much more rigorously confirmed that growth and margin have similar\neffects on valuation. Very cool.\n\nHow the rules have changed\nHere's how the market value of growth and profitability have evolved over time:\n\n\nWe can see a number of interesting features:\n\n * The market value of profitability temporarily spiked in the early days of the\n   pandemic but then fell significantly, bottoming out at almost zero in Q1 2021\n * Meanwhile, the market's thirst for growth surged from only 0.5% per\n   percentage point of growth to 1.5% at the peak in late 2020\n * Beginning in early 2021, margin began a steady comeback, and profitability is\n   now as important as it was in the most uncertain days of the pandemic\n * The value of growth fell in early 2021, recovered somewhat, and crashed even\n   more spectacularly later in the year, returning growth to its pre-pandemic\n   value\n\nWe can also plot the \"spread\" between the value of growth vs. margin, an\ninteresting chart in its own right:\n\n\n * Growth and margin start off fairly close, with a slight market preference\n   toward margin\n * After a brief period of uncertainty, the value of software growth relative to\n   profitability roars back, peaking at a ~1% premium at the end of 2020\n * Again, we see the first blow to growth in the first half of 2021 and a second\n   blow landing in late 2021\n * Relative to profitability, growth is even less valuable than it was pre-COVID\n\nRewriting the rules\nA few conclusions:\n\n * On average, growth and profitability are equally impactful to valuation, but\n   one may win out over the other at various periods\n * Growth matters much less than simple cross-sectional regressions imply\n * As of early 2022, the market has turned decisively against growth in favor of\n   profitability\n\nIn a way, these results affirm the utility of the Rule of 40: growth and margin\nare similarly important. However it adds a wrinkle: the degree of similarity\nvaries over the market cycle.\n\nThough the days of \"growth at all costs\" are clearly over, it's still fair to\nask: growth at what cost? In other words, how should companies trade off growth\nand margin?\n\nI'll leave that to a future post. ðŸ‘€\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2022/03/header.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2022-03-02T21:19:30.000Z","updated_at":"2022-03-03T09:49:27.000Z","published_at":"2022-03-03T09:49:27.000Z","custom_excerpt":"Rules are meant to be broken, and the Rule of 40 is no exception","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"6262a2e8fec7d1542d1d2b78","uuid":"36db92f4-baa5-4c5f-9873-c1a85bdafe10","title":"Funding Simply Shifts the Bottleneck","slug":"funding-bottleneck","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Abundant capital is not a panacea for founders.\\n\\nFor the best companies, raising large war chests along with the branding effect that comes with them can serve as an \\\"unfair advantage\\\" against competitors, compounding gains and maintaining pole position.\\n\\nThis unfair advantage often comes through the hiring channel, which is high-octane leverage for fast-growing companies:\\n> **The â€œ10xâ€ in â€œ10x engineerâ€ conveys leverage just as the â€œ3xâ€ in â€œ3x S&Pâ€ does.** As an investor, leverage can multiply the returns you receive from a great investment thesis. And similarly, if youâ€™re a founder with a great vision, your superstar employees will help you realize it faster and better â€“ [Talent as leverage](https://www.dwarkeshpatel.com/p/talent-as-leverage)\\n\\nFor most however, **a frothy funding environment means more competition for talent.** If everyone is raising tons of cheap capital and plowing those funds into hiring, your job as a founder hasn't necessarily gotten easier, since presumably you'll be working that much harder to recruit against every other startup doing the same.\\n\\nThe capital \\\"bottleneck\\\" hasn't disappeared â€“ it's moved to another part of the production chain. **Funding gets easier; hiring gets harder.**\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Funding Simply Shifts the Bottleneck\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## Cheap money, expensive people\\n\\nHe deleted the tweet, but [Mike Speiser](https://twitter.com/laserlikemike) once said:\\n>When money is cheap, people are expensive. When money is expensive, people are cheap. \\\\#dilution\\n\\nThe idea that hiring gets harder when funding gets easier (and vice versa) has two foundational components. The first one is easy, so let's get that out of the way first.\\n\\nWhen companies are cash rich, they tend to spend more (\\\\*shocker\\\\*). Startups raise funding in large part to expand their teams. When the entire startup ecosystem simultaneously raises tons of capital, the additional money sloshing around inevitably shows up in the W2s of startup employees and the \\\"voluntary churn\\\" column of board of directors presentations. Recruiters spam the LinkedIn inboxes of every warm body in sight, and the hiring market heats up.\\n\\nThat's fairly intuitive. The second reason is much less so â€“ discount rates.\\n\\nGo back to the Mike Speiser quote. What does it mean for money to be \\\"cheap?\\\" Financial theory introduced us to the concept of the \\\"discount rate\\\" or equivalently the required rate of return or cost of capital. Money is \\\"cheap\\\" when discount rates are low, implying that investors and lenders require only a small rate of return on their investments in order to be satisfied.\\n\\nTypically, low discount rates are associated with high valuations, since the present value of a series of cash flows rises as discount rates falls. Thus we get the frequent gyrations of the stock market, which summarize this dynamic in a single number:\\n> the large movements in the value of the stock market arise mainly from changes in discount rates and only secondarily from changes in the dividend or profit flow capitalized in the stock market â€“ [High Discounts and High Unemployment](https://web.stanford.edu/~rehall/High%20Discounts%20and%20High%20Unemployment%20AER)\\n\\nIt's quite natural to apply the notion of discount rates to the value of financial assets, like company equity. But why limit our thinking to financial assets?\\n\\n## The present value of talent\\n\\nDiscount rates apply to human capital too.\\n\\nIf you don't believe me, check out the following chart. It plots the unemployment rate over time along with the *inverse* of the detrended (i.e. accounting for the size of the U.S. economy) S&P 500 index (so down is up and vice versa). Notice the tight relationship between the two:\\n![Pasted-image-20220126122928](__GHOST_URL__/content/images/2022/04/Pasted-image-20220126122928.png)\\n\\n> Figure 2 suggests that **the stock market and unemployment respond to the same underlying forces**, especially in the past few decades â€“ [High Discounts and High Unemployment](https://web.stanford.edu/~rehall/High%20Discounts%20and%20High%20Unemployment%20AER)\\n\\nYou might ascribe this correlation to general economic conditions rather than discount rates, but unemployment and output per worker don't actually track each other very well:\\n![Pasted-image-20220416164600](__GHOST_URL__/content/images/2022/04/Pasted-image-20220416164600.png)\\n\\nTo see how discount rates apply to workers in the same way they do to financial assets, imagine the net value of a worker to a company being their productivity minus their cost, i.e. wage. This \\\"job value\\\" takes into account all future value the worker generates along with their cost of employment, in present value terms:\\n\\n$$\\\\text{Job Value} = \\\\text{Present Value }(\\\\text{Productivity} - \\\\text{Wage})$$\\n\\nJob value tends to increase during booms, for two reasons:\\n1. Discount rates are low, which inflates present value calculations, \\n2. Productivity is more variable than wages, which tend to be sticky\\n\\nThus, the present value of productivity moves up and down by more than wages, driving job value up or down with the market cycle:\\n> **A higher discount lowers the job value**â€¦ The present value of the wage moves in the same direction as productivity, but less than in proportion. In this sense, the wage is sticky. Because the wage falls less than productivity, the job valueâ€¦ falls more than in proportion to the fall in productivity â€“ [High Discounts and High Unemployment](https://web.stanford.edu/~rehall/High%20Discounts%20and%20High%20Unemployment%20AER)\\n\\nNaturally, the higher the \\\"job value,\\\" the more eager employers are to hire workers. We get cutthroat competition among employers during good economic times and workers being dropped like hot potatoes during bad times. When the present value of hiring an additional worker is high, employers clamor to grow their ranks.\\n\\nIt's possible to use economic data to estimate job value across the entire U.S. economy. **Job value and the stock market move together in lockstep**:\\n![Pasted-image-20220126125737](__GHOST_URL__/content/images/2022/04/Pasted-image-20220126125737.png)\\n\\n> The similarity of the job value and the stock market value is remarkable. The figure strongly confirms the hypothesis that **similar forces govern the market values of claims on jobs and claims on corporations** â€“ [High Discounts and High Unemployment](https://web.stanford.edu/~rehall/High%20Discounts%20and%20High%20Unemployment%20AER)\\n\\nThe up and down movement of job value is incredibly consistent across industries too:\\n![Pasted-image-20220416154129](__GHOST_URL__/content/images/2022/04/Pasted-image-20220416154129.png)\\n\\n> The strikingly similar responses in diverse industries strongly supports the hypothesis that an aggregate driving force dominates the movements of the job value at the industry level. **This evidence points in the direction of aggregate forces such as rising discounts in recessions** â€“ [High Discounts and High Unemployment](https://web.stanford.edu/~rehall/High%20Discounts%20and%20High%20Unemployment%20AER)\\n\\n## When hiring falls apart\\n\\n**When interest rates are low, leverage becomes more attractive.** Although the venture capital world likes to think of itself as distinct from debt-laden private equity land, in fact technology startups engage in all sorts of leverage, especially during boom times. I talked about one form of it, [preferred equity](https://whoisnnamdi.com/schrodingers-balance-sheet/), in a prior essay:\\n> In this way, startups become **synthetically levered**. No debt appears on the balance sheet, yet the returns of the common equity (any really anyone below the most senior preferred stock) get juiced by the lower cost of capital achieved via preferred equity â€“ [Schrodinger's Balance Sheet: When Equity Becomes a Liability](https://whoisnnamdi.com/schrodingers-balance-sheet/)\\n\\nI referred earlier to the notion that exceptional employees are a form of leverage. Just like financial leverage, *talent leverage* allows a company to do things they wouldn't otherwise be capable of with existing resources.\\n\\nTo attract such special individuals, startups have to promise the world to these ambitious folks, a sort of \\\"debt.\\\" **These superstar employees wouldn't join otherwise** â€“ the cash compensation alone is rarely worth it. They must be promised quickly-appreciating equity, as well as the Silicon Valley cache and prestige associated with a successful startup. This is related to Keith Rabois' idea of  \\\"[talent arbitrage](https://leveragingideas.com/talent-arbitrage/).\\\"\\n\\nThis Silicon Valley \\\"spin\\\" peaks during market highs â€“ frothy periods where slick storytellers paint increasingly fantastical and implausible visions for what their company will achieve. It's a competition to see who can lever up their fragile enterprise the most.\\n\\nIf things start to go south, the bubble bursts, and these 10x employees are often the first to abandon ship:\\n> The leverage you get from hiring really talented people is a huge risk during rough times, because these people have lots of other options and the ambition to pursue them.\\n> â€¦\\n> If any of of the people in this chain stop believing the hype around which their project is organized, then the hype becomes unjustifiedâ€¦ And once the bubble starts to wobble, 10x employees will move on to the next compelling tech vision, causing the leveraged death spiral mentioned in the last section. **Leveraging your company with talent increases your volatility - either you orchestrate a revolution, or you implode** â€“ [Talent as leverage](https://www.dwarkeshpatel.com/p/talent-as-leverage)\\n\\nIt's never pretty when leverage blows up, and talent leverage is no different. Troubled startups face double jeopardy â€“ preferred equity implodes, as does the talent stack.\\n\\n## Easy funding =/= easy life\\n![Funding-Simply-Shifts-the-Bottleneck_2022-04-18-17.19.06.excalidraw](__GHOST_URL__/content/images/2022/04/Funding-Simply-Shifts-the-Bottleneck_2022-04-18-17.19.06.excalidraw.png)\\n\\nI'm increasingly skeptical of the notion that easy funding makes the lives of founders easier. *Funding merely shifts the bottleneck.*\\n\\nDifficulty hiring is a recurring theme I've seen among founders during red-hot markets. **The financial capital comes easy; the human capital doesn't.**\\n\\nIn fact, hiring can be *tougher* after raising at a big valuation because candidates might think all the upside is gone already, making equity compensation less attractive:\\n> At Retool, we decided to raise the smallest Series C we could, at a valuation substantially lower than most offers we received. Why? Because even though maximizing our valuation and money raised might be optically good (the press loves to report on large financing rounds at large valuations), it hurts the core constituency that got us here: our teamâ€¦ **Reaching peak valuations too early results in substantially less upside for employees.** â€“ [Raising less money at lower valuations](https://retool.com/blog/series-c/)\\n\\nBetween the increased effort that hiring requires during boom periods and the prospect of employee exodus after hitting choppy waters, founders should be wary of getting caught up in the irrational exuberance of the broader market.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: Funding Simply Shifts the Bottleneck\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>Abundant capital is not a panacea for founders.</p>\n<p>For the best companies, raising large war chests along with the branding effect that comes with them can serve as an &quot;unfair advantage&quot; against competitors, compounding gains and maintaining pole position.</p>\n<p>This unfair advantage often comes through the hiring channel, which is high-octane leverage for fast-growing companies:</p>\n<blockquote>\n<p><strong>The â€œ10xâ€ in â€œ10x engineerâ€ conveys leverage just as the â€œ3xâ€ in â€œ3x S&amp;Pâ€ does.</strong> As an investor, leverage can multiply the returns you receive from a great investment thesis. And similarly, if youâ€™re a founder with a great vision, your superstar employees will help you realize it faster and better â€“ <a href=\"https://www.dwarkeshpatel.com/p/talent-as-leverage\">Talent as leverage</a></p>\n</blockquote>\n<p>For most however, <strong>a frothy funding environment means more competition for talent.</strong> If everyone is raising tons of cheap capital and plowing those funds into hiring, your job as a founder hasn't necessarily gotten easier, since presumably you'll be working that much harder to recruit against every other startup doing the same.</p>\n<p>The capital &quot;bottleneck&quot; hasn't disappeared â€“ it's moved to another part of the production chain. <strong>Funding gets easier; hiring gets harder.</strong></p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Funding Simply Shifts the Bottleneck\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"cheap-money-expensive-people\">Cheap money, expensive people</h2>\n<p>He deleted the tweet, but <a href=\"https://twitter.com/laserlikemike\">Mike Speiser</a> once said:</p>\n<blockquote>\n<p>When money is cheap, people are expensive. When money is expensive, people are cheap. #dilution</p>\n</blockquote>\n<p>The idea that hiring gets harder when funding gets easier (and vice versa) has two foundational components. The first one is easy, so let's get that out of the way first.</p>\n<p>When companies are cash rich, they tend to spend more (*shocker*). Startups raise funding in large part to expand their teams. When the entire startup ecosystem simultaneously raises tons of capital, the additional money sloshing around inevitably shows up in the W2s of startup employees and the &quot;voluntary churn&quot; column of board of directors presentations. Recruiters spam the LinkedIn inboxes of every warm body in sight, and the hiring market heats up.</p>\n<p>That's fairly intuitive. The second reason is much less so â€“ discount rates.</p>\n<p>Go back to the Mike Speiser quote. What does it mean for money to be &quot;cheap?&quot; Financial theory introduced us to the concept of the &quot;discount rate&quot; or equivalently the required rate of return or cost of capital. Money is &quot;cheap&quot; when discount rates are low, implying that investors and lenders require only a small rate of return on their investments in order to be satisfied.</p>\n<p>Typically, low discount rates are associated with high valuations, since the present value of a series of cash flows rises as discount rates falls. Thus we get the frequent gyrations of the stock market, which summarize this dynamic in a single number:</p>\n<blockquote>\n<p>the large movements in the value of the stock market arise mainly from changes in discount rates and only secondarily from changes in the dividend or profit flow capitalized in the stock market â€“ <a href=\"https://web.stanford.edu/~rehall/High%20Discounts%20and%20High%20Unemployment%20AER\">High Discounts and High Unemployment</a></p>\n</blockquote>\n<p>It's quite natural to apply the notion of discount rates to the value of financial assets, like company equity. But why limit our thinking to financial assets?</p>\n<h2 id=\"the-present-value-of-talent\">The present value of talent</h2>\n<p>Discount rates apply to human capital too.</p>\n<p>If you don't believe me, check out the following chart. It plots the unemployment rate over time along with the <em>inverse</em> of the detrended (i.e. accounting for the size of the U.S. economy) S&amp;P 500 index (so down is up and vice versa). Notice the tight relationship between the two:<br>\n<img src=\"__GHOST_URL__/content/images/2022/04/Pasted-image-20220126122928.png\" alt=\"Pasted-image-20220126122928\" loading=\"lazy\"></p>\n<blockquote>\n<p>Figure 2 suggests that <strong>the stock market and unemployment respond to the same underlying forces</strong>, especially in the past few decades â€“ <a href=\"https://web.stanford.edu/~rehall/High%20Discounts%20and%20High%20Unemployment%20AER\">High Discounts and High Unemployment</a></p>\n</blockquote>\n<p>You might ascribe this correlation to general economic conditions rather than discount rates, but unemployment and output per worker don't actually track each other very well:<br>\n<img src=\"__GHOST_URL__/content/images/2022/04/Pasted-image-20220416164600.png\" alt=\"Pasted-image-20220416164600\" loading=\"lazy\"></p>\n<p>To see how discount rates apply to workers in the same way they do to financial assets, imagine the net value of a worker to a company being their productivity minus their cost, i.e. wage. This &quot;job value&quot; takes into account all future value the worker generates along with their cost of employment, in present value terms:</p>\n<p>$$\\text{Job Value} = \\text{Present Value }(\\text{Productivity} - \\text{Wage})$$</p>\n<p>Job value tends to increase during booms, for two reasons:</p>\n<ol>\n<li>Discount rates are low, which inflates present value calculations,</li>\n<li>Productivity is more variable than wages, which tend to be sticky</li>\n</ol>\n<p>Thus, the present value of productivity moves up and down by more than wages, driving job value up or down with the market cycle:</p>\n<blockquote>\n<p><strong>A higher discount lowers the job value</strong>â€¦ The present value of the wage moves in the same direction as productivity, but less than in proportion. In this sense, the wage is sticky. Because the wage falls less than productivity, the job valueâ€¦ falls more than in proportion to the fall in productivity â€“ <a href=\"https://web.stanford.edu/~rehall/High%20Discounts%20and%20High%20Unemployment%20AER\">High Discounts and High Unemployment</a></p>\n</blockquote>\n<p>Naturally, the higher the &quot;job value,&quot; the more eager employers are to hire workers. We get cutthroat competition among employers during good economic times and workers being dropped like hot potatoes during bad times. When the present value of hiring an additional worker is high, employers clamor to grow their ranks.</p>\n<p>It's possible to use economic data to estimate job value across the entire U.S. economy. <strong>Job value and the stock market move together in lockstep</strong>:<br>\n<img src=\"__GHOST_URL__/content/images/2022/04/Pasted-image-20220126125737.png\" alt=\"Pasted-image-20220126125737\" loading=\"lazy\"></p>\n<blockquote>\n<p>The similarity of the job value and the stock market value is remarkable. The figure strongly confirms the hypothesis that <strong>similar forces govern the market values of claims on jobs and claims on corporations</strong> â€“ <a href=\"https://web.stanford.edu/~rehall/High%20Discounts%20and%20High%20Unemployment%20AER\">High Discounts and High Unemployment</a></p>\n</blockquote>\n<p>The up and down movement of job value is incredibly consistent across industries too:<br>\n<img src=\"__GHOST_URL__/content/images/2022/04/Pasted-image-20220416154129.png\" alt=\"Pasted-image-20220416154129\" loading=\"lazy\"></p>\n<blockquote>\n<p>The strikingly similar responses in diverse industries strongly supports the hypothesis that an aggregate driving force dominates the movements of the job value at the industry level. <strong>This evidence points in the direction of aggregate forces such as rising discounts in recessions</strong> â€“ <a href=\"https://web.stanford.edu/~rehall/High%20Discounts%20and%20High%20Unemployment%20AER\">High Discounts and High Unemployment</a></p>\n</blockquote>\n<h2 id=\"when-hiring-falls-apart\">When hiring falls apart</h2>\n<p><strong>When interest rates are low, leverage becomes more attractive.</strong> Although the venture capital world likes to think of itself as distinct from debt-laden private equity land, in fact technology startups engage in all sorts of leverage, especially during boom times. I talked about one form of it, <a href=\"https://whoisnnamdi.com/schrodingers-balance-sheet/\">preferred equity</a>, in a prior essay:</p>\n<blockquote>\n<p>In this way, startups become <strong>synthetically levered</strong>. No debt appears on the balance sheet, yet the returns of the common equity (any really anyone below the most senior preferred stock) get juiced by the lower cost of capital achieved via preferred equity â€“ <a href=\"https://whoisnnamdi.com/schrodingers-balance-sheet/\">Schrodinger's Balance Sheet: When Equity Becomes a Liability</a></p>\n</blockquote>\n<p>I referred earlier to the notion that exceptional employees are a form of leverage. Just like financial leverage, <em>talent leverage</em> allows a company to do things they wouldn't otherwise be capable of with existing resources.</p>\n<p>To attract such special individuals, startups have to promise the world to these ambitious folks, a sort of &quot;debt.&quot; <strong>These superstar employees wouldn't join otherwise</strong> â€“ the cash compensation alone is rarely worth it. They must be promised quickly-appreciating equity, as well as the Silicon Valley cache and prestige associated with a successful startup. This is related to Keith Rabois' idea of  &quot;<a href=\"https://leveragingideas.com/talent-arbitrage/\">talent arbitrage</a>.&quot;</p>\n<p>This Silicon Valley &quot;spin&quot; peaks during market highs â€“ frothy periods where slick storytellers paint increasingly fantastical and implausible visions for what their company will achieve. It's a competition to see who can lever up their fragile enterprise the most.</p>\n<p>If things start to go south, the bubble bursts, and these 10x employees are often the first to abandon ship:</p>\n<blockquote>\n<p>The leverage you get from hiring really talented people is a huge risk during rough times, because these people have lots of other options and the ambition to pursue them.<br>\nâ€¦<br>\nIf any of of the people in this chain stop believing the hype around which their project is organized, then the hype becomes unjustifiedâ€¦ And once the bubble starts to wobble, 10x employees will move on to the next compelling tech vision, causing the leveraged death spiral mentioned in the last section. <strong>Leveraging your company with talent increases your volatility - either you orchestrate a revolution, or you implode</strong> â€“ <a href=\"https://www.dwarkeshpatel.com/p/talent-as-leverage\">Talent as leverage</a></p>\n</blockquote>\n<p>It's never pretty when leverage blows up, and talent leverage is no different. Troubled startups face double jeopardy â€“ preferred equity implodes, as does the talent stack.</p>\n<h2 id=\"easy-funding-easy-life\">Easy funding =/= easy life</h2>\n<p><img src=\"__GHOST_URL__/content/images/2022/04/Funding-Simply-Shifts-the-Bottleneck_2022-04-18-17.19.06.excalidraw.png\" alt=\"Funding-Simply-Shifts-the-Bottleneck_2022-04-18-17.19.06.excalidraw\" loading=\"lazy\"></p>\n<p>I'm increasingly skeptical of the notion that easy funding makes the lives of founders easier. <em>Funding merely shifts the bottleneck.</em></p>\n<p>Difficulty hiring is a recurring theme I've seen among founders during red-hot markets. <strong>The financial capital comes easy; the human capital doesn't.</strong></p>\n<p>In fact, hiring can be <em>tougher</em> after raising at a big valuation because candidates might think all the upside is gone already, making equity compensation less attractive:</p>\n<blockquote>\n<p>At Retool, we decided to raise the smallest Series C we could, at a valuation substantially lower than most offers we received. Why? Because even though maximizing our valuation and money raised might be optically good (the press loves to report on large financing rounds at large valuations), it hurts the core constituency that got us here: our teamâ€¦ <strong>Reaching peak valuations too early results in substantially less upside for employees.</strong> â€“ <a href=\"https://retool.com/blog/series-c/\">Raising less money at lower valuations</a></p>\n</blockquote>\n<p>Between the increased effort that hiring requires during boom periods and the prospect of employee exodus after hitting choppy waters, founders should be wary of getting caught up in the irrational exuberance of the broader market.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: Funding Simply Shifts the Bottleneck\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"6262a2e8fec7d1542d1d2b78","plaintext":"Abundant capital is not a panacea for founders.\n\nFor the best companies, raising large war chests along with the branding effect\nthat comes with them can serve as an \"unfair advantage\" against competitors,\ncompounding gains and maintaining pole position.\n\nThis unfair advantage often comes through the hiring channel, which is\nhigh-octane leverage for fast-growing companies:\n\n> The â€œ10xâ€ in â€œ10x engineerâ€ conveys leverage just as the â€œ3xâ€ in â€œ3x S&Pâ€ does. \nAs an investor, leverage can multiply the returns you receive from a great\ninvestment thesis. And similarly, if youâ€™re a founder with a great vision, your\nsuperstar employees will help you realize it faster and better â€“ Talent as\nleverage [https://www.dwarkeshpatel.com/p/talent-as-leverage]\n\n\nFor most however, a frothy funding environment means more competition for\ntalent. If everyone is raising tons of cheap capital and plowing those funds\ninto hiring, your job as a founder hasn't necessarily gotten easier, since\npresumably you'll be working that much harder to recruit against every other\nstartup doing the same.\n\nThe capital \"bottleneck\" hasn't disappeared â€“ it's moved to another part of the\nproduction chain. Funding gets easier; hiring gets harder.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Cheap money, expensive people\nHe deleted the tweet, but Mike Speiser [https://twitter.com/laserlikemike] once\nsaid:\n\n> When money is cheap, people are expensive. When money is expensive, people are\ncheap. #dilution\n\n\nThe idea that hiring gets harder when funding gets easier (and vice versa) has\ntwo foundational components. The first one is easy, so let's get that out of the\nway first.\n\nWhen companies are cash rich, they tend to spend more (*shocker*). Startups\nraise funding in large part to expand their teams. When the entire startup\necosystem simultaneously raises tons of capital, the additional money sloshing\naround inevitably shows up in the W2s of startup employees and the \"voluntary\nchurn\" column of board of directors presentations. Recruiters spam the LinkedIn\ninboxes of every warm body in sight, and the hiring market heats up.\n\nThat's fairly intuitive. The second reason is much less so â€“ discount rates.\n\nGo back to the Mike Speiser quote. What does it mean for money to be \"cheap?\"\nFinancial theory introduced us to the concept of the \"discount rate\" or\nequivalently the required rate of return or cost of capital. Money is \"cheap\"\nwhen discount rates are low, implying that investors and lenders require only a\nsmall rate of return on their investments in order to be satisfied.\n\nTypically, low discount rates are associated with high valuations, since the\npresent value of a series of cash flows rises as discount rates falls. Thus we\nget the frequent gyrations of the stock market, which summarize this dynamic in\na single number:\n\n> the large movements in the value of the stock market arise mainly from changes\nin discount rates and only secondarily from changes in the dividend or profit\nflow capitalized in the stock market â€“ High Discounts and High Unemployment\n[https://web.stanford.edu/~rehall/High%20Discounts%20and%20High%20Unemployment%20AER]\n\n\nIt's quite natural to apply the notion of discount rates to the value of\nfinancial assets, like company equity. But why limit our thinking to financial\nassets?\n\nThe present value of talent\nDiscount rates apply to human capital too.\n\nIf you don't believe me, check out the following chart. It plots the\nunemployment rate over time along with the inverse of the detrended (i.e.\naccounting for the size of the U.S. economy) S&P 500 index (so down is up and\nvice versa). Notice the tight relationship between the two:\n\n\n> Figure 2 suggests that the stock market and unemployment respond to the same\nunderlying forces, especially in the past few decades â€“ High Discounts and High\nUnemployment\n[https://web.stanford.edu/~rehall/High%20Discounts%20and%20High%20Unemployment%20AER]\n\n\nYou might ascribe this correlation to general economic conditions rather than\ndiscount rates, but unemployment and output per worker don't actually track each\nother very well:\n\n\nTo see how discount rates apply to workers in the same way they do to financial\nassets, imagine the net value of a worker to a company being their productivity\nminus their cost, i.e. wage. This \"job value\" takes into account all future\nvalue the worker generates along with their cost of employment, in present value\nterms:\n\n$$\\text{Job Value} = \\text{Present Value }(\\text{Productivity} - \\text{Wage})$$\n\nJob value tends to increase during booms, for two reasons:\n\n 1. Discount rates are low, which inflates present value calculations,\n 2. Productivity is more variable than wages, which tend to be sticky\n\nThus, the present value of productivity moves up and down by more than wages,\ndriving job value up or down with the market cycle:\n\n> A higher discount lowers the job valueâ€¦ The present value of the wage moves in\nthe same direction as productivity, but less than in proportion. In this sense,\nthe wage is sticky. Because the wage falls less than productivity, the job\nvalueâ€¦ falls more than in proportion to the fall in productivity â€“ High\nDiscounts and High Unemployment\n[https://web.stanford.edu/~rehall/High%20Discounts%20and%20High%20Unemployment%20AER]\n\n\nNaturally, the higher the \"job value,\" the more eager employers are to hire\nworkers. We get cutthroat competition among employers during good economic times\nand workers being dropped like hot potatoes during bad times. When the present\nvalue of hiring an additional worker is high, employers clamor to grow their\nranks.\n\nIt's possible to use economic data to estimate job value across the entire U.S.\neconomy. Job value and the stock market move together in lockstep:\n\n\n> The similarity of the job value and the stock market value is remarkable. The\nfigure strongly confirms the hypothesis that similar forces govern the market\nvalues of claims on jobs and claims on corporations â€“ High Discounts and High\nUnemployment\n[https://web.stanford.edu/~rehall/High%20Discounts%20and%20High%20Unemployment%20AER]\n\n\nThe up and down movement of job value is incredibly consistent across industries\ntoo:\n\n\n> The strikingly similar responses in diverse industries strongly supports the\nhypothesis that an aggregate driving force dominates the movements of the job\nvalue at the industry level. This evidence points in the direction of aggregate\nforces such as rising discounts in recessions â€“ High Discounts and High\nUnemployment\n[https://web.stanford.edu/~rehall/High%20Discounts%20and%20High%20Unemployment%20AER]\n\n\nWhen hiring falls apart\nWhen interest rates are low, leverage becomes more attractive. Although the\nventure capital world likes to think of itself as distinct from debt-laden\nprivate equity land, in fact technology startups engage in all sorts of\nleverage, especially during boom times. I talked about one form of it, \npreferred\nequity [https://whoisnnamdi.com/schrodingers-balance-sheet/], in a prior essay:\n\n> In this way, startups become synthetically levered. No debt appears on the\nbalance sheet, yet the returns of the common equity (any really anyone below the\nmost senior preferred stock) get juiced by the lower cost of capital achieved\nvia preferred equity â€“ Schrodinger's Balance Sheet: When Equity Becomes a\nLiability [https://whoisnnamdi.com/schrodingers-balance-sheet/]\n\n\nI referred earlier to the notion that exceptional employees are a form of\nleverage. Just like financial leverage, talent leverage allows a company to do\nthings they wouldn't otherwise be capable of with existing resources.\n\nTo attract such special individuals, startups have to promise the world to these\nambitious folks, a sort of \"debt.\" These superstar employees wouldn't join\notherwise â€“ the cash compensation alone is rarely worth it. They must be\npromised quickly-appreciating equity, as well as the Silicon Valley cache and\nprestige associated with a successful startup. This is related to Keith Rabois'\nidea of \"talent arbitrage [https://leveragingideas.com/talent-arbitrage/].\"\n\nThis Silicon Valley \"spin\" peaks during market highs â€“ frothy periods where\nslick storytellers paint increasingly fantastical and implausible visions for\nwhat their company will achieve. It's a competition to see who can lever up\ntheir fragile enterprise the most.\n\nIf things start to go south, the bubble bursts, and these 10x employees are\noften the first to abandon ship:\n\n> The leverage you get from hiring really talented people is a huge risk during\nrough times, because these people have lots of other options and the ambition to\npursue them.\nâ€¦\nIf any of of the people in this chain stop believing the hype around which their\nproject is organized, then the hype becomes unjustifiedâ€¦ And once the bubble\nstarts to wobble, 10x employees will move on to the next compelling tech vision,\ncausing the leveraged death spiral mentioned in the last section. Leveraging\nyour company with talent increases your volatility - either you orchestrate a\nrevolution, or you implode â€“ Talent as leverage\n[https://www.dwarkeshpatel.com/p/talent-as-leverage]\n\n\nIt's never pretty when leverage blows up, and talent leverage is no different.\nTroubled startups face double jeopardy â€“ preferred equity implodes, as does the\ntalent stack.\n\nEasy funding =/= easy life\n\n\nI'm increasingly skeptical of the notion that easy funding makes the lives of\nfounders easier. Funding merely shifts the bottleneck.\n\nDifficulty hiring is a recurring theme I've seen among founders during red-hot\nmarkets. The financial capital comes easy; the human capital doesn't.\n\nIn fact, hiring can be tougher after raising at a big valuation because\ncandidates might think all the upside is gone already, making equity\ncompensation less attractive:\n\n> At Retool, we decided to raise the smallest Series C we could, at a valuation\nsubstantially lower than most offers we received. Why? Because even though\nmaximizing our valuation and money raised might be optically good (the press\nloves to report on large financing rounds at large valuations), it hurts the\ncore constituency that got us here: our teamâ€¦ Reaching peak valuations too early\nresults in substantially less upside for employees. â€“ Raising less money at\nlower valuations [https://retool.com/blog/series-c/]\n\n\nBetween the increased effort that hiring requires during boom periods and the\nprospect of employee exodus after hitting choppy waters, founders should be wary\nof getting caught up in the irrational exuberance of the broader market.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2022/04/Funding-Simply-Shifts-the-Bottleneck_2022-04-18-15.51.14.excalidraw-2.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2022-04-22T12:43:20.000Z","updated_at":"2022-04-26T06:03:33.000Z","published_at":"2022-04-22T12:56:12.000Z","custom_excerpt":"A frothy funding environment means more competition for talent. Funding gets easier; hiring gets harder.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"62b9dd89fec7d1542d1d2bd4","uuid":"7e1e0761-c556-4572-b05c-1002900658d4","title":"Series A Rounds Are a Math Test","slug":"series-a-math","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"For your seed stage startup to graduate to the next level, it must pass a new test.\\n\\nSuddenly, a PowerPoint deck isn't enough. *Traction and monetization matter.*\\n\\nYour startup might have more of one than the other, and that's OK.\\n\\nBut less of one means you need more of the other. That's just math.\\n\\nHow much more? It turns out â€“ more than you think.\\n\\n**Low monetization requires extraordinary traction, and vice versa.**\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Series A Rounds Are a Math Test\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## 2 + 2 = 4\\n\\nIn addition to factors like *team quality* and *market size* (which also matter at the pre-seed/seed stage), investors evaluate Series A startups on their **traction** and **monetization**.\\n\\nBy traction, I mean some rough mix of:\\n- bottom-up adoption\\n- free usage / free trials\\n- organic, inbound interest in the product\\n- proliferation of an open source project\\n- downloads\\n- a vibrant, growing community\\n- product-led growth\\n\\nBy monetization, I'm loosely referring to:\\n- revenue (duh!)\\n- customers\\n- top-down / direct sales\\n- production deployments\\n- pilots / POCs (proofs of concept)\\n- qualified pipeline\\n\\n*Note: monetization is a catch-all for activities and metrics that tend to correlate with revenue, so a company with zero revenue can still have a decent monetization \\\"score.\\\"*\\n\\nIf traction and monetization are collectively high enough, you will successfully raise your Series A round.\\n\\nYou can even make a little equation out of this:\\n\\n$$\\\\text{Fundraising Success} = \\\\text{Traction} + \\\\text{Monetization}$$\\n\\nThere's a threshold, a sort of activation energy, required to successfully raise a round at the early-stage. Hit this bar and you're in the clear. Miss it, and you're not:\\n\\n![1](__GHOST_URL__/content/images/2022/06/1.png)\\n\\nLet's make up some numbers.\\n\\nSay the threshold is \\\"4\\\". You'd need some combination of traction and monetization to get to a sum of four:\\n- A score of two on both traction and monetization would work. We could call that \\\"moderate traction and moderate monetization\\\", or (2, 2)\\n- But a (3, 1) combo would also work â€“ perhaps \\\"high traction, low monetization\\\", and so on.\\n\\nAs long as you can get to a total of four, you're good.\\n\\n## 2 x 2 = 4\\n\\nWhat if our model is wrong though?\\n\\nImagine investors evaluate your startup not on the *sum* of traction and monetization, but rather the *product*. In other words, traction and monetization multiply, rather than add:\\n\\n$$\\\\text{Fundraising Success} = \\\\text{Traction} \\\\times \\\\text{Monetization}$$\\n\\nThrough this lens, the marginal value of one factor depends on the other. Traction makes monetization more valuable, and vice versa. Monetization is more valuable when you have more traction.\\n\\nThis is a much better model for how venture investors think about startups.\\n\\nThink about it:\\n- Strong traction makes additional monetization more valuable, since there's a preexisting, large group of interested, engaged users to sell into.\\n- Strong monetization increases the value of additional traction, since you know that traction will be monetizable in the future.\\n\\nThe multiplicative model has an important implication however â€“ it disproportionately penalizes low traction and/or low monetization.\\n\\nTo successfully fundraise, low monetization requires extraordinary traction, and vice versa:\\n\\n![2](__GHOST_URL__/content/images/2022/06/2.png)\\n\\nHere's an analogy â€“ a stock that drops by 50% (OK, maybe more reality than analogy) must rise by much more than 50% to reach its original price level, since returns are multiplicative (50% x 150% is only 75%). Likewise, **low monetization requires more than proportionally higher traction** to make up for it.\\n\\n(2, 2) still works, since 2 x 2 = 4. But the (3, 1) combination is no longer viable, since 3 x 1 only equals 3. If your startup is merely a \\\"1\\\" on the monetization scale, you now need to be a \\\"4\\\" on traction. 0.5 on monetization? You need to be an 8 on traction!\\n\\nYou can see where this is going.\\n\\n## 3 x 1 = â˜ \\n\\nUnfortunately, founders fall into the trap of thinking low monetization or traction can be made up for with merely moderate amounts of the other factor. This is wrong.\\n\\nMany founders think investors will evaluate them with the linear, additive model. While many investors are quite linear in their thinking (sorry, had to do it), the multiplicative perspective is the more accurate one.\\n\\nThis clash of reality vs. expectations creates a \\\"[no man's land](https://en.wikipedia.org/wiki/No_man%27s_land)\\\" between the additive and multiplicative perspectives: founders think they'll be fine when they go out to fundraise, only to be rudely mugged by ~~the valley~~ reality:\\n\\n![3](__GHOST_URL__/content/images/2022/06/3.png)\\n\\nI've noticed many startups in the space between the linear and convex curves attempting to raise Series A rounds lately. **This invariably goes badly.** The founders are surprised by the lack of investor interest and end up taking much longer to raise their round, at a lower valuation than expected. \\n\\nSome never raise at all.\\n\\n## Quick maths\\n\\nAvoid this needless suffering. Be honest with yourself â€“ if you're lacking in either traction or monetization, be sure you're killing it on the other dimension.\\n\\nI've made the point that low monetization requires extraordinary traction (and vice versa), but I haven't defined what \\\"extraordinary\\\" means. Frankly, it's subjective at best, and I'd be lying if I said there was an objective standard or rubric.\\n\\nWhen you know, you know:\\n> you can always feel product/market fit when it's happening â€“ [Marc Andreessen](https://pmarchive.com/guide_to_startups_part4.html)\\n\\n> â€¦ once you have product-market fitâ€¦ [business] performance accelerates so meaningfully that any ambiguity goes out the window. You get it \\\"in your gut.\\\" It becomes obvious, as nearly everything about the business gets better â€“ [Product-Market Fit is Lindy](https://whoisnnamdi.com/product-market-fit-is-lindy/)\\n\\n> If it is true that product-market fit yields much better business performance, then product-market fit should be relatively obvious, even with little data â€“ [Product-Market Fit is Lindy](https://whoisnnamdi.com/product-market-fit-is-lindy/)\\n\\nFurther, I've simplified the framework here and taken other factors like team, market, etc as given. Realistically, investors will evaluate those things too, complicating our math a bit:\\n\\n$$\\\\text{Fundraising Success} = \\\\text{Traction} \\\\times \\\\text{Monetization} \\\\times \\\\text{Team} \\\\times \\\\text{Market} \\\\times \\\\ldots$$\\n\\nThat's a lot harder to visualize, but the same ideas apply. You need to really spike on one or more factors to make up for lower scores on the others. Get this math wrong, and you'll be in for a nasty surprise.\\n\\nRather than cram for the exam, delay your Series A until you pass the simple math test I've outlined here. Until then, keep practicing those multiplication tables!\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: Series A Rounds Are a Math Test\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>For your seed stage startup to graduate to the next level, it must pass a new test.</p>\n<p>Suddenly, a PowerPoint deck isn't enough. <em>Traction and monetization matter.</em></p>\n<p>Your startup might have more of one than the other, and that's OK.</p>\n<p>But less of one means you need more of the other. That's just math.</p>\n<p>How much more? It turns out â€“ more than you think.</p>\n<p><strong>Low monetization requires extraordinary traction, and vice versa.</strong></p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Series A Rounds Are a Math Test\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"2-2-4\">2 + 2 = 4</h2>\n<p>In addition to factors like <em>team quality</em> and <em>market size</em> (which also matter at the pre-seed/seed stage), investors evaluate Series A startups on their <strong>traction</strong> and <strong>monetization</strong>.</p>\n<p>By traction, I mean some rough mix of:</p>\n<ul>\n<li>bottom-up adoption</li>\n<li>free usage / free trials</li>\n<li>organic, inbound interest in the product</li>\n<li>proliferation of an open source project</li>\n<li>downloads</li>\n<li>a vibrant, growing community</li>\n<li>product-led growth</li>\n</ul>\n<p>By monetization, I'm loosely referring to:</p>\n<ul>\n<li>revenue (duh!)</li>\n<li>customers</li>\n<li>top-down / direct sales</li>\n<li>production deployments</li>\n<li>pilots / POCs (proofs of concept)</li>\n<li>qualified pipeline</li>\n</ul>\n<p><em>Note: monetization is a catch-all for activities and metrics that tend to correlate with revenue, so a company with zero revenue can still have a decent monetization &quot;score.&quot;</em></p>\n<p>If traction and monetization are collectively high enough, you will successfully raise your Series A round.</p>\n<p>You can even make a little equation out of this:</p>\n<p>$$\\text{Fundraising Success} = \\text{Traction} + \\text{Monetization}$$</p>\n<p>There's a threshold, a sort of activation energy, required to successfully raise a round at the early-stage. Hit this bar and you're in the clear. Miss it, and you're not:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/06/1.png\" alt=\"1\" loading=\"lazy\"></p>\n<p>Let's make up some numbers.</p>\n<p>Say the threshold is &quot;4&quot;. You'd need some combination of traction and monetization to get to a sum of four:</p>\n<ul>\n<li>A score of two on both traction and monetization would work. We could call that &quot;moderate traction and moderate monetization&quot;, or (2, 2)</li>\n<li>But a (3, 1) combo would also work â€“ perhaps &quot;high traction, low monetization&quot;, and so on.</li>\n</ul>\n<p>As long as you can get to a total of four, you're good.</p>\n<h2 id=\"2-x-2-4\">2 x 2 = 4</h2>\n<p>What if our model is wrong though?</p>\n<p>Imagine investors evaluate your startup not on the <em>sum</em> of traction and monetization, but rather the <em>product</em>. In other words, traction and monetization multiply, rather than add:</p>\n<p>$$\\text{Fundraising Success} = \\text{Traction} \\times \\text{Monetization}$$</p>\n<p>Through this lens, the marginal value of one factor depends on the other. Traction makes monetization more valuable, and vice versa. Monetization is more valuable when you have more traction.</p>\n<p>This is a much better model for how venture investors think about startups.</p>\n<p>Think about it:</p>\n<ul>\n<li>Strong traction makes additional monetization more valuable, since there's a preexisting, large group of interested, engaged users to sell into.</li>\n<li>Strong monetization increases the value of additional traction, since you know that traction will be monetizable in the future.</li>\n</ul>\n<p>The multiplicative model has an important implication however â€“ it disproportionately penalizes low traction and/or low monetization.</p>\n<p>To successfully fundraise, low monetization requires extraordinary traction, and vice versa:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/06/2.png\" alt=\"2\" loading=\"lazy\"></p>\n<p>Here's an analogy â€“ a stock that drops by 50% (OK, maybe more reality than analogy) must rise by much more than 50% to reach its original price level, since returns are multiplicative (50% x 150% is only 75%). Likewise, <strong>low monetization requires more than proportionally higher traction</strong> to make up for it.</p>\n<p>(2, 2) still works, since 2 x 2 = 4. But the (3, 1) combination is no longer viable, since 3 x 1 only equals 3. If your startup is merely a &quot;1&quot; on the monetization scale, you now need to be a &quot;4&quot; on traction. 0.5 on monetization? You need to be an 8 on traction!</p>\n<p>You can see where this is going.</p>\n<h2 id=\"3-x-1-%E2%98%A0\">3 x 1 = â˜ </h2>\n<p>Unfortunately, founders fall into the trap of thinking low monetization or traction can be made up for with merely moderate amounts of the other factor. This is wrong.</p>\n<p>Many founders think investors will evaluate them with the linear, additive model. While many investors are quite linear in their thinking (sorry, had to do it), the multiplicative perspective is the more accurate one.</p>\n<p>This clash of reality vs. expectations creates a &quot;<a href=\"https://en.wikipedia.org/wiki/No_man%27s_land\">no man's land</a>&quot; between the additive and multiplicative perspectives: founders think they'll be fine when they go out to fundraise, only to be rudely mugged by <s>the valley</s> reality:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/06/3.png\" alt=\"3\" loading=\"lazy\"></p>\n<p>I've noticed many startups in the space between the linear and convex curves attempting to raise Series A rounds lately. <strong>This invariably goes badly.</strong> The founders are surprised by the lack of investor interest and end up taking much longer to raise their round, at a lower valuation than expected.</p>\n<p>Some never raise at all.</p>\n<h2 id=\"quick-maths\">Quick maths</h2>\n<p>Avoid this needless suffering. Be honest with yourself â€“ if you're lacking in either traction or monetization, be sure you're killing it on the other dimension.</p>\n<p>I've made the point that low monetization requires extraordinary traction (and vice versa), but I haven't defined what &quot;extraordinary&quot; means. Frankly, it's subjective at best, and I'd be lying if I said there was an objective standard or rubric.</p>\n<p>When you know, you know:</p>\n<blockquote>\n<p>you can always feel product/market fit when it's happening â€“ <a href=\"https://pmarchive.com/guide_to_startups_part4.html\">Marc Andreessen</a></p>\n</blockquote>\n<blockquote>\n<p>â€¦ once you have product-market fitâ€¦ [business] performance accelerates so meaningfully that any ambiguity goes out the window. You get it &quot;in your gut.&quot; It becomes obvious, as nearly everything about the business gets better â€“ <a href=\"https://whoisnnamdi.com/product-market-fit-is-lindy/\">Product-Market Fit is Lindy</a></p>\n</blockquote>\n<blockquote>\n<p>If it is true that product-market fit yields much better business performance, then product-market fit should be relatively obvious, even with little data â€“ <a href=\"https://whoisnnamdi.com/product-market-fit-is-lindy/\">Product-Market Fit is Lindy</a></p>\n</blockquote>\n<p>Further, I've simplified the framework here and taken other factors like team, market, etc as given. Realistically, investors will evaluate those things too, complicating our math a bit:</p>\n<p>$$\\text{Fundraising Success} = \\text{Traction} \\times \\text{Monetization} \\times \\text{Team} \\times \\text{Market} \\times \\ldots$$</p>\n<p>That's a lot harder to visualize, but the same ideas apply. You need to really spike on one or more factors to make up for lower scores on the others. Get this math wrong, and you'll be in for a nasty surprise.</p>\n<p>Rather than cram for the exam, delay your Series A until you pass the simple math test I've outlined here. Until then, keep practicing those multiplication tables!</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: Series A Rounds Are a Math Test\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"62b9dd89fec7d1542d1d2bd4","plaintext":"For your seed stage startup to graduate to the next level, it must pass a new\ntest.\n\nSuddenly, a PowerPoint deck isn't enough. Traction and monetization matter.\n\nYour startup might have more of one than the other, and that's OK.\n\nBut less of one means you need more of the other. That's just math.\n\nHow much more? It turns out â€“ more than you think.\n\nLow monetization requires extraordinary traction, and vice versa.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡2 + 2 = 4\nIn addition to factors like team quality and market size (which also matter at\nthe pre-seed/seed stage), investors evaluate Series A startups on their traction \nand monetization.\n\nBy traction, I mean some rough mix of:\n\n * bottom-up adoption\n * free usage / free trials\n * organic, inbound interest in the product\n * proliferation of an open source project\n * downloads\n * a vibrant, growing community\n * product-led growth\n\nBy monetization, I'm loosely referring to:\n\n * revenue (duh!)\n * customers\n * top-down / direct sales\n * production deployments\n * pilots / POCs (proofs of concept)\n * qualified pipeline\n\nNote: monetization is a catch-all for activities and metrics that tend to\ncorrelate with revenue, so a company with zero revenue can still have a decent\nmonetization \"score.\"\n\nIf traction and monetization are collectively high enough, you will successfully\nraise your Series A round.\n\nYou can even make a little equation out of this:\n\n$$\\text{Fundraising Success} = \\text{Traction} + \\text{Monetization}$$\n\nThere's a threshold, a sort of activation energy, required to successfully raise\na round at the early-stage. Hit this bar and you're in the clear. Miss it, and\nyou're not:\n\n\n\nLet's make up some numbers.\n\nSay the threshold is \"4\". You'd need some combination of traction and\nmonetization to get to a sum of four:\n\n * A score of two on both traction and monetization would work. We could call\n   that \"moderate traction and moderate monetization\", or (2, 2)\n * But a (3, 1) combo would also work â€“ perhaps \"high traction, low\n   monetization\", and so on.\n\nAs long as you can get to a total of four, you're good.\n\n2 x 2 = 4\nWhat if our model is wrong though?\n\nImagine investors evaluate your startup not on the sum of traction and\nmonetization, but rather the product. In other words, traction and monetization\nmultiply, rather than add:\n\n$$\\text{Fundraising Success} = \\text{Traction} \\times \\text{Monetization}$$\n\nThrough this lens, the marginal value of one factor depends on the other.\nTraction makes monetization more valuable, and vice versa. Monetization is more\nvaluable when you have more traction.\n\nThis is a much better model for how venture investors think about startups.\n\nThink about it:\n\n * Strong traction makes additional monetization more valuable, since there's a\n   preexisting, large group of interested, engaged users to sell into.\n * Strong monetization increases the value of additional traction, since you\n   know that traction will be monetizable in the future.\n\nThe multiplicative model has an important implication however â€“ it\ndisproportionately penalizes low traction and/or low monetization.\n\nTo successfully fundraise, low monetization requires extraordinary traction, and\nvice versa:\n\n\n\nHere's an analogy â€“ a stock that drops by 50% (OK, maybe more reality than\nanalogy) must rise by much more than 50% to reach its original price level,\nsince returns are multiplicative (50% x 150% is only 75%). Likewise, low\nmonetization requires more than proportionally higher traction to make up for\nit.\n\n(2, 2) still works, since 2 x 2 = 4. But the (3, 1) combination is no longer\nviable, since 3 x 1 only equals 3. If your startup is merely a \"1\" on the\nmonetization scale, you now need to be a \"4\" on traction. 0.5 on monetization?\nYou need to be an 8 on traction!\n\nYou can see where this is going.\n\n3 x 1 = â˜ \nUnfortunately, founders fall into the trap of thinking low monetization or\ntraction can be made up for with merely moderate amounts of the other factor.\nThis is wrong.\n\nMany founders think investors will evaluate them with the linear, additive\nmodel. While many investors are quite linear in their thinking (sorry, had to do\nit), the multiplicative perspective is the more accurate one.\n\nThis clash of reality vs. expectations creates a \"no man's land\n[https://en.wikipedia.org/wiki/No_man%27s_land]\" between the additive and\nmultiplicative perspectives: founders think they'll be fine when they go out to\nfundraise, only to be rudely mugged by the valley reality:\n\n\n\nI've noticed many startups in the space between the linear and convex curves\nattempting to raise Series A rounds lately. This invariably goes badly. The\nfounders are surprised by the lack of investor interest and end up taking much\nlonger to raise their round, at a lower valuation than expected.\n\nSome never raise at all.\n\nQuick maths\nAvoid this needless suffering. Be honest with yourself â€“ if you're lacking in\neither traction or monetization, be sure you're killing it on the other\ndimension.\n\nI've made the point that low monetization requires extraordinary traction (and\nvice versa), but I haven't defined what \"extraordinary\" means. Frankly, it's\nsubjective at best, and I'd be lying if I said there was an objective standard\nor rubric.\n\nWhen you know, you know:\n\n> you can always feel product/market fit when it's happening â€“ Marc Andreessen\n[https://pmarchive.com/guide_to_startups_part4.html]\n\n\n> â€¦ once you have product-market fitâ€¦ [business] performance accelerates so\nmeaningfully that any ambiguity goes out the window. You get it \"in your gut.\"\nIt becomes obvious, as nearly everything about the business gets better â€“ \nProduct-Market Fit is Lindy\n[https://whoisnnamdi.com/product-market-fit-is-lindy/]\n\n\n> If it is true that product-market fit yields much better business performance,\nthen product-market fit should be relatively obvious, even with little data â€“ \nProduct-Market Fit is Lindy\n[https://whoisnnamdi.com/product-market-fit-is-lindy/]\n\n\nFurther, I've simplified the framework here and taken other factors like team,\nmarket, etc as given. Realistically, investors will evaluate those things too,\ncomplicating our math a bit:\n\n$$\\text{Fundraising Success} = \\text{Traction} \\times \\text{Monetization} \\times\n\\text{Team} \\times \\text{Market} \\times \\ldots$$\n\nThat's a lot harder to visualize, but the same ideas apply. You need to really\nspike on one or more factors to make up for lower scores on the others. Get this\nmath wrong, and you'll be in for a nasty surprise.\n\nRather than cram for the exam, delay your Series A until you pass the simple\nmath test I've outlined here. Until then, keep practicing those multiplication\ntables!\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2022/06/header.jpg","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2022-06-27T16:40:41.000Z","updated_at":"2022-07-03T23:59:35.000Z","published_at":"2022-06-27T17:01:07.000Z","custom_excerpt":"Low monetization requires extraordinary traction, and vice versa.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"62d5ca2dfec7d1542d1d2c27","uuid":"5453fa60-5a5b-4881-b4d3-bb3c29f1a43a","title":"The Dark Matter of Software Valuations","slug":"dark-matter","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"There's something strange about software valuations.\\n\\nInvestors tend to focus on [revenue growth and profitability](https://whoisnnamdi.com/rule-40/) as significant variables for valuing software companies, but those metrics only explain about *half* of the overall variation in valuations. \\n\\nThis leaves a vast amount of \\\"dark matter\\\" in the software universe â€“ variation in valuations that goes *unexplained*.\\n\\nI want to explore this vast darkness.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: The Dark Matter of Software Valuations\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## Who knew there was such skew?\\n![avg](__GHOST_URL__/content/images/2022/07/avg.png)\\n*Note: this analysis only includes public software companies that traded continuously from January 2020 to May 2022. Companies that went public or got acquired during that period are excluded.*\\n\\nIt's been said before, and it's worth repeating: **averages don't tell the whole story.**\\n\\nYou can begin to see why by plotting average revenue multiples against median multiples. *They aren't the same.*\\n\\nIn fact, the distance between them tends to fluctuate over time.\\n- In the lead up to COVID they were quite close\\n- Then, they grew apart\\n- Only recently, they've gravitated closer again\\n\\nA single line at best summarizes the data and invariably misses important details.\\n\\nLet's zoom in:\\n\\n![muldist](__GHOST_URL__/content/images/2022/07/muldist.png)\\n\\nLike [software monetization](https://whoisnnamdi.com/software-fat-tailed/), software valuations are [fat-tailed](https://en.wikipedia.org/wiki/Fat-tailed_distribution):\\n- Most companies have unremarkable valuation multiples\\n- A few, however, skew well to the right, creating a long tail of multiples\\n\\nThis tail skews the distribution of multiples and increases the variance between public software companies. I'd imagine the situation is even more extreme among private software companies.\\n\\nThat variance changes over time, rising and falling:\\n\\n![mulvar](__GHOST_URL__/content/images/2022/07/mulvar.png)\\n\\n*Note: for statistical reasons I won't explain here, the remainder of this essay will refer to log-transformed software multiples instead of their raw values.*\\n\\nI'd love to explain this dynamic.\\n\\nIt's at this point that any good software investor turns to ol' reliable: regressions of valuation multiples on revenue growth and profitability:\\n\\n![gm](__GHOST_URL__/content/images/2022/07/gm.png)\\n\\nWe see a similar, if subdued, pattern in the variance that can be explained by financial performance. But notice how much variance our standard regression leaves on the table, unexplained.\\n\\nGrowth and profitability do not perfectly predict valuations.\\n\\nI call this unexplained variance, the \\\"dark matter\\\" of software valuations:\\n\\n![varexp](__GHOST_URL__/content/images/2022/07/varexp.png)\\n\\nGrowth and profitability never explain much more than half of the variation in multiples:\\n\\n![pvarexp](__GHOST_URL__/content/images/2022/07/pvarexp.png)\\n\\nWhat's hiding down in the deep, dark depths of the software universe?\\n\\nLet's grab our telescope and zoom in once again.\\n\\n## Stranger things (and valuations)\\n\\nWe know that growth and profitability are imperfect predictors of valuation.\\n\\nLet's remove their effect and focus now on the remaining, residual, variance in valuations. This means that we'll focus on relative rather than absolute valuations â€“ relative to what growth and margins would predict, that is.\\n\\nHere's how it looks:\\n\\n![resdist](__GHOST_URL__/content/images/2022/07/resdist.png)\\n\\nThe fat tail is less severe but still persists, even after accounting for financial performance.\\n\\nMany companies hover near zero, which is to say their valuations are perfectly predicted by growth and profitability, but a number are quite \\\"overvalued\\\" on the basis of their financials alone.\\n\\nThis gap between expectations and reality is quite persistent. Over/undervaluation *does not* meaningfully mean-revert, even over multiple years:\\n\\n![resplot](__GHOST_URL__/content/images/2022/07/resplot.png)\\n\\n- A 50% overvalued company in January 2020 by May 2022 still traded **~40% above** the valuation implied by its growth and profitability\\n- A 50% undervalued company continued to sag **~35% below** its predicted valuation by the end of this period\\n\\nSome did see major revisions:\\n- Shopify, Okta, Coupa, DocuSign, and RingCentral all fell back down to Earth after flying high for some time\\n- Cloudflare, Appian, Alteryx, MongoDB, Atlassian, Anaplan, and Guidewire all ended up much higher than where they were pre-COVID\\n\\nIn addition to individual companies, the overall distribution of unexplained \\\"valuation inequality\\\" held in place the past few years, with some fluctuations:\\n\\n![percplot](__GHOST_URL__/content/images/2022/07/percplot.png)\\n\\n- Investors value the 90th percentile company **~75% more** than you'd expected from its growth and profitability\\n- Meanwhile, they peg the 10th percentile company **~50% lower** than you'd predict.\\n- In terms of ratios, 90th percentile software vendors are worth **3-5 times** their 10th percentile peers.\\n\\nRemember, *we've already accounted for revenue growth and cash flow*, yet we still see massive variability:\\n\\n![resgm](__GHOST_URL__/content/images/2022/07/resgm.png)\\n\\n- On the revenue side, among companies growing ~50% annually we see valuation gaps as large as **~70%** (i.e., same growth, yet one company is worth 70% more).\\n- It's even worse for software companies growing closer to 20% year-over-year, where the gaps are even bigger: the most valuable company is worth **~2.5 times** the least valuable.\\n- On the free cash flow side, if we look at companies within +/- 10 percentage points of breakeven, we see companies worth **five times** as much as the least valuable\\n\\nNeedless to say, the variation in software valuations is extreme, and that's *after* factoring out what we'd already expect based on financial profiles.\\n\\n## Darkness into light\\n\\nI hope I've driven the point home that growth and profitability aren't everything.\\n\\nOK, but what *is* this dark matter stuff?\\n\\nClearly the most obvious metrics fail to account for a sizable share of the variation in valuations among software stocks. Some sort of unobserved or latent characteristics drive the remaining differences.\\n\\n[Principal Component Analysis (PCA)](https://setosa.io/ev/principal-component-analysis/) is a great way to identify such latent factors. It's a statistical technique for summarizing the key informational content contained within a larger data set.\\n\\nA full explanation of PCA is beyond the scope of this essay. Just know that, like alchemy, PCA lets us put dark matter in and get some nuggets of gold out.\\n\\nWhen I run PCA, here's what I find:\\n\\n![fac](__GHOST_URL__/content/images/2022/07/fac.png)\\n\\nPCA spits out two latent \\\"factors\\\" that highly explain our up-till-now unexplained valuation puzzle.\\n\\nUnfortunately, these factors don't come out of the box with much explanation. We must interpret them manually.\\n\\nAfter staring at \\\"Factor 1\\\" for a while, it hit me â€“ the line looks eerily similar to the path of the U.S. economy over that period!\\n\\nFolks, we have a winner:\\n\\n![gdpfac](__GHOST_URL__/content/images/2022/07/gdpfac.png)\\n\\nBeautiful.\\n\\nOur first hidden factor is not a particularly mysterious one.\\n\\nDespite some claims to the contrary, investors believe software companies are quite sensitive to the broader macroeconomic environment. In fact, it's the variable that correlates *most highly* with valuations after accounting for the individual financial performance of each company.\\n\\nThe latent factor tracks the COVID recovery quite well, in some ways even better than the official GDP statistic, which is only released quarterly â€“ a significant delay.\\n\\nThe factor provides a daily, real-time estimate of economic performance, at least that portion which is relevant for software companies (also called [nowcasting](https://www.oecd.org/economy/weekly-tracker-of-gdp-growth/)).\\n\\nI had less success figuring out the second factor. If you have any ideas, please send them my way!\\n\\n With PCA, it's customary to plot the data against the first two factors, with the X and Y axes representing each company's correlation with the factor:\\n\\n![load](__GHOST_URL__/content/images/2022/07/load.png)\\n\\n- Companies on the right side correlative *positively* with the GDP factor, suggesting they've benefitted disproportionately from the COVID bounce-back\\n- Conversely, stocks hovering to the left had *less* to gain from the rebound\\n\\nI could spend (and may have already spent) hours staring at this plot. Rather than continuing to play \\\"[Where's Waldo](https://en.wikipedia.org/wiki/Where%27s_Wally%3F),\\\" here are a few clusters I noticed (Q: What did I miss?):\\n- **Financial engineering:** Developer-centric tooling and infrastructure like Datadog, Elastic, MongoDB, Atlassian, PagerDuty\\n- **Easy storage, easy life:** Storage companies Dropbox and Box\\n- **Trust, but verify:** Zero-trust and identity solutions like Okta, Ping Identity, Zscaler\\n- **Call me maybe:** Cloud-based contact center and communications companies Five9, RingCentral, 8x8\\n\\n## A step in the right direction\\n\\nNow let's come full circle and incorporate the GDP factor into our previous regression while also allowing each stock to have different sensitivity to the factor.\\n\\nHere's what we get:\\n\\n![varexp2](__GHOST_URL__/content/images/2022/07/varexp2.png)\\n\\nThe GDP factor helps explain some of the mysterious \\\"dark matter\\\" but not always the same amount:\\n- In the weeks before COVID turned everything upside-down, the GDP factor didn't explain much variation in valuations\\n- Then, as the pandemic began, the GDP factor rose in importance, granting significant predictive power\\n- As the first positive results of the mRNA vaccines come out, it recedes again, and for about three quarters the GDP factor doesn't explain much over and above individual financial performance\\n- Finally, as the COVID recovery finally stalls out, the GDP factor rises in importance again\\n\\nHere's how it looks in [R-squared](https://www.investopedia.com/terms/r/r-squared.asp) terms:\\n\\n![pvarexpfac](__GHOST_URL__/content/images/2022/07/pvarexpfac.png)\\n\\nStill a lot of dark matter out there, but we've made great progress:\\n- At it's highest, the combination of (1) individual financial performance and (2) sensitivity to economic conditions explains ~80% of the cross-sectional variance in software valuations\\n- That said, there remain times when it explains no more than 50% of valuation variance\\n\\nI'm fascinated by these dynamics, especially the middle period where, for whatever reason, economic sensitivity temporarily stopped mattering for how software companies were being valued, at least relative to one another.\\n\\n## Conclusion\\n\\nSo we've managed to chip away at some of the dark matter hiding among software valuations.\\n\\nIt's often said that the long-term growth trajectory of cloud companies is relatively secular, which is to say it's independent of general economic fluctuations.\\n\\nIt turns out software companies \\\\*are\\\\* sensitive to broader economic conditions in the short-run, at least in eyes of public investors.\\n\\nThe relevance of this sensitivity rises and falls over time:\\n- In periods of economic uncertainty (e.g. early pandemic, Q2 2022, etc), the GDP factor begins to matter quite a bit. Public investors care who gains and loses from a weakening economy.\\n- Meanwhile, when times are good, investors throw caution to the wind and ignore the economic sensitivity of software companies.\\n\\nMore sophisticated [factor modeling](https://en.wikipedia.org/wiki/Factor_analysis) could yield even more insights. No one pays me to do that though, so I think I'll [move on](https://www.youtube.com/watch?v=waEC-8GFTP4).\\n\\nIf you do have thoughts on that second mystery factor, shoot me a note!\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: The Dark Matter of Software Valuations\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>There's something strange about software valuations.</p>\n<p>Investors tend to focus on <a href=\"https://whoisnnamdi.com/rule-40/\">revenue growth and profitability</a> as significant variables for valuing software companies, but those metrics only explain about <em>half</em> of the overall variation in valuations.</p>\n<p>This leaves a vast amount of &quot;dark matter&quot; in the software universe â€“ variation in valuations that goes <em>unexplained</em>.</p>\n<p>I want to explore this vast darkness.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: The Dark Matter of Software Valuations\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"who-knew-there-was-such-skew\">Who knew there was such skew?</h2>\n<p><img src=\"__GHOST_URL__/content/images/2022/07/avg.png\" alt=\"avg\" loading=\"lazy\"><br>\n<em>Note: this analysis only includes public software companies that traded continuously from January 2020 to May 2022. Companies that went public or got acquired during that period are excluded.</em></p>\n<p>It's been said before, and it's worth repeating: <strong>averages don't tell the whole story.</strong></p>\n<p>You can begin to see why by plotting average revenue multiples against median multiples. <em>They aren't the same.</em></p>\n<p>In fact, the distance between them tends to fluctuate over time.</p>\n<ul>\n<li>In the lead up to COVID they were quite close</li>\n<li>Then, they grew apart</li>\n<li>Only recently, they've gravitated closer again</li>\n</ul>\n<p>A single line at best summarizes the data and invariably misses important details.</p>\n<p>Let's zoom in:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/07/muldist.png\" alt=\"muldist\" loading=\"lazy\"></p>\n<p>Like <a href=\"https://whoisnnamdi.com/software-fat-tailed/\">software monetization</a>, software valuations are <a href=\"https://en.wikipedia.org/wiki/Fat-tailed_distribution\">fat-tailed</a>:</p>\n<ul>\n<li>Most companies have unremarkable valuation multiples</li>\n<li>A few, however, skew well to the right, creating a long tail of multiples</li>\n</ul>\n<p>This tail skews the distribution of multiples and increases the variance between public software companies. I'd imagine the situation is even more extreme among private software companies.</p>\n<p>That variance changes over time, rising and falling:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/07/mulvar.png\" alt=\"mulvar\" loading=\"lazy\"></p>\n<p><em>Note: for statistical reasons I won't explain here, the remainder of this essay will refer to log-transformed software multiples instead of their raw values.</em></p>\n<p>I'd love to explain this dynamic.</p>\n<p>It's at this point that any good software investor turns to ol' reliable: regressions of valuation multiples on revenue growth and profitability:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/07/gm.png\" alt=\"gm\" loading=\"lazy\"></p>\n<p>We see a similar, if subdued, pattern in the variance that can be explained by financial performance. But notice how much variance our standard regression leaves on the table, unexplained.</p>\n<p>Growth and profitability do not perfectly predict valuations.</p>\n<p>I call this unexplained variance, the &quot;dark matter&quot; of software valuations:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/07/varexp.png\" alt=\"varexp\" loading=\"lazy\"></p>\n<p>Growth and profitability never explain much more than half of the variation in multiples:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/07/pvarexp.png\" alt=\"pvarexp\" loading=\"lazy\"></p>\n<p>What's hiding down in the deep, dark depths of the software universe?</p>\n<p>Let's grab our telescope and zoom in once again.</p>\n<h2 id=\"stranger-things-and-valuations\">Stranger things (and valuations)</h2>\n<p>We know that growth and profitability are imperfect predictors of valuation.</p>\n<p>Let's remove their effect and focus now on the remaining, residual, variance in valuations. This means that we'll focus on relative rather than absolute valuations â€“ relative to what growth and margins would predict, that is.</p>\n<p>Here's how it looks:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/07/resdist.png\" alt=\"resdist\" loading=\"lazy\"></p>\n<p>The fat tail is less severe but still persists, even after accounting for financial performance.</p>\n<p>Many companies hover near zero, which is to say their valuations are perfectly predicted by growth and profitability, but a number are quite &quot;overvalued&quot; on the basis of their financials alone.</p>\n<p>This gap between expectations and reality is quite persistent. Over/undervaluation <em>does not</em> meaningfully mean-revert, even over multiple years:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/07/resplot.png\" alt=\"resplot\" loading=\"lazy\"></p>\n<ul>\n<li>A 50% overvalued company in January 2020 by May 2022 still traded <strong>~40% above</strong> the valuation implied by its growth and profitability</li>\n<li>A 50% undervalued company continued to sag <strong>~35% below</strong> its predicted valuation by the end of this period</li>\n</ul>\n<p>Some did see major revisions:</p>\n<ul>\n<li>Shopify, Okta, Coupa, DocuSign, and RingCentral all fell back down to Earth after flying high for some time</li>\n<li>Cloudflare, Appian, Alteryx, MongoDB, Atlassian, Anaplan, and Guidewire all ended up much higher than where they were pre-COVID</li>\n</ul>\n<p>In addition to individual companies, the overall distribution of unexplained &quot;valuation inequality&quot; held in place the past few years, with some fluctuations:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/07/percplot.png\" alt=\"percplot\" loading=\"lazy\"></p>\n<ul>\n<li>Investors value the 90th percentile company <strong>~75% more</strong> than you'd expected from its growth and profitability</li>\n<li>Meanwhile, they peg the 10th percentile company <strong>~50% lower</strong> than you'd predict.</li>\n<li>In terms of ratios, 90th percentile software vendors are worth <strong>3-5 times</strong> their 10th percentile peers.</li>\n</ul>\n<p>Remember, <em>we've already accounted for revenue growth and cash flow</em>, yet we still see massive variability:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/07/resgm.png\" alt=\"resgm\" loading=\"lazy\"></p>\n<ul>\n<li>On the revenue side, among companies growing ~50% annually we see valuation gaps as large as <strong>~70%</strong> (i.e., same growth, yet one company is worth 70% more).</li>\n<li>It's even worse for software companies growing closer to 20% year-over-year, where the gaps are even bigger: the most valuable company is worth <strong>~2.5 times</strong> the least valuable.</li>\n<li>On the free cash flow side, if we look at companies within +/- 10 percentage points of breakeven, we see companies worth <strong>five times</strong> as much as the least valuable</li>\n</ul>\n<p>Needless to say, the variation in software valuations is extreme, and that's <em>after</em> factoring out what we'd already expect based on financial profiles.</p>\n<h2 id=\"darkness-into-light\">Darkness into light</h2>\n<p>I hope I've driven the point home that growth and profitability aren't everything.</p>\n<p>OK, but what <em>is</em> this dark matter stuff?</p>\n<p>Clearly the most obvious metrics fail to account for a sizable share of the variation in valuations among software stocks. Some sort of unobserved or latent characteristics drive the remaining differences.</p>\n<p><a href=\"https://setosa.io/ev/principal-component-analysis/\">Principal Component Analysis (PCA)</a> is a great way to identify such latent factors. It's a statistical technique for summarizing the key informational content contained within a larger data set.</p>\n<p>A full explanation of PCA is beyond the scope of this essay. Just know that, like alchemy, PCA lets us put dark matter in and get some nuggets of gold out.</p>\n<p>When I run PCA, here's what I find:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/07/fac.png\" alt=\"fac\" loading=\"lazy\"></p>\n<p>PCA spits out two latent &quot;factors&quot; that highly explain our up-till-now unexplained valuation puzzle.</p>\n<p>Unfortunately, these factors don't come out of the box with much explanation. We must interpret them manually.</p>\n<p>After staring at &quot;Factor 1&quot; for a while, it hit me â€“ the line looks eerily similar to the path of the U.S. economy over that period!</p>\n<p>Folks, we have a winner:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/07/gdpfac.png\" alt=\"gdpfac\" loading=\"lazy\"></p>\n<p>Beautiful.</p>\n<p>Our first hidden factor is not a particularly mysterious one.</p>\n<p>Despite some claims to the contrary, investors believe software companies are quite sensitive to the broader macroeconomic environment. In fact, it's the variable that correlates <em>most highly</em> with valuations after accounting for the individual financial performance of each company.</p>\n<p>The latent factor tracks the COVID recovery quite well, in some ways even better than the official GDP statistic, which is only released quarterly â€“ a significant delay.</p>\n<p>The factor provides a daily, real-time estimate of economic performance, at least that portion which is relevant for software companies (also called <a href=\"https://www.oecd.org/economy/weekly-tracker-of-gdp-growth/\">nowcasting</a>).</p>\n<p>I had less success figuring out the second factor. If you have any ideas, please send them my way!</p>\n<p>With PCA, it's customary to plot the data against the first two factors, with the X and Y axes representing each company's correlation with the factor:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/07/load.png\" alt=\"load\" loading=\"lazy\"></p>\n<ul>\n<li>Companies on the right side correlative <em>positively</em> with the GDP factor, suggesting they've benefitted disproportionately from the COVID bounce-back</li>\n<li>Conversely, stocks hovering to the left had <em>less</em> to gain from the rebound</li>\n</ul>\n<p>I could spend (and may have already spent) hours staring at this plot. Rather than continuing to play &quot;<a href=\"https://en.wikipedia.org/wiki/Where%27s_Wally%3F\">Where's Waldo</a>,&quot; here are a few clusters I noticed (Q: What did I miss?):</p>\n<ul>\n<li><strong>Financial engineering:</strong> Developer-centric tooling and infrastructure like Datadog, Elastic, MongoDB, Atlassian, PagerDuty</li>\n<li><strong>Easy storage, easy life:</strong> Storage companies Dropbox and Box</li>\n<li><strong>Trust, but verify:</strong> Zero-trust and identity solutions like Okta, Ping Identity, Zscaler</li>\n<li><strong>Call me maybe:</strong> Cloud-based contact center and communications companies Five9, RingCentral, 8x8</li>\n</ul>\n<h2 id=\"a-step-in-the-right-direction\">A step in the right direction</h2>\n<p>Now let's come full circle and incorporate the GDP factor into our previous regression while also allowing each stock to have different sensitivity to the factor.</p>\n<p>Here's what we get:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/07/varexp2.png\" alt=\"varexp2\" loading=\"lazy\"></p>\n<p>The GDP factor helps explain some of the mysterious &quot;dark matter&quot; but not always the same amount:</p>\n<ul>\n<li>In the weeks before COVID turned everything upside-down, the GDP factor didn't explain much variation in valuations</li>\n<li>Then, as the pandemic began, the GDP factor rose in importance, granting significant predictive power</li>\n<li>As the first positive results of the mRNA vaccines come out, it recedes again, and for about three quarters the GDP factor doesn't explain much over and above individual financial performance</li>\n<li>Finally, as the COVID recovery finally stalls out, the GDP factor rises in importance again</li>\n</ul>\n<p>Here's how it looks in <a href=\"https://www.investopedia.com/terms/r/r-squared.asp\">R-squared</a> terms:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/07/pvarexpfac.png\" alt=\"pvarexpfac\" loading=\"lazy\"></p>\n<p>Still a lot of dark matter out there, but we've made great progress:</p>\n<ul>\n<li>At it's highest, the combination of (1) individual financial performance and (2) sensitivity to economic conditions explains ~80% of the cross-sectional variance in software valuations</li>\n<li>That said, there remain times when it explains no more than 50% of valuation variance</li>\n</ul>\n<p>I'm fascinated by these dynamics, especially the middle period where, for whatever reason, economic sensitivity temporarily stopped mattering for how software companies were being valued, at least relative to one another.</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>So we've managed to chip away at some of the dark matter hiding among software valuations.</p>\n<p>It's often said that the long-term growth trajectory of cloud companies is relatively secular, which is to say it's independent of general economic fluctuations.</p>\n<p>It turns out software companies *are* sensitive to broader economic conditions in the short-run, at least in eyes of public investors.</p>\n<p>The relevance of this sensitivity rises and falls over time:</p>\n<ul>\n<li>In periods of economic uncertainty (e.g. early pandemic, Q2 2022, etc), the GDP factor begins to matter quite a bit. Public investors care who gains and loses from a weakening economy.</li>\n<li>Meanwhile, when times are good, investors throw caution to the wind and ignore the economic sensitivity of software companies.</li>\n</ul>\n<p>More sophisticated <a href=\"https://en.wikipedia.org/wiki/Factor_analysis\">factor modeling</a> could yield even more insights. No one pays me to do that though, so I think I'll <a href=\"https://www.youtube.com/watch?v=waEC-8GFTP4\">move on</a>.</p>\n<p>If you do have thoughts on that second mystery factor, shoot me a note!</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: The Dark Matter of Software Valuations\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"62d5ca2dfec7d1542d1d2c27","plaintext":"There's something strange about software valuations.\n\nInvestors tend to focus on revenue growth and profitability\n[https://whoisnnamdi.com/rule-40/] as significant variables for valuing software\ncompanies, but those metrics only explain about half of the overall variation in\nvaluations.\n\nThis leaves a vast amount of \"dark matter\" in the software universe â€“ variation\nin valuations that goes unexplained.\n\nI want to explore this vast darkness.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Who knew there was such skew?\n\nNote: this analysis only includes public software companies that traded\ncontinuously from January 2020 to May 2022. Companies that went public or got\nacquired during that period are excluded.\n\nIt's been said before, and it's worth repeating: averages don't tell the whole\nstory.\n\nYou can begin to see why by plotting average revenue multiples against median\nmultiples. They aren't the same.\n\nIn fact, the distance between them tends to fluctuate over time.\n\n * In the lead up to COVID they were quite close\n * Then, they grew apart\n * Only recently, they've gravitated closer again\n\nA single line at best summarizes the data and invariably misses important\ndetails.\n\nLet's zoom in:\n\n\n\nLike software monetization [https://whoisnnamdi.com/software-fat-tailed/],\nsoftware valuations are fat-tailed\n[https://en.wikipedia.org/wiki/Fat-tailed_distribution]:\n\n * Most companies have unremarkable valuation multiples\n * A few, however, skew well to the right, creating a long tail of multiples\n\nThis tail skews the distribution of multiples and increases the variance between\npublic software companies. I'd imagine the situation is even more extreme among\nprivate software companies.\n\nThat variance changes over time, rising and falling:\n\n\n\nNote: for statistical reasons I won't explain here, the remainder of this essay\nwill refer to log-transformed software multiples instead of their raw values.\n\nI'd love to explain this dynamic.\n\nIt's at this point that any good software investor turns to ol' reliable:\nregressions of valuation multiples on revenue growth and profitability:\n\n\n\nWe see a similar, if subdued, pattern in the variance that can be explained by\nfinancial performance. But notice how much variance our standard regression\nleaves on the table, unexplained.\n\nGrowth and profitability do not perfectly predict valuations.\n\nI call this unexplained variance, the \"dark matter\" of software valuations:\n\n\n\nGrowth and profitability never explain much more than half of the variation in\nmultiples:\n\n\n\nWhat's hiding down in the deep, dark depths of the software universe?\n\nLet's grab our telescope and zoom in once again.\n\nStranger things (and valuations)\nWe know that growth and profitability are imperfect predictors of valuation.\n\nLet's remove their effect and focus now on the remaining, residual, variance in\nvaluations. This means that we'll focus on relative rather than absolute\nvaluations â€“ relative to what growth and margins would predict, that is.\n\nHere's how it looks:\n\n\n\nThe fat tail is less severe but still persists, even after accounting for\nfinancial performance.\n\nMany companies hover near zero, which is to say their valuations are perfectly\npredicted by growth and profitability, but a number are quite \"overvalued\" on\nthe basis of their financials alone.\n\nThis gap between expectations and reality is quite persistent.\nOver/undervaluation does not meaningfully mean-revert, even over multiple years:\n\n\n\n * A 50% overvalued company in January 2020 by May 2022 still traded ~40% above \n   the valuation implied by its growth and profitability\n * A 50% undervalued company continued to sag ~35% below its predicted valuation\n   by the end of this period\n\nSome did see major revisions:\n\n * Shopify, Okta, Coupa, DocuSign, and RingCentral all fell back down to Earth\n   after flying high for some time\n * Cloudflare, Appian, Alteryx, MongoDB, Atlassian, Anaplan, and Guidewire all\n   ended up much higher than where they were pre-COVID\n\nIn addition to individual companies, the overall distribution of unexplained\n\"valuation inequality\" held in place the past few years, with some fluctuations:\n\n\n\n * Investors value the 90th percentile company ~75% more than you'd expected\n   from its growth and profitability\n * Meanwhile, they peg the 10th percentile company ~50% lower than you'd\n   predict.\n * In terms of ratios, 90th percentile software vendors are worth 3-5 times \n   their 10th percentile peers.\n\nRemember, we've already accounted for revenue growth and cash flow, yet we still\nsee massive variability:\n\n\n\n * On the revenue side, among companies growing ~50% annually we see valuation\n   gaps as large as ~70% (i.e., same growth, yet one company is worth 70% more).\n * It's even worse for software companies growing closer to 20% year-over-year,\n   where the gaps are even bigger: the most valuable company is worth ~2.5 times \n   the least valuable.\n * On the free cash flow side, if we look at companies within +/- 10 percentage\n   points of breakeven, we see companies worth five times as much as the least\n   valuable\n\nNeedless to say, the variation in software valuations is extreme, and that's \nafter factoring out what we'd already expect based on financial profiles.\n\nDarkness into light\nI hope I've driven the point home that growth and profitability aren't\neverything.\n\nOK, but what is this dark matter stuff?\n\nClearly the most obvious metrics fail to account for a sizable share of the\nvariation in valuations among software stocks. Some sort of unobserved or latent\ncharacteristics drive the remaining differences.\n\nPrincipal Component Analysis (PCA)\n[https://setosa.io/ev/principal-component-analysis/] is a great way to identify\nsuch latent factors. It's a statistical technique for summarizing the key\ninformational content contained within a larger data set.\n\nA full explanation of PCA is beyond the scope of this essay. Just know that,\nlike alchemy, PCA lets us put dark matter in and get some nuggets of gold out.\n\nWhen I run PCA, here's what I find:\n\n\n\nPCA spits out two latent \"factors\" that highly explain our up-till-now\nunexplained valuation puzzle.\n\nUnfortunately, these factors don't come out of the box with much explanation. We\nmust interpret them manually.\n\nAfter staring at \"Factor 1\" for a while, it hit me â€“ the line looks eerily\nsimilar to the path of the U.S. economy over that period!\n\nFolks, we have a winner:\n\n\n\nBeautiful.\n\nOur first hidden factor is not a particularly mysterious one.\n\nDespite some claims to the contrary, investors believe software companies are\nquite sensitive to the broader macroeconomic environment. In fact, it's the\nvariable that correlates most highly with valuations after accounting for the\nindividual financial performance of each company.\n\nThe latent factor tracks the COVID recovery quite well, in some ways even better\nthan the official GDP statistic, which is only released quarterly â€“ a\nsignificant delay.\n\nThe factor provides a daily, real-time estimate of economic performance, at\nleast that portion which is relevant for software companies (also called \nnowcasting [https://www.oecd.org/economy/weekly-tracker-of-gdp-growth/]).\n\nI had less success figuring out the second factor. If you have any ideas, please\nsend them my way!\n\nWith PCA, it's customary to plot the data against the first two factors, with\nthe X and Y axes representing each company's correlation with the factor:\n\n\n\n * Companies on the right side correlative positively with the GDP factor,\n   suggesting they've benefitted disproportionately from the COVID bounce-back\n * Conversely, stocks hovering to the left had less to gain from the rebound\n\nI could spend (and may have already spent) hours staring at this plot. Rather\nthan continuing to play \"Where's Waldo\n[https://en.wikipedia.org/wiki/Where%27s_Wally%3F],\" here are a few clusters I\nnoticed (Q: What did I miss?):\n\n * Financial engineering: Developer-centric tooling and infrastructure like\n   Datadog, Elastic, MongoDB, Atlassian, PagerDuty\n * Easy storage, easy life: Storage companies Dropbox and Box\n * Trust, but verify: Zero-trust and identity solutions like Okta, Ping\n   Identity, Zscaler\n * Call me maybe: Cloud-based contact center and communications companies Five9,\n   RingCentral, 8x8\n\nA step in the right direction\nNow let's come full circle and incorporate the GDP factor into our previous\nregression while also allowing each stock to have different sensitivity to the\nfactor.\n\nHere's what we get:\n\n\n\nThe GDP factor helps explain some of the mysterious \"dark matter\" but not always\nthe same amount:\n\n * In the weeks before COVID turned everything upside-down, the GDP factor\n   didn't explain much variation in valuations\n * Then, as the pandemic began, the GDP factor rose in importance, granting\n   significant predictive power\n * As the first positive results of the mRNA vaccines come out, it recedes\n   again, and for about three quarters the GDP factor doesn't explain much over\n   and above individual financial performance\n * Finally, as the COVID recovery finally stalls out, the GDP factor rises in\n   importance again\n\nHere's how it looks in R-squared\n[https://www.investopedia.com/terms/r/r-squared.asp] terms:\n\n\n\nStill a lot of dark matter out there, but we've made great progress:\n\n * At it's highest, the combination of (1) individual financial performance and\n   (2) sensitivity to economic conditions explains ~80% of the cross-sectional\n   variance in software valuations\n * That said, there remain times when it explains no more than 50% of valuation\n   variance\n\nI'm fascinated by these dynamics, especially the middle period where, for\nwhatever reason, economic sensitivity temporarily stopped mattering for how\nsoftware companies were being valued, at least relative to one another.\n\nConclusion\nSo we've managed to chip away at some of the dark matter hiding among software\nvaluations.\n\nIt's often said that the long-term growth trajectory of cloud companies is\nrelatively secular, which is to say it's independent of general economic\nfluctuations.\n\nIt turns out software companies *are* sensitive to broader economic conditions\nin the short-run, at least in eyes of public investors.\n\nThe relevance of this sensitivity rises and falls over time:\n\n * In periods of economic uncertainty (e.g. early pandemic, Q2 2022, etc), the\n   GDP factor begins to matter quite a bit. Public investors care who gains and\n   loses from a weakening economy.\n * Meanwhile, when times are good, investors throw caution to the wind and\n   ignore the economic sensitivity of software companies.\n\nMore sophisticated factor modeling\n[https://en.wikipedia.org/wiki/Factor_analysis] could yield even more insights.\nNo one pays me to do that though, so I think I'll move on\n[https://www.youtube.com/watch?v=waEC-8GFTP4].\n\nIf you do have thoughts on that second mystery factor, shoot me a note!\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2022/07/varexp-1.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2022-07-18T21:01:33.000Z","updated_at":"2022-07-24T08:03:51.000Z","published_at":"2022-07-19T09:56:45.000Z","custom_excerpt":"Exploring the vast \"dark matter\" of the software universe","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"62e93fd1fec7d1542d1d2c71","uuid":"b366d006-9ef8-48ec-8fee-cc2bbbd6f7a7","title":"COVID Hurt Most Software Companies","slug":"covid-hurt-software","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"COVID hurt most software companies.\\n\\nWhile many [claim](https://www.mckinsey.com/business-functions/strategy-and-corporate-finance/our-insights/how-covid-19-has-pushed-companies-over-the-technology-tipping-point-and-transformed-business-forever) COVID accelerated technology adoption and digital transformation, this didn't show up in the revenue of most software vendors.\\n\\nIn fact, the typical public software company remains 10-12% below its pre-COVID revenue trend, and the gap is only widening.\\n\\n**COVID put most software companies on a permanently lower growth trajectory.**\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: COVID Hurt Most Software Companies\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## A few case studies\\nThe COVID shock generated divergent outcomes across software companies.\\n\\nLet's focus on three examples to see what I mean: Zoom, Cloudflare, and Splunk.\\n\\nThe solid lines below represent the ([log-transformed](https://people.duke.edu/~rnau/411log.htm)) quarterly revenue of each company. The dashed line represents a constant-growth linear trend based on their two-year *pre-COVID* revenue trajectory. Since the scale is in logs, straight lines imply *constant quarter-over-quarter growth*:\\n\\n![trends](__GHOST_URL__/content/images/2022/08/trends.png)\\n\\nWe see some interesting behavior as we cross the dashed line, which represents Q4 2019, the last quarter before COVID struck:\\n- **Zoom** immediately takes off, \\\"zooming\\\" above its pre-COVID trend as millions move to online communication. The trend eventually catches up\\n- **Cloudflare** is totally in the clouds, floating along like nothing happened, perfectly matching its pre-COVID trend of constant, exponential growth\\n- **Splunk** exhibits strong seasonality, so the initial decline is no surprise. However, it never recovers to trend, even two years later. Splunk got dunked\\n\\nThese symptoms run the gamut from manic to lethargic. Clearly, COVID was not a tide that raised all boats.\\n\\n## Mean reversion, or mean revision?\\nWe can repeat the above analysis for all public software companies with enough data to establish a two-year pre-COVID trend. Given the different revenue scales, for visualization purposes let's normalize by dividing each company's actual performance by its extrapolated trend. This gives us the relative revenue performance of each vs. trend:\\n\\n![deviation](__GHOST_URL__/content/images/2022/08/deviation.png)\\n\\nEach line represents performance vs. trend for one of fifty different public software companies.\\n\\nWith this we can begin to see the rich variety of post-COVID outcomes. Let's highlight our three case studies once more:\\n\\n![equal](__GHOST_URL__/content/images/2022/08/equal.png)\\n\\n- Notice how dramatic and unrepresentative Zoom is among all software companies. **Zoom peaks at ~150% above trend** before gliding back down to Earth\\n- On the other hand, Splunk comes out as one of the worst performers, among others like Alteryx and Benefitfocus\\n\\nThere's a lot going on here, making it difficult to get a sense of the underlying distribution. Let's flip the axes and look at it a different way:\\n\\n![dispersion](__GHOST_URL__/content/images/2022/08/dispersion.png)\\n\\nThe above chart plots histograms of performance relative to trend across public software companies from Q1 2020 onward:\\n- Upon impact, performance is normally distributed, centered somewhat below zero\\n- Over the subsequent quarters, the distribution *shifts left and widens*, implying worse outcomes and greater dispersion between companies\\n- By eight quarters out, **performance is unambiguously below trend**, while variance continues to grow\\n\\nNotice the skew: **a handful of winners among a majority of losers.**\\n\\nAnother way to look at the data is to calculate the proportion of software companies that climbed  above their pre-COVID trend over time:\\n\\n![aversion](__GHOST_URL__/content/images/2022/08/aversion.png)\\n\\n- Initially, only a quarter of software vendors were above trend\\n- One year out, one-third of companies have returned to trend \\n- The proportion stabilizes thereafter. **Mean reversion is over**\\n\\n*This is interesting.* As dispersion grew in the first year of the pandemic, some companies returned to their pre-COVID trend. After these initial quick recoveries, however, **mean reversion completely shuts down.** The last lifeboats cast off, and if you aren't onboard, you're [ngmi](https://nftska.com/what-is-the-meaning-of-ngmi-and-wagmi-nft-terminology/).\\n\\nA key point I want to drive home: mean reversion is a strong force, but **COVID was stronger**, especially on the downside. Once knocked down, the typical software business never got back up.\\n\\n## Weakness, in numbers\\nFinally, let's summarize those performance distributions by their means and medians:\\n\\n![mm-1](__GHOST_URL__/content/images/2022/08/mm-1.png)\\n\\nThis is what I've been building up to â€“ **COVID materially impaired the typical software company, knocking it off trend**:\\n- On average, software companies were down **~5% relative to trend 4 quarters out and down ~10% 8 quarters after impact**\\n- The median dampens the impact of outliers like Zoom. Notice, median performance is *even worse*, **~7.5% at 4 quarters and ~12.5% at 8 quarters**\\n- Meanwhile, underperformance relative to trend is still increasing. The gap between actual revenue and trend is growing ~4% per year\\n\\nThus, COVID's impact was not transitory: **COVID permanently reduced the annual growth rate of public software companies by 4 percentage points.**\\n\\n*Mean revision* is at least as important as mean reversion. Not only are software companies below their pre-COVID trend, *the trend itself* has changed for the worse.\\n\\n## Conclusion: Conflation\\nI think there's been a massive conflation between:\\n1. the equity returns of software companies during the first year and half of COVID (exceptional, but temporary),\\n2. the financial performance of a select few COVID beneficiaries like Zoom (again, exceptional, but transitory), and \\n3. the business performance of the broader software market (poor, and durably so)\\n\\nThe temporarily exuberant stock prices of most software companies distracted from the toll COVID took on business performance. While investors got high on the Fed's supply, businesses themselves were silently suffocating.\\n\\nThis corroborates the findings of my [last essay](https://whoisnnamdi.com/dark-matter/), where I explored how the mysterious \\\"GDP factor\\\" explains some the the \\\"dark matter\\\" in software valuations:\\n> Despite some claims to the contrary, investors believe software companies are quite sensitive to the broader macroeconomic environment. In fact, it's the variable that correlatesÂ _most highly_Â with valuations after accounting for the individual financial performance of each company â€“ [The Dark Matter of Software Valuations](https://whoisnnamdi.com/dark-matter/)\\n\\nHere again, I find that software companies are sensitive to economic conditions, even in a best case scenario that supposedly favored them. \\\"Digital transformation\\\" can't come quickly enough it seems.\\n\\nSo let's set the record straight: **COVID left a nasty scar on us all, software companies included.**\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: COVID Hurt Most Software Companies\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>COVID hurt most software companies.</p>\n<p>While many <a href=\"https://www.mckinsey.com/business-functions/strategy-and-corporate-finance/our-insights/how-covid-19-has-pushed-companies-over-the-technology-tipping-point-and-transformed-business-forever\">claim</a> COVID accelerated technology adoption and digital transformation, this didn't show up in the revenue of most software vendors.</p>\n<p>In fact, the typical public software company remains 10-12% below its pre-COVID revenue trend, and the gap is only widening.</p>\n<p><strong>COVID put most software companies on a permanently lower growth trajectory.</strong></p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: COVID Hurt Most Software Companies\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"a-few-case-studies\">A few case studies</h2>\n<p>The COVID shock generated divergent outcomes across software companies.</p>\n<p>Let's focus on three examples to see what I mean: Zoom, Cloudflare, and Splunk.</p>\n<p>The solid lines below represent the (<a href=\"https://people.duke.edu/~rnau/411log.htm\">log-transformed</a>) quarterly revenue of each company. The dashed line represents a constant-growth linear trend based on their two-year <em>pre-COVID</em> revenue trajectory. Since the scale is in logs, straight lines imply <em>constant quarter-over-quarter growth</em>:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/08/trends.png\" alt=\"trends\" loading=\"lazy\"></p>\n<p>We see some interesting behavior as we cross the dashed line, which represents Q4 2019, the last quarter before COVID struck:</p>\n<ul>\n<li><strong>Zoom</strong> immediately takes off, &quot;zooming&quot; above its pre-COVID trend as millions move to online communication. The trend eventually catches up</li>\n<li><strong>Cloudflare</strong> is totally in the clouds, floating along like nothing happened, perfectly matching its pre-COVID trend of constant, exponential growth</li>\n<li><strong>Splunk</strong> exhibits strong seasonality, so the initial decline is no surprise. However, it never recovers to trend, even two years later. Splunk got dunked</li>\n</ul>\n<p>These symptoms run the gamut from manic to lethargic. Clearly, COVID was not a tide that raised all boats.</p>\n<h2 id=\"mean-reversion-or-mean-revision\">Mean reversion, or mean revision?</h2>\n<p>We can repeat the above analysis for all public software companies with enough data to establish a two-year pre-COVID trend. Given the different revenue scales, for visualization purposes let's normalize by dividing each company's actual performance by its extrapolated trend. This gives us the relative revenue performance of each vs. trend:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/08/deviation.png\" alt=\"deviation\" loading=\"lazy\"></p>\n<p>Each line represents performance vs. trend for one of fifty different public software companies.</p>\n<p>With this we can begin to see the rich variety of post-COVID outcomes. Let's highlight our three case studies once more:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/08/equal.png\" alt=\"equal\" loading=\"lazy\"></p>\n<ul>\n<li>Notice how dramatic and unrepresentative Zoom is among all software companies. <strong>Zoom peaks at ~150% above trend</strong> before gliding back down to Earth</li>\n<li>On the other hand, Splunk comes out as one of the worst performers, among others like Alteryx and Benefitfocus</li>\n</ul>\n<p>There's a lot going on here, making it difficult to get a sense of the underlying distribution. Let's flip the axes and look at it a different way:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/08/dispersion.png\" alt=\"dispersion\" loading=\"lazy\"></p>\n<p>The above chart plots histograms of performance relative to trend across public software companies from Q1 2020 onward:</p>\n<ul>\n<li>Upon impact, performance is normally distributed, centered somewhat below zero</li>\n<li>Over the subsequent quarters, the distribution <em>shifts left and widens</em>, implying worse outcomes and greater dispersion between companies</li>\n<li>By eight quarters out, <strong>performance is unambiguously below trend</strong>, while variance continues to grow</li>\n</ul>\n<p>Notice the skew: <strong>a handful of winners among a majority of losers.</strong></p>\n<p>Another way to look at the data is to calculate the proportion of software companies that climbed  above their pre-COVID trend over time:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/08/aversion.png\" alt=\"aversion\" loading=\"lazy\"></p>\n<ul>\n<li>Initially, only a quarter of software vendors were above trend</li>\n<li>One year out, one-third of companies have returned to trend</li>\n<li>The proportion stabilizes thereafter. <strong>Mean reversion is over</strong></li>\n</ul>\n<p><em>This is interesting.</em> As dispersion grew in the first year of the pandemic, some companies returned to their pre-COVID trend. After these initial quick recoveries, however, <strong>mean reversion completely shuts down.</strong> The last lifeboats cast off, and if you aren't onboard, you're <a href=\"https://nftska.com/what-is-the-meaning-of-ngmi-and-wagmi-nft-terminology/\">ngmi</a>.</p>\n<p>A key point I want to drive home: mean reversion is a strong force, but <strong>COVID was stronger</strong>, especially on the downside. Once knocked down, the typical software business never got back up.</p>\n<h2 id=\"weakness-in-numbers\">Weakness, in numbers</h2>\n<p>Finally, let's summarize those performance distributions by their means and medians:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/08/mm-1.png\" alt=\"mm-1\" loading=\"lazy\"></p>\n<p>This is what I've been building up to â€“ <strong>COVID materially impaired the typical software company, knocking it off trend</strong>:</p>\n<ul>\n<li>On average, software companies were down <strong>~5% relative to trend 4 quarters out and down ~10% 8 quarters after impact</strong></li>\n<li>The median dampens the impact of outliers like Zoom. Notice, median performance is <em>even worse</em>, <strong>~7.5% at 4 quarters and ~12.5% at 8 quarters</strong></li>\n<li>Meanwhile, underperformance relative to trend is still increasing. The gap between actual revenue and trend is growing ~4% per year</li>\n</ul>\n<p>Thus, COVID's impact was not transitory: <strong>COVID permanently reduced the annual growth rate of public software companies by 4 percentage points.</strong></p>\n<p><em>Mean revision</em> is at least as important as mean reversion. Not only are software companies below their pre-COVID trend, <em>the trend itself</em> has changed for the worse.</p>\n<h2 id=\"conclusion-conflation\">Conclusion: Conflation</h2>\n<p>I think there's been a massive conflation between:</p>\n<ol>\n<li>the equity returns of software companies during the first year and half of COVID (exceptional, but temporary),</li>\n<li>the financial performance of a select few COVID beneficiaries like Zoom (again, exceptional, but transitory), and</li>\n<li>the business performance of the broader software market (poor, and durably so)</li>\n</ol>\n<p>The temporarily exuberant stock prices of most software companies distracted from the toll COVID took on business performance. While investors got high on the Fed's supply, businesses themselves were silently suffocating.</p>\n<p>This corroborates the findings of my <a href=\"https://whoisnnamdi.com/dark-matter/\">last essay</a>, where I explored how the mysterious &quot;GDP factor&quot; explains some the the &quot;dark matter&quot; in software valuations:</p>\n<blockquote>\n<p>Despite some claims to the contrary, investors believe software companies are quite sensitive to the broader macroeconomic environment. In fact, it's the variable that correlatesÂ <em>most highly</em>Â with valuations after accounting for the individual financial performance of each company â€“ <a href=\"https://whoisnnamdi.com/dark-matter/\">The Dark Matter of Software Valuations</a></p>\n</blockquote>\n<p>Here again, I find that software companies are sensitive to economic conditions, even in a best case scenario that supposedly favored them. &quot;Digital transformation&quot; can't come quickly enough it seems.</p>\n<p>So let's set the record straight: <strong>COVID left a nasty scar on us all, software companies included.</strong></p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: COVID Hurt Most Software Companies\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"62e93fd1fec7d1542d1d2c71","plaintext":"COVID hurt most software companies.\n\nWhile many claim\n[https://www.mckinsey.com/business-functions/strategy-and-corporate-finance/our-insights/how-covid-19-has-pushed-companies-over-the-technology-tipping-point-and-transformed-business-forever] \nCOVID accelerated technology adoption and digital transformation, this didn't\nshow up in the revenue of most software vendors.\n\nIn fact, the typical public software company remains 10-12% below its pre-COVID\nrevenue trend, and the gap is only widening.\n\nCOVID put most software companies on a permanently lower growth trajectory.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡A few case studies\nThe COVID shock generated divergent outcomes across software companies.\n\nLet's focus on three examples to see what I mean: Zoom, Cloudflare, and Splunk.\n\nThe solid lines below represent the (log-transformed\n[https://people.duke.edu/~rnau/411log.htm]) quarterly revenue of each company.\nThe dashed line represents a constant-growth linear trend based on their\ntwo-year pre-COVID revenue trajectory. Since the scale is in logs, straight\nlines imply constant quarter-over-quarter growth:\n\n\n\nWe see some interesting behavior as we cross the dashed line, which represents\nQ4 2019, the last quarter before COVID struck:\n\n * Zoom immediately takes off, \"zooming\" above its pre-COVID trend as millions\n   move to online communication. The trend eventually catches up\n * Cloudflare is totally in the clouds, floating along like nothing happened,\n   perfectly matching its pre-COVID trend of constant, exponential growth\n * Splunk exhibits strong seasonality, so the initial decline is no surprise.\n   However, it never recovers to trend, even two years later. Splunk got dunked\n\nThese symptoms run the gamut from manic to lethargic. Clearly, COVID was not a\ntide that raised all boats.\n\nMean reversion, or mean revision?\nWe can repeat the above analysis for all public software companies with enough\ndata to establish a two-year pre-COVID trend. Given the different revenue\nscales, for visualization purposes let's normalize by dividing each company's\nactual performance by its extrapolated trend. This gives us the relative revenue\nperformance of each vs. trend:\n\n\n\nEach line represents performance vs. trend for one of fifty different public\nsoftware companies.\n\nWith this we can begin to see the rich variety of post-COVID outcomes. Let's\nhighlight our three case studies once more:\n\n\n\n * Notice how dramatic and unrepresentative Zoom is among all software\n   companies. Zoom peaks at ~150% above trend before gliding back down to Earth\n * On the other hand, Splunk comes out as one of the worst performers, among\n   others like Alteryx and Benefitfocus\n\nThere's a lot going on here, making it difficult to get a sense of the\nunderlying distribution. Let's flip the axes and look at it a different way:\n\n\n\nThe above chart plots histograms of performance relative to trend across public\nsoftware companies from Q1 2020 onward:\n\n * Upon impact, performance is normally distributed, centered somewhat below\n   zero\n * Over the subsequent quarters, the distribution shifts left and widens,\n   implying worse outcomes and greater dispersion between companies\n * By eight quarters out, performance is unambiguously below trend, while\n   variance continues to grow\n\nNotice the skew: a handful of winners among a majority of losers.\n\nAnother way to look at the data is to calculate the proportion of software\ncompanies that climbed above their pre-COVID trend over time:\n\n\n\n * Initially, only a quarter of software vendors were above trend\n * One year out, one-third of companies have returned to trend\n * The proportion stabilizes thereafter. Mean reversion is over\n\nThis is interesting. As dispersion grew in the first year of the pandemic, some\ncompanies returned to their pre-COVID trend. After these initial quick\nrecoveries, however, mean reversion completely shuts down. The last lifeboats\ncast off, and if you aren't onboard, you're ngmi\n[https://nftska.com/what-is-the-meaning-of-ngmi-and-wagmi-nft-terminology/].\n\nA key point I want to drive home: mean reversion is a strong force, but COVID\nwas stronger, especially on the downside. Once knocked down, the typical\nsoftware business never got back up.\n\nWeakness, in numbers\nFinally, let's summarize those performance distributions by their means and\nmedians:\n\n\n\nThis is what I've been building up to â€“ COVID materially impaired the typical\nsoftware company, knocking it off trend:\n\n * On average, software companies were down ~5% relative to trend 4 quarters out\n   and down ~10% 8 quarters after impact\n * The median dampens the impact of outliers like Zoom. Notice, median\n   performance is even worse, ~7.5% at 4 quarters and ~12.5% at 8 quarters\n * Meanwhile, underperformance relative to trend is still increasing. The gap\n   between actual revenue and trend is growing ~4% per year\n\nThus, COVID's impact was not transitory: COVID permanently reduced the annual\ngrowth rate of public software companies by 4 percentage points.\n\nMean revision is at least as important as mean reversion. Not only are software\ncompanies below their pre-COVID trend, the trend itself has changed for the\nworse.\n\nConclusion: Conflation\nI think there's been a massive conflation between:\n\n 1. the equity returns of software companies during the first year and half of\n    COVID (exceptional, but temporary),\n 2. the financial performance of a select few COVID beneficiaries like Zoom\n    (again, exceptional, but transitory), and\n 3. the business performance of the broader software market (poor, and durably\n    so)\n\nThe temporarily exuberant stock prices of most software companies distracted\nfrom the toll COVID took on business performance. While investors got high on\nthe Fed's supply, businesses themselves were silently suffocating.\n\nThis corroborates the findings of my last essay\n[https://whoisnnamdi.com/dark-matter/], where I explored how the mysterious \"GDP\nfactor\" explains some the the \"dark matter\" in software valuations:\n\n> Despite some claims to the contrary, investors believe software companies are\nquite sensitive to the broader macroeconomic environment. In fact, it's the\nvariable that correlatesmost highlywith valuations after accounting for the\nindividual financial performance of each company â€“ The Dark Matter of Software\nValuations [https://whoisnnamdi.com/dark-matter/]\n\n\nHere again, I find that software companies are sensitive to economic conditions,\neven in a best case scenario that supposedly favored them. \"Digital\ntransformation\" can't come quickly enough it seems.\n\nSo let's set the record straight: COVID left a nasty scar on us all, software\ncompanies included.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2022/08/mm.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2022-08-02T15:16:33.000Z","updated_at":"2022-08-02T16:15:30.000Z","published_at":"2022-08-02T15:25:00.000Z","custom_excerpt":"COVID put software companies on a permanently lower growth trajectory.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"630f3947fec7d1542d1d2cc5","uuid":"402e7ebf-9a66-4685-8073-542c9bf332f4","title":"Layoffs Don't Tell the Whole Story","slug":"layoffs","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Layoffs grab headlines. Hiring freezes, less so.\\n\\nSites like [layoffs.fyi](https://layoffs.fyi/) track layoffs in gory detail, as do journalists and tech writers:\"}],[\"embed\",{\"url\":\"https://twitter.com/GergelyOrosz/status/1549765632790601729\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">Large layoff rounds in tech, sadly, are still on.<br><br>Olive AI let go ~30% of staff. They were one of the biggest unicorns in the Midwest (valued $4B)<br><br>Capsule (digital pharmacy startup, valued &gt;$1B) had large layoffs. I&#39;m still not sure of the exact % here (feel free to DM)</p>&mdash; Gergely Orosz (@GergelyOrosz) <a href=\\\"https://twitter.com/GergelyOrosz/status/1549765632790601729?ref_src=twsrc%5Etfw\\\">July 20, 2022</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\",\"metadata\":{\"url\":\"https://twitter.com/GergelyOrosz/status/1549765632790601729\",\"author_name\":\"Gergely Orosz\",\"author_url\":\"https://twitter.com/GergelyOrosz\",\"width\":550,\"height\":null,\"cache_age\":\"3153600000\",\"provider_name\":\"Twitter\",\"provider_url\":\"http://www.twitter.com/\",\"version\":\"1.0\"}}],[\"markdown\",{\"markdown\":\"However, it's slow hiring, not layoffs, that most drives unemployment.\\n\\nLayoffs don't tell the whole story.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Layoffs Don't Tell the Whole Story\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## Stocking up\\n\\nEmployment and unemployment are both \\\"stocks\\\".\\n\\nStocks are quantities measured at a point in time that change over time. For example:\\n* The volume of water in a lake\\n* The stock (hint hint) of inventory in a retail store\\n* Cash on a company's balance sheet\\n\\nOn the other hand, \\\"flows\\\" are rates of change of a particular stock. For example:\\n- Water from various rivers flowing (hint hint) into a lake\\n- Shipments of new inventory\\n- A startup's monthly burn rate\\n\\nA single stock can have multiple associated flows, and the sum total of these flows determines how the stock changes over time.\\n\\nIn the labor market, workers flow between employment and unemployment (stocks) at various rates (flows):\\n![SCR-20220831-4nv](__GHOST_URL__/content/images/2022/08/SCR-20220831-4nv.png)\\n\\nIn equilibrium, the various stocks of a closed system are stable. However, if the individual flows change, the related stocks change too:\\n- During recessions, flows from employment to unemployment (job separation) increase, while the flows out of unemployment into employment (job finding) decrease\\n- Vice versa for recoveries â€“ people find jobs more quickly and fewer people get laid off in the first place\\n\\nIn this way, variation in job separation and job finding \\\"explain\\\" changes in unemployment.\\n\\n## As the labor market cools, hiring freezes\\n\\nWe commonly associate unemployment with layoffs. During recessions, we imagine heartless employers suddenly laying off droves of workers:\\n![CleanShot-2022-08-18-at-12.54.17@2x](__GHOST_URL__/content/images/2022/08/CleanShot-2022-08-18-at-12.54.17@2x.png)\\n\\nWhile this story feels intuitive, the data doesn't bear this out.\\n\\nThe below chart plots the U.S. \\\"employment exit rate\\\" (a euphemism for layoffs or voluntary quitting that ends in unemployment) along with the unemployment rate itself. Think about the exit rate as the share of all employed workers who leave employment each quarter:\\n![exit-1](__GHOST_URL__/content/images/2022/08/exit-1.png)\\n\\nEmployment exits jiggle up and down at a much higher frequency than unemployment, and the timing of those short term fluctuations doesn't align well with granular movements in unemployment. Over longer periods though, they do seem loosely connected. \\n\\nNow let's look at the other piece of the puzzle. Here, I've swapped out employment exit for the \\\"job finding rate,\\\" i.e. the proportion of unemployed workers who find a job each quarter:\\n![job](__GHOST_URL__/content/images/2022/08/job.png)\\n\\n**The lines perfectly mirror each other.** \\n\\nThe fluctuations closely track the state of the economy. When job finding plummets, unemployment rises at the same time. As the economist Robert Shimer put it:\\n> â€¦ a decline in the job finding rateâ€¦ contributed to every increase in the unemployment rate during the post-war period â€“ [Reassessing the Ins and Outs of Unemployment](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1014798)\\n\\nAs the job finding rate slowly recovers, so does unemployment.\\n\\nSo, rather than massive layoffs defining recessions and spikes in unemployment, the more powerful explanatory story is one of hiring freezes â€“ employers simply stop hiring during recessions. \\n\\nPer our stocks-and-flows model, the stock of unemployed workers grows and shrinks primarily due to variation in the *outflow* from unemployment to employment rather than the *inflow* of employment to unemployment.\\n\\nIn other words, **hiring freezes are the real story**, not layoffs.\\n\\n## Hiring or firing?\\n\\nWhat's the relative importance of hiring freezes vs layoffs?\\n\\nHere's how we can estimate this:\\n- Let's say we hold variable A constant and allow variable B to move around. If unemployment still moves around a lot then we know most of its variation is driven by variable B\\n- Similar logic applies in the opposite scenario (allowing A to fluctuate while holding B constant)\\n\\nThis table quantifies the relative contributions of job entry and exit rates to overall unemployment variability by calculating counterfactual scenarios in which either variable is held constant while the other is allowed to fluctuate. The first row holds job separation constant and the second holds job finding constant ([Source](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1014798)):\\n![Pasted-image-20220814173836](__GHOST_URL__/content/images/2022/08/Pasted-image-20220814173836.png)\\n\\nThe result?\\n> ... since 1987, including the recessions in 1990â€“1991 and 2001, and 2008â€“2009, the job finding rate accounted for virtually all fluctuations in the unemployment rate â€“ [Reassessing the Ins and Outs of Unemployment](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1014798)\\n\\n**The job finding rate explains the vast majority of variation in unemployment**, and the proportion has only increased over time.\\n\\nFrom 1987 to 2010, **variation in the job finding rate explained 90% of the variance in unemployment,** while employment exit only explained 10%.\\n\\nHere's Shimer again:\\n> The bulk of the reason unemployment rises and stays high throughout the recovery is because the unemployed workers stay unemployed for longerâ€¦\\n\\nThis is precise, quantitative evidence for the overwhelming importance of hiring over firing in explaining unemployment.\\n\\n## Hyper-(de)growth\\n\\nIf the prior data seemed counterintuitive, the following example shouldn't.\\n\\nImagine you're a high-growth startup with big ambitions to grow the employee base in the coming year:\\n- You are currently 100 employees\\n- You want to hire an additional 100 people over the next year\\n- We ignore voluntary attrition just to keep the numbers simple\\n\\nSuddenly, the environment changes:\\n- Economic conditions worsen, capital gets tighter, you start to miss plan, etc\\n- You need to make cuts, both in the current employee base *and* the future one\\n- So, you lay off 20% of the team\\n\\nThis is extremely painful, demoralizing, and controversial, only made easier by the fact that everyone else is doing it too:\"}],[\"embed\",{\"url\":\"https://twitter.com/whoisnnamdi/status/1522354980111347712\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">My sense is that it&#39;s partly - &quot;if we layoff people at the same time everyone else does, it&#39;ll look more like bad market conditions were to blame and less like we&#39;ve ran this thing poorly&quot;<br><br>i.e. if everyone stampedes at the same time, no one is to blame for trampling anyone</p>&mdash; Nnamdi Iregbulem (@whoisnnamdi) <a href=\\\"https://twitter.com/whoisnnamdi/status/1522354980111347712?ref_src=twsrc%5Etfw\\\">May 5, 2022</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\",\"metadata\":{\"url\":\"https://twitter.com/whoisnnamdi/status/1522354980111347712\",\"author_name\":\"Nnamdi Iregbulem\",\"author_url\":\"https://twitter.com/whoisnnamdi\",\"width\":550,\"height\":null,\"cache_age\":\"3153600000\",\"provider_name\":\"Twitter\",\"provider_url\":\"http://www.twitter.com/\",\"version\":\"1.0\"}}],[\"markdown\",{\"markdown\":\"You also institute a hiring freeze, which only seems fair after laying off so many team members:\"}],[\"embed\",{\"url\":\"https://twitter.com/GergelyOrosz/status/1545358652424568833\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">3. Immediately re-hiring after layoffs paints the picture of leadership of what it is:<br><br>Incompetent.<br><br>Couldn&#39;t even figure out what % of people to lay off.</p>&mdash; Gergely Orosz (@GergelyOrosz) <a href=\\\"https://twitter.com/GergelyOrosz/status/1545358652424568833?ref_src=twsrc%5Etfw\\\">July 8, 2022</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\",\"metadata\":{\"url\":\"https://twitter.com/GergelyOrosz/status/1545358652424568833\",\"author_name\":\"Gergely Orosz\",\"author_url\":\"https://twitter.com/GergelyOrosz\",\"width\":550,\"height\":null,\"cache_age\":\"3153600000\",\"provider_name\":\"Twitter\",\"provider_url\":\"http://www.twitter.com/\",\"version\":\"1.0\"}}],[\"markdown\",{\"markdown\":\"It doesn't take an HR savant to realize you aren't going to hit your original 200 headcount target for next year.\\n\\nNow do the gap analysis â€“ between layoffs and slowed hiring, which is more responsible for missing the original headcount target?\\n\\nIt's the hiring freeze of course!\\n- You laid off 100 x 20% = 20 people\\n- Meanwhile, you cut the hiring plan from 100 to zero\\n\\nIn effect, you \\\"fired\\\" or \\\"laid off\\\" 100 *future* employees while only laying off 20 *current* ones:\\n![SCR-20220831-4vs](__GHOST_URL__/content/images/2022/08/SCR-20220831-4vs.png)\\n\\nAs one founder friend whose recent layoff was leaked on social media told me:\\n> Sure, the layoff news leaked, but when we modeled this stuff out we realized it's the reduced hiring that would save us the most cash.\\n\\nA hiring freeze is a **much** bigger story, even if the media only reports layoffs:\\n- Internally, management knows the hiring freeze will have a larger impact on team velocity (and, frankly, cash burn) than the layoffs.\\n- Yet externally, everyone will focus on the layoffs.\\n\\nThis misses the raging forest fire for the merely singed trees.\\n\\n## A new perspective\\n\\nRecognizing the importance of hiring freezes should change your focus regardless of whether you're a founder or an employee.\\n\\nAs a tech worker:\\n- The biggest risk you face in an economic downturn is not so much losing your current job but instead **being unable to find a new one** (due to hiring freezes)\\n- In addition, as you assess the viability of various startups, pay equal, if not more, attention to slowed hiring at the company than highly visible layoffs\\n- When interviewing, ask about the hiring plan and how it's changed in recent quarters\\n\\nIf you're a founder:\\n- Slowed hiring is the real sign of weakness and vulnerability in your competition\\n- Even with no layoffs, your competitors could be in a dire financial straits, necessitating a complete freeze in hiring\\n- If you're well-capitalized, your biggest opportunity during a downturn isn't picking up people who were laid off (though you should definitely consider this) but rather hiring the people your competitors *would have wanted* but now can't due to hiring constraints\\n\\n## Lay off the layoffs\\n\\nLayoffs are a noisy estimate of company performance:\\n- Layoffs are tainted with worries about public perception and internal morale, making otherwise troubled companies hesitant to do them\\n- Companies conduct layoffs during downturns in part because everyone else is doing it, and they know they wonâ€™t look as bad if they move with the herd\\n\\nHiring freezes are a clean signal of a viability and confidence of management:\\n- Few companies would cut back on their hiring plans *simply to fit in* \\n- If anything, knowing others are pulling back makes companies *more* aggressive in hiring\\n\\nThat said, hiring freezes are opaque from the outside:\\n- Outside of large organizations, most never publicly announce hiring freezes\\n- In many cases, hiring freezes aren't even openly discussed *internally* outside of the core executive team and the board of directors\\n\\nKeep in mind both the seen *and* the unseen. It's easy to focus on the shock and awe of layoffs, but you miss so much in doing so.\\n\\nLayoffs aren't even half the story â€“ they're 10% of it.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: Layoffs Don't Tell the Whole Story\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[10,3],[10,4],[10,5],[10,6],[1,\"p\",[]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>Layoffs grab headlines. Hiring freezes, less so.</p>\n<p>Sites like <a href=\"https://layoffs.fyi/\">layoffs.fyi</a> track layoffs in gory detail, as do journalists and tech writers:</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Large layoff rounds in tech, sadly, are still on.<br><br>Olive AI let go ~30% of staff. They were one of the biggest unicorns in the Midwest (valued $4B)<br><br>Capsule (digital pharmacy startup, valued &gt;$1B) had large layoffs. I&#39;m still not sure of the exact % here (feel free to DM)</p>&mdash; Gergely Orosz (@GergelyOrosz) <a href=\"https://twitter.com/GergelyOrosz/status/1549765632790601729?ref_src=twsrc%5Etfw\">July 20, 2022</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><!--kg-card-begin: markdown--><p>However, it's slow hiring, not layoffs, that most drives unemployment.</p>\n<p>Layoffs don't tell the whole story.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Layoffs Don't Tell the Whole Story\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"stocking-up\">Stocking up</h2>\n<p>Employment and unemployment are both &quot;stocks&quot;.</p>\n<p>Stocks are quantities measured at a point in time that change over time. For example:</p>\n<ul>\n<li>The volume of water in a lake</li>\n<li>The stock (hint hint) of inventory in a retail store</li>\n<li>Cash on a company's balance sheet</li>\n</ul>\n<p>On the other hand, &quot;flows&quot; are rates of change of a particular stock. For example:</p>\n<ul>\n<li>Water from various rivers flowing (hint hint) into a lake</li>\n<li>Shipments of new inventory</li>\n<li>A startup's monthly burn rate</li>\n</ul>\n<p>A single stock can have multiple associated flows, and the sum total of these flows determines how the stock changes over time.</p>\n<p>In the labor market, workers flow between employment and unemployment (stocks) at various rates (flows):<br>\n<img src=\"__GHOST_URL__/content/images/2022/08/SCR-20220831-4nv.png\" alt=\"SCR-20220831-4nv\" loading=\"lazy\"></p>\n<p>In equilibrium, the various stocks of a closed system are stable. However, if the individual flows change, the related stocks change too:</p>\n<ul>\n<li>During recessions, flows from employment to unemployment (job separation) increase, while the flows out of unemployment into employment (job finding) decrease</li>\n<li>Vice versa for recoveries â€“ people find jobs more quickly and fewer people get laid off in the first place</li>\n</ul>\n<p>In this way, variation in job separation and job finding &quot;explain&quot; changes in unemployment.</p>\n<h2 id=\"as-the-labor-market-cools-hiring-freezes\">As the labor market cools, hiring freezes</h2>\n<p>We commonly associate unemployment with layoffs. During recessions, we imagine heartless employers suddenly laying off droves of workers:<br>\n<img src=\"__GHOST_URL__/content/images/2022/08/CleanShot-2022-08-18-at-12.54.17@2x.png\" alt=\"CleanShot-2022-08-18-at-12.54.17@2x\" loading=\"lazy\"></p>\n<p>While this story feels intuitive, the data doesn't bear this out.</p>\n<p>The below chart plots the U.S. &quot;employment exit rate&quot; (a euphemism for layoffs or voluntary quitting that ends in unemployment) along with the unemployment rate itself. Think about the exit rate as the share of all employed workers who leave employment each quarter:<br>\n<img src=\"__GHOST_URL__/content/images/2022/08/exit-1.png\" alt=\"exit-1\" loading=\"lazy\"></p>\n<p>Employment exits jiggle up and down at a much higher frequency than unemployment, and the timing of those short term fluctuations doesn't align well with granular movements in unemployment. Over longer periods though, they do seem loosely connected.</p>\n<p>Now let's look at the other piece of the puzzle. Here, I've swapped out employment exit for the &quot;job finding rate,&quot; i.e. the proportion of unemployed workers who find a job each quarter:<br>\n<img src=\"__GHOST_URL__/content/images/2022/08/job.png\" alt=\"job\" loading=\"lazy\"></p>\n<p><strong>The lines perfectly mirror each other.</strong></p>\n<p>The fluctuations closely track the state of the economy. When job finding plummets, unemployment rises at the same time. As the economist Robert Shimer put it:</p>\n<blockquote>\n<p>â€¦ a decline in the job finding rateâ€¦ contributed to every increase in the unemployment rate during the post-war period â€“ <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1014798\">Reassessing the Ins and Outs of Unemployment</a></p>\n</blockquote>\n<p>As the job finding rate slowly recovers, so does unemployment.</p>\n<p>So, rather than massive layoffs defining recessions and spikes in unemployment, the more powerful explanatory story is one of hiring freezes â€“ employers simply stop hiring during recessions.</p>\n<p>Per our stocks-and-flows model, the stock of unemployed workers grows and shrinks primarily due to variation in the <em>outflow</em> from unemployment to employment rather than the <em>inflow</em> of employment to unemployment.</p>\n<p>In other words, <strong>hiring freezes are the real story</strong>, not layoffs.</p>\n<h2 id=\"hiring-or-firing\">Hiring or firing?</h2>\n<p>What's the relative importance of hiring freezes vs layoffs?</p>\n<p>Here's how we can estimate this:</p>\n<ul>\n<li>Let's say we hold variable A constant and allow variable B to move around. If unemployment still moves around a lot then we know most of its variation is driven by variable B</li>\n<li>Similar logic applies in the opposite scenario (allowing A to fluctuate while holding B constant)</li>\n</ul>\n<p>This table quantifies the relative contributions of job entry and exit rates to overall unemployment variability by calculating counterfactual scenarios in which either variable is held constant while the other is allowed to fluctuate. The first row holds job separation constant and the second holds job finding constant (<a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1014798\">Source</a>):<br>\n<img src=\"__GHOST_URL__/content/images/2022/08/Pasted-image-20220814173836.png\" alt=\"Pasted-image-20220814173836\" loading=\"lazy\"></p>\n<p>The result?</p>\n<blockquote>\n<p>... since 1987, including the recessions in 1990â€“1991 and 2001, and 2008â€“2009, the job finding rate accounted for virtually all fluctuations in the unemployment rate â€“ <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1014798\">Reassessing the Ins and Outs of Unemployment</a></p>\n</blockquote>\n<p><strong>The job finding rate explains the vast majority of variation in unemployment</strong>, and the proportion has only increased over time.</p>\n<p>From 1987 to 2010, <strong>variation in the job finding rate explained 90% of the variance in unemployment,</strong> while employment exit only explained 10%.</p>\n<p>Here's Shimer again:</p>\n<blockquote>\n<p>The bulk of the reason unemployment rises and stays high throughout the recovery is because the unemployed workers stay unemployed for longerâ€¦</p>\n</blockquote>\n<p>This is precise, quantitative evidence for the overwhelming importance of hiring over firing in explaining unemployment.</p>\n<h2 id=\"hyper-degrowth\">Hyper-(de)growth</h2>\n<p>If the prior data seemed counterintuitive, the following example shouldn't.</p>\n<p>Imagine you're a high-growth startup with big ambitions to grow the employee base in the coming year:</p>\n<ul>\n<li>You are currently 100 employees</li>\n<li>You want to hire an additional 100 people over the next year</li>\n<li>We ignore voluntary attrition just to keep the numbers simple</li>\n</ul>\n<p>Suddenly, the environment changes:</p>\n<ul>\n<li>Economic conditions worsen, capital gets tighter, you start to miss plan, etc</li>\n<li>You need to make cuts, both in the current employee base <em>and</em> the future one</li>\n<li>So, you lay off 20% of the team</li>\n</ul>\n<p>This is extremely painful, demoralizing, and controversial, only made easier by the fact that everyone else is doing it too:</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">My sense is that it&#39;s partly - &quot;if we layoff people at the same time everyone else does, it&#39;ll look more like bad market conditions were to blame and less like we&#39;ve ran this thing poorly&quot;<br><br>i.e. if everyone stampedes at the same time, no one is to blame for trampling anyone</p>&mdash; Nnamdi Iregbulem (@whoisnnamdi) <a href=\"https://twitter.com/whoisnnamdi/status/1522354980111347712?ref_src=twsrc%5Etfw\">May 5, 2022</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><!--kg-card-begin: markdown--><p>You also institute a hiring freeze, which only seems fair after laying off so many team members:</p>\n<!--kg-card-end: markdown--><figure class=\"kg-card kg-embed-card\"><blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">3. Immediately re-hiring after layoffs paints the picture of leadership of what it is:<br><br>Incompetent.<br><br>Couldn&#39;t even figure out what % of people to lay off.</p>&mdash; Gergely Orosz (@GergelyOrosz) <a href=\"https://twitter.com/GergelyOrosz/status/1545358652424568833?ref_src=twsrc%5Etfw\">July 8, 2022</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</figure><!--kg-card-begin: markdown--><p>It doesn't take an HR savant to realize you aren't going to hit your original 200 headcount target for next year.</p>\n<p>Now do the gap analysis â€“ between layoffs and slowed hiring, which is more responsible for missing the original headcount target?</p>\n<p>It's the hiring freeze of course!</p>\n<ul>\n<li>You laid off 100 x 20% = 20 people</li>\n<li>Meanwhile, you cut the hiring plan from 100 to zero</li>\n</ul>\n<p>In effect, you &quot;fired&quot; or &quot;laid off&quot; 100 <em>future</em> employees while only laying off 20 <em>current</em> ones:<br>\n<img src=\"__GHOST_URL__/content/images/2022/08/SCR-20220831-4vs.png\" alt=\"SCR-20220831-4vs\" loading=\"lazy\"></p>\n<p>As one founder friend whose recent layoff was leaked on social media told me:</p>\n<blockquote>\n<p>Sure, the layoff news leaked, but when we modeled this stuff out we realized it's the reduced hiring that would save us the most cash.</p>\n</blockquote>\n<p>A hiring freeze is a <strong>much</strong> bigger story, even if the media only reports layoffs:</p>\n<ul>\n<li>Internally, management knows the hiring freeze will have a larger impact on team velocity (and, frankly, cash burn) than the layoffs.</li>\n<li>Yet externally, everyone will focus on the layoffs.</li>\n</ul>\n<p>This misses the raging forest fire for the merely singed trees.</p>\n<h2 id=\"a-new-perspective\">A new perspective</h2>\n<p>Recognizing the importance of hiring freezes should change your focus regardless of whether you're a founder or an employee.</p>\n<p>As a tech worker:</p>\n<ul>\n<li>The biggest risk you face in an economic downturn is not so much losing your current job but instead <strong>being unable to find a new one</strong> (due to hiring freezes)</li>\n<li>In addition, as you assess the viability of various startups, pay equal, if not more, attention to slowed hiring at the company than highly visible layoffs</li>\n<li>When interviewing, ask about the hiring plan and how it's changed in recent quarters</li>\n</ul>\n<p>If you're a founder:</p>\n<ul>\n<li>Slowed hiring is the real sign of weakness and vulnerability in your competition</li>\n<li>Even with no layoffs, your competitors could be in a dire financial straits, necessitating a complete freeze in hiring</li>\n<li>If you're well-capitalized, your biggest opportunity during a downturn isn't picking up people who were laid off (though you should definitely consider this) but rather hiring the people your competitors <em>would have wanted</em> but now can't due to hiring constraints</li>\n</ul>\n<h2 id=\"lay-off-the-layoffs\">Lay off the layoffs</h2>\n<p>Layoffs are a noisy estimate of company performance:</p>\n<ul>\n<li>Layoffs are tainted with worries about public perception and internal morale, making otherwise troubled companies hesitant to do them</li>\n<li>Companies conduct layoffs during downturns in part because everyone else is doing it, and they know they wonâ€™t look as bad if they move with the herd</li>\n</ul>\n<p>Hiring freezes are a clean signal of a viability and confidence of management:</p>\n<ul>\n<li>Few companies would cut back on their hiring plans <em>simply to fit in</em></li>\n<li>If anything, knowing others are pulling back makes companies <em>more</em> aggressive in hiring</li>\n</ul>\n<p>That said, hiring freezes are opaque from the outside:</p>\n<ul>\n<li>Outside of large organizations, most never publicly announce hiring freezes</li>\n<li>In many cases, hiring freezes aren't even openly discussed <em>internally</em> outside of the core executive team and the board of directors</li>\n</ul>\n<p>Keep in mind both the seen <em>and</em> the unseen. It's easy to focus on the shock and awe of layoffs, but you miss so much in doing so.</p>\n<p>Layoffs aren't even half the story â€“ they're 10% of it.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: Layoffs Don't Tell the Whole Story\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown--><p></p>","comment_id":"630f3947fec7d1542d1d2cc5","plaintext":"Layoffs grab headlines. Hiring freezes, less so.\n\nSites like layoffs.fyi [https://layoffs.fyi/] track layoffs in gory detail, as\ndo journalists and tech writers:\n\n> Large layoff rounds in tech, sadly, are still on.\n\nOlive AI let go ~30% of staff. They were one of the biggest unicorns in the\nMidwest (valued $4B)\n\nCapsule (digital pharmacy startup, valued >$1B) had large layoffs. I'm still not\nsure of the exact % here (feel free to DM)\n\nâ€” Gergely Orosz (@GergelyOrosz) July 20, 2022\n[https://twitter.com/GergelyOrosz/status/1549765632790601729?ref_src=twsrc%5Etfw]\nHowever, it's slow hiring, not layoffs, that most drives unemployment.\n\nLayoffs don't tell the whole story.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Stocking up\nEmployment and unemployment are both \"stocks\".\n\nStocks are quantities measured at a point in time that change over time. For\nexample:\n\n * The volume of water in a lake\n * The stock (hint hint) of inventory in a retail store\n * Cash on a company's balance sheet\n\nOn the other hand, \"flows\" are rates of change of a particular stock. For\nexample:\n\n * Water from various rivers flowing (hint hint) into a lake\n * Shipments of new inventory\n * A startup's monthly burn rate\n\nA single stock can have multiple associated flows, and the sum total of these\nflows determines how the stock changes over time.\n\nIn the labor market, workers flow between employment and unemployment (stocks)\nat various rates (flows):\n\n\nIn equilibrium, the various stocks of a closed system are stable. However, if\nthe individual flows change, the related stocks change too:\n\n * During recessions, flows from employment to unemployment (job separation)\n   increase, while the flows out of unemployment into employment (job finding)\n   decrease\n * Vice versa for recoveries â€“ people find jobs more quickly and fewer people\n   get laid off in the first place\n\nIn this way, variation in job separation and job finding \"explain\" changes in\nunemployment.\n\nAs the labor market cools, hiring freezes\nWe commonly associate unemployment with layoffs. During recessions, we imagine\nheartless employers suddenly laying off droves of workers:\n\n\nWhile this story feels intuitive, the data doesn't bear this out.\n\nThe below chart plots the U.S. \"employment exit rate\" (a euphemism for layoffs\nor voluntary quitting that ends in unemployment) along with the unemployment\nrate itself. Think about the exit rate as the share of all employed workers who\nleave employment each quarter:\n\n\nEmployment exits jiggle up and down at a much higher frequency than\nunemployment, and the timing of those short term fluctuations doesn't align well\nwith granular movements in unemployment. Over longer periods though, they do\nseem loosely connected.\n\nNow let's look at the other piece of the puzzle. Here, I've swapped out\nemployment exit for the \"job finding rate,\" i.e. the proportion of unemployed\nworkers who find a job each quarter:\n\n\nThe lines perfectly mirror each other.\n\nThe fluctuations closely track the state of the economy. When job finding\nplummets, unemployment rises at the same time. As the economist Robert Shimer\nput it:\n\n> â€¦ a decline in the job finding rateâ€¦ contributed to every increase in the\nunemployment rate during the post-war period â€“ Reassessing the Ins and Outs of\nUnemployment [https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1014798]\n\n\nAs the job finding rate slowly recovers, so does unemployment.\n\nSo, rather than massive layoffs defining recessions and spikes in unemployment,\nthe more powerful explanatory story is one of hiring freezes â€“ employers simply\nstop hiring during recessions.\n\nPer our stocks-and-flows model, the stock of unemployed workers grows and\nshrinks primarily due to variation in the outflow from unemployment to\nemployment rather than the inflow of employment to unemployment.\n\nIn other words, hiring freezes are the real story, not layoffs.\n\nHiring or firing?\nWhat's the relative importance of hiring freezes vs layoffs?\n\nHere's how we can estimate this:\n\n * Let's say we hold variable A constant and allow variable B to move around. If\n   unemployment still moves around a lot then we know most of its variation is\n   driven by variable B\n * Similar logic applies in the opposite scenario (allowing A to fluctuate while\n   holding B constant)\n\nThis table quantifies the relative contributions of job entry and exit rates to\noverall unemployment variability by calculating counterfactual scenarios in\nwhich either variable is held constant while the other is allowed to fluctuate.\nThe first row holds job separation constant and the second holds job finding\nconstant (Source [https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1014798]):\n\n\nThe result?\n\n> ... since 1987, including the recessions in 1990â€“1991 and 2001, and 2008â€“2009,\nthe job finding rate accounted for virtually all fluctuations in the\nunemployment rate â€“ Reassessing the Ins and Outs of Unemployment\n[https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1014798]\n\n\nThe job finding rate explains the vast majority of variation in unemployment,\nand the proportion has only increased over time.\n\nFrom 1987 to 2010, variation in the job finding rate explained 90% of the\nvariance in unemployment, while employment exit only explained 10%.\n\nHere's Shimer again:\n\n> The bulk of the reason unemployment rises and stays high throughout the recovery\nis because the unemployed workers stay unemployed for longerâ€¦\n\n\nThis is precise, quantitative evidence for the overwhelming importance of hiring\nover firing in explaining unemployment.\n\nHyper-(de)growth\nIf the prior data seemed counterintuitive, the following example shouldn't.\n\nImagine you're a high-growth startup with big ambitions to grow the employee\nbase in the coming year:\n\n * You are currently 100 employees\n * You want to hire an additional 100 people over the next year\n * We ignore voluntary attrition just to keep the numbers simple\n\nSuddenly, the environment changes:\n\n * Economic conditions worsen, capital gets tighter, you start to miss plan, etc\n * You need to make cuts, both in the current employee base and the future one\n * So, you lay off 20% of the team\n\nThis is extremely painful, demoralizing, and controversial, only made easier by\nthe fact that everyone else is doing it too:\n\n> My sense is that it's partly - \"if we layoff people at the same time everyone\nelse does, it'll look more like bad market conditions were to blame and less\nlike we've ran this thing poorly\"\n\ni.e. if everyone stampedes at the same time, no one is to blame for trampling\nanyone\n\nâ€” Nnamdi Iregbulem (@whoisnnamdi) May 5, 2022\n[https://twitter.com/whoisnnamdi/status/1522354980111347712?ref_src=twsrc%5Etfw]\nYou also institute a hiring freeze, which only seems fair after laying off so\nmany team members:\n\n> 3. Immediately re-hiring after layoffs paints the picture of leadership of what\nit is:\n\nIncompetent.\n\nCouldn't even figure out what % of people to lay off.\n\nâ€” Gergely Orosz (@GergelyOrosz) July 8, 2022\n[https://twitter.com/GergelyOrosz/status/1545358652424568833?ref_src=twsrc%5Etfw]\nIt doesn't take an HR savant to realize you aren't going to hit your original\n200 headcount target for next year.\n\nNow do the gap analysis â€“ between layoffs and slowed hiring, which is more\nresponsible for missing the original headcount target?\n\nIt's the hiring freeze of course!\n\n * You laid off 100 x 20% = 20 people\n * Meanwhile, you cut the hiring plan from 100 to zero\n\nIn effect, you \"fired\" or \"laid off\" 100 future employees while only laying off\n20 current ones:\n\n\nAs one founder friend whose recent layoff was leaked on social media told me:\n\n> Sure, the layoff news leaked, but when we modeled this stuff out we realized\nit's the reduced hiring that would save us the most cash.\n\n\nA hiring freeze is a much bigger story, even if the media only reports layoffs:\n\n * Internally, management knows the hiring freeze will have a larger impact on\n   team velocity (and, frankly, cash burn) than the layoffs.\n * Yet externally, everyone will focus on the layoffs.\n\nThis misses the raging forest fire for the merely singed trees.\n\nA new perspective\nRecognizing the importance of hiring freezes should change your focus regardless\nof whether you're a founder or an employee.\n\nAs a tech worker:\n\n * The biggest risk you face in an economic downturn is not so much losing your\n   current job but instead being unable to find a new one (due to hiring\n   freezes)\n * In addition, as you assess the viability of various startups, pay equal, if\n   not more, attention to slowed hiring at the company than highly visible\n   layoffs\n * When interviewing, ask about the hiring plan and how it's changed in recent\n   quarters\n\nIf you're a founder:\n\n * Slowed hiring is the real sign of weakness and vulnerability in your\n   competition\n * Even with no layoffs, your competitors could be in a dire financial straits,\n   necessitating a complete freeze in hiring\n * If you're well-capitalized, your biggest opportunity during a downturn isn't\n   picking up people who were laid off (though you should definitely consider\n   this) but rather hiring the people your competitors would have wanted but now\n   can't due to hiring constraints\n\nLay off the layoffs\nLayoffs are a noisy estimate of company performance:\n\n * Layoffs are tainted with worries about public perception and internal morale,\n   making otherwise troubled companies hesitant to do them\n * Companies conduct layoffs during downturns in part because everyone else is\n   doing it, and they know they wonâ€™t look as bad if they move with the herd\n\nHiring freezes are a clean signal of a viability and confidence of management:\n\n * Few companies would cut back on their hiring plans simply to fit in\n * If anything, knowing others are pulling back makes companies more aggressive\n   in hiring\n\nThat said, hiring freezes are opaque from the outside:\n\n * Outside of large organizations, most never publicly announce hiring freezes\n * In many cases, hiring freezes aren't even openly discussed internally outside\n   of the core executive team and the board of directors\n\nKeep in mind both the seen and the unseen. It's easy to focus on the shock and\nawe of layoffs, but you miss so much in doing so.\n\nLayoffs aren't even half the story â€“ they're 10% of it.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2022/08/exit.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2022-08-31T10:34:47.000Z","updated_at":"2022-08-31T11:03:00.000Z","published_at":"2022-08-31T11:00:43.000Z","custom_excerpt":"Hiring freezes matter more than layoffs","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"63219ca4fec7d1542d1d2d1d","uuid":"8bc4ccac-de52-427b-aaa9-33c8a6191246","title":"Beats and Misses Are Forever","slug":"forever","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Subscription revenue is a double-edged sword:\\n* It's predictable, making the business much easier to forecast\\n* It's persistent â€“ over or underperformance today reverberates far into the future\\n\\nContrary to popular belief, SaaS companies do not in fact \\\"pull forward revenue.\\\" A beat today puts the company on a permanently higher trajectory. Revenue doesn't mean revert later.\\n\\nLikewise, deals might \\\"slip,\\\" but there's no \\\"catch up growth\\\" â€“ a missed quarter doesn't get made up for next quarter. A miss today predicts lower revenue for years to come.\\n\\n[Diamonds](https://youtu.be/92FCRmggNqQ?t=56), beats, and misses are forever ðŸ’Ž.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Beats and Misses Are Forever\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## Long vs. short\\n\\nPublic market investors are often criticized for being too \\\"short-term focused.\\\"\\n\\nPoliticians and CEOs alike love to hate on investors for overreacting to current business results, bidding up the stock or kicking off a fire sale depending on how quarterly earnings play out\\n> A widely-held view among Washington policymakers, corporate executives, the media, and the public is that frenzied, short-term stock market trading has coupled with Wall Streetâ€™s unquenchable thirst for immediate results to disrupt US firms and badly hurt the economy â€“ [How Big Is the Problem of Stock-Market-Driven Short-Termism?](https://www.americanbar.org/groups/business_law/publications/blt/2022/05/short-termism/)\\n\\nBaked into this criticism is a view that the long-run is hard to influence â€“ fluctuations in the short-run tend to mean revert over time. One's view of a company should change only slowly and in the face of extraordinary evidence.\\n\\nIn defiance of this heavy-handed finger-wagging, there's an alternate view that short-run performance matters and is informative *about the long-run*. The future is bound to the present, and we should decisively update our forecasts in light of new information.\\n\\nIn summary:\\n* Long-termists believe revenue will eventually revert back to some long-run trend based on the fundamentals of the business, its market opportunity, etc. Short-term fluctuations are noise and should be ignored. Quarterly beats and misses should have little, if any, impact on fundamental valuation analysis.\\n* Short-termists (though they would never refer to themselves as such) believe the present moment matters and says much about the future. Short-term performance is a valuable signal that should factor into valuations. Mean revision dominates mean reversion.\\n\\nWho is right? And how would we know?\\n\\n## A random or deterministic walk down Wall Street?\\n\\nThere's a simple way to resolve this dispute. We only need to rephrase the positions of the long/short-termists, and the resolution will be clear.\\n\\nLong-termists think today's revenue fluctuations poorly predict future revenue. They don't often phrase it that way, but that's the core underlying logic behind the belief in a stable, long-run trend.\\n\\nThis has multiple important implications.\\n\\nFor one â€“ revenue can be \\\"pulled forward,\\\" but this will tend not to influence the long-run trajectory of the company:\\n> Adobe was downgraded to neutral from buy at UBS... Analyst Karl Keirstead said after speaking with 14 large enterprise IT executives and services partners of Adobe, he's worried that spending was pulled forward in 2020 and 2021, which will pressure its growth rate this year. ([Link](https://markets.businessinsider.com/news/stocks/adobe-downgraded-to-neutral-at-ubs-on-concerns-that-spending-was-pulled-forward-10896540))\\n\\nFurther, a missed quarter today can be made up for next quarter. Missing the target leads to revenue in the future quarters to be slightly higher, as revenue reverts back to trend. You could call this \\\"catch up growth.\\\"\\n\\nMeanwhile, short-termists think today's revenue movements predict future revenue. One's long-term revenue forecast should be quite sensitive to beats and misses in the present day.\\n\\nSo, pulling forward revenue doesn't come at the cost of future revenue. Similarly, missing your target today doesn't mean you're any more likely to hit tomorrow's target. In fact, you're less likely, since you're now on a lower revenue path.\\n\\nThe clean and simple test?\\n\\nSimply run a regression of future revenue on current over/underperformance! The coefficient tells us to what extent our estimates of future revenue should shift in response to strong or weak results today:\\n* A coefficient near or greater than one tells us future revenue rises/falls by at least $1 for a $1 beat/miss today (the short-termists win)\\n* A coefficient well below one means forward revenue is insensitive to today's performance and tends to mean revert (the long-termists win)\\n\\n## Back to the future\\n\\nThe chart below plots revenue growth over four quarters against revenue growth today for 35 public software companies, demeaned by the respective average rate for each company. Positive values mean revenue came in higher than normal, and vice versa:\\n\\n![future](__GHOST_URL__/content/images/2022/09/future.png)\\n\\n**Future and current revenue over/underperformance are positively related.** The coefficient is 1.16, implying **a $1 beat today forecasts a $1.16 beat four quarters from now.** The exact reverse is true of a miss â€“ a dollar of missed revenue this quarter lowers our expected revenue in four quarters by $1.16.\\n\\nAdditionally, the R^2 is decently high â€“ 0.49, so about half of the variation in expected revenue four quarters out can be explained by revenue performance in the current quarter.\\n\\nOne quick aside since I know what certain folks are thinking here: I am not merely saying that current revenue predicts future revenue. I'm saying *changes in revenue* predict changes in future revenue.\\n\\nSo far, the short-termists seem to be winning. But one year is not a long-time â€“ perhaps mean reversion takes longer? Let's check by extending the analysis to eight and twelve quarters out. That's too crowded for a single scatterplot, so I'll summarize the results and only show the coefficients at each horizon:\\n\\n![forever-3](__GHOST_URL__/content/images/2022/09/forever-3.png)\\n\\nIf anything, the case for short-termism only gets stronger. The two-year revenue forecast shifts by $1.25 for a $1 beat/miss today. The three-year forecast changes by $1.43.\\n\\nEven three years out, we see no evidence of mean-reversion among the typical public software company. Beats and misses permanently shift the trajectory of the company.\\n\\nNow, dollars are a nice unit of account, but they're admittedly hard to contextualize. A $1 beat/miss that turns into a $1.43 beat/miss three years out could be more or less meaningful depending on the scale of the company and its growth rate. Many of these companies were likely to be much larger in three years anyway.\\n\\nLet's do the same analysis with percentages instead. What impact does a 1% beat/miss have on future revenue, also in percentage terms?\\n\\n![persists](__GHOST_URL__/content/images/2022/09/persists.png)\\n\\nPersistence persists, but this tells a slightly different story. Revenue three years from now is still 0.85% higher/lower than it would have otherwise been.\\n\\nMy interpretation: the additional (or lost) revenue from a beat (or miss) grows at a somewhat slower pace than the remaining revenue base, so we see some convergence. In other words, \\\"surprise\\\" revenue doesn't grow as fast as \\\"expected\\\" revenue.\\n\\nYou could frame this as slight mean reversion. Personally, I'd say the short-termists still have it.\\n\\n## Working as intended\\n\\nWhy does this happen? Why is the future so sensitive to the present?\\n\\nRather than a surprising phenomenon, I see this as **the defining characteristic of subscription business models.**\\n\\nTo say revenue \\\"recurs\\\" is merely to say revenue today generates revenue tomorrow. Said differently, a good test of subscription revenue quality is **the degree to which it persists and predicts future revenue**.\\n\\nIn that light, these results are expected. If a change in revenue today didn't predict a change in revenue tomorrow, it'd be hard to call it recurring.\\n\\nFor some intuition, look at those [cohort revenue charts](https://thetaclv.com/resource/c3/) that have become so popular among public software companies (at least among those with good retention dynamics to show off):\\n\\n![Pasted-image-20220910172026](__GHOST_URL__/content/images/2022/09/Pasted-image-20220910172026.png)\\n\\nMissing a quarter means losing a slice of the cohort stack. Assuming positive net dollar retention, that slice would have grown over time; the opportunity cost of weak performance grows over time.\\n\\nIronically, a miss for a company with high retention hurts more than one for a company with low net retention, since the high retention company has more (future revenue) to lose. I examined this phenomenon from a slightly different angle a few years back:\\n> Both in theory and in practice,Â **better retention drives higher volatility** â€“ [\\\"High Retention = High Volatility\\\"](https://whoisnnamdi.com/high-retention-high-volatility/)\\n\\n**This is why SaaS beats and misses are so consequential.**\\n\\nIf investors think a miss or beat is likely to stick, that will meaningfully impact their valuation views, as it must. On the other hand, the stock shouldn't move much if short-term performance reflects merely temporary dynamics in a company's go-to-market engine.\\n\\nThat SaaS valuations tend to react so strongly implies investors do believe these GTM gyrations are permanent and must be reflected in future projections. It's possible there's some mean reversion happening under the hood, but this effect is totally swamped by the magnitude and persistence of the beat/miss itself.\\n\\n## Revision of the mean\\n\\nA bad reaction to this analysis would be: your sales leader says the quarter came in light because some deals slipped, you look them in the eyes and confidently tell them \\\"there's no such thing as a deal slipping,\\\" and point them to this essay.\\n\\n**No.** That's not what I'm saying at all. (Please do send them this essay though!)\\n\\nAt the level of individual sales, deals slip from one quarter to another all the time. But at the level of aggregate revenue that doesn't seem to matter. Revenue won't be higher next quarter simply because revenue came in low this quarter. Every quarter is, for the most part, a blank slate.\\n\\nLikewise with pulling forward revenue â€“ it happens, but on average you can't find it in the data. COVID is a good exception to this â€“ companies that benefitted from the transition to remote work like Zoom or DocuSign are now slowing, reverting back to their long-run trend line:\\n> While DocuSign beat revenue expectations last quarter, full-year guidance came in far lower than expected. DocuSignâ€¦ was perceived to be a \\\"COVID winner.\\\" There are now fears that the company merely pulled forward years of sales over the course of the past two years, and that its revenue growth trajectory will be lower going forward. ([Link](https://www.theglobeandmail.com/investing/markets/stocks/APPN-Q/pressreleases/7587079/why-snowflake-appian-and-twilio-plunged-today-again/))\\n\\n> While Coupa's upside certainly isn't at risk long term, it does appear some of its future growth was pulled forward during the COVID-19 crisis. ([Link](https://www.nasdaq.com/articles/down-over-30-is-coupa-software-stock-a-buy-2021-03-27))\\n\\n> Unfortunately for Twilio, it belongs to the â€œhigh beta growthâ€ club, which began a secular decline early last year. The San Francisco-based Cloud Communications company boomed from the work-from-home trend... But, like so many other tech companies, it pulled forward too many gains, setting itself up for a nasty re-pricing. ([Link](https://finance.yahoo.com/news/trade-twilio-stock-wednesday-earnings-175540896.html))\\n\\n**Note:** this analysis only includes software companies. Businesses with more transactional business models probably see less persistence and more mean reversion. Think about companies like Peloton:\\n- Despite having a subscription service, the vast majority of revenue was in physical bike sales that are one-time in nature \\n- Peloton really did pull forward demand, which left little market left to grow into by the time things returned to normal\\n\\nHowever, if you have significant recurring revenue, mean reversion is much less relevant.\\n\\nThis analysis continues a line of thinking I touched on in a [prior piece](https://whoisnnamdi.com/covid-hurt-software/) exploring COVID's impact on software companies:\\n> â€¦ mean reversion is a strong force, butÂ **COVID was stronger**, especially on the downside. Once knocked down, the typical software business never got back upâ€¦\\n> \\n> _Mean revision_Â is at least as important as mean reversion. Not only are software companies below their pre-COVID trend,Â _the trend itself_Â has changed for the worse â€“ [COVID Hurt Most Software Companies](https://whoisnnamdi.com/covid-hurt-software/)\\n\\nFor software companies, every day is [Day 1](https://s2.q4cdn.com/299287126/files/doc_financials/annual/Shareholderletter97.pdf) or, at least, dependent on it.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: Beats and Misses Are Forever\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>Subscription revenue is a double-edged sword:</p>\n<ul>\n<li>It's predictable, making the business much easier to forecast</li>\n<li>It's persistent â€“ over or underperformance today reverberates far into the future</li>\n</ul>\n<p>Contrary to popular belief, SaaS companies do not in fact &quot;pull forward revenue.&quot; A beat today puts the company on a permanently higher trajectory. Revenue doesn't mean revert later.</p>\n<p>Likewise, deals might &quot;slip,&quot; but there's no &quot;catch up growth&quot; â€“ a missed quarter doesn't get made up for next quarter. A miss today predicts lower revenue for years to come.</p>\n<p><a href=\"https://youtu.be/92FCRmggNqQ?t=56\">Diamonds</a>, beats, and misses are forever ðŸ’Ž.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Beats and Misses Are Forever\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"long-vs-short\">Long vs. short</h2>\n<p>Public market investors are often criticized for being too &quot;short-term focused.&quot;</p>\n<p>Politicians and CEOs alike love to hate on investors for overreacting to current business results, bidding up the stock or kicking off a fire sale depending on how quarterly earnings play out</p>\n<blockquote>\n<p>A widely-held view among Washington policymakers, corporate executives, the media, and the public is that frenzied, short-term stock market trading has coupled with Wall Streetâ€™s unquenchable thirst for immediate results to disrupt US firms and badly hurt the economy â€“ <a href=\"https://www.americanbar.org/groups/business_law/publications/blt/2022/05/short-termism/\">How Big Is the Problem of Stock-Market-Driven Short-Termism?</a></p>\n</blockquote>\n<p>Baked into this criticism is a view that the long-run is hard to influence â€“ fluctuations in the short-run tend to mean revert over time. One's view of a company should change only slowly and in the face of extraordinary evidence.</p>\n<p>In defiance of this heavy-handed finger-wagging, there's an alternate view that short-run performance matters and is informative <em>about the long-run</em>. The future is bound to the present, and we should decisively update our forecasts in light of new information.</p>\n<p>In summary:</p>\n<ul>\n<li>Long-termists believe revenue will eventually revert back to some long-run trend based on the fundamentals of the business, its market opportunity, etc. Short-term fluctuations are noise and should be ignored. Quarterly beats and misses should have little, if any, impact on fundamental valuation analysis.</li>\n<li>Short-termists (though they would never refer to themselves as such) believe the present moment matters and says much about the future. Short-term performance is a valuable signal that should factor into valuations. Mean revision dominates mean reversion.</li>\n</ul>\n<p>Who is right? And how would we know?</p>\n<h2 id=\"a-random-or-deterministic-walk-down-wall-street\">A random or deterministic walk down Wall Street?</h2>\n<p>There's a simple way to resolve this dispute. We only need to rephrase the positions of the long/short-termists, and the resolution will be clear.</p>\n<p>Long-termists think today's revenue fluctuations poorly predict future revenue. They don't often phrase it that way, but that's the core underlying logic behind the belief in a stable, long-run trend.</p>\n<p>This has multiple important implications.</p>\n<p>For one â€“ revenue can be &quot;pulled forward,&quot; but this will tend not to influence the long-run trajectory of the company:</p>\n<blockquote>\n<p>Adobe was downgraded to neutral from buy at UBS... Analyst Karl Keirstead said after speaking with 14 large enterprise IT executives and services partners of Adobe, he's worried that spending was pulled forward in 2020 and 2021, which will pressure its growth rate this year. (<a href=\"https://markets.businessinsider.com/news/stocks/adobe-downgraded-to-neutral-at-ubs-on-concerns-that-spending-was-pulled-forward-10896540\">Link</a>)</p>\n</blockquote>\n<p>Further, a missed quarter today can be made up for next quarter. Missing the target leads to revenue in the future quarters to be slightly higher, as revenue reverts back to trend. You could call this &quot;catch up growth.&quot;</p>\n<p>Meanwhile, short-termists think today's revenue movements predict future revenue. One's long-term revenue forecast should be quite sensitive to beats and misses in the present day.</p>\n<p>So, pulling forward revenue doesn't come at the cost of future revenue. Similarly, missing your target today doesn't mean you're any more likely to hit tomorrow's target. In fact, you're less likely, since you're now on a lower revenue path.</p>\n<p>The clean and simple test?</p>\n<p>Simply run a regression of future revenue on current over/underperformance! The coefficient tells us to what extent our estimates of future revenue should shift in response to strong or weak results today:</p>\n<ul>\n<li>A coefficient near or greater than one tells us future revenue rises/falls by at least $1 for a $1 beat/miss today (the short-termists win)</li>\n<li>A coefficient well below one means forward revenue is insensitive to today's performance and tends to mean revert (the long-termists win)</li>\n</ul>\n<h2 id=\"back-to-the-future\">Back to the future</h2>\n<p>The chart below plots revenue growth over four quarters against revenue growth today for 35 public software companies, demeaned by the respective average rate for each company. Positive values mean revenue came in higher than normal, and vice versa:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/09/future.png\" alt=\"future\" loading=\"lazy\"></p>\n<p><strong>Future and current revenue over/underperformance are positively related.</strong> The coefficient is 1.16, implying <strong>a $1 beat today forecasts a $1.16 beat four quarters from now.</strong> The exact reverse is true of a miss â€“ a dollar of missed revenue this quarter lowers our expected revenue in four quarters by $1.16.</p>\n<p>Additionally, the R^2 is decently high â€“ 0.49, so about half of the variation in expected revenue four quarters out can be explained by revenue performance in the current quarter.</p>\n<p>One quick aside since I know what certain folks are thinking here: I am not merely saying that current revenue predicts future revenue. I'm saying <em>changes in revenue</em> predict changes in future revenue.</p>\n<p>So far, the short-termists seem to be winning. But one year is not a long-time â€“ perhaps mean reversion takes longer? Let's check by extending the analysis to eight and twelve quarters out. That's too crowded for a single scatterplot, so I'll summarize the results and only show the coefficients at each horizon:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/09/forever-3.png\" alt=\"forever-3\" loading=\"lazy\"></p>\n<p>If anything, the case for short-termism only gets stronger. The two-year revenue forecast shifts by $1.25 for a $1 beat/miss today. The three-year forecast changes by $1.43.</p>\n<p>Even three years out, we see no evidence of mean-reversion among the typical public software company. Beats and misses permanently shift the trajectory of the company.</p>\n<p>Now, dollars are a nice unit of account, but they're admittedly hard to contextualize. A $1 beat/miss that turns into a $1.43 beat/miss three years out could be more or less meaningful depending on the scale of the company and its growth rate. Many of these companies were likely to be much larger in three years anyway.</p>\n<p>Let's do the same analysis with percentages instead. What impact does a 1% beat/miss have on future revenue, also in percentage terms?</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/09/persists.png\" alt=\"persists\" loading=\"lazy\"></p>\n<p>Persistence persists, but this tells a slightly different story. Revenue three years from now is still 0.85% higher/lower than it would have otherwise been.</p>\n<p>My interpretation: the additional (or lost) revenue from a beat (or miss) grows at a somewhat slower pace than the remaining revenue base, so we see some convergence. In other words, &quot;surprise&quot; revenue doesn't grow as fast as &quot;expected&quot; revenue.</p>\n<p>You could frame this as slight mean reversion. Personally, I'd say the short-termists still have it.</p>\n<h2 id=\"working-as-intended\">Working as intended</h2>\n<p>Why does this happen? Why is the future so sensitive to the present?</p>\n<p>Rather than a surprising phenomenon, I see this as <strong>the defining characteristic of subscription business models.</strong></p>\n<p>To say revenue &quot;recurs&quot; is merely to say revenue today generates revenue tomorrow. Said differently, a good test of subscription revenue quality is <strong>the degree to which it persists and predicts future revenue</strong>.</p>\n<p>In that light, these results are expected. If a change in revenue today didn't predict a change in revenue tomorrow, it'd be hard to call it recurring.</p>\n<p>For some intuition, look at those <a href=\"https://thetaclv.com/resource/c3/\">cohort revenue charts</a> that have become so popular among public software companies (at least among those with good retention dynamics to show off):</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/09/Pasted-image-20220910172026.png\" alt=\"Pasted-image-20220910172026\" loading=\"lazy\"></p>\n<p>Missing a quarter means losing a slice of the cohort stack. Assuming positive net dollar retention, that slice would have grown over time; the opportunity cost of weak performance grows over time.</p>\n<p>Ironically, a miss for a company with high retention hurts more than one for a company with low net retention, since the high retention company has more (future revenue) to lose. I examined this phenomenon from a slightly different angle a few years back:</p>\n<blockquote>\n<p>Both in theory and in practice,Â <strong>better retention drives higher volatility</strong> â€“ <a href=\"https://whoisnnamdi.com/high-retention-high-volatility/\">&quot;High Retention = High Volatility&quot;</a></p>\n</blockquote>\n<p><strong>This is why SaaS beats and misses are so consequential.</strong></p>\n<p>If investors think a miss or beat is likely to stick, that will meaningfully impact their valuation views, as it must. On the other hand, the stock shouldn't move much if short-term performance reflects merely temporary dynamics in a company's go-to-market engine.</p>\n<p>That SaaS valuations tend to react so strongly implies investors do believe these GTM gyrations are permanent and must be reflected in future projections. It's possible there's some mean reversion happening under the hood, but this effect is totally swamped by the magnitude and persistence of the beat/miss itself.</p>\n<h2 id=\"revision-of-the-mean\">Revision of the mean</h2>\n<p>A bad reaction to this analysis would be: your sales leader says the quarter came in light because some deals slipped, you look them in the eyes and confidently tell them &quot;there's no such thing as a deal slipping,&quot; and point them to this essay.</p>\n<p><strong>No.</strong> That's not what I'm saying at all. (Please do send them this essay though!)</p>\n<p>At the level of individual sales, deals slip from one quarter to another all the time. But at the level of aggregate revenue that doesn't seem to matter. Revenue won't be higher next quarter simply because revenue came in low this quarter. Every quarter is, for the most part, a blank slate.</p>\n<p>Likewise with pulling forward revenue â€“ it happens, but on average you can't find it in the data. COVID is a good exception to this â€“ companies that benefitted from the transition to remote work like Zoom or DocuSign are now slowing, reverting back to their long-run trend line:</p>\n<blockquote>\n<p>While DocuSign beat revenue expectations last quarter, full-year guidance came in far lower than expected. DocuSignâ€¦ was perceived to be a &quot;COVID winner.&quot; There are now fears that the company merely pulled forward years of sales over the course of the past two years, and that its revenue growth trajectory will be lower going forward. (<a href=\"https://www.theglobeandmail.com/investing/markets/stocks/APPN-Q/pressreleases/7587079/why-snowflake-appian-and-twilio-plunged-today-again/\">Link</a>)</p>\n</blockquote>\n<blockquote>\n<p>While Coupa's upside certainly isn't at risk long term, it does appear some of its future growth was pulled forward during the COVID-19 crisis. (<a href=\"https://www.nasdaq.com/articles/down-over-30-is-coupa-software-stock-a-buy-2021-03-27\">Link</a>)</p>\n</blockquote>\n<blockquote>\n<p>Unfortunately for Twilio, it belongs to the â€œhigh beta growthâ€ club, which began a secular decline early last year. The San Francisco-based Cloud Communications company boomed from the work-from-home trend... But, like so many other tech companies, it pulled forward too many gains, setting itself up for a nasty re-pricing. (<a href=\"https://finance.yahoo.com/news/trade-twilio-stock-wednesday-earnings-175540896.html\">Link</a>)</p>\n</blockquote>\n<p><strong>Note:</strong> this analysis only includes software companies. Businesses with more transactional business models probably see less persistence and more mean reversion. Think about companies like Peloton:</p>\n<ul>\n<li>Despite having a subscription service, the vast majority of revenue was in physical bike sales that are one-time in nature</li>\n<li>Peloton really did pull forward demand, which left little market left to grow into by the time things returned to normal</li>\n</ul>\n<p>However, if you have significant recurring revenue, mean reversion is much less relevant.</p>\n<p>This analysis continues a line of thinking I touched on in a <a href=\"https://whoisnnamdi.com/covid-hurt-software/\">prior piece</a> exploring COVID's impact on software companies:</p>\n<blockquote>\n<p>â€¦ mean reversion is a strong force, butÂ <strong>COVID was stronger</strong>, especially on the downside. Once knocked down, the typical software business never got back upâ€¦</p>\n<p><em>Mean revision</em>Â is at least as important as mean reversion. Not only are software companies below their pre-COVID trend,Â <em>the trend itself</em>Â has changed for the worse â€“ <a href=\"https://whoisnnamdi.com/covid-hurt-software/\">COVID Hurt Most Software Companies</a></p>\n</blockquote>\n<p>For software companies, every day is <a href=\"https://s2.q4cdn.com/299287126/files/doc_financials/annual/Shareholderletter97.pdf\">Day 1</a> or, at least, dependent on it.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: Beats and Misses Are Forever\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"63219ca4fec7d1542d1d2d1d","plaintext":"Subscription revenue is a double-edged sword:\n\n * It's predictable, making the business much easier to forecast\n * It's persistent â€“ over or underperformance today reverberates far into the\n   future\n\nContrary to popular belief, SaaS companies do not in fact \"pull forward\nrevenue.\" A beat today puts the company on a permanently higher trajectory.\nRevenue doesn't mean revert later.\n\nLikewise, deals might \"slip,\" but there's no \"catch up growth\" â€“ a missed\nquarter doesn't get made up for next quarter. A miss today predicts lower\nrevenue for years to come.\n\nDiamonds [https://youtu.be/92FCRmggNqQ?t=56], beats, and misses are forever ðŸ’Ž.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Long vs. short\nPublic market investors are often criticized for being too \"short-term focused.\"\n\nPoliticians and CEOs alike love to hate on investors for overreacting to current\nbusiness results, bidding up the stock or kicking off a fire sale depending on\nhow quarterly earnings play out\n\n> A widely-held view among Washington policymakers, corporate executives, the\nmedia, and the public is that frenzied, short-term stock market trading has\ncoupled with Wall Streetâ€™s unquenchable thirst for immediate results to disrupt\nUS firms and badly hurt the economy â€“ How Big Is the Problem of\nStock-Market-Driven Short-Termism?\n[https://www.americanbar.org/groups/business_law/publications/blt/2022/05/short-termism/]\n\n\nBaked into this criticism is a view that the long-run is hard to influence â€“\nfluctuations in the short-run tend to mean revert over time. One's view of a\ncompany should change only slowly and in the face of extraordinary evidence.\n\nIn defiance of this heavy-handed finger-wagging, there's an alternate view that\nshort-run performance matters and is informative about the long-run. The future\nis bound to the present, and we should decisively update our forecasts in light\nof new information.\n\nIn summary:\n\n * Long-termists believe revenue will eventually revert back to some long-run\n   trend based on the fundamentals of the business, its market opportunity, etc.\n   Short-term fluctuations are noise and should be ignored. Quarterly beats and\n   misses should have little, if any, impact on fundamental valuation analysis.\n * Short-termists (though they would never refer to themselves as such) believe\n   the present moment matters and says much about the future. Short-term\n   performance is a valuable signal that should factor into valuations. Mean\n   revision dominates mean reversion.\n\nWho is right? And how would we know?\n\nA random or deterministic walk down Wall Street?\nThere's a simple way to resolve this dispute. We only need to rephrase the\npositions of the long/short-termists, and the resolution will be clear.\n\nLong-termists think today's revenue fluctuations poorly predict future revenue.\nThey don't often phrase it that way, but that's the core underlying logic behind\nthe belief in a stable, long-run trend.\n\nThis has multiple important implications.\n\nFor one â€“ revenue can be \"pulled forward,\" but this will tend not to influence\nthe long-run trajectory of the company:\n\n> Adobe was downgraded to neutral from buy at UBS... Analyst Karl Keirstead said\nafter speaking with 14 large enterprise IT executives and services partners of\nAdobe, he's worried that spending was pulled forward in 2020 and 2021, which\nwill pressure its growth rate this year. (Link\n[https://markets.businessinsider.com/news/stocks/adobe-downgraded-to-neutral-at-ubs-on-concerns-that-spending-was-pulled-forward-10896540]\n)\n\n\nFurther, a missed quarter today can be made up for next quarter. Missing the\ntarget leads to revenue in the future quarters to be slightly higher, as revenue\nreverts back to trend. You could call this \"catch up growth.\"\n\nMeanwhile, short-termists think today's revenue movements predict future\nrevenue. One's long-term revenue forecast should be quite sensitive to beats and\nmisses in the present day.\n\nSo, pulling forward revenue doesn't come at the cost of future revenue.\nSimilarly, missing your target today doesn't mean you're any more likely to hit\ntomorrow's target. In fact, you're less likely, since you're now on a lower\nrevenue path.\n\nThe clean and simple test?\n\nSimply run a regression of future revenue on current over/underperformance! The\ncoefficient tells us to what extent our estimates of future revenue should shift\nin response to strong or weak results today:\n\n * A coefficient near or greater than one tells us future revenue rises/falls by\n   at least $1 for a $1 beat/miss today (the short-termists win)\n * A coefficient well below one means forward revenue is insensitive to today's\n   performance and tends to mean revert (the long-termists win)\n\nBack to the future\nThe chart below plots revenue growth over four quarters against revenue growth\ntoday for 35 public software companies, demeaned by the respective average rate\nfor each company. Positive values mean revenue came in higher than normal, and\nvice versa:\n\n\n\nFuture and current revenue over/underperformance are positively related. The\ncoefficient is 1.16, implying a $1 beat today forecasts a $1.16 beat four\nquarters from now. The exact reverse is true of a miss â€“ a dollar of missed\nrevenue this quarter lowers our expected revenue in four quarters by $1.16.\n\nAdditionally, the R^2 is decently high â€“ 0.49, so about half of the variation in\nexpected revenue four quarters out can be explained by revenue performance in\nthe current quarter.\n\nOne quick aside since I know what certain folks are thinking here: I am not\nmerely saying that current revenue predicts future revenue. I'm saying changes\nin revenue predict changes in future revenue.\n\nSo far, the short-termists seem to be winning. But one year is not a long-time â€“\nperhaps mean reversion takes longer? Let's check by extending the analysis to\neight and twelve quarters out. That's too crowded for a single scatterplot, so\nI'll summarize the results and only show the coefficients at each horizon:\n\n\n\nIf anything, the case for short-termism only gets stronger. The two-year revenue\nforecast shifts by $1.25 for a $1 beat/miss today. The three-year forecast\nchanges by $1.43.\n\nEven three years out, we see no evidence of mean-reversion among the typical\npublic software company. Beats and misses permanently shift the trajectory of\nthe company.\n\nNow, dollars are a nice unit of account, but they're admittedly hard to\ncontextualize. A $1 beat/miss that turns into a $1.43 beat/miss three years out\ncould be more or less meaningful depending on the scale of the company and its\ngrowth rate. Many of these companies were likely to be much larger in three\nyears anyway.\n\nLet's do the same analysis with percentages instead. What impact does a 1%\nbeat/miss have on future revenue, also in percentage terms?\n\n\n\nPersistence persists, but this tells a slightly different story. Revenue three\nyears from now is still 0.85% higher/lower than it would have otherwise been.\n\nMy interpretation: the additional (or lost) revenue from a beat (or miss) grows\nat a somewhat slower pace than the remaining revenue base, so we see some\nconvergence. In other words, \"surprise\" revenue doesn't grow as fast as\n\"expected\" revenue.\n\nYou could frame this as slight mean reversion. Personally, I'd say the\nshort-termists still have it.\n\nWorking as intended\nWhy does this happen? Why is the future so sensitive to the present?\n\nRather than a surprising phenomenon, I see this as the defining characteristic\nof subscription business models.\n\nTo say revenue \"recurs\" is merely to say revenue today generates revenue\ntomorrow. Said differently, a good test of subscription revenue quality is the\ndegree to which it persists and predicts future revenue.\n\nIn that light, these results are expected. If a change in revenue today didn't\npredict a change in revenue tomorrow, it'd be hard to call it recurring.\n\nFor some intuition, look at those cohort revenue charts\n[https://thetaclv.com/resource/c3/] that have become so popular among public\nsoftware companies (at least among those with good retention dynamics to show\noff):\n\n\n\nMissing a quarter means losing a slice of the cohort stack. Assuming positive\nnet dollar retention, that slice would have grown over time; the opportunity\ncost of weak performance grows over time.\n\nIronically, a miss for a company with high retention hurts more than one for a\ncompany with low net retention, since the high retention company has more\n(future revenue) to lose. I examined this phenomenon from a slightly different\nangle a few years back:\n\n> Both in theory and in practice,better retention drives higher volatility â€“ \n\"High\nRetention = High Volatility\"\n[https://whoisnnamdi.com/high-retention-high-volatility/]\n\n\nThis is why SaaS beats and misses are so consequential.\n\nIf investors think a miss or beat is likely to stick, that will meaningfully\nimpact their valuation views, as it must. On the other hand, the stock shouldn't\nmove much if short-term performance reflects merely temporary dynamics in a\ncompany's go-to-market engine.\n\nThat SaaS valuations tend to react so strongly implies investors do believe\nthese GTM gyrations are permanent and must be reflected in future projections.\nIt's possible there's some mean reversion happening under the hood, but this\neffect is totally swamped by the magnitude and persistence of the beat/miss\nitself.\n\nRevision of the mean\nA bad reaction to this analysis would be: your sales leader says the quarter\ncame in light because some deals slipped, you look them in the eyes and\nconfidently tell them \"there's no such thing as a deal slipping,\" and point them\nto this essay.\n\nNo. That's not what I'm saying at all. (Please do send them this essay though!)\n\nAt the level of individual sales, deals slip from one quarter to another all the\ntime. But at the level of aggregate revenue that doesn't seem to matter. Revenue\nwon't be higher next quarter simply because revenue came in low this quarter.\nEvery quarter is, for the most part, a blank slate.\n\nLikewise with pulling forward revenue â€“ it happens, but on average you can't\nfind it in the data. COVID is a good exception to this â€“ companies that\nbenefitted from the transition to remote work like Zoom or DocuSign are now\nslowing, reverting back to their long-run trend line:\n\n> While DocuSign beat revenue expectations last quarter, full-year guidance came\nin far lower than expected. DocuSignâ€¦ was perceived to be a \"COVID winner.\"\nThere are now fears that the company merely pulled forward years of sales over\nthe course of the past two years, and that its revenue growth trajectory will be\nlower going forward. (Link\n[https://www.theglobeandmail.com/investing/markets/stocks/APPN-Q/pressreleases/7587079/why-snowflake-appian-and-twilio-plunged-today-again/]\n)\n\n\n> While Coupa's upside certainly isn't at risk long term, it does appear some of\nits future growth was pulled forward during the COVID-19 crisis. (Link\n[https://www.nasdaq.com/articles/down-over-30-is-coupa-software-stock-a-buy-2021-03-27]\n)\n\n\n> Unfortunately for Twilio, it belongs to the â€œhigh beta growthâ€ club, which began\na secular decline early last year. The San Francisco-based Cloud Communications\ncompany boomed from the work-from-home trend... But, like so many other tech\ncompanies, it pulled forward too many gains, setting itself up for a nasty\nre-pricing. (Link\n[https://finance.yahoo.com/news/trade-twilio-stock-wednesday-earnings-175540896.html]\n)\n\n\nNote: this analysis only includes software companies. Businesses with more\ntransactional business models probably see less persistence and more mean\nreversion. Think about companies like Peloton:\n\n * Despite having a subscription service, the vast majority of revenue was in\n   physical bike sales that are one-time in nature\n * Peloton really did pull forward demand, which left little market left to grow\n   into by the time things returned to normal\n\nHowever, if you have significant recurring revenue, mean reversion is much less\nrelevant.\n\nThis analysis continues a line of thinking I touched on in a prior piece\n[https://whoisnnamdi.com/covid-hurt-software/] exploring COVID's impact on\nsoftware companies:\n\n> â€¦ mean reversion is a strong force, butCOVID was stronger, especially on the\ndownside. Once knocked down, the typical software business never got back upâ€¦\n\nMean revisionis at least as important as mean reversion. Not only are software\ncompanies below their pre-COVID trend,the trend itselfhas changed for the worse\nâ€“ COVID Hurt Most Software Companies\n[https://whoisnnamdi.com/covid-hurt-software/]\n\n\nFor software companies, every day is Day 1\n[https://s2.q4cdn.com/299287126/files/doc_financials/annual/Shareholderletter97.pdf] \nor, at least, dependent on it.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2022/09/forever.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2022-09-14T09:19:32.000Z","updated_at":"2022-09-14T09:29:07.000Z","published_at":"2022-09-14T09:29:07.000Z","custom_excerpt":"Revenue surprises permanently shift the trajectory of SaaS companies","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"6360bd1afec7d1542d1d2d50","uuid":"9a067119-02f0-4784-9107-7d9da16498b4","title":"It's Valuations (Almost) All the Way Down","slug":"its-valuations","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Venture funding hasn't grown as much as you think.\\n\\nSoaring valuations over the last decade inflated financing volumes.\\n\\nAs a result, \\\"real\\\", price-adjusted funding growth looks quite different from unadjusted growth, similar to traditional economic measures like GDP.\\n\\nAdjusting for rising valuations, real venture funding at the early stage is only growing at *half* the unadjusted pace.\\n\\nAt the later stages, valuation-adjusted venture funding isn't growing \\\\*at all\\\\*.\\n\\nIt's valuations (almost) all the way down.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: It's Valuations (Almost) All the Way Down\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## Pre-Algebra\\n\\nFirst, a quick math refresher:\\n- Total funding volume equals the number of financing rounds multiplied by the average round size\\n- Assuming a standard equity round, average round size further separates into valuation multiplied by dilution (the proportion of shares sold to investors)\\n\\nThat gives us three components â€“ deals, valuations, and dilution:\\n\\n![SCR-20221031-wdu](__GHOST_URL__/content/images/2022/11/SCR-20221031-wdu.png)\\n\\nThis framework is simple but powerful.\\n\\nWith it, we can explain the individual sources of growth in the venture funding ecosystem, cumulating into overall funding growth.\\n\\n## Algebra II\\n\\nLet's walk through each component one-by-one.\\n\\nI'll plot the growth over time of each component since 2010, leveraging data from Pitchbook for all venture deals completed in Western markets through 2021.\\n\\nImportantly, I'll plot the cumulative *log growth*:\\n- This makes the components additive rather than multiplicative, which will help the analysis later\\n- This also means you can read compound annual growth rates (CAGRs) off of the y-axis. Just take the value on the y-axis and divide by 11, which is the number of years this analysis covers\\n\\nLet's start with growth in funding volume by stage:\\n\\n![capital](__GHOST_URL__/content/images/2022/11/capital.png)\\n\\n- Across stages, annual venture funding grew by 2.5 to 3 log points, with CAGRs ranging from 23-27% CAGR (again, just divide the log growth by 11)\\n- The earliest (Seed) and latest (Series D+) stages grew fastest\\n\\nNext, let's dive into each of the components.\\n\\nDeal counts have ballooned across all stages, but the Seed stage stands out:\\n\\n![deals](__GHOST_URL__/content/images/2022/11/deals.png)\\n\\n- Seed deals grew the most by far over this period, 2.1 log points or 19% on an annual basis\\n- On the other hand, Series C deals and later only grew ~0.75 log points, a 7% CAGR\\n- As and Bs were somewhere in the middle, growing 10% annually over this time\\n\\nIt should be noted: that Seed deals grew so much faster than the rest implies the \\\"graduation\\\" or \\\"survival\\\" rate of startups fell materially, as they've had more than enough time to mature.\\n\\n**More early-stage startups has not led to many more late-stage startups.**\\n\\nWe'll revisit this.\\n\\nNext up, valuations:\\n\\n![valuations](__GHOST_URL__/content/images/2022/11/valuations.png)\\n\\n- Unlike deal counts, which grew the most at the early stage, valuations grew the most *at the later stages*\\n- Series C valuations grew at a ~20% CAGR, while Series D+ grew at ~24%\\n- Series As and Bs again formed the middle of the pack, growing 1.75 log points or 16% year-over-year\\n- Seed valuations \\\"only\\\" grew 10% annually, which is still exceptional if you think about it\\n\\nLastly, let's look at dilution. Note again these numbers are in log points (*not* percentage points):\\n\\n![dilution](__GHOST_URL__/content/images/2022/11/dilution.png)\\n\\n- Dilution has fallen in every stage since 2010\\n- Dilution at the Series A and C has fallen the most, while dilution at the Series B has fallen the least\\n- Dilution evolved similarly across stages through 2019, but for whatever reason, VCs over the last few years were much less desperate to \\\"get their ownership\\\" in Series A, C, and D+ rounds\\n\\nNote that falling dilution *negatively* impacts funding volume since less equity gets sold.\\n\\n## Multivariable calculus\\n\\nAnd now, the main event. \\n\\nFor every financing stage, let's aggregate the change in deals, valuations, and dilution to explain the cumulative growth of funding:\\n\\n![decomp_g](__GHOST_URL__/content/images/2022/11/decomp_g.png)\\n\\n- At the Seed stage, most funding growth came from more deals getting done. Valuations rose too, but deal count explains most of the overall funding growth\\n\\nThis seems healthy â€“ growth in funding should ideally come from growth in the total number of deals.\\n\\n- It's a completely different story at every other stage: *valuations explain most of the growth in funding at Series A and later.*\\n- **At the later-stage, valuation inflation explains nearly \\\\*all\\\\* growth in venture funding over the last eleven years**\\n\\nIn contrast to the Seed stage, this seems unhealthy: growth in the majority of the venture ecosystem (at least as measured in dollars) over the last decade was primarily driven by rising valuations.\\n\\nNow, if you've spent a lot of time staring at data like I have, you'll know that these sorts of analyses can be very dependent on the starting year (in this case, 2010).\\n\\nJust to be safe, we can avoid privileging any particular year as the starting point by instead calculating the variance in funding levels over time rather than the growth. Variance decomposes the same way as growth, but this time there won't be a \\\"base year\\\" affecting the results.\\n\\nDo this, and the conclusion is the same â€“ year-to-year variation in valuations accounts for most of the variance in funding volume over time at the later stages:\\n\\n![decomp_v](__GHOST_URL__/content/images/2022/11/decomp_v.png)\\n\\n- At the seed stage, two-thirds of funding variance over time is accounted for by deal volume and one-third by valuations\\n- At Series A and B, 65-70% of funding variance is explained by valuations\\n- **At Series C and later, valuations account for more than 80% of the annual variance in venture capital funding**\\n\\nIn economics, when quantities and prices rise together, you can be fairly sure it's driven by growth of demand, or equivalently, you know the market in question is supply constrained:\\n- The supply of startup equity at the later stages is constrained; there's only so much of it to go around\\n- On the other hand, investor demand for venture assets has exploded, especially at the later stages where companies have been significantly de-risked\\n\\nIn this sense, the valuation inflation we've seen \\\"comes from\\\" the incredible growth in demand and lack of supply of startup equity.\\n\\n## Real analysis\\n\\nHere's another trick â€“ if we go back to our decomposition and divide both sides by valuation, we get the following:\\n\\n![SCR-20221031-wg9](__GHOST_URL__/content/images/2022/11/SCR-20221031-wg9.png)\\n\\nIn other words, we can adjust funding volume by the average valuation at which these financings occurred to get a \\\"valuation-adjusted\\\" funding metric. This is analogous to how economists \\\"deflate\\\" nominal GDP by inflation (e.g. [CPI](https://www.bls.gov/cpi/) or similar) to arrive at \\\"real\\\" GDP.\\n\\nIt's also the result of multiplying deal count each year by average dilution, i.e. the total equity bought and sold in the venture market each year.\\n\\nThis lets us measure \\\"real\\\" growth in venture funding rather than dollar-based growth, which conflates deal activity with valuation movements.\\n\\nCompare this \\\"real\\\" funding metric to the \\\"nominal\\\" one I showed earlier:\\n\\n![adj](__GHOST_URL__/content/images/2022/11/adj.png)\\n\\nWow.\\n\\nReal venture funding is growing much, much slower than you think:\\n- At the Seed stage, real funding growth has a 17% CAGR vs. 27% for raw funding dollars\\n- At the Series A and B, real funding grew at a 7% CAGR vs. 23% for nominal funding, one-third the rate\\n- **Real funding was flat for a decade at the later stages** before finally ticking up in the heydays of 2021. Real annual growth is only 2% and 4% at the Series C and D+ respectively, vs. 23 and 27% without adjustment\\n\\nI want to state this as directly as possible: **there was no growth in real late-stage funding activity for a decade until the bonanza of 2021.**\\n\\nSaid differently, no more late-stage equity traded hands in 2020 than in 2010, measured in terms of points of cap table ownership.\\n\\n## Now you're ready for Economics 101\\n\\nThis data contradicts the common narratives of the past decade of growth in the venture ecosystem.\\n\\nVenture capital is about two things, ventures and capital.\\n\\nCapital has been in excess supply the last decade, but ventures haven't.\\n\\nValuations can't rise forever, so over the long-run venture capital can't grow much faster than the number of ventures themselves.\\n\\nIn a way it all makes sense:\\n- By the time startups graduate to the later stages, they are real companies, typically with meaningful revenue, operations, and headcount\\n- Accordingly, their total count *should* grow roughly in line with the real growth rate of modern, industrialized economies. We wouldn't expect an order of magnitude difference, otherwise late-stage startups would overtake the whole economy\\n\\nIn other ways, it's highly concerning:\\n- **The supply of late-stage startup equity hasn't risen to match investor demand**\\n- Perhaps this explains why late-stage funding seems so anemic right now - activity has reverted back to the zero-growth trend, which feels quite slow relative to the flurry of 2021 deal-making\\n\\nThe venture ecosystem is supply-constrained â€“ there isn't nearly enough startup equity out there to satisfy investor demand.\\n\\nAdditional capital drives opportunistic company formation at the Seed stage. However, the additional capital doesn't improve *survival* to the later stages â€“ it simply drives prices up for the remaining companies.\\n\\nI've long felt this but never had the data to back it up.\\n\\nNow I do, and I think it's a big problem.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: It's Valuations (Almost) All the Way Down\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>Venture funding hasn't grown as much as you think.</p>\n<p>Soaring valuations over the last decade inflated financing volumes.</p>\n<p>As a result, &quot;real&quot;, price-adjusted funding growth looks quite different from unadjusted growth, similar to traditional economic measures like GDP.</p>\n<p>Adjusting for rising valuations, real venture funding at the early stage is only growing at <em>half</em> the unadjusted pace.</p>\n<p>At the later stages, valuation-adjusted venture funding isn't growing *at all*.</p>\n<p>It's valuations (almost) all the way down.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: It's Valuations (Almost) All the Way Down\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"pre-algebra\">Pre-Algebra</h2>\n<p>First, a quick math refresher:</p>\n<ul>\n<li>Total funding volume equals the number of financing rounds multiplied by the average round size</li>\n<li>Assuming a standard equity round, average round size further separates into valuation multiplied by dilution (the proportion of shares sold to investors)</li>\n</ul>\n<p>That gives us three components â€“ deals, valuations, and dilution:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/11/SCR-20221031-wdu.png\" alt=\"SCR-20221031-wdu\" loading=\"lazy\"></p>\n<p>This framework is simple but powerful.</p>\n<p>With it, we can explain the individual sources of growth in the venture funding ecosystem, cumulating into overall funding growth.</p>\n<h2 id=\"algebra-ii\">Algebra II</h2>\n<p>Let's walk through each component one-by-one.</p>\n<p>I'll plot the growth over time of each component since 2010, leveraging data from Pitchbook for all venture deals completed in Western markets through 2021.</p>\n<p>Importantly, I'll plot the cumulative <em>log growth</em>:</p>\n<ul>\n<li>This makes the components additive rather than multiplicative, which will help the analysis later</li>\n<li>This also means you can read compound annual growth rates (CAGRs) off of the y-axis. Just take the value on the y-axis and divide by 11, which is the number of years this analysis covers</li>\n</ul>\n<p>Let's start with growth in funding volume by stage:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/11/capital.png\" alt=\"capital\" loading=\"lazy\"></p>\n<ul>\n<li>Across stages, annual venture funding grew by 2.5 to 3 log points, with CAGRs ranging from 23-27% CAGR (again, just divide the log growth by 11)</li>\n<li>The earliest (Seed) and latest (Series D+) stages grew fastest</li>\n</ul>\n<p>Next, let's dive into each of the components.</p>\n<p>Deal counts have ballooned across all stages, but the Seed stage stands out:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/11/deals.png\" alt=\"deals\" loading=\"lazy\"></p>\n<ul>\n<li>Seed deals grew the most by far over this period, 2.1 log points or 19% on an annual basis</li>\n<li>On the other hand, Series C deals and later only grew ~0.75 log points, a 7% CAGR</li>\n<li>As and Bs were somewhere in the middle, growing 10% annually over this time</li>\n</ul>\n<p>It should be noted: that Seed deals grew so much faster than the rest implies the &quot;graduation&quot; or &quot;survival&quot; rate of startups fell materially, as they've had more than enough time to mature.</p>\n<p><strong>More early-stage startups has not led to many more late-stage startups.</strong></p>\n<p>We'll revisit this.</p>\n<p>Next up, valuations:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/11/valuations.png\" alt=\"valuations\" loading=\"lazy\"></p>\n<ul>\n<li>Unlike deal counts, which grew the most at the early stage, valuations grew the most <em>at the later stages</em></li>\n<li>Series C valuations grew at a ~20% CAGR, while Series D+ grew at ~24%</li>\n<li>Series As and Bs again formed the middle of the pack, growing 1.75 log points or 16% year-over-year</li>\n<li>Seed valuations &quot;only&quot; grew 10% annually, which is still exceptional if you think about it</li>\n</ul>\n<p>Lastly, let's look at dilution. Note again these numbers are in log points (<em>not</em> percentage points):</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/11/dilution.png\" alt=\"dilution\" loading=\"lazy\"></p>\n<ul>\n<li>Dilution has fallen in every stage since 2010</li>\n<li>Dilution at the Series A and C has fallen the most, while dilution at the Series B has fallen the least</li>\n<li>Dilution evolved similarly across stages through 2019, but for whatever reason, VCs over the last few years were much less desperate to &quot;get their ownership&quot; in Series A, C, and D+ rounds</li>\n</ul>\n<p>Note that falling dilution <em>negatively</em> impacts funding volume since less equity gets sold.</p>\n<h2 id=\"multivariable-calculus\">Multivariable calculus</h2>\n<p>And now, the main event.</p>\n<p>For every financing stage, let's aggregate the change in deals, valuations, and dilution to explain the cumulative growth of funding:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/11/decomp_g.png\" alt=\"decomp_g\" loading=\"lazy\"></p>\n<ul>\n<li>At the Seed stage, most funding growth came from more deals getting done. Valuations rose too, but deal count explains most of the overall funding growth</li>\n</ul>\n<p>This seems healthy â€“ growth in funding should ideally come from growth in the total number of deals.</p>\n<ul>\n<li>It's a completely different story at every other stage: <em>valuations explain most of the growth in funding at Series A and later.</em></li>\n<li><strong>At the later-stage, valuation inflation explains nearly *all* growth in venture funding over the last eleven years</strong></li>\n</ul>\n<p>In contrast to the Seed stage, this seems unhealthy: growth in the majority of the venture ecosystem (at least as measured in dollars) over the last decade was primarily driven by rising valuations.</p>\n<p>Now, if you've spent a lot of time staring at data like I have, you'll know that these sorts of analyses can be very dependent on the starting year (in this case, 2010).</p>\n<p>Just to be safe, we can avoid privileging any particular year as the starting point by instead calculating the variance in funding levels over time rather than the growth. Variance decomposes the same way as growth, but this time there won't be a &quot;base year&quot; affecting the results.</p>\n<p>Do this, and the conclusion is the same â€“ year-to-year variation in valuations accounts for most of the variance in funding volume over time at the later stages:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/11/decomp_v.png\" alt=\"decomp_v\" loading=\"lazy\"></p>\n<ul>\n<li>At the seed stage, two-thirds of funding variance over time is accounted for by deal volume and one-third by valuations</li>\n<li>At Series A and B, 65-70% of funding variance is explained by valuations</li>\n<li><strong>At Series C and later, valuations account for more than 80% of the annual variance in venture capital funding</strong></li>\n</ul>\n<p>In economics, when quantities and prices rise together, you can be fairly sure it's driven by growth of demand, or equivalently, you know the market in question is supply constrained:</p>\n<ul>\n<li>The supply of startup equity at the later stages is constrained; there's only so much of it to go around</li>\n<li>On the other hand, investor demand for venture assets has exploded, especially at the later stages where companies have been significantly de-risked</li>\n</ul>\n<p>In this sense, the valuation inflation we've seen &quot;comes from&quot; the incredible growth in demand and lack of supply of startup equity.</p>\n<h2 id=\"real-analysis\">Real analysis</h2>\n<p>Here's another trick â€“ if we go back to our decomposition and divide both sides by valuation, we get the following:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/11/SCR-20221031-wg9.png\" alt=\"SCR-20221031-wg9\" loading=\"lazy\"></p>\n<p>In other words, we can adjust funding volume by the average valuation at which these financings occurred to get a &quot;valuation-adjusted&quot; funding metric. This is analogous to how economists &quot;deflate&quot; nominal GDP by inflation (e.g. <a href=\"https://www.bls.gov/cpi/\">CPI</a> or similar) to arrive at &quot;real&quot; GDP.</p>\n<p>It's also the result of multiplying deal count each year by average dilution, i.e. the total equity bought and sold in the venture market each year.</p>\n<p>This lets us measure &quot;real&quot; growth in venture funding rather than dollar-based growth, which conflates deal activity with valuation movements.</p>\n<p>Compare this &quot;real&quot; funding metric to the &quot;nominal&quot; one I showed earlier:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/11/adj.png\" alt=\"adj\" loading=\"lazy\"></p>\n<p>Wow.</p>\n<p>Real venture funding is growing much, much slower than you think:</p>\n<ul>\n<li>At the Seed stage, real funding growth has a 17% CAGR vs. 27% for raw funding dollars</li>\n<li>At the Series A and B, real funding grew at a 7% CAGR vs. 23% for nominal funding, one-third the rate</li>\n<li><strong>Real funding was flat for a decade at the later stages</strong> before finally ticking up in the heydays of 2021. Real annual growth is only 2% and 4% at the Series C and D+ respectively, vs. 23 and 27% without adjustment</li>\n</ul>\n<p>I want to state this as directly as possible: <strong>there was no growth in real late-stage funding activity for a decade until the bonanza of 2021.</strong></p>\n<p>Said differently, no more late-stage equity traded hands in 2020 than in 2010, measured in terms of points of cap table ownership.</p>\n<h2 id=\"now-youre-ready-for-economics-101\">Now you're ready for Economics 101</h2>\n<p>This data contradicts the common narratives of the past decade of growth in the venture ecosystem.</p>\n<p>Venture capital is about two things, ventures and capital.</p>\n<p>Capital has been in excess supply the last decade, but ventures haven't.</p>\n<p>Valuations can't rise forever, so over the long-run venture capital can't grow much faster than the number of ventures themselves.</p>\n<p>In a way it all makes sense:</p>\n<ul>\n<li>By the time startups graduate to the later stages, they are real companies, typically with meaningful revenue, operations, and headcount</li>\n<li>Accordingly, their total count <em>should</em> grow roughly in line with the real growth rate of modern, industrialized economies. We wouldn't expect an order of magnitude difference, otherwise late-stage startups would overtake the whole economy</li>\n</ul>\n<p>In other ways, it's highly concerning:</p>\n<ul>\n<li><strong>The supply of late-stage startup equity hasn't risen to match investor demand</strong></li>\n<li>Perhaps this explains why late-stage funding seems so anemic right now - activity has reverted back to the zero-growth trend, which feels quite slow relative to the flurry of 2021 deal-making</li>\n</ul>\n<p>The venture ecosystem is supply-constrained â€“ there isn't nearly enough startup equity out there to satisfy investor demand.</p>\n<p>Additional capital drives opportunistic company formation at the Seed stage. However, the additional capital doesn't improve <em>survival</em> to the later stages â€“ it simply drives prices up for the remaining companies.</p>\n<p>I've long felt this but never had the data to back it up.</p>\n<p>Now I do, and I think it's a big problem.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: It's Valuations (Almost) All the Way Down\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"6360bd1afec7d1542d1d2d50","plaintext":"Venture funding hasn't grown as much as you think.\n\nSoaring valuations over the last decade inflated financing volumes.\n\nAs a result, \"real\", price-adjusted funding growth looks quite different from\nunadjusted growth, similar to traditional economic measures like GDP.\n\nAdjusting for rising valuations, real venture funding at the early stage is only\ngrowing at half the unadjusted pace.\n\nAt the later stages, valuation-adjusted venture funding isn't growing *at all*.\n\nIt's valuations (almost) all the way down.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Pre-Algebra\nFirst, a quick math refresher:\n\n * Total funding volume equals the number of financing rounds multiplied by the\n   average round size\n * Assuming a standard equity round, average round size further separates into\n   valuation multiplied by dilution (the proportion of shares sold to investors)\n\nThat gives us three components â€“ deals, valuations, and dilution:\n\n\n\nThis framework is simple but powerful.\n\nWith it, we can explain the individual sources of growth in the venture funding\necosystem, cumulating into overall funding growth.\n\nAlgebra II\nLet's walk through each component one-by-one.\n\nI'll plot the growth over time of each component since 2010, leveraging data\nfrom Pitchbook for all venture deals completed in Western markets through 2021.\n\nImportantly, I'll plot the cumulative log growth:\n\n * This makes the components additive rather than multiplicative, which will\n   help the analysis later\n * This also means you can read compound annual growth rates (CAGRs) off of the\n   y-axis. Just take the value on the y-axis and divide by 11, which is the\n   number of years this analysis covers\n\nLet's start with growth in funding volume by stage:\n\n\n\n * Across stages, annual venture funding grew by 2.5 to 3 log points, with CAGRs\n   ranging from 23-27% CAGR (again, just divide the log growth by 11)\n * The earliest (Seed) and latest (Series D+) stages grew fastest\n\nNext, let's dive into each of the components.\n\nDeal counts have ballooned across all stages, but the Seed stage stands out:\n\n\n\n * Seed deals grew the most by far over this period, 2.1 log points or 19% on an\n   annual basis\n * On the other hand, Series C deals and later only grew ~0.75 log points, a 7%\n   CAGR\n * As and Bs were somewhere in the middle, growing 10% annually over this time\n\nIt should be noted: that Seed deals grew so much faster than the rest implies\nthe \"graduation\" or \"survival\" rate of startups fell materially, as they've had\nmore than enough time to mature.\n\nMore early-stage startups has not led to many more late-stage startups.\n\nWe'll revisit this.\n\nNext up, valuations:\n\n\n\n * Unlike deal counts, which grew the most at the early stage, valuations grew\n   the most at the later stages\n * Series C valuations grew at a ~20% CAGR, while Series D+ grew at ~24%\n * Series As and Bs again formed the middle of the pack, growing 1.75 log points\n   or 16% year-over-year\n * Seed valuations \"only\" grew 10% annually, which is still exceptional if you\n   think about it\n\nLastly, let's look at dilution. Note again these numbers are in log points (not \npercentage points):\n\n\n\n * Dilution has fallen in every stage since 2010\n * Dilution at the Series A and C has fallen the most, while dilution at the\n   Series B has fallen the least\n * Dilution evolved similarly across stages through 2019, but for whatever\n   reason, VCs over the last few years were much less desperate to \"get their\n   ownership\" in Series A, C, and D+ rounds\n\nNote that falling dilution negatively impacts funding volume since less equity\ngets sold.\n\nMultivariable calculus\nAnd now, the main event.\n\nFor every financing stage, let's aggregate the change in deals, valuations, and\ndilution to explain the cumulative growth of funding:\n\n\n\n * At the Seed stage, most funding growth came from more deals getting done.\n   Valuations rose too, but deal count explains most of the overall funding\n   growth\n\nThis seems healthy â€“ growth in funding should ideally come from growth in the\ntotal number of deals.\n\n * It's a completely different story at every other stage: valuations explain\n   most of the growth in funding at Series A and later.\n * At the later-stage, valuation inflation explains nearly *all* growth in\n   venture funding over the last eleven years\n\nIn contrast to the Seed stage, this seems unhealthy: growth in the majority of\nthe venture ecosystem (at least as measured in dollars) over the last decade was\nprimarily driven by rising valuations.\n\nNow, if you've spent a lot of time staring at data like I have, you'll know that\nthese sorts of analyses can be very dependent on the starting year (in this\ncase, 2010).\n\nJust to be safe, we can avoid privileging any particular year as the starting\npoint by instead calculating the variance in funding levels over time rather\nthan the growth. Variance decomposes the same way as growth, but this time there\nwon't be a \"base year\" affecting the results.\n\nDo this, and the conclusion is the same â€“ year-to-year variation in valuations\naccounts for most of the variance in funding volume over time at the later\nstages:\n\n\n\n * At the seed stage, two-thirds of funding variance over time is accounted for\n   by deal volume and one-third by valuations\n * At Series A and B, 65-70% of funding variance is explained by valuations\n * At Series C and later, valuations account for more than 80% of the annual\n   variance in venture capital funding\n\nIn economics, when quantities and prices rise together, you can be fairly sure\nit's driven by growth of demand, or equivalently, you know the market in\nquestion is supply constrained:\n\n * The supply of startup equity at the later stages is constrained; there's only\n   so much of it to go around\n * On the other hand, investor demand for venture assets has exploded,\n   especially at the later stages where companies have been significantly\n   de-risked\n\nIn this sense, the valuation inflation we've seen \"comes from\" the incredible\ngrowth in demand and lack of supply of startup equity.\n\nReal analysis\nHere's another trick â€“ if we go back to our decomposition and divide both sides\nby valuation, we get the following:\n\n\n\nIn other words, we can adjust funding volume by the average valuation at which\nthese financings occurred to get a \"valuation-adjusted\" funding metric. This is\nanalogous to how economists \"deflate\" nominal GDP by inflation (e.g. CPI\n[https://www.bls.gov/cpi/] or similar) to arrive at \"real\" GDP.\n\nIt's also the result of multiplying deal count each year by average dilution,\ni.e. the total equity bought and sold in the venture market each year.\n\nThis lets us measure \"real\" growth in venture funding rather than dollar-based\ngrowth, which conflates deal activity with valuation movements.\n\nCompare this \"real\" funding metric to the \"nominal\" one I showed earlier:\n\n\n\nWow.\n\nReal venture funding is growing much, much slower than you think:\n\n * At the Seed stage, real funding growth has a 17% CAGR vs. 27% for raw funding\n   dollars\n * At the Series A and B, real funding grew at a 7% CAGR vs. 23% for nominal\n   funding, one-third the rate\n * Real funding was flat for a decade at the later stages before finally ticking\n   up in the heydays of 2021. Real annual growth is only 2% and 4% at the Series\n   C and D+ respectively, vs. 23 and 27% without adjustment\n\nI want to state this as directly as possible: there was no growth in real\nlate-stage funding activity for a decade until the bonanza of 2021.\n\nSaid differently, no more late-stage equity traded hands in 2020 than in 2010,\nmeasured in terms of points of cap table ownership.\n\nNow you're ready for Economics 101\nThis data contradicts the common narratives of the past decade of growth in the\nventure ecosystem.\n\nVenture capital is about two things, ventures and capital.\n\nCapital has been in excess supply the last decade, but ventures haven't.\n\nValuations can't rise forever, so over the long-run venture capital can't grow\nmuch faster than the number of ventures themselves.\n\nIn a way it all makes sense:\n\n * By the time startups graduate to the later stages, they are real companies,\n   typically with meaningful revenue, operations, and headcount\n * Accordingly, their total count should grow roughly in line with the real\n   growth rate of modern, industrialized economies. We wouldn't expect an order\n   of magnitude difference, otherwise late-stage startups would overtake the\n   whole economy\n\nIn other ways, it's highly concerning:\n\n * The supply of late-stage startup equity hasn't risen to match investor demand\n * Perhaps this explains why late-stage funding seems so anemic right now -\n   activity has reverted back to the zero-growth trend, which feels quite slow\n   relative to the flurry of 2021 deal-making\n\nThe venture ecosystem is supply-constrained â€“ there isn't nearly enough startup\nequity out there to satisfy investor demand.\n\nAdditional capital drives opportunistic company formation at the Seed stage.\nHowever, the additional capital doesn't improve survival to the later stages â€“\nit simply drives prices up for the remaining companies.\n\nI've long felt this but never had the data to back it up.\n\nNow I do, and I think it's a big problem.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2022/11/decomp_g-1.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2022-11-01T06:30:50.000Z","updated_at":"2022-11-01T15:57:51.000Z","published_at":"2022-11-01T15:48:34.000Z","custom_excerpt":"Venture funding hasn't grown as much as you think","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"6398b3ccfec7d1542d1d2da6","uuid":"7f9e5e67-bed4-407a-95d8-94037b51d9f3","title":"Old Valuations Die Hard","slug":"old-valuations","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Public technology valuations have crashed.\\n\\nA worsening economic outlook and tight monetary policy sent tech stocks through the floor.\\n\\nHowever, private valuations are slower to adjust.\\n\\nPrivate valuations lag public valuations, often by a substantial amount and for a long time.\\n\\nAs we all lick our wounds during this venture downturn, many are asking: when will it all end?\\n\\nThe answer? **About three years.**\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Old Valuations Die Hard\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## Public-private partnership\\n\\nPrivate valuations rose dramatically over the last decade. But so did the Nasdaq:\\n\\n![nasdaq_valuation](__GHOST_URL__/content/images/2022/12/nasdaq_valuation.png)\\n\\nIt's remarkable how well the two track one another.\\n\\nIn a sense, the growth of public tech valuations seems to pin down the rise of private valuations, defining a trend to which private valuations always tend to return. It's clear that venture investors use public valuations to justify private ones.\\n\\nOne feature immediately stands out â€“ private valuations are much more volatile than public valuations, particularly at the later stages:\\n- This is to be expected â€“ it's not the same companies that are fundraising each quarter, so we'd naturally expect the prices to jump around a bit\\n- Meanwhile, the composition of the Nasdaq doesn't change much quarter to quarter, so as an aggregate it's much more stable\\n\\nIf we throw each one on its own axis, the relationship is even more obvious:\\n\\n![nasdaq_valuation2](__GHOST_URL__/content/images/2022/12/nasdaq_valuation2.png)\\n\\nAcross stages, private valuations move one-for-one with public valuations.\\n- Seed valuations have grown somewhat slower than the Nasdaq, moving 0.5% for every 1% move in the tech index\\n- Series A, B, and C valuations have moved one-for-one\\n- Series D+ valuations have grown 1.3% each point of growth in the Nasdaq\\n\\nWe can replicate the same analysis for private venture activity. The relationship is not as tight:\\n\\n![nasdaq_deals](__GHOST_URL__/content/images/2022/12/nasdaq_deals.png)\\n\\nDeal activity is more or less related to public tech valuations, depending on stage. Here too we see much more volatility in the private realm than the public, again, for understandable reasons.\\n\\n![nasdaq_deals2](__GHOST_URL__/content/images/2022/12/nasdaq_deals2.png)\\n\\nIn general the slopes here are flatter than for valuations:\\n- Seed deals have grown at roughly the same pace as public valuations\\n- For other stages, growth has lagged public tech valuations â€“ growing  at about half the pace\\n\\n## Level with me\\n\\nThough intuitive, these comparisons are not rigorous. It's too easy to find spurious relationships among variables that are all trending in the same direction. There's less risk of that in our case since public and private technology markets are closely linked, but we should be wary regardless.\\n\\nWe can do better by focusing less on the relationship between *level* of the Nasdaq and some other variable and more on the correlation between *changes* in the respective metrics.\\n\\n**The key question:** how does a change (up or down) in public technology valuations affect the prices of private financings, and how quickly?\\n\\nSome good ol' regression analysis can answer this.\\n\\nGlossing over a bunch of detail:\\n- We can forecast future changes in private valuations and financings based on current changes in public tech valuations.\\n- We'll run one regression for each forecast horizon: concurrent (time zero) impact, one quarter out, two quarters out, etc.\\n- The coefficients of these regressions trace out the impact of the original movement in the Nasdaq on private prices and volume in later periods.\\n\\n## The path to recovery\\n\\nHope you're still with me. Let's run those regressions and see what we get.\\n\\nWe'll focus on downward movements in the Nasdaq. This is how a 1% decline in the Nasdaq affects private valuations and deal flow over future quarters:\\n\\n![valuations_deals-1](__GHOST_URL__/content/images/2022/12/valuations_deals-1.png)\\n\\nPrivate valuations gradually decline after a drop in the Nasdaq:\\n- **Prices drop continuously for four quarters**\\n- At the trough, private valuations fall ~2.25% lower for every 1% loss in the Nasdaq\\n- **Venture valuations take 10 quarters to recover**\\n\\nMovements in the Nasdaq reliably forecast venture deal activity too, which drops and rebounds faster than prices:\\n- Deal activity bottoms in the third quarter after impact\\n- Overall deal count rises back to its original level by the 8th quarter\\n\\n## Down for a down round?\\n\\nThis masks a lot of underlying variance between the different segments of the venture ecosystem. Starting with valuations, let's explore how the shape of the recovery varies by stage:\\n\\n![nasdaq_valuation3-2](__GHOST_URL__/content/images/2022/12/nasdaq_valuation3-2.png)\\n\\n**Valuation dynamics depend on stage:** Early stage valuations drop 1-1.5% for every 1% decline in the Nasdaq, while growth and late stage valuations decline 2-2.25%.\\n\\n**Note: these aren't exact estimates.** Uncertainty grows as we look further out from initial impact, so don't pay much attention to the numbers at the 12-quarter mark. It's the shape and length of the recovery that matters most.\\n\\nWith some back-of-the-envelope math, we can estimate both the magnitude and the length of the current downturn:\\n- The peak to trough decline in the Nasdaq this past year was about 25%, **implying a ~25-35% haircut to early stage valuations and a ~50-55% cut in growth and later stage valuations**\\n- That might sound extreme, but the sudden explosion of late stage valuations these past few years was itself quite unusual. It's not implausible that prices could fall as dramatically as they rose\\n\\nIn fact, the correction is already well underway:\\n\\n![nasdaq_valuation4](__GHOST_URL__/content/images/2022/12/nasdaq_valuation4.png)\\n\\nAs predicted, late stage valuations drop much more than the Nasdaq, while early stage valuations move roughly in line. Prices have fallen faster than my forecast, but the magnitudes are on point.\\n\\nTiming the bottom based on my regression here is a bit tricky, as the market began its decline in Q1 2022 and mostly ran its course by Q3 2022. If we use the midpoint of Q2 2022 as the \\\"start\\\" of the venture recession:\\n* **Private valuations should bottom in Q2 2023**\\n* I'm hesitant to forecast the heydays of 2021 ever returning, but if they did, it'd happen around Q4 2024. *I wouldn't hold your breath though*\\n\\n## Coming to terms\\n\\nAgain, let's focus on a 1% decline in the Nasdaq:\\n\\n![nasdaq_deals3](__GHOST_URL__/content/images/2022/12/nasdaq_deals3.png)\\n\\nFinancings follow an interesting \\\"sine wave\\\" recovery in the aftermath of a plunge in the Nasdaq. Again we see more severe impact in the later stages: The quarterly volume of Seeds and As drops by 0.75-1% for each 1% decline in the Nasdaq. Late stage deals sink 2%.\\n\\nOne ray of hope â€“ financing activity seems to come back *stronger* after a venture recession.\\n\\nPulling out that scribbled envelope again, these numbers suggest **early stage deal activity will drop 20-25%; growth and late stage deal volumes should slide about 50%.**\\n\\nAgain, the data bears this out:\\n\\n![nasdaq_deals4](__GHOST_URL__/content/images/2022/12/nasdaq_deals4.png)\\n\\nRemember, the venture deals should only take about a year to hit their low, so activity should stabilize in or around Q1 2023, notably ahead of valuations.\\n\\nAs I've said, these are rough estimates. All the typical caveats apply: \\\"this time could be different,\\\" etc.\\n\\n## Conclusion\\n\\nThe bubble burst, but the pain won't last forever.\\n\\nThe historical relationship between the public and private tech markets lets us trace out the likely path of the venture recovery.\\n\\nThe first year is the hardest. Prices drop precipitously, in many cases, much further than their public tech comparables.\\n\\nThings get better from there, with deal activity back on track after another year or so. Prices, however, remain depressed a little while longer.\\n\\nAll-in-all, it's a three year odyssey from start to finish.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: Old Valuations Die Hard\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>Public technology valuations have crashed.</p>\n<p>A worsening economic outlook and tight monetary policy sent tech stocks through the floor.</p>\n<p>However, private valuations are slower to adjust.</p>\n<p>Private valuations lag public valuations, often by a substantial amount and for a long time.</p>\n<p>As we all lick our wounds during this venture downturn, many are asking: when will it all end?</p>\n<p>The answer? <strong>About three years.</strong></p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Old Valuations Die Hard\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"public-private-partnership\">Public-private partnership</h2>\n<p>Private valuations rose dramatically over the last decade. But so did the Nasdaq:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/12/nasdaq_valuation.png\" alt=\"nasdaq_valuation\" loading=\"lazy\"></p>\n<p>It's remarkable how well the two track one another.</p>\n<p>In a sense, the growth of public tech valuations seems to pin down the rise of private valuations, defining a trend to which private valuations always tend to return. It's clear that venture investors use public valuations to justify private ones.</p>\n<p>One feature immediately stands out â€“ private valuations are much more volatile than public valuations, particularly at the later stages:</p>\n<ul>\n<li>This is to be expected â€“ it's not the same companies that are fundraising each quarter, so we'd naturally expect the prices to jump around a bit</li>\n<li>Meanwhile, the composition of the Nasdaq doesn't change much quarter to quarter, so as an aggregate it's much more stable</li>\n</ul>\n<p>If we throw each one on its own axis, the relationship is even more obvious:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/12/nasdaq_valuation2.png\" alt=\"nasdaq_valuation2\" loading=\"lazy\"></p>\n<p>Across stages, private valuations move one-for-one with public valuations.</p>\n<ul>\n<li>Seed valuations have grown somewhat slower than the Nasdaq, moving 0.5% for every 1% move in the tech index</li>\n<li>Series A, B, and C valuations have moved one-for-one</li>\n<li>Series D+ valuations have grown 1.3% each point of growth in the Nasdaq</li>\n</ul>\n<p>We can replicate the same analysis for private venture activity. The relationship is not as tight:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/12/nasdaq_deals.png\" alt=\"nasdaq_deals\" loading=\"lazy\"></p>\n<p>Deal activity is more or less related to public tech valuations, depending on stage. Here too we see much more volatility in the private realm than the public, again, for understandable reasons.</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/12/nasdaq_deals2.png\" alt=\"nasdaq_deals2\" loading=\"lazy\"></p>\n<p>In general the slopes here are flatter than for valuations:</p>\n<ul>\n<li>Seed deals have grown at roughly the same pace as public valuations</li>\n<li>For other stages, growth has lagged public tech valuations â€“ growing  at about half the pace</li>\n</ul>\n<h2 id=\"level-with-me\">Level with me</h2>\n<p>Though intuitive, these comparisons are not rigorous. It's too easy to find spurious relationships among variables that are all trending in the same direction. There's less risk of that in our case since public and private technology markets are closely linked, but we should be wary regardless.</p>\n<p>We can do better by focusing less on the relationship between <em>level</em> of the Nasdaq and some other variable and more on the correlation between <em>changes</em> in the respective metrics.</p>\n<p><strong>The key question:</strong> how does a change (up or down) in public technology valuations affect the prices of private financings, and how quickly?</p>\n<p>Some good ol' regression analysis can answer this.</p>\n<p>Glossing over a bunch of detail:</p>\n<ul>\n<li>We can forecast future changes in private valuations and financings based on current changes in public tech valuations.</li>\n<li>We'll run one regression for each forecast horizon: concurrent (time zero) impact, one quarter out, two quarters out, etc.</li>\n<li>The coefficients of these regressions trace out the impact of the original movement in the Nasdaq on private prices and volume in later periods.</li>\n</ul>\n<h2 id=\"the-path-to-recovery\">The path to recovery</h2>\n<p>Hope you're still with me. Let's run those regressions and see what we get.</p>\n<p>We'll focus on downward movements in the Nasdaq. This is how a 1% decline in the Nasdaq affects private valuations and deal flow over future quarters:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/12/valuations_deals-1.png\" alt=\"valuations_deals-1\" loading=\"lazy\"></p>\n<p>Private valuations gradually decline after a drop in the Nasdaq:</p>\n<ul>\n<li><strong>Prices drop continuously for four quarters</strong></li>\n<li>At the trough, private valuations fall ~2.25% lower for every 1% loss in the Nasdaq</li>\n<li><strong>Venture valuations take 10 quarters to recover</strong></li>\n</ul>\n<p>Movements in the Nasdaq reliably forecast venture deal activity too, which drops and rebounds faster than prices:</p>\n<ul>\n<li>Deal activity bottoms in the third quarter after impact</li>\n<li>Overall deal count rises back to its original level by the 8th quarter</li>\n</ul>\n<h2 id=\"down-for-a-down-round\">Down for a down round?</h2>\n<p>This masks a lot of underlying variance between the different segments of the venture ecosystem. Starting with valuations, let's explore how the shape of the recovery varies by stage:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/12/nasdaq_valuation3-2.png\" alt=\"nasdaq_valuation3-2\" loading=\"lazy\"></p>\n<p><strong>Valuation dynamics depend on stage:</strong> Early stage valuations drop 1-1.5% for every 1% decline in the Nasdaq, while growth and late stage valuations decline 2-2.25%.</p>\n<p><strong>Note: these aren't exact estimates.</strong> Uncertainty grows as we look further out from initial impact, so don't pay much attention to the numbers at the 12-quarter mark. It's the shape and length of the recovery that matters most.</p>\n<p>With some back-of-the-envelope math, we can estimate both the magnitude and the length of the current downturn:</p>\n<ul>\n<li>The peak to trough decline in the Nasdaq this past year was about 25%, <strong>implying a ~25-35% haircut to early stage valuations and a ~50-55% cut in growth and later stage valuations</strong></li>\n<li>That might sound extreme, but the sudden explosion of late stage valuations these past few years was itself quite unusual. It's not implausible that prices could fall as dramatically as they rose</li>\n</ul>\n<p>In fact, the correction is already well underway:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/12/nasdaq_valuation4.png\" alt=\"nasdaq_valuation4\" loading=\"lazy\"></p>\n<p>As predicted, late stage valuations drop much more than the Nasdaq, while early stage valuations move roughly in line. Prices have fallen faster than my forecast, but the magnitudes are on point.</p>\n<p>Timing the bottom based on my regression here is a bit tricky, as the market began its decline in Q1 2022 and mostly ran its course by Q3 2022. If we use the midpoint of Q2 2022 as the &quot;start&quot; of the venture recession:</p>\n<ul>\n<li><strong>Private valuations should bottom in Q2 2023</strong></li>\n<li>I'm hesitant to forecast the heydays of 2021 ever returning, but if they did, it'd happen around Q4 2024. <em>I wouldn't hold your breath though</em></li>\n</ul>\n<h2 id=\"coming-to-terms\">Coming to terms</h2>\n<p>Again, let's focus on a 1% decline in the Nasdaq:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/12/nasdaq_deals3.png\" alt=\"nasdaq_deals3\" loading=\"lazy\"></p>\n<p>Financings follow an interesting &quot;sine wave&quot; recovery in the aftermath of a plunge in the Nasdaq. Again we see more severe impact in the later stages: The quarterly volume of Seeds and As drops by 0.75-1% for each 1% decline in the Nasdaq. Late stage deals sink 2%.</p>\n<p>One ray of hope â€“ financing activity seems to come back <em>stronger</em> after a venture recession.</p>\n<p>Pulling out that scribbled envelope again, these numbers suggest <strong>early stage deal activity will drop 20-25%; growth and late stage deal volumes should slide about 50%.</strong></p>\n<p>Again, the data bears this out:</p>\n<p><img src=\"__GHOST_URL__/content/images/2022/12/nasdaq_deals4.png\" alt=\"nasdaq_deals4\" loading=\"lazy\"></p>\n<p>Remember, the venture deals should only take about a year to hit their low, so activity should stabilize in or around Q1 2023, notably ahead of valuations.</p>\n<p>As I've said, these are rough estimates. All the typical caveats apply: &quot;this time could be different,&quot; etc.</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>The bubble burst, but the pain won't last forever.</p>\n<p>The historical relationship between the public and private tech markets lets us trace out the likely path of the venture recovery.</p>\n<p>The first year is the hardest. Prices drop precipitously, in many cases, much further than their public tech comparables.</p>\n<p>Things get better from there, with deal activity back on track after another year or so. Prices, however, remain depressed a little while longer.</p>\n<p>All-in-all, it's a three year odyssey from start to finish.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: Old Valuations Die Hard\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"6398b3ccfec7d1542d1d2da6","plaintext":"Public technology valuations have crashed.\n\nA worsening economic outlook and tight monetary policy sent tech stocks through\nthe floor.\n\nHowever, private valuations are slower to adjust.\n\nPrivate valuations lag public valuations, often by a substantial amount and for\na long time.\n\nAs we all lick our wounds during this venture downturn, many are asking: when\nwill it all end?\n\nThe answer? About three years.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Public-private partnership\nPrivate valuations rose dramatically over the last decade. But so did the\nNasdaq:\n\n\n\nIt's remarkable how well the two track one another.\n\nIn a sense, the growth of public tech valuations seems to pin down the rise of\nprivate valuations, defining a trend to which private valuations always tend to\nreturn. It's clear that venture investors use public valuations to justify\nprivate ones.\n\nOne feature immediately stands out â€“ private valuations are much more volatile\nthan public valuations, particularly at the later stages:\n\n * This is to be expected â€“ it's not the same companies that are fundraising\n   each quarter, so we'd naturally expect the prices to jump around a bit\n * Meanwhile, the composition of the Nasdaq doesn't change much quarter to\n   quarter, so as an aggregate it's much more stable\n\nIf we throw each one on its own axis, the relationship is even more obvious:\n\n\n\nAcross stages, private valuations move one-for-one with public valuations.\n\n * Seed valuations have grown somewhat slower than the Nasdaq, moving 0.5% for\n   every 1% move in the tech index\n * Series A, B, and C valuations have moved one-for-one\n * Series D+ valuations have grown 1.3% each point of growth in the Nasdaq\n\nWe can replicate the same analysis for private venture activity. The\nrelationship is not as tight:\n\n\n\nDeal activity is more or less related to public tech valuations, depending on\nstage. Here too we see much more volatility in the private realm than the\npublic, again, for understandable reasons.\n\n\n\nIn general the slopes here are flatter than for valuations:\n\n * Seed deals have grown at roughly the same pace as public valuations\n * For other stages, growth has lagged public tech valuations â€“ growing at about\n   half the pace\n\nLevel with me\nThough intuitive, these comparisons are not rigorous. It's too easy to find\nspurious relationships among variables that are all trending in the same\ndirection. There's less risk of that in our case since public and private\ntechnology markets are closely linked, but we should be wary regardless.\n\nWe can do better by focusing less on the relationship between level of the\nNasdaq and some other variable and more on the correlation between changes in\nthe respective metrics.\n\nThe key question: how does a change (up or down) in public technology valuations\naffect the prices of private financings, and how quickly?\n\nSome good ol' regression analysis can answer this.\n\nGlossing over a bunch of detail:\n\n * We can forecast future changes in private valuations and financings based on\n   current changes in public tech valuations.\n * We'll run one regression for each forecast horizon: concurrent (time zero)\n   impact, one quarter out, two quarters out, etc.\n * The coefficients of these regressions trace out the impact of the original\n   movement in the Nasdaq on private prices and volume in later periods.\n\nThe path to recovery\nHope you're still with me. Let's run those regressions and see what we get.\n\nWe'll focus on downward movements in the Nasdaq. This is how a 1% decline in the\nNasdaq affects private valuations and deal flow over future quarters:\n\n\n\nPrivate valuations gradually decline after a drop in the Nasdaq:\n\n * Prices drop continuously for four quarters\n * At the trough, private valuations fall ~2.25% lower for every 1% loss in the\n   Nasdaq\n * Venture valuations take 10 quarters to recover\n\nMovements in the Nasdaq reliably forecast venture deal activity too, which drops\nand rebounds faster than prices:\n\n * Deal activity bottoms in the third quarter after impact\n * Overall deal count rises back to its original level by the 8th quarter\n\nDown for a down round?\nThis masks a lot of underlying variance between the different segments of the\nventure ecosystem. Starting with valuations, let's explore how the shape of the\nrecovery varies by stage:\n\n\n\nValuation dynamics depend on stage: Early stage valuations drop 1-1.5% for every\n1% decline in the Nasdaq, while growth and late stage valuations decline\n2-2.25%.\n\nNote: these aren't exact estimates. Uncertainty grows as we look further out\nfrom initial impact, so don't pay much attention to the numbers at the\n12-quarter mark. It's the shape and length of the recovery that matters most.\n\nWith some back-of-the-envelope math, we can estimate both the magnitude and the\nlength of the current downturn:\n\n * The peak to trough decline in the Nasdaq this past year was about 25%, \n   implying a ~25-35% haircut to early stage valuations and a ~50-55% cut in\n   growth and later stage valuations\n * That might sound extreme, but the sudden explosion of late stage valuations\n   these past few years was itself quite unusual. It's not implausible that\n   prices could fall as dramatically as they rose\n\nIn fact, the correction is already well underway:\n\n\n\nAs predicted, late stage valuations drop much more than the Nasdaq, while early\nstage valuations move roughly in line. Prices have fallen faster than my\nforecast, but the magnitudes are on point.\n\nTiming the bottom based on my regression here is a bit tricky, as the market\nbegan its decline in Q1 2022 and mostly ran its course by Q3 2022. If we use the\nmidpoint of Q2 2022 as the \"start\" of the venture recession:\n\n * Private valuations should bottom in Q2 2023\n * I'm hesitant to forecast the heydays of 2021 ever returning, but if they did,\n   it'd happen around Q4 2024. I wouldn't hold your breath though\n\nComing to terms\nAgain, let's focus on a 1% decline in the Nasdaq:\n\n\n\nFinancings follow an interesting \"sine wave\" recovery in the aftermath of a\nplunge in the Nasdaq. Again we see more severe impact in the later stages: The\nquarterly volume of Seeds and As drops by 0.75-1% for each 1% decline in the\nNasdaq. Late stage deals sink 2%.\n\nOne ray of hope â€“ financing activity seems to come back stronger after a venture\nrecession.\n\nPulling out that scribbled envelope again, these numbers suggest early stage\ndeal activity will drop 20-25%; growth and late stage deal volumes should slide\nabout 50%.\n\nAgain, the data bears this out:\n\n\n\nRemember, the venture deals should only take about a year to hit their low, so\nactivity should stabilize in or around Q1 2023, notably ahead of valuations.\n\nAs I've said, these are rough estimates. All the typical caveats apply: \"this\ntime could be different,\" etc.\n\nConclusion\nThe bubble burst, but the pain won't last forever.\n\nThe historical relationship between the public and private tech markets lets us\ntrace out the likely path of the venture recovery.\n\nThe first year is the hardest. Prices drop precipitously, in many cases, much\nfurther than their public tech comparables.\n\nThings get better from there, with deal activity back on track after another\nyear or so. Prices, however, remain depressed a little while longer.\n\nAll-in-all, it's a three year odyssey from start to finish.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2022/12/header-6.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2022-12-13T17:18:04.000Z","updated_at":"2022-12-13T22:23:35.000Z","published_at":"2022-12-13T17:47:55.000Z","custom_excerpt":"Private valuations substantially lag public tech valuations","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"63bf0c12fec7d1542d1d2dfb","uuid":"e3f345da-65f0-46e4-864c-8fc4aaa21d7c","title":"We Don't Have Nearly Enough Startups","slug":"not-enough-startups","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Where did the explosive growth in venture activity come from?\\n\\nTwo possible drivers â€“ investor exuberance and founder fervor:\\n- Did investors become substantially more favorable toward private startups, and founders merely reacted to that increased interest?\\n- Or, did we all become much more entrepreneurial, and investors simply provided the capital in response?\\n\\nIn other words, was it demand, supply, or some combination of the two?\\n\\nHere's a hint: we don't have nearly enough startups.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: We Don't Have Nearly Enough Startups\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## Narrative violation\\n\\nMeasured in either financing activity or equity valuations, the venture-backed startup ecosystem has grown *a lot*:\\n\\n![deals_valuation](__GHOST_URL__/content/images/2023/01/deals_valuation.png)\\n\\nThere's a common narrative out there that the bonanza in venture-backed startups over the last decade reflects growing entrepreneurialism, the ease of starting a company, etc.\\n\\nI question this story.\\n\\nOnly Seed rounds grew significantly faster than real GDP over the last decade. Series A's also outpaced GDP but not by much. The rest are on or even below trend, especially after the recent slowdown:\\n![deals_gdp](__GHOST_URL__/content/images/2023/01/deals_gdp.png)\\n*Note: Q4 2022 US GDP not yet available as of publication*\\n\\nThe long-run trend of real GDP reflects supply-side factors, i.e. the fundamental productive capacity of the economy. The similar trends at the later stages imply the \\\"fundamental productive capacity\\\" of the venture ecosystem, i.e. its ability to generate real, meaningful businesses, is growing no faster than the rest of the economy.\\n\\nThe U.S. economy isn't growing quickly by the way â€“ 2% real growth year-over-year is a good benchmark. So if the trends line up, the venture world can't be growing much faster than 2% in real terms, that is, excluding the impact of [valuation inflation](https://whoisnnamdi.com/its-valuations/) that I discussed a few essays ago.\\n\\n> At the later-stage, valuation inflation explains nearly *all* growth in venture funding over the last eleven years â€“ [It's Valuations (Almost) All the Way Down](https://whoisnnamdi.com/its-valuations/)\\n\\nAn equally if not more plausible story is that demand-side factors drove the explosion in venture activity over the last decade. Growing investor interest and appetite for private startups could explain much of the growth. \\n\\nHowever, merely staring at trend lines doesn't yield much insight. It's like a tough marketing attribution exercise â€“ the growth attributable to either demand or supply is ambiguous.\\n\\nWe should resolve this ambiguity:\\n- As participants in this ecosystem, we should want to see it grow in real terms rather than merely nominal ones\\n- In other words, we'd be much better off if venture activity reflects growing capacity and ability of entrepreneurs to start successful new businesses\\n- If in fact the growth in venture activity is merely a reflection of investors needing increasingly obscure and speculative places to park their money, we have a big problem on our hands. The shell game will implode:\\n> Valuations can't rise forever, so over the long-run venture capital can't grow much faster than the number of ventures themselves â€“ [It's Valuations (Almost) All the Way Down](https://whoisnnamdi.com/its-valuations/)\\n\\n## Economics 101: Supply and Demand\\n\\nFirst, let's quickly review Economics 101.\\n\\nHere's the classic supply and demand chart. Supply and demand together determine equilibrium prices (Y-axis) and quantities (X-axis). Importantly, demand is downward sloping (you want more stuff the cheaper it is) and supply is upward sloping (you produce more stuff when you can sell it for more):\\n![supply_demand](__GHOST_URL__/content/images/2023/01/supply_demand.png)\\n\\nIn this model, two forces can move markets. Demand can shift (for reasons that don't have to do with prices themselves), which causes prices and quantities to move in the **same** direction (up when demand increases, down when demand decreases):\\n![supply_demand2](__GHOST_URL__/content/images/2023/01/supply_demand2.png)\\n\\nOr, supply can change (again, for reasons other than price), in which case prices and quantities move in **opposite** directions (price move *against* supply, quantities move *with* supply):\\n![supply_demand3](__GHOST_URL__/content/images/2023/01/supply_demand3.png)\\n\\nIn simple terms, when everyone wants the same thing and wants it *really badly*, the price tends to go up and more of that item gets bought and sold. When everyone wants to produce and sell the same thing and wants to do so *really badly*, they compete against one another, driving prices down to accommodate the increased activity.\\n\\nIn venture terms, when investor demand for startups rises, valuations increase and more deals get inked. When entrepreneurial supply expands, valuations decline and more deals get done.\\n\\n## VC is trendy\\n\\nVenture deals and valuations have both grown over time, so it's all demand-driven right?\\n![deals_valuation2](__GHOST_URL__/content/images/2023/01/deals_valuation2.png)\\n\\nNot so fast.\\n\\nWhile it's tempting to end the analysis here, for reasons I'll skip over, you can't simply compare two trending metrics and assume they're correlated. The relationship could easily be [spurious](https://www.tylervigen.com/spurious-correlations), and we don't want that. By the magical transitive property, anything we concluded based on that relationship would be spurious as well. Cool math.\\n\\nThe key is to \\\"de-trend\\\" the data first. We need to remove the long-run trend and then compare *deviations* from that trend.\\n\\nIgnoring the details, here's what that looks like (data normalized and smoothed slightly to remove noise):\\n![deals_valuation3](__GHOST_URL__/content/images/2023/01/deals_valuation3.png)\\n\\n*Lo' and behold:* deal flow and valuations fluctuate together around their respective trends.\\n\\nOK, maybe that's not *always* true, but it's nearly always true. Early stage is the exception to the rule.\\n\\nSeed financings were negatively correlated with valuations before roughly 2017:\\n- When deal flow increased, valuations plummeted, and vice versa\\n- **This smells like supply to me** â€“ there was only so much investor demand, so when more startups came to market, they competed, and prices tended to fall, benefitting investors. When the supply of startups contracted, prices rose as investor battled over the few remaining deals\\n\\nSeries A rounds used to be positively linked to valuations, but they've de-correlated over the last few years:\\n- Pre-2019, Series A deal flow and valuations tended to move in the same direction\\n- **Sounds like demand to me** â€“ startup supply was constrained, so investor sentiment drove the market, moving prices up as they grew more eager and down as they soured on the venture ecosystem\\n\\nAcross growth and later stages, deal flow and valuations are unambiguously positively related, moving almost in perfect unison for the last decade:\\n- **Demand clearly wins it** â€“ late stage supply is badly constrained, so investor demand is the prime mover. Their manic and depressive episodes move the market accordingly\\n\\nSome of these relationships have shifted over time, so let's visualize that with rolling three-year correlations for each stage:\\n![deals_valuation4](__GHOST_URL__/content/images/2023/01/deals_valuation4.png)\\n\\nThis is my qualitative narrative in quantitative terms:\\n- The Seed stage flipped being negatively correlated to positively (supply â†’ demand)\\n- Series A de-correlated to effectively zero (demand â†’ â“)\\n- Series B and later deal flow and valuations have always been strongly positively related (demand all day baby)\\n\\n## Channel attribution\\n\\nThis is the best evidence I've seen to date for the demand-side hypothesis.\\n\\nThe scorecard so far suggests demand reigns:\\n- Investors are the primary driver of fluctuations in venture activity and equity prices around their long-run trend\\n- Yes, more deals are getting done (so by definition more startups are getting funded), but that appears to be a function of increasingly desperate investors rather than increasingly bold and enabled founders\\n\\nIn other words, the supply of startup equity is badly constrained:\\n> The venture ecosystem is supply-constrained â€“ there isn't nearly enough startup equity out there to satisfy investor demand.\\n> \\n> Additional capital drives opportunistic company formation at the Seed stage. However, the additional capital doesn't improve survival to the later stages â€“ it simply drives prices up for the remaining companies â€“ [It's Valuations (Almost) All the Way Down](https://whoisnnamdi.com/its-valuations/)\\n\\nAs a reminder, our evidence for this is the positive link between de-trended deal activity and valuations. That's a nice trick, but it only tells us at each point in time whether movements in demand or supply dominated. I want to explain the *entire last decade or so* of venture history in terms of supply and demand channels.\\n\\nYes, yes, history is not bi-causal, hammer looking for a nail, etc, but how about one more magic trick to close things out?\\n\\n***Warning: armchair econometrics ahead!***\\n\\nLet's stretch our simple supply and demand model to the absolute extreme:\\n- Remember, a positive relationship between deal flow and valuations suggests a change in demand, while a negative or inverse relationship suggests shifting supply\\n- So, we could simply attribute each quarter of venture activity to either demand or supply demand based on whether deal flow and valuations move in similar or opposing directions during the quarter\\n- We can then cumulate the respective contributions of demand and supply to the growth of the venture ecosystem over time\\n\\nHere's what that looks like for venture deal flow since early 2010. Demand is red, supply is blue, sugar is sweet, and so are you:\\n![deals_supply](__GHOST_URL__/content/images/2023/01/deals_supply.png)\\n\\nThat's a lot of red out there:\\n- The demand channel drove most of the growth in venture activity in nearly every stage other than Seed, where its relative contribution is closer to 50/50\\n- Early stage supply contributed positively to deal flow from 2010 to about 2015 but then stagnated\\n- Supply has never been a meaningful contributor at the growth and late stage and even seems to have *contracted* in certain cases\\n\\nEt tu, valuations?\\n\\n![deals_supply2](__GHOST_URL__/content/images/2023/01/deals_supply2.png)\\n\\nThe story isn't much different for valuations, except perhaps with some signs flipped:\\n- Here again, investor demand was the main driver, pushing prices higher in every stage\\n- The increase in early stage supply in the early 2010s relieved some price pressure, but this eventually receded\\n- The effect of late stage supply on valuations is somewhat noisy, but by the end of the sample those supply constraints appear to have driven prices higher, on balance\\n\\nIn case I haven't sufficiently caveated already: *this is extremely unscientific.* No Nobels will be awarded for this work (your subscription is enough reward for me, awwww), but it does serve as coarse, suggestive evidence that demand is, or at least has been, king in venture over the last decade.\\n\\n## There's only so many startups to go around\\n\\nSo, what have we learned?\\n\\nTo the degree founders are starting more venture-backable companies, it's largely driven by the cold, rational calculus that investors are much more eager to buy up equity in private companies today than they used to be.\\n\\nThis explains much of the growth in the venture ecosystem over the last decade: more deals get done and those deals are more expensive because of surging investor demand. This has been great for founders.\\n\\nHowever, this will be painful for investors, since [companies rarely grow into their valuations](https://whoisnnamdi.com/grow-valuation/):\\n> Most often, companies don't grow fast enough to compensate for rising valuation multiples. Instead, high valuations today imply slower value appreciation in the future, i.e. lower returns.\\n> â€¦\\n> Investors like to think companies will grow into their valuations, but more often than not, the stock simply underperforms â€“ [Companies Rarely Grow Into Their Valuations](https://whoisnnamdi.com/grow-valuation/)\\n\\nMeanwhile, the supply of startup equity remains constrained. Rather than potential founders becoming more eager to start companies for \\\"fundamental\\\" reasons, entrepreneurs are reacting to investor sentiment. While there's been some growth in supply at the earliest stages, the fundamentals haven't necessarily improved much, which is why late stage deal flow hasn't grown any faster than U.S. GDP.\\n\\nI'll repeat what I said earlier â€“ **we'll all be much better off if more people start companies for good, wholesome reasons that don't have anything to do with valuations.**\\n\\nThere was a time where the notion of handing millions of dollars to an extremely young company sounded crazy, and anyone willing to do so extracted a significant ownership stake for taking on that risk. Founders got diluted, badly.\\n\\nWe're well past that now. [Dilution has fallen in every stage since 2010:](https://whoisnnamdi.com/its-valuations/)\\n![dilution](__GHOST_URL__/content/images/2023/01/dilution.png)\\n\\nWe have more startups, but:\\n- It's largely been a reaction to attractive valuations and reduced dilution that founders must endure to raise capital\\n- Past the seed stage, it's not at all obvious that founders are fundamentally better equipped to build successful companies today vs. a decade ago\\n\\nThe demand side got a bit ahead of itself. It's time for the supply side to catch up.\\n\\nWe don't have *nearly* enough startups.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: We Don't Have Nearly Enough Startups\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>Where did the explosive growth in venture activity come from?</p>\n<p>Two possible drivers â€“ investor exuberance and founder fervor:</p>\n<ul>\n<li>Did investors become substantially more favorable toward private startups, and founders merely reacted to that increased interest?</li>\n<li>Or, did we all become much more entrepreneurial, and investors simply provided the capital in response?</li>\n</ul>\n<p>In other words, was it demand, supply, or some combination of the two?</p>\n<p>Here's a hint: we don't have nearly enough startups.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: We Don't Have Nearly Enough Startups\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"narrative-violation\">Narrative violation</h2>\n<p>Measured in either financing activity or equity valuations, the venture-backed startup ecosystem has grown <em>a lot</em>:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/01/deals_valuation.png\" alt=\"deals_valuation\" loading=\"lazy\"></p>\n<p>There's a common narrative out there that the bonanza in venture-backed startups over the last decade reflects growing entrepreneurialism, the ease of starting a company, etc.</p>\n<p>I question this story.</p>\n<p>Only Seed rounds grew significantly faster than real GDP over the last decade. Series A's also outpaced GDP but not by much. The rest are on or even below trend, especially after the recent slowdown:<br>\n<img src=\"__GHOST_URL__/content/images/2023/01/deals_gdp.png\" alt=\"deals_gdp\" loading=\"lazy\"><br>\n<em>Note: Q4 2022 US GDP not yet available as of publication</em></p>\n<p>The long-run trend of real GDP reflects supply-side factors, i.e. the fundamental productive capacity of the economy. The similar trends at the later stages imply the &quot;fundamental productive capacity&quot; of the venture ecosystem, i.e. its ability to generate real, meaningful businesses, is growing no faster than the rest of the economy.</p>\n<p>The U.S. economy isn't growing quickly by the way â€“ 2% real growth year-over-year is a good benchmark. So if the trends line up, the venture world can't be growing much faster than 2% in real terms, that is, excluding the impact of <a href=\"https://whoisnnamdi.com/its-valuations/\">valuation inflation</a> that I discussed a few essays ago.</p>\n<blockquote>\n<p>At the later-stage, valuation inflation explains nearly <em>all</em> growth in venture funding over the last eleven years â€“ <a href=\"https://whoisnnamdi.com/its-valuations/\">It's Valuations (Almost) All the Way Down</a></p>\n</blockquote>\n<p>An equally if not more plausible story is that demand-side factors drove the explosion in venture activity over the last decade. Growing investor interest and appetite for private startups could explain much of the growth.</p>\n<p>However, merely staring at trend lines doesn't yield much insight. It's like a tough marketing attribution exercise â€“ the growth attributable to either demand or supply is ambiguous.</p>\n<p>We should resolve this ambiguity:</p>\n<ul>\n<li>As participants in this ecosystem, we should want to see it grow in real terms rather than merely nominal ones</li>\n<li>In other words, we'd be much better off if venture activity reflects growing capacity and ability of entrepreneurs to start successful new businesses</li>\n<li>If in fact the growth in venture activity is merely a reflection of investors needing increasingly obscure and speculative places to park their money, we have a big problem on our hands. The shell game will implode:</li>\n</ul>\n<blockquote>\n<p>Valuations can't rise forever, so over the long-run venture capital can't grow much faster than the number of ventures themselves â€“ <a href=\"https://whoisnnamdi.com/its-valuations/\">It's Valuations (Almost) All the Way Down</a></p>\n</blockquote>\n<h2 id=\"economics-101-supply-and-demand\">Economics 101: Supply and Demand</h2>\n<p>First, let's quickly review Economics 101.</p>\n<p>Here's the classic supply and demand chart. Supply and demand together determine equilibrium prices (Y-axis) and quantities (X-axis). Importantly, demand is downward sloping (you want more stuff the cheaper it is) and supply is upward sloping (you produce more stuff when you can sell it for more):<br>\n<img src=\"__GHOST_URL__/content/images/2023/01/supply_demand.png\" alt=\"supply_demand\" loading=\"lazy\"></p>\n<p>In this model, two forces can move markets. Demand can shift (for reasons that don't have to do with prices themselves), which causes prices and quantities to move in the <strong>same</strong> direction (up when demand increases, down when demand decreases):<br>\n<img src=\"__GHOST_URL__/content/images/2023/01/supply_demand2.png\" alt=\"supply_demand2\" loading=\"lazy\"></p>\n<p>Or, supply can change (again, for reasons other than price), in which case prices and quantities move in <strong>opposite</strong> directions (price move <em>against</em> supply, quantities move <em>with</em> supply):<br>\n<img src=\"__GHOST_URL__/content/images/2023/01/supply_demand3.png\" alt=\"supply_demand3\" loading=\"lazy\"></p>\n<p>In simple terms, when everyone wants the same thing and wants it <em>really badly</em>, the price tends to go up and more of that item gets bought and sold. When everyone wants to produce and sell the same thing and wants to do so <em>really badly</em>, they compete against one another, driving prices down to accommodate the increased activity.</p>\n<p>In venture terms, when investor demand for startups rises, valuations increase and more deals get inked. When entrepreneurial supply expands, valuations decline and more deals get done.</p>\n<h2 id=\"vc-is-trendy\">VC is trendy</h2>\n<p>Venture deals and valuations have both grown over time, so it's all demand-driven right?<br>\n<img src=\"__GHOST_URL__/content/images/2023/01/deals_valuation2.png\" alt=\"deals_valuation2\" loading=\"lazy\"></p>\n<p>Not so fast.</p>\n<p>While it's tempting to end the analysis here, for reasons I'll skip over, you can't simply compare two trending metrics and assume they're correlated. The relationship could easily be <a href=\"https://www.tylervigen.com/spurious-correlations\">spurious</a>, and we don't want that. By the magical transitive property, anything we concluded based on that relationship would be spurious as well. Cool math.</p>\n<p>The key is to &quot;de-trend&quot; the data first. We need to remove the long-run trend and then compare <em>deviations</em> from that trend.</p>\n<p>Ignoring the details, here's what that looks like (data normalized and smoothed slightly to remove noise):<br>\n<img src=\"__GHOST_URL__/content/images/2023/01/deals_valuation3.png\" alt=\"deals_valuation3\" loading=\"lazy\"></p>\n<p><em>Lo' and behold:</em> deal flow and valuations fluctuate together around their respective trends.</p>\n<p>OK, maybe that's not <em>always</em> true, but it's nearly always true. Early stage is the exception to the rule.</p>\n<p>Seed financings were negatively correlated with valuations before roughly 2017:</p>\n<ul>\n<li>When deal flow increased, valuations plummeted, and vice versa</li>\n<li><strong>This smells like supply to me</strong> â€“ there was only so much investor demand, so when more startups came to market, they competed, and prices tended to fall, benefitting investors. When the supply of startups contracted, prices rose as investor battled over the few remaining deals</li>\n</ul>\n<p>Series A rounds used to be positively linked to valuations, but they've de-correlated over the last few years:</p>\n<ul>\n<li>Pre-2019, Series A deal flow and valuations tended to move in the same direction</li>\n<li><strong>Sounds like demand to me</strong> â€“ startup supply was constrained, so investor sentiment drove the market, moving prices up as they grew more eager and down as they soured on the venture ecosystem</li>\n</ul>\n<p>Across growth and later stages, deal flow and valuations are unambiguously positively related, moving almost in perfect unison for the last decade:</p>\n<ul>\n<li><strong>Demand clearly wins it</strong> â€“ late stage supply is badly constrained, so investor demand is the prime mover. Their manic and depressive episodes move the market accordingly</li>\n</ul>\n<p>Some of these relationships have shifted over time, so let's visualize that with rolling three-year correlations for each stage:<br>\n<img src=\"__GHOST_URL__/content/images/2023/01/deals_valuation4.png\" alt=\"deals_valuation4\" loading=\"lazy\"></p>\n<p>This is my qualitative narrative in quantitative terms:</p>\n<ul>\n<li>The Seed stage flipped being negatively correlated to positively (supply â†’ demand)</li>\n<li>Series A de-correlated to effectively zero (demand â†’ â“)</li>\n<li>Series B and later deal flow and valuations have always been strongly positively related (demand all day baby)</li>\n</ul>\n<h2 id=\"channel-attribution\">Channel attribution</h2>\n<p>This is the best evidence I've seen to date for the demand-side hypothesis.</p>\n<p>The scorecard so far suggests demand reigns:</p>\n<ul>\n<li>Investors are the primary driver of fluctuations in venture activity and equity prices around their long-run trend</li>\n<li>Yes, more deals are getting done (so by definition more startups are getting funded), but that appears to be a function of increasingly desperate investors rather than increasingly bold and enabled founders</li>\n</ul>\n<p>In other words, the supply of startup equity is badly constrained:</p>\n<blockquote>\n<p>The venture ecosystem is supply-constrained â€“ there isn't nearly enough startup equity out there to satisfy investor demand.</p>\n<p>Additional capital drives opportunistic company formation at the Seed stage. However, the additional capital doesn't improve survival to the later stages â€“ it simply drives prices up for the remaining companies â€“ <a href=\"https://whoisnnamdi.com/its-valuations/\">It's Valuations (Almost) All the Way Down</a></p>\n</blockquote>\n<p>As a reminder, our evidence for this is the positive link between de-trended deal activity and valuations. That's a nice trick, but it only tells us at each point in time whether movements in demand or supply dominated. I want to explain the <em>entire last decade or so</em> of venture history in terms of supply and demand channels.</p>\n<p>Yes, yes, history is not bi-causal, hammer looking for a nail, etc, but how about one more magic trick to close things out?</p>\n<p><em><strong>Warning: armchair econometrics ahead!</strong></em></p>\n<p>Let's stretch our simple supply and demand model to the absolute extreme:</p>\n<ul>\n<li>Remember, a positive relationship between deal flow and valuations suggests a change in demand, while a negative or inverse relationship suggests shifting supply</li>\n<li>So, we could simply attribute each quarter of venture activity to either demand or supply demand based on whether deal flow and valuations move in similar or opposing directions during the quarter</li>\n<li>We can then cumulate the respective contributions of demand and supply to the growth of the venture ecosystem over time</li>\n</ul>\n<p>Here's what that looks like for venture deal flow since early 2010. Demand is red, supply is blue, sugar is sweet, and so are you:<br>\n<img src=\"__GHOST_URL__/content/images/2023/01/deals_supply.png\" alt=\"deals_supply\" loading=\"lazy\"></p>\n<p>That's a lot of red out there:</p>\n<ul>\n<li>The demand channel drove most of the growth in venture activity in nearly every stage other than Seed, where its relative contribution is closer to 50/50</li>\n<li>Early stage supply contributed positively to deal flow from 2010 to about 2015 but then stagnated</li>\n<li>Supply has never been a meaningful contributor at the growth and late stage and even seems to have <em>contracted</em> in certain cases</li>\n</ul>\n<p>Et tu, valuations?</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/01/deals_supply2.png\" alt=\"deals_supply2\" loading=\"lazy\"></p>\n<p>The story isn't much different for valuations, except perhaps with some signs flipped:</p>\n<ul>\n<li>Here again, investor demand was the main driver, pushing prices higher in every stage</li>\n<li>The increase in early stage supply in the early 2010s relieved some price pressure, but this eventually receded</li>\n<li>The effect of late stage supply on valuations is somewhat noisy, but by the end of the sample those supply constraints appear to have driven prices higher, on balance</li>\n</ul>\n<p>In case I haven't sufficiently caveated already: <em>this is extremely unscientific.</em> No Nobels will be awarded for this work (your subscription is enough reward for me, awwww), but it does serve as coarse, suggestive evidence that demand is, or at least has been, king in venture over the last decade.</p>\n<h2 id=\"theres-only-so-many-startups-to-go-around\">There's only so many startups to go around</h2>\n<p>So, what have we learned?</p>\n<p>To the degree founders are starting more venture-backable companies, it's largely driven by the cold, rational calculus that investors are much more eager to buy up equity in private companies today than they used to be.</p>\n<p>This explains much of the growth in the venture ecosystem over the last decade: more deals get done and those deals are more expensive because of surging investor demand. This has been great for founders.</p>\n<p>However, this will be painful for investors, since <a href=\"https://whoisnnamdi.com/grow-valuation/\">companies rarely grow into their valuations</a>:</p>\n<blockquote>\n<p>Most often, companies don't grow fast enough to compensate for rising valuation multiples. Instead, high valuations today imply slower value appreciation in the future, i.e. lower returns.<br>\nâ€¦<br>\nInvestors like to think companies will grow into their valuations, but more often than not, the stock simply underperforms â€“ <a href=\"https://whoisnnamdi.com/grow-valuation/\">Companies Rarely Grow Into Their Valuations</a></p>\n</blockquote>\n<p>Meanwhile, the supply of startup equity remains constrained. Rather than potential founders becoming more eager to start companies for &quot;fundamental&quot; reasons, entrepreneurs are reacting to investor sentiment. While there's been some growth in supply at the earliest stages, the fundamentals haven't necessarily improved much, which is why late stage deal flow hasn't grown any faster than U.S. GDP.</p>\n<p>I'll repeat what I said earlier â€“ <strong>we'll all be much better off if more people start companies for good, wholesome reasons that don't have anything to do with valuations.</strong></p>\n<p>There was a time where the notion of handing millions of dollars to an extremely young company sounded crazy, and anyone willing to do so extracted a significant ownership stake for taking on that risk. Founders got diluted, badly.</p>\n<p>We're well past that now. <a href=\"https://whoisnnamdi.com/its-valuations/\">Dilution has fallen in every stage since 2010:</a><br>\n<img src=\"__GHOST_URL__/content/images/2023/01/dilution.png\" alt=\"dilution\" loading=\"lazy\"></p>\n<p>We have more startups, but:</p>\n<ul>\n<li>It's largely been a reaction to attractive valuations and reduced dilution that founders must endure to raise capital</li>\n<li>Past the seed stage, it's not at all obvious that founders are fundamentally better equipped to build successful companies today vs. a decade ago</li>\n</ul>\n<p>The demand side got a bit ahead of itself. It's time for the supply side to catch up.</p>\n<p>We don't have <em>nearly</em> enough startups.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: We Don't Have Nearly Enough Startups\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"63bf0c12fec7d1542d1d2dfb","plaintext":"Where did the explosive growth in venture activity come from?\n\nTwo possible drivers â€“ investor exuberance and founder fervor:\n\n * Did investors become substantially more favorable toward private startups,\n   and founders merely reacted to that increased interest?\n * Or, did we all become much more entrepreneurial, and investors simply\n   provided the capital in response?\n\nIn other words, was it demand, supply, or some combination of the two?\n\nHere's a hint: we don't have nearly enough startups.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Narrative violation\nMeasured in either financing activity or equity valuations, the venture-backed\nstartup ecosystem has grown a lot:\n\n\n\nThere's a common narrative out there that the bonanza in venture-backed startups\nover the last decade reflects growing entrepreneurialism, the ease of starting a\ncompany, etc.\n\nI question this story.\n\nOnly Seed rounds grew significantly faster than real GDP over the last decade.\nSeries A's also outpaced GDP but not by much. The rest are on or even below\ntrend, especially after the recent slowdown:\n\nNote: Q4 2022 US GDP not yet available as of publication\n\nThe long-run trend of real GDP reflects supply-side factors, i.e. the\nfundamental productive capacity of the economy. The similar trends at the later\nstages imply the \"fundamental productive capacity\" of the venture ecosystem,\ni.e. its ability to generate real, meaningful businesses, is growing no faster\nthan the rest of the economy.\n\nThe U.S. economy isn't growing quickly by the way â€“ 2% real growth\nyear-over-year is a good benchmark. So if the trends line up, the venture world\ncan't be growing much faster than 2% in real terms, that is, excluding the\nimpact of valuation inflation [https://whoisnnamdi.com/its-valuations/] that I\ndiscussed a few essays ago.\n\n> At the later-stage, valuation inflation explains nearly all growth in venture\nfunding over the last eleven years â€“ It's Valuations (Almost) All the Way Down\n[https://whoisnnamdi.com/its-valuations/]\n\n\nAn equally if not more plausible story is that demand-side factors drove the\nexplosion in venture activity over the last decade. Growing investor interest\nand appetite for private startups could explain much of the growth.\n\nHowever, merely staring at trend lines doesn't yield much insight. It's like a\ntough marketing attribution exercise â€“ the growth attributable to either demand\nor supply is ambiguous.\n\nWe should resolve this ambiguity:\n\n * As participants in this ecosystem, we should want to see it grow in real\n   terms rather than merely nominal ones\n * In other words, we'd be much better off if venture activity reflects growing\n   capacity and ability of entrepreneurs to start successful new businesses\n * If in fact the growth in venture activity is merely a reflection of investors\n   needing increasingly obscure and speculative places to park their money, we\n   have a big problem on our hands. The shell game will implode:\n\n> Valuations can't rise forever, so over the long-run venture capital can't grow\nmuch faster than the number of ventures themselves â€“ It's Valuations (Almost)\nAll the Way Down [https://whoisnnamdi.com/its-valuations/]\n\n\nEconomics 101: Supply and Demand\nFirst, let's quickly review Economics 101.\n\nHere's the classic supply and demand chart. Supply and demand together determine\nequilibrium prices (Y-axis) and quantities (X-axis). Importantly, demand is\ndownward sloping (you want more stuff the cheaper it is) and supply is upward\nsloping (you produce more stuff when you can sell it for more):\n\n\nIn this model, two forces can move markets. Demand can shift (for reasons that\ndon't have to do with prices themselves), which causes prices and quantities to\nmove in the same direction (up when demand increases, down when demand\ndecreases):\n\n\nOr, supply can change (again, for reasons other than price), in which case\nprices and quantities move in opposite directions (price move against supply,\nquantities move with supply):\n\n\nIn simple terms, when everyone wants the same thing and wants it really badly,\nthe price tends to go up and more of that item gets bought and sold. When\neveryone wants to produce and sell the same thing and wants to do so really\nbadly, they compete against one another, driving prices down to accommodate the\nincreased activity.\n\nIn venture terms, when investor demand for startups rises, valuations increase\nand more deals get inked. When entrepreneurial supply expands, valuations\ndecline and more deals get done.\n\nVC is trendy\nVenture deals and valuations have both grown over time, so it's all\ndemand-driven right?\n\n\nNot so fast.\n\nWhile it's tempting to end the analysis here, for reasons I'll skip over, you\ncan't simply compare two trending metrics and assume they're correlated. The\nrelationship could easily be spurious\n[https://www.tylervigen.com/spurious-correlations], and we don't want that. By\nthe magical transitive property, anything we concluded based on that\nrelationship would be spurious as well. Cool math.\n\nThe key is to \"de-trend\" the data first. We need to remove the long-run trend\nand then compare deviations from that trend.\n\nIgnoring the details, here's what that looks like (data normalized and smoothed\nslightly to remove noise):\n\n\nLo' and behold: deal flow and valuations fluctuate together around their\nrespective trends.\n\nOK, maybe that's not always true, but it's nearly always true. Early stage is\nthe exception to the rule.\n\nSeed financings were negatively correlated with valuations before roughly 2017:\n\n * When deal flow increased, valuations plummeted, and vice versa\n * This smells like supply to me â€“ there was only so much investor demand, so\n   when more startups came to market, they competed, and prices tended to fall,\n   benefitting investors. When the supply of startups contracted, prices rose as\n   investor battled over the few remaining deals\n\nSeries A rounds used to be positively linked to valuations, but they've\nde-correlated over the last few years:\n\n * Pre-2019, Series A deal flow and valuations tended to move in the same\n   direction\n * Sounds like demand to me â€“ startup supply was constrained, so investor\n   sentiment drove the market, moving prices up as they grew more eager and down\n   as they soured on the venture ecosystem\n\nAcross growth and later stages, deal flow and valuations are unambiguously\npositively related, moving almost in perfect unison for the last decade:\n\n * Demand clearly wins it â€“ late stage supply is badly constrained, so investor\n   demand is the prime mover. Their manic and depressive episodes move the\n   market accordingly\n\nSome of these relationships have shifted over time, so let's visualize that with\nrolling three-year correlations for each stage:\n\n\nThis is my qualitative narrative in quantitative terms:\n\n * The Seed stage flipped being negatively correlated to positively (supply â†’\n   demand)\n * Series A de-correlated to effectively zero (demand â†’ â“)\n * Series B and later deal flow and valuations have always been strongly\n   positively related (demand all day baby)\n\nChannel attribution\nThis is the best evidence I've seen to date for the demand-side hypothesis.\n\nThe scorecard so far suggests demand reigns:\n\n * Investors are the primary driver of fluctuations in venture activity and\n   equity prices around their long-run trend\n * Yes, more deals are getting done (so by definition more startups are getting\n   funded), but that appears to be a function of increasingly desperate\n   investors rather than increasingly bold and enabled founders\n\nIn other words, the supply of startup equity is badly constrained:\n\n> The venture ecosystem is supply-constrained â€“ there isn't nearly enough startup\nequity out there to satisfy investor demand.\n\nAdditional capital drives opportunistic company formation at the Seed stage.\nHowever, the additional capital doesn't improve survival to the later stages â€“\nit simply drives prices up for the remaining companies â€“ It's Valuations\n(Almost) All the Way Down [https://whoisnnamdi.com/its-valuations/]\n\n\nAs a reminder, our evidence for this is the positive link between de-trended\ndeal activity and valuations. That's a nice trick, but it only tells us at each\npoint in time whether movements in demand or supply dominated. I want to explain\nthe entire last decade or so of venture history in terms of supply and demand\nchannels.\n\nYes, yes, history is not bi-causal, hammer looking for a nail, etc, but how\nabout one more magic trick to close things out?\n\nWarning: armchair econometrics ahead!\n\nLet's stretch our simple supply and demand model to the absolute extreme:\n\n * Remember, a positive relationship between deal flow and valuations suggests a\n   change in demand, while a negative or inverse relationship suggests shifting\n   supply\n * So, we could simply attribute each quarter of venture activity to either\n   demand or supply demand based on whether deal flow and valuations move in\n   similar or opposing directions during the quarter\n * We can then cumulate the respective contributions of demand and supply to the\n   growth of the venture ecosystem over time\n\nHere's what that looks like for venture deal flow since early 2010. Demand is\nred, supply is blue, sugar is sweet, and so are you:\n\n\nThat's a lot of red out there:\n\n * The demand channel drove most of the growth in venture activity in nearly\n   every stage other than Seed, where its relative contribution is closer to\n   50/50\n * Early stage supply contributed positively to deal flow from 2010 to about\n   2015 but then stagnated\n * Supply has never been a meaningful contributor at the growth and late stage\n   and even seems to have contracted in certain cases\n\nEt tu, valuations?\n\n\n\nThe story isn't much different for valuations, except perhaps with some signs\nflipped:\n\n * Here again, investor demand was the main driver, pushing prices higher in\n   every stage\n * The increase in early stage supply in the early 2010s relieved some price\n   pressure, but this eventually receded\n * The effect of late stage supply on valuations is somewhat noisy, but by the\n   end of the sample those supply constraints appear to have driven prices\n   higher, on balance\n\nIn case I haven't sufficiently caveated already: this is extremely unscientific. \nNo Nobels will be awarded for this work (your subscription is enough reward for\nme, awwww), but it does serve as coarse, suggestive evidence that demand is, or\nat least has been, king in venture over the last decade.\n\nThere's only so many startups to go around\nSo, what have we learned?\n\nTo the degree founders are starting more venture-backable companies, it's\nlargely driven by the cold, rational calculus that investors are much more eager\nto buy up equity in private companies today than they used to be.\n\nThis explains much of the growth in the venture ecosystem over the last decade:\nmore deals get done and those deals are more expensive because of surging\ninvestor demand. This has been great for founders.\n\nHowever, this will be painful for investors, since companies rarely grow into\ntheir valuations [https://whoisnnamdi.com/grow-valuation/]:\n\n> Most often, companies don't grow fast enough to compensate for rising valuation\nmultiples. Instead, high valuations today imply slower value appreciation in the\nfuture, i.e. lower returns.\nâ€¦\nInvestors like to think companies will grow into their valuations, but more\noften than not, the stock simply underperforms â€“ Companies Rarely Grow Into\nTheir Valuations [https://whoisnnamdi.com/grow-valuation/]\n\n\nMeanwhile, the supply of startup equity remains constrained. Rather than\npotential founders becoming more eager to start companies for \"fundamental\"\nreasons, entrepreneurs are reacting to investor sentiment. While there's been\nsome growth in supply at the earliest stages, the fundamentals haven't\nnecessarily improved much, which is why late stage deal flow hasn't grown any\nfaster than U.S. GDP.\n\nI'll repeat what I said earlier â€“ we'll all be much better off if more people\nstart companies for good, wholesome reasons that don't have anything to do with\nvaluations.\n\nThere was a time where the notion of handing millions of dollars to an extremely\nyoung company sounded crazy, and anyone willing to do so extracted a significant\nownership stake for taking on that risk. Founders got diluted, badly.\n\nWe're well past that now. Dilution has fallen in every stage since 2010:\n[https://whoisnnamdi.com/its-valuations/]\n\n\nWe have more startups, but:\n\n * It's largely been a reaction to attractive valuations and reduced dilution\n   that founders must endure to raise capital\n * Past the seed stage, it's not at all obvious that founders are fundamentally\n   better equipped to build successful companies today vs. a decade ago\n\nThe demand side got a bit ahead of itself. It's time for the supply side to\ncatch up.\n\nWe don't have nearly enough startups.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2023/01/header.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2023-01-11T19:20:50.000Z","updated_at":"2023-02-23T09:52:05.000Z","published_at":"2023-01-11T19:38:41.000Z","custom_excerpt":"Where did the explosive growth in venture activity come from?","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"645bc999fec7d1542d1d2e4e","uuid":"b434e7f1-a613-4072-aa76-f514d25c32b7","title":"Don't Discount Interest Rates","slug":"discount-rates","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Interest rates are the Federal Reserve's go-to treatment for an ailing, lethargic economy.\\n\\nBut the Fed's meds have a curious side effect â€“ **they're a shot of adrenaline for the venture market.**\\n\\nLow interest rates jolt the heart rate of venture capital, driving a manic frenzy of transactions and funding for startups.\\n\\nOn the other hand, high interest rates kill the vibe, causing deals to dwindle and prices to plummet.\\n\\nYou don't need a PhD to understand that. What's less obvious is exactly how large of an effect we're talking about here.\\n\\nTurns out â€“ it's huge. For a 25 basis point or 0.25% change in the one-year Treasury yield:\\n* Deal activity adjusts ~10%\\n* Valuations move ~25%\\n* Capital invested shifts by ~30%\\n\\nThese effects are persistent, meaning we're always dealing with the aftermath of past interest rate shocks. It's the (highly oxygenated) air we breathe.\\n\\nIt's Jay Powell's world. We're just living in it.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Don't Discount Interest Rates\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## Interest rates are interesting\\n\\nThe Federal Reserve's zero interest rate policy (ZIRP) has come to an end:\\n\\n![int_rate](__GHOST_URL__/content/images/2023/05/int_rate.png)\\n\\nIt's no secret interest rates affect tech valuations:\\n> During the last few years low interest rates and money printing [led to a funding bubble in private technology](https://blog.eladgil.com/p/changing-times-or-why-is-every-layoff) â€“ Elad Gil, [Startup Decoupling & Reckoning](https://blog.eladgil.com/p/startup-decoupling-and-reckoning)\\n\\nSo the corporate finance logic goes, companies are worth the [present value](https://www.investopedia.com/terms/n/npv.asp) of their cash flows, and the \\\"discount rate\\\" one applies to those cash flows is the key input â€“ lower rates mean higher valuations, and vice versa.\\n\\nAs much as investors like to ignore it, there's an obvious connection between valuations and interest rates:\\n\\n![Pasted-image-20230321221512](__GHOST_URL__/content/images/2023/05/Pasted-image-20230321221512.png)\\nSource: [Redpoint Ventures](https://docs.google.com/presentation/d/1Hyn4FWHSNRrWJeddi0BMEQIMlmXy2SNj50T8jJcrKbw/edit#slide=id.g11953bc14ff_2_116)\\n\\n![Pasted-image-20230413194408](__GHOST_URL__/content/images/2023/05/Pasted-image-20230413194408.png)\\nSource: [Bessemer Venture Partners](https://www.bvp.com/atlas/state-of-the-cloud-2023)\\n\\nThese charts reference publicly traded companies. However, I've never seen anyone quantify the sensitivity of *private* tech valuations. In other words, \\\"if interest rates fall by X percentage points, venture valuations rise by Y%,\\\" and vice versa:\\n* Merely knowing Y is a positive number is only marginally helpful; **we should really want to know exactly how large Y is!**\\n* Also, to what extent are tech valuations driven by interest rates and to what extent by other factors?\\n* Oh, and while we're at it â€“ is the effect instantaneous? Or does the effect take time to percolate given the inefficiencies of the venture market?\\n\\nMeanwhile, interest rates could affect more than just valuations. Recall [a few essays ago](https://whoisnnamdi.com/its-valuations/) I introduced the following framework for thinking about the individual \\\"components\\\" of a dollar of venture capital funding â€“ deals, valuation, and dilution:\\n\\n![decomposition_excalidraw](__GHOST_URL__/content/images/2023/05/decomposition_excalidraw.png)\\n\\nInterest rates could affect all these variables, and we should want to know how:\\n* **Deals:** Low interest rates drive speculation, encouraging \\\"betting\\\" on startups. High rates send the gamblers home.\\n* **Dilution:** Low rates create a more founder-friendly environment, reducing the ownership founders give up. Vice versa for high rates.\\n* **Funding:** To the degree investors \\\"search for yield,\\\" startups attract capital when other investment opportunities are scarce.\\n\\nSo I set out to find some answers.\\n\\nA quick note before we proceed. It turns out, the Federal Reserve is mostly predictable, so most of its moves are already \\\"priced in\\\" by the market. I instead focus on *unexpected* and unanticipated shifts in interest rates that market actors haven't yet reacted to. To account for these expectations, I control for other macro variables like U.S. GDP, inflation, and the Nasdaq index.\\n\\nFor example, if the one-year Treasury rate declines by 0.5%, the market may have only expected a 0.25% decline based on current economic conditions, leaving 0.25% unexpected:\\n\\n![int_rate_excalidraw](__GHOST_URL__/content/images/2023/05/int_rate_excalidraw.png)\\n\\nOK â€“ that's the most complicated concept you need to understand. With that out of the way, let's jump to the results.\\n\\n## Long and variable lags\\n\\nThe following charts trace the effect of a 0.25 percentage point or 25 basis point (bps) cut in the [one year U.S. Treasury yield](https://fred.stlouisfed.org/series/DGS1) on various measures of venture activity, up to twelve quarters / three years out:\\n- 25 bps is the typical increment the Federal Reserve uses.\\n- I focus solely on the \\\"surprise\\\" component. The \\\"total\\\" change in rates would have been even larger.\\n\\nThe effects are quite strong, especially on deal flow and valuations:\\n\\n![lp_1](__GHOST_URL__/content/images/2023/05/lp_1.png)\\n\\n- Deal activity rises for six quarters before receding back down to zero after ten quarters. Peak impact is substantial â€“ **about 10% more deals are getting done six quarters out**\\n- Valuations take longer to peak but the size of the effect is more extreme; **seven quarters out valuations are up ~25%**, falling back to their original level after three years\\n- **Dilution is more muted**, remaining largely flat initially but then dipping ~5% after a few quarters without ever recovering with the three year window\\n\\nCritically, interest rates affect deal flow, not just valuations:\\n- It's not simply the same set of companies raising money at higher prices. **More companies get funded in the first place as well.** \\n- As I found in [Old Valuations Die Hard](https://whoisnnamdi.com/old-valuations/), deal flow reacts quickly, while valuations take longer to adjust but see a larger impact overall.\\n\\nThis has pros and cons:\\n- More deals means more entrepreneurs get to take a swing.\\n- Conversely, however, when interest rates rise, founders not only accept lower valuations â€“ *some founders don't get funded at all*.\\n\\nLet's drive that point home by visualizing the same analysis but for an increase in interest rates rather than a decrease:\\n\\n![lp_1n](__GHOST_URL__/content/images/2023/05/lp_1n.png)\\n\\nRising rates squeeze the life out of venture capital. Per the logic I outlined in my [last essay](https://whoisnnamdi.com/not-enough-startups/), we know this reflects reduced investor demand, since quantities and prices drift together:\\n> Demand can shiftâ€¦ which causes prices and quantities to move in the **same** direction (up when demand increases, down when demand decreases â€“ [We Don't Have Nearly Enough Startups](https://whoisnnamdi.com/not-enough-startups/)\\n\\nThe (multiplicative) aggregation of these individual sub-effects yields the overall effect on venture funding:\\n\\n![lp_2](__GHOST_URL__/content/images/2023/05/lp_2.png)\\n\\n- Funding builds up for almost two years, peaks at nearly 30% above baseline, then falls back to zero by about 11 quarters out.\\n\\nWith rising rates, funding falls just over 20%:\\n\\n![lp_2n](__GHOST_URL__/content/images/2023/05/lp_2n.png)\\n\\nPerhaps it's obvious, but these are extremely large effects!\\n\\nThankfully, interest rates don't move up or down enough to regularly generate these sorts of reactions. A 10 bps / 0.1% surprise is much more common than a 25 bps / 0.25% one.\\n\\nNotably, the effects aren't permanent; As interest rates reset, so does the venture market.\\n\\n## A brief history of time value\\n\\nThe current \\\"era\\\" of venture capital has been deeply influenced by this strange interest rate regime, having evolved entirely within it.\\n\\nWith our previous estimates, we can run a backwards-looking \\\"attribution analysis\\\", explaining the ups and downs of venture in terms of interest rates. In other words, we can break down the recent history of venture activity into the portions influenced by interest rates vs. other factors.\\n\\nFirst up: deal activity. In red I plot an index of the overall growth in venture deal activity since early 2014, averaged across funding stages, and in blue I plot the portion attributable to unexpected interest rate shocks:\\n\\n![hd_deals](__GHOST_URL__/content/images/2023/05/hd_deals.png)\\n\\n- **Interest rates explain nearly the entire explosion of venture deal activity over the last few years.**\\n\\nOf all the charts, this is the one I probably spent the most time staring at and double-checking the numbers, as it's just so striking.\\n\\nLet's do the same for valuations (notice the bigger scale here):\\n\\n![hd_valuation](__GHOST_URL__/content/images/2023/05/hd_valuation.png)\\n\\n- The higher rates of the 2018 era pushed down valuations, but the effect reversed as rates fell heading into 2020. **Interest rates on their own doubled valuations.**\\n- However, the valuation inflation was so extreme that interest rates can't explain it all, implying more had to be going on.\\n\\n**This is important:** that interest rates explain nearly all deal flow but only part of the rise in valuations implies that demand for startups has outstripped supply of startups. With nowhere else to go, that excess demand spills over into prices. You can't invest in startups that don't yet exist, so you compete for the few that do, bidding up prices. This is the same conclusion I reached in a prior essay:\\n> â€¦ the valuation inflation we've seen \\\"comes from\\\" the incredible growth in demand and lack of supply of startup equity â€“ [It's Valuations (Almost) All the Way Down](https://whoisnnamdi.com/its-valuations/)\\n\\nHere's dilution:\\n\\n![hd_dilution](__GHOST_URL__/content/images/2023/05/hd_dilution.png)\\n\\n- Dilution is noisier, complicating interpretation. The way to read this chart is that interest rates increased dilution through 2019 but afterward exerted downward pressure on dilution.\\n- From 2019 through 2022, interest rates drove dilution down 20%, which is exactly how much they declined in total, therefore **accounting for nearly all of the fall.**\\n\\nPutting it all together, here's what our little attribution methodology has to say about the effect of interest rates on overall VC funding:\\n\\n![hd_capital](__GHOST_URL__/content/images/2023/05/hd_capital.png)\\n\\n- From 2014 through the top of the market in 2021, **interest rates accounted for a 200% (!!!) expansion in venture funding.**\\n- As with valuations, the run up in venture funding was too extreme to be completely explained by interest rates.\\n\\n## Don't discount interest rates\\n\\n> Monetary actions affect economic conditions only after a lag that is both long and variable â€“ Milton Friedman\\n\\nBefore concluding, I should mention some caveats to this analysis:\\n- First, **there aren't many examples of big interest rate moves over this period.** I may have overfit to the few meaningful changes in rates since the 2008 Financial Crisis.\\n- Second, **it's possible I haven't controlled for all the relevant variables.** For example, a lot happened during the pandemic that isn't fully captured by my choice of controls.\\n- Third, **I use the U.S. Treasury yield, i.e. the risk free rate, as my measure of interest rates**, which doesn't fit a high-risk asset class like venture capital. Unfortunately, no venture-specific analog exists.\\n- Fourth, and I'm repeating myself because it's important, **these are the effects of an unexpected shift in rates**, whereas most interest rate movement is expected by the market. If interest rates change by 50 basis points tomorrow, no more than half of that was in fact a \\\"surprise.\\\"\\n\\nCaveats aside, Friedman's proclamation appears to hold for venture capital â€“ it takes multiple years for interest rate effects to fully play out.\\n\\n**Even in the private markets, we're all Fed watchers now:** these interest rate effects are too large to ignore. In fact, interest rates are so impactful that they explain most of the mass hysteria of the last few years, both on the upside and the down.\\n\\nImportantly, **interest rates cannot forever move in one direction.** Over the years, they mean revert, making their impact temporary at best. Don't get too accustomed to any particular regime â€“ the new normal will always eventually look like the \\\"old normal.\\\"\\n\\nDon't discount interest rates.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: Don't Discount Interest Rates\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>Interest rates are the Federal Reserve's go-to treatment for an ailing, lethargic economy.</p>\n<p>But the Fed's meds have a curious side effect â€“ <strong>they're a shot of adrenaline for the venture market.</strong></p>\n<p>Low interest rates jolt the heart rate of venture capital, driving a manic frenzy of transactions and funding for startups.</p>\n<p>On the other hand, high interest rates kill the vibe, causing deals to dwindle and prices to plummet.</p>\n<p>You don't need a PhD to understand that. What's less obvious is exactly how large of an effect we're talking about here.</p>\n<p>Turns out â€“ it's huge. For a 25 basis point or 0.25% change in the one-year Treasury yield:</p>\n<ul>\n<li>Deal activity adjusts ~10%</li>\n<li>Valuations move ~25%</li>\n<li>Capital invested shifts by ~30%</li>\n</ul>\n<p>These effects are persistent, meaning we're always dealing with the aftermath of past interest rate shocks. It's the (highly oxygenated) air we breathe.</p>\n<p>It's Jay Powell's world. We're just living in it.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Don't Discount Interest Rates\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"interest-rates-are-interesting\">Interest rates are interesting</h2>\n<p>The Federal Reserve's zero interest rate policy (ZIRP) has come to an end:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/05/int_rate.png\" alt=\"int_rate\" loading=\"lazy\"></p>\n<p>It's no secret interest rates affect tech valuations:</p>\n<blockquote>\n<p>During the last few years low interest rates and money printing <a href=\"https://blog.eladgil.com/p/changing-times-or-why-is-every-layoff\">led to a funding bubble in private technology</a> â€“ Elad Gil, <a href=\"https://blog.eladgil.com/p/startup-decoupling-and-reckoning\">Startup Decoupling &amp; Reckoning</a></p>\n</blockquote>\n<p>So the corporate finance logic goes, companies are worth the <a href=\"https://www.investopedia.com/terms/n/npv.asp\">present value</a> of their cash flows, and the &quot;discount rate&quot; one applies to those cash flows is the key input â€“ lower rates mean higher valuations, and vice versa.</p>\n<p>As much as investors like to ignore it, there's an obvious connection between valuations and interest rates:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/05/Pasted-image-20230321221512.png\" alt=\"Pasted-image-20230321221512\" loading=\"lazy\"><br>\nSource: <a href=\"https://docs.google.com/presentation/d/1Hyn4FWHSNRrWJeddi0BMEQIMlmXy2SNj50T8jJcrKbw/edit#slide=id.g11953bc14ff_2_116\">Redpoint Ventures</a></p>\n<p><img src=\"__GHOST_URL__/content/images/2023/05/Pasted-image-20230413194408.png\" alt=\"Pasted-image-20230413194408\" loading=\"lazy\"><br>\nSource: <a href=\"https://www.bvp.com/atlas/state-of-the-cloud-2023\">Bessemer Venture Partners</a></p>\n<p>These charts reference publicly traded companies. However, I've never seen anyone quantify the sensitivity of <em>private</em> tech valuations. In other words, &quot;if interest rates fall by X percentage points, venture valuations rise by Y%,&quot; and vice versa:</p>\n<ul>\n<li>Merely knowing Y is a positive number is only marginally helpful; <strong>we should really want to know exactly how large Y is!</strong></li>\n<li>Also, to what extent are tech valuations driven by interest rates and to what extent by other factors?</li>\n<li>Oh, and while we're at it â€“ is the effect instantaneous? Or does the effect take time to percolate given the inefficiencies of the venture market?</li>\n</ul>\n<p>Meanwhile, interest rates could affect more than just valuations. Recall <a href=\"https://whoisnnamdi.com/its-valuations/\">a few essays ago</a> I introduced the following framework for thinking about the individual &quot;components&quot; of a dollar of venture capital funding â€“ deals, valuation, and dilution:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/05/decomposition_excalidraw.png\" alt=\"decomposition_excalidraw\" loading=\"lazy\"></p>\n<p>Interest rates could affect all these variables, and we should want to know how:</p>\n<ul>\n<li><strong>Deals:</strong> Low interest rates drive speculation, encouraging &quot;betting&quot; on startups. High rates send the gamblers home.</li>\n<li><strong>Dilution:</strong> Low rates create a more founder-friendly environment, reducing the ownership founders give up. Vice versa for high rates.</li>\n<li><strong>Funding:</strong> To the degree investors &quot;search for yield,&quot; startups attract capital when other investment opportunities are scarce.</li>\n</ul>\n<p>So I set out to find some answers.</p>\n<p>A quick note before we proceed. It turns out, the Federal Reserve is mostly predictable, so most of its moves are already &quot;priced in&quot; by the market. I instead focus on <em>unexpected</em> and unanticipated shifts in interest rates that market actors haven't yet reacted to. To account for these expectations, I control for other macro variables like U.S. GDP, inflation, and the Nasdaq index.</p>\n<p>For example, if the one-year Treasury rate declines by 0.5%, the market may have only expected a 0.25% decline based on current economic conditions, leaving 0.25% unexpected:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/05/int_rate_excalidraw.png\" alt=\"int_rate_excalidraw\" loading=\"lazy\"></p>\n<p>OK â€“ that's the most complicated concept you need to understand. With that out of the way, let's jump to the results.</p>\n<h2 id=\"long-and-variable-lags\">Long and variable lags</h2>\n<p>The following charts trace the effect of a 0.25 percentage point or 25 basis point (bps) cut in the <a href=\"https://fred.stlouisfed.org/series/DGS1\">one year U.S. Treasury yield</a> on various measures of venture activity, up to twelve quarters / three years out:</p>\n<ul>\n<li>25 bps is the typical increment the Federal Reserve uses.</li>\n<li>I focus solely on the &quot;surprise&quot; component. The &quot;total&quot; change in rates would have been even larger.</li>\n</ul>\n<p>The effects are quite strong, especially on deal flow and valuations:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/05/lp_1.png\" alt=\"lp_1\" loading=\"lazy\"></p>\n<ul>\n<li>Deal activity rises for six quarters before receding back down to zero after ten quarters. Peak impact is substantial â€“ <strong>about 10% more deals are getting done six quarters out</strong></li>\n<li>Valuations take longer to peak but the size of the effect is more extreme; <strong>seven quarters out valuations are up ~25%</strong>, falling back to their original level after three years</li>\n<li><strong>Dilution is more muted</strong>, remaining largely flat initially but then dipping ~5% after a few quarters without ever recovering with the three year window</li>\n</ul>\n<p>Critically, interest rates affect deal flow, not just valuations:</p>\n<ul>\n<li>It's not simply the same set of companies raising money at higher prices. <strong>More companies get funded in the first place as well.</strong></li>\n<li>As I found in <a href=\"https://whoisnnamdi.com/old-valuations/\">Old Valuations Die Hard</a>, deal flow reacts quickly, while valuations take longer to adjust but see a larger impact overall.</li>\n</ul>\n<p>This has pros and cons:</p>\n<ul>\n<li>More deals means more entrepreneurs get to take a swing.</li>\n<li>Conversely, however, when interest rates rise, founders not only accept lower valuations â€“ <em>some founders don't get funded at all</em>.</li>\n</ul>\n<p>Let's drive that point home by visualizing the same analysis but for an increase in interest rates rather than a decrease:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/05/lp_1n.png\" alt=\"lp_1n\" loading=\"lazy\"></p>\n<p>Rising rates squeeze the life out of venture capital. Per the logic I outlined in my <a href=\"https://whoisnnamdi.com/not-enough-startups/\">last essay</a>, we know this reflects reduced investor demand, since quantities and prices drift together:</p>\n<blockquote>\n<p>Demand can shiftâ€¦ which causes prices and quantities to move in the <strong>same</strong> direction (up when demand increases, down when demand decreases â€“ <a href=\"https://whoisnnamdi.com/not-enough-startups/\">We Don't Have Nearly Enough Startups</a></p>\n</blockquote>\n<p>The (multiplicative) aggregation of these individual sub-effects yields the overall effect on venture funding:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/05/lp_2.png\" alt=\"lp_2\" loading=\"lazy\"></p>\n<ul>\n<li>Funding builds up for almost two years, peaks at nearly 30% above baseline, then falls back to zero by about 11 quarters out.</li>\n</ul>\n<p>With rising rates, funding falls just over 20%:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/05/lp_2n.png\" alt=\"lp_2n\" loading=\"lazy\"></p>\n<p>Perhaps it's obvious, but these are extremely large effects!</p>\n<p>Thankfully, interest rates don't move up or down enough to regularly generate these sorts of reactions. A 10 bps / 0.1% surprise is much more common than a 25 bps / 0.25% one.</p>\n<p>Notably, the effects aren't permanent; As interest rates reset, so does the venture market.</p>\n<h2 id=\"a-brief-history-of-time-value\">A brief history of time value</h2>\n<p>The current &quot;era&quot; of venture capital has been deeply influenced by this strange interest rate regime, having evolved entirely within it.</p>\n<p>With our previous estimates, we can run a backwards-looking &quot;attribution analysis&quot;, explaining the ups and downs of venture in terms of interest rates. In other words, we can break down the recent history of venture activity into the portions influenced by interest rates vs. other factors.</p>\n<p>First up: deal activity. In red I plot an index of the overall growth in venture deal activity since early 2014, averaged across funding stages, and in blue I plot the portion attributable to unexpected interest rate shocks:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/05/hd_deals.png\" alt=\"hd_deals\" loading=\"lazy\"></p>\n<ul>\n<li><strong>Interest rates explain nearly the entire explosion of venture deal activity over the last few years.</strong></li>\n</ul>\n<p>Of all the charts, this is the one I probably spent the most time staring at and double-checking the numbers, as it's just so striking.</p>\n<p>Let's do the same for valuations (notice the bigger scale here):</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/05/hd_valuation.png\" alt=\"hd_valuation\" loading=\"lazy\"></p>\n<ul>\n<li>The higher rates of the 2018 era pushed down valuations, but the effect reversed as rates fell heading into 2020. <strong>Interest rates on their own doubled valuations.</strong></li>\n<li>However, the valuation inflation was so extreme that interest rates can't explain it all, implying more had to be going on.</li>\n</ul>\n<p><strong>This is important:</strong> that interest rates explain nearly all deal flow but only part of the rise in valuations implies that demand for startups has outstripped supply of startups. With nowhere else to go, that excess demand spills over into prices. You can't invest in startups that don't yet exist, so you compete for the few that do, bidding up prices. This is the same conclusion I reached in a prior essay:</p>\n<blockquote>\n<p>â€¦ the valuation inflation we've seen &quot;comes from&quot; the incredible growth in demand and lack of supply of startup equity â€“ <a href=\"https://whoisnnamdi.com/its-valuations/\">It's Valuations (Almost) All the Way Down</a></p>\n</blockquote>\n<p>Here's dilution:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/05/hd_dilution.png\" alt=\"hd_dilution\" loading=\"lazy\"></p>\n<ul>\n<li>Dilution is noisier, complicating interpretation. The way to read this chart is that interest rates increased dilution through 2019 but afterward exerted downward pressure on dilution.</li>\n<li>From 2019 through 2022, interest rates drove dilution down 20%, which is exactly how much they declined in total, therefore <strong>accounting for nearly all of the fall.</strong></li>\n</ul>\n<p>Putting it all together, here's what our little attribution methodology has to say about the effect of interest rates on overall VC funding:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/05/hd_capital.png\" alt=\"hd_capital\" loading=\"lazy\"></p>\n<ul>\n<li>From 2014 through the top of the market in 2021, <strong>interest rates accounted for a 200% (!!!) expansion in venture funding.</strong></li>\n<li>As with valuations, the run up in venture funding was too extreme to be completely explained by interest rates.</li>\n</ul>\n<h2 id=\"dont-discount-interest-rates\">Don't discount interest rates</h2>\n<blockquote>\n<p>Monetary actions affect economic conditions only after a lag that is both long and variable â€“ Milton Friedman</p>\n</blockquote>\n<p>Before concluding, I should mention some caveats to this analysis:</p>\n<ul>\n<li>First, <strong>there aren't many examples of big interest rate moves over this period.</strong> I may have overfit to the few meaningful changes in rates since the 2008 Financial Crisis.</li>\n<li>Second, <strong>it's possible I haven't controlled for all the relevant variables.</strong> For example, a lot happened during the pandemic that isn't fully captured by my choice of controls.</li>\n<li>Third, <strong>I use the U.S. Treasury yield, i.e. the risk free rate, as my measure of interest rates</strong>, which doesn't fit a high-risk asset class like venture capital. Unfortunately, no venture-specific analog exists.</li>\n<li>Fourth, and I'm repeating myself because it's important, <strong>these are the effects of an unexpected shift in rates</strong>, whereas most interest rate movement is expected by the market. If interest rates change by 50 basis points tomorrow, no more than half of that was in fact a &quot;surprise.&quot;</li>\n</ul>\n<p>Caveats aside, Friedman's proclamation appears to hold for venture capital â€“ it takes multiple years for interest rate effects to fully play out.</p>\n<p><strong>Even in the private markets, we're all Fed watchers now:</strong> these interest rate effects are too large to ignore. In fact, interest rates are so impactful that they explain most of the mass hysteria of the last few years, both on the upside and the down.</p>\n<p>Importantly, <strong>interest rates cannot forever move in one direction.</strong> Over the years, they mean revert, making their impact temporary at best. Don't get too accustomed to any particular regime â€“ the new normal will always eventually look like the &quot;old normal.&quot;</p>\n<p>Don't discount interest rates.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: Don't Discount Interest Rates\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"645bc999fec7d1542d1d2e4e","plaintext":"Interest rates are the Federal Reserve's go-to treatment for an ailing,\nlethargic economy.\n\nBut the Fed's meds have a curious side effect â€“ they're a shot of adrenaline for\nthe venture market.\n\nLow interest rates jolt the heart rate of venture capital, driving a manic\nfrenzy of transactions and funding for startups.\n\nOn the other hand, high interest rates kill the vibe, causing deals to dwindle\nand prices to plummet.\n\nYou don't need a PhD to understand that. What's less obvious is exactly how\nlarge of an effect we're talking about here.\n\nTurns out â€“ it's huge. For a 25 basis point or 0.25% change in the one-year\nTreasury yield:\n\n * Deal activity adjusts ~10%\n * Valuations move ~25%\n * Capital invested shifts by ~30%\n\nThese effects are persistent, meaning we're always dealing with the aftermath of\npast interest rate shocks. It's the (highly oxygenated) air we breathe.\n\nIt's Jay Powell's world. We're just living in it.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Interest rates are interesting\nThe Federal Reserve's zero interest rate policy (ZIRP) has come to an end:\n\n\n\nIt's no secret interest rates affect tech valuations:\n\n> During the last few years low interest rates and money printing led to a\nfunding\nbubble in private technology\n[https://blog.eladgil.com/p/changing-times-or-why-is-every-layoff] â€“ Elad Gil, \nStartup Decoupling & Reckoning\n[https://blog.eladgil.com/p/startup-decoupling-and-reckoning]\n\n\nSo the corporate finance logic goes, companies are worth the present value\n[https://www.investopedia.com/terms/n/npv.asp] of their cash flows, and the\n\"discount rate\" one applies to those cash flows is the key input â€“ lower rates\nmean higher valuations, and vice versa.\n\nAs much as investors like to ignore it, there's an obvious connection between\nvaluations and interest rates:\n\n\nSource: Redpoint Ventures\n[https://docs.google.com/presentation/d/1Hyn4FWHSNRrWJeddi0BMEQIMlmXy2SNj50T8jJcrKbw/edit#slide=id.g11953bc14ff_2_116]\n\n\nSource: Bessemer Venture Partners\n[https://www.bvp.com/atlas/state-of-the-cloud-2023]\n\nThese charts reference publicly traded companies. However, I've never seen\nanyone quantify the sensitivity of private tech valuations. In other words, \"if\ninterest rates fall by X percentage points, venture valuations rise by Y%,\" and\nvice versa:\n\n * Merely knowing Y is a positive number is only marginally helpful; we should\n   really want to know exactly how large Y is!\n * Also, to what extent are tech valuations driven by interest rates and to what\n   extent by other factors?\n * Oh, and while we're at it â€“ is the effect instantaneous? Or does the effect\n   take time to percolate given the inefficiencies of the venture market?\n\nMeanwhile, interest rates could affect more than just valuations. Recall a few\nessays ago [https://whoisnnamdi.com/its-valuations/] I introduced the following\nframework for thinking about the individual \"components\" of a dollar of venture\ncapital funding â€“ deals, valuation, and dilution:\n\n\n\nInterest rates could affect all these variables, and we should want to know how:\n\n * Deals: Low interest rates drive speculation, encouraging \"betting\" on\n   startups. High rates send the gamblers home.\n * Dilution: Low rates create a more founder-friendly environment, reducing the\n   ownership founders give up. Vice versa for high rates.\n * Funding: To the degree investors \"search for yield,\" startups attract capital\n   when other investment opportunities are scarce.\n\nSo I set out to find some answers.\n\nA quick note before we proceed. It turns out, the Federal Reserve is mostly\npredictable, so most of its moves are already \"priced in\" by the market. I\ninstead focus on unexpected and unanticipated shifts in interest rates that\nmarket actors haven't yet reacted to. To account for these expectations, I\ncontrol for other macro variables like U.S. GDP, inflation, and the Nasdaq\nindex.\n\nFor example, if the one-year Treasury rate declines by 0.5%, the market may have\nonly expected a 0.25% decline based on current economic conditions, leaving\n0.25% unexpected:\n\n\n\nOK â€“ that's the most complicated concept you need to understand. With that out\nof the way, let's jump to the results.\n\nLong and variable lags\nThe following charts trace the effect of a 0.25 percentage point or 25 basis\npoint (bps) cut in the one year U.S. Treasury yield\n[https://fred.stlouisfed.org/series/DGS1] on various measures of venture\nactivity, up to twelve quarters / three years out:\n\n * 25 bps is the typical increment the Federal Reserve uses.\n * I focus solely on the \"surprise\" component. The \"total\" change in rates would\n   have been even larger.\n\nThe effects are quite strong, especially on deal flow and valuations:\n\n\n\n * Deal activity rises for six quarters before receding back down to zero after\n   ten quarters. Peak impact is substantial â€“ about 10% more deals are getting\n   done six quarters out\n * Valuations take longer to peak but the size of the effect is more extreme; \n   seven quarters out valuations are up ~25%, falling back to their original\n   level after three years\n * Dilution is more muted, remaining largely flat initially but then dipping ~5%\n   after a few quarters without ever recovering with the three year window\n\nCritically, interest rates affect deal flow, not just valuations:\n\n * It's not simply the same set of companies raising money at higher prices. \n   More companies get funded in the first place as well.\n * As I found in Old Valuations Die Hard\n   [https://whoisnnamdi.com/old-valuations/], deal flow reacts quickly, while\n   valuations take longer to adjust but see a larger impact overall.\n\nThis has pros and cons:\n\n * More deals means more entrepreneurs get to take a swing.\n * Conversely, however, when interest rates rise, founders not only accept lower\n   valuations â€“ some founders don't get funded at all.\n\nLet's drive that point home by visualizing the same analysis but for an increase\nin interest rates rather than a decrease:\n\n\n\nRising rates squeeze the life out of venture capital. Per the logic I outlined\nin my last essay [https://whoisnnamdi.com/not-enough-startups/], we know this\nreflects reduced investor demand, since quantities and prices drift together:\n\n> Demand can shiftâ€¦ which causes prices and quantities to move in the same \ndirection (up when demand increases, down when demand decreases â€“ We Don't Have\nNearly Enough Startups [https://whoisnnamdi.com/not-enough-startups/]\n\n\nThe (multiplicative) aggregation of these individual sub-effects yields the\noverall effect on venture funding:\n\n\n\n * Funding builds up for almost two years, peaks at nearly 30% above baseline,\n   then falls back to zero by about 11 quarters out.\n\nWith rising rates, funding falls just over 20%:\n\n\n\nPerhaps it's obvious, but these are extremely large effects!\n\nThankfully, interest rates don't move up or down enough to regularly generate\nthese sorts of reactions. A 10 bps / 0.1% surprise is much more common than a 25\nbps / 0.25% one.\n\nNotably, the effects aren't permanent; As interest rates reset, so does the\nventure market.\n\nA brief history of time value\nThe current \"era\" of venture capital has been deeply influenced by this strange\ninterest rate regime, having evolved entirely within it.\n\nWith our previous estimates, we can run a backwards-looking \"attribution\nanalysis\", explaining the ups and downs of venture in terms of interest rates.\nIn other words, we can break down the recent history of venture activity into\nthe portions influenced by interest rates vs. other factors.\n\nFirst up: deal activity. In red I plot an index of the overall growth in venture\ndeal activity since early 2014, averaged across funding stages, and in blue I\nplot the portion attributable to unexpected interest rate shocks:\n\n\n\n * Interest rates explain nearly the entire explosion of venture deal activity\n   over the last few years.\n\nOf all the charts, this is the one I probably spent the most time staring at and\ndouble-checking the numbers, as it's just so striking.\n\nLet's do the same for valuations (notice the bigger scale here):\n\n\n\n * The higher rates of the 2018 era pushed down valuations, but the effect\n   reversed as rates fell heading into 2020. Interest rates on their own doubled\n   valuations.\n * However, the valuation inflation was so extreme that interest rates can't\n   explain it all, implying more had to be going on.\n\nThis is important: that interest rates explain nearly all deal flow but only\npart of the rise in valuations implies that demand for startups has outstripped\nsupply of startups. With nowhere else to go, that excess demand spills over into\nprices. You can't invest in startups that don't yet exist, so you compete for\nthe few that do, bidding up prices. This is the same conclusion I reached in a\nprior essay:\n\n> â€¦ the valuation inflation we've seen \"comes from\" the incredible growth in\ndemand and lack of supply of startup equity â€“ It's Valuations (Almost) All the\nWay Down [https://whoisnnamdi.com/its-valuations/]\n\n\nHere's dilution:\n\n\n\n * Dilution is noisier, complicating interpretation. The way to read this chart\n   is that interest rates increased dilution through 2019 but afterward exerted\n   downward pressure on dilution.\n * From 2019 through 2022, interest rates drove dilution down 20%, which is\n   exactly how much they declined in total, therefore accounting for nearly all\n   of the fall.\n\nPutting it all together, here's what our little attribution methodology has to\nsay about the effect of interest rates on overall VC funding:\n\n\n\n * From 2014 through the top of the market in 2021, interest rates accounted for\n   a 200% (!!!) expansion in venture funding.\n * As with valuations, the run up in venture funding was too extreme to be\n   completely explained by interest rates.\n\nDon't discount interest rates\n> Monetary actions affect economic conditions only after a lag that is both long\nand variable â€“ Milton Friedman\n\n\nBefore concluding, I should mention some caveats to this analysis:\n\n * First, there aren't many examples of big interest rate moves over this\n   period. I may have overfit to the few meaningful changes in rates since the\n   2008 Financial Crisis.\n * Second, it's possible I haven't controlled for all the relevant variables. \n   For example, a lot happened during the pandemic that isn't fully captured by\n   my choice of controls.\n * Third, I use the U.S. Treasury yield, i.e. the risk free rate, as my measure\n   of interest rates, which doesn't fit a high-risk asset class like venture\n   capital. Unfortunately, no venture-specific analog exists.\n * Fourth, and I'm repeating myself because it's important, these are the\n   effects of an unexpected shift in rates, whereas most interest rate movement\n   is expected by the market. If interest rates change by 50 basis points\n   tomorrow, no more than half of that was in fact a \"surprise.\"\n\nCaveats aside, Friedman's proclamation appears to hold for venture capital â€“ it\ntakes multiple years for interest rate effects to fully play out.\n\nEven in the private markets, we're all Fed watchers now: these interest rate\neffects are too large to ignore. In fact, interest rates are so impactful that\nthey explain most of the mass hysteria of the last few years, both on the upside\nand the down.\n\nImportantly, interest rates cannot forever move in one direction. Over the\nyears, they mean revert, making their impact temporary at best. Don't get too\naccustomed to any particular regime â€“ the new normal will always eventually look\nlike the \"old normal.\"\n\nDon't discount interest rates.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2023/05/header.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2023-05-10T16:43:05.000Z","updated_at":"2023-05-10T17:08:03.000Z","published_at":"2023-05-10T16:59:24.000Z","custom_excerpt":"It's Jay Powell's world. We're just living in it.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"6489f030fec7d1542d1d2ea9","uuid":"6f39ddba-56bc-448e-9b8a-04a0377f8326","title":"The Shadow Price of Venture Capital","slug":"shadow-price","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Venture valuations have fallen off a cliff, but they are still too high.\\n\\nValuations rise and fall with the volume of dollars invested in startups according to a stable ratio: for every one percent change in funding, valuations move two-thirds of a percent.\\n\\nBut since peaking in late 2021, valuations have only fallen 0.4% for every 1% drop in funding. This pricing \\\"error\\\" has accumulated: **today's valuations are 60% higher than youâ€™d expect for the amount of capital invested.**\\n\\nIn other words, the \\\"shadow price\\\" of venture capital is a lot lower than what we're seeing in announced transactions these days. Never before have valuations and funding diverged so meaningfully from their long-run equilibrium, for so long.\\n\\nWhat does it all mean?\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: The Shadow Price of Venture Capital\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## A 3-for-2 special\\n\\nValuations and capital invested in venture have both grown substantially since 2010:\\n\\n![val_cap](__GHOST_URL__/content/images/2023/06/val_cap.png)\\n\\nInterestingly, they trend together. As one rises, the other does too. Same in the other direction.\\n\\nIt's not a perfect relationship, but there's clearly something tying them together.\\n\\nIn fact, you can predict average valuations from the capital invested each quarter. The below chart plots actual valuations over time against what we'd predict based on capital deployment â€“ a simple regression of valuations on funding:\\n\\n![val_pred](__GHOST_URL__/content/images/2023/06/val_pred.png)\\n\\n**Capital invested predicts the average valuation of deals done each quarter.**\\n\\nMost of the time, the \\\"errors\\\" of this capital-based prediction are small. Further, these deviations typically correct themselves within a quarter or two.\\n\\nIn this sense, **venture valuations are a function of capital flows.** More capital drives valuations ever higher, in a fairly predictable fashion. There's an equilibrium, a balance between the two.\\n\\nThey don't grow at the same rate, however. For every 1% increase in funding, valuations rise about 0.66% or two-thirds of a percent. If you like clean whole numbers, the ratio is about 3:2.\\n\\nMost of the increased funding goes to rising prices rather than more individual investments. This mirrors points I've made previously:\\n> \\\"the valuation inflation we've seen \\\"comes from\\\" the incredible growth in demand and lack of supply of startup equity\\\"\\n> â€¦\\n> \\\"Additional capital drives opportunistic company formation at the Seed stage. However, the additional capital doesn't improveÂ _survival_Â to the later stages â€“ it simply drives prices up for the remaining companies\\\" â€“ [It's Valuations (Almost) All the Way Down](https://whoisnnamdi.com/its-valuations/)\\n\\n## Price check, please?\\n\\nEconomists have a term I think is relevant â€“ **shadow price** â€“ or, the price of something that either isn't typically traded in the market or for which accurate pricing is hard to come by. For example:\\n- The price of an illicit good (drugs, contraband of various sorts, etc)\\n- In certain economies like Argentina, the shadow or \\\"black market\\\" price for exchanging the local currency for a foreign currency like the U.S. dollar, which differs from the \\\"official\\\" rate.\\n\\nWhy is this relevant to venture capital?\\n\\nWell, because so many venture transactions *don't* happen. Most startups fundraise only once in a while. Founders delay fundraising if they can't fetch an attractive price from investors. Down rounds are verboten. Those deals are *missing* from the quarterly venture activity data:\\n- Accounting for these phantom fundraises would lower the average venture valuation, since low prices are the whole reason those deals aren't happening. In other words, there's massive **selection bias**.\\n- Companies also tend to be more public about their valuations the higher they are. Journalists love reporting on high valuations. As a result, the data we have on valuations is also likely skewed too high due to **reporting bias**.\\n\\nThe prices we see investments getting done at are misleading. Thus, the concept of a shadow price applies to venture â€“ it's the price that would prevail if companies were forced to transact at current prices and we had perfect data on all fundraises.\\n\\nI think of the dashed line in the chart above as something akin to the \\\"shadow valuation\\\" of venture capital investment.\\n\\n## Wow, that's a high price!\\n\\nThe reliable relationship between prices and funding has broken down in recent quarters.\\n\\nWhile valuations and funding have both declined since late 2021, funding declined by much more. Valuations have not fallen by nearly as much as the 3:2 ratio would imply. Instead, since the market peaked the ratio has been more like 5:2, or, said differently, valuations have only fallen 0.4% for every 1% drop in funding.\\n\\nIn other words, even after collapsing, valuations are still too high relative to their historical relationship with funding.\\n\\nWe can visualize this growing \\\"error\\\" â€“ the percentage difference between actual and predicted valuations â€“ shown below. Above the zero line means valuations are too high, below means valuations are too low:\\n\\n![coint_res](__GHOST_URL__/content/images/2023/06/coint_res.png)\\n\\n**Current valuations are ~60% too high relative to the volume of capital being deployed.** There just aren't enough dollars sloshing around to support these prices, at least based on the 10 years of venture history prior to the go-go days of 2021.\\n\\nSince 2010 valuations have rarely been \\\"off\\\" by more than 20%. 60% is *unprecedented*.\\n\\nAgain, notice how in the past any deviation from equilibrium quickly reverts, nearly always within a quarter or two. Something has changed â€“ \\\"error correction\\\" is *totally absent* in recent quarters.\\n\\n**This is worrying.** Never in the last decade-plus of venture activity have valuations and funding flows diverged so meaningfully from their long-run equilibrium, for so long. Could this mean there's a lot more pain ahead?\\n\\n## These deals won't last\\n\\nNow, it's totally possible we have it all backwards.\\n\\nTill now I've taken for granted the idea that capital flows drive valuations.\\n\\nPerhaps valuations have risen for separate, independent reasons and funding volume grew to meet these new prices. Thus, it could be funding that corrects itself, rather than valuations. Perhaps the current gap signals funding is *too low* rather than warning valuations are *too high*.\\n\\nLet's check what happened in the past. That is, **how have valuations and funding historically reacted to past deviations from their long-run ratio?** That would be a strong clue as to which is the driver and which is the passenger here.\\n\\nThat's straightforward enough â€“ just run a regression of valuation and funding growth on deviations. If valuations react more, then we know valuations correct for past deviations from equilibrium. If invested capital reacts more, then its funding that corrects.\\n\\nTurns out, valuations correct past deviations (left chart), funding does not (right chart):\\n\\n![err_corr](__GHOST_URL__/content/images/2023/06/err_corr.png)\\n\\nWhen valuations and funding volume drift apart, it's valuations that come running back:\\n- If valuations are high relative to funding, valuations tend to fall the following quarter\\n- If valuations are too low relative to funding, valuations rise next quarter\\n\\nFunding doesn't respond at all.\\n\\nDeviations reflect unusual valuations rather than abnormal funding. **Valuations are out of whack, not funding volume.**\\n\\nPricing \\\"errors\\\" forecast future valuations, since valuations reliably and quickly respond to those deviations in later periods. The implication? **Valuations should fall dramatically from here.** That they haven't yet can be chalked up to a combination of market inefficiency and reluctance.\\n\\nJust like in a Keynesian model of the economy, where sticky, slow to adjust prices exacerbate economic downturns, \\\"sticky valuations\\\" lengthen and worsen venture recessions. Deals that could get done at more reasonable valuations don't happen, as founders and existing investors don't want to take the hit:\\n> Private valuations lag public valuations, often by a substantial amount and for a long time â€“ [Old Valuations Die Hard](https://whoisnnamdi.com/old-valuations/)\\n\\nWe should prefer swift, definitive corrections over slow moving train wrecks. Instead, we drag things out. Everyone suffers as a result.\\n\\n## Tourist prices\\n\\nThat venture prices are tied so strongly to capital flows is striking: \\n* This contradicts standard corporate finance which values companies based on fundamentals. The amount of capital in the market shouldn't impact valuations if the intrinsic value hasn't changed.\\n* However, that's not what we see â€“ there doesn't seem to be anything \\\"fundamental\\\" anchoring the price of startups. Startups are priced based on the amount of capital in the private markets at the time. \\n\\n**More capital, higher prices.** Again, it's not one-for-one, but it's clear most of the capital goes toward higher prices rather than more deals getting done.\\n\\nIn my last essay, I was struck by how sensitive private valuations were to interest rates:\\n> â€¦ **seven quarters out valuations are up ~25%**, falling back to their original level after three years â€“ [Don't Discount Interest Rates](https://whoisnnamdi.com/discount-rates/)\\n\\nAs readers pointed out, a pure discounted cash flow (DCF) analysis would never suggest such a large impact. This is a fair point, and one I too pondered.\\n\\nHowever, these magnitudes make much more sense in the context of capital flows. Low interest rates attract capital to risky assets like venture capital as investors [reach for yield](https://www.richmondfed.org/~/media/richmondfedorg/publications/research/econ_focus/2013/q3/pdf/federal_reserve.pdf) unavailable elsewhere. If capital flowing into startups raises prices, then we really have two simultaneous effects:\\n- The first is traditional, static, corporate finance, which says interest rates (or rather, the discount rate) influence valuations.\\n- The second is the dynamic effect of interest rates on venture capital funding, which then impacts valuations via the 3:2 relationship I studied above.\\n\\nThis double whammy is how you end up with such severe valuation swings.\\n\\nIronically, it's the tourists who \\\"price\\\" venture investments on the margin â€“ those much-derided investors who, like birds, cyclically flock to and flee from venture investing with the changing economic winds. Us \\\"locals\\\" have no choice but to live with it.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: The Shadow Price of Venture Capital\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>Venture valuations have fallen off a cliff, but they are still too high.</p>\n<p>Valuations rise and fall with the volume of dollars invested in startups according to a stable ratio: for every one percent change in funding, valuations move two-thirds of a percent.</p>\n<p>But since peaking in late 2021, valuations have only fallen 0.4% for every 1% drop in funding. This pricing &quot;error&quot; has accumulated: <strong>today's valuations are 60% higher than youâ€™d expect for the amount of capital invested.</strong></p>\n<p>In other words, the &quot;shadow price&quot; of venture capital is a lot lower than what we're seeing in announced transactions these days. Never before have valuations and funding diverged so meaningfully from their long-run equilibrium, for so long.</p>\n<p>What does it all mean?</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: The Shadow Price of Venture Capital\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"a-3-for-2-special\">A 3-for-2 special</h2>\n<p>Valuations and capital invested in venture have both grown substantially since 2010:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/06/val_cap.png\" alt=\"val_cap\" loading=\"lazy\"></p>\n<p>Interestingly, they trend together. As one rises, the other does too. Same in the other direction.</p>\n<p>It's not a perfect relationship, but there's clearly something tying them together.</p>\n<p>In fact, you can predict average valuations from the capital invested each quarter. The below chart plots actual valuations over time against what we'd predict based on capital deployment â€“ a simple regression of valuations on funding:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/06/val_pred.png\" alt=\"val_pred\" loading=\"lazy\"></p>\n<p><strong>Capital invested predicts the average valuation of deals done each quarter.</strong></p>\n<p>Most of the time, the &quot;errors&quot; of this capital-based prediction are small. Further, these deviations typically correct themselves within a quarter or two.</p>\n<p>In this sense, <strong>venture valuations are a function of capital flows.</strong> More capital drives valuations ever higher, in a fairly predictable fashion. There's an equilibrium, a balance between the two.</p>\n<p>They don't grow at the same rate, however. For every 1% increase in funding, valuations rise about 0.66% or two-thirds of a percent. If you like clean whole numbers, the ratio is about 3:2.</p>\n<p>Most of the increased funding goes to rising prices rather than more individual investments. This mirrors points I've made previously:</p>\n<blockquote>\n<p>&quot;the valuation inflation we've seen &quot;comes from&quot; the incredible growth in demand and lack of supply of startup equity&quot;<br>\nâ€¦<br>\n&quot;Additional capital drives opportunistic company formation at the Seed stage. However, the additional capital doesn't improveÂ <em>survival</em>Â to the later stages â€“ it simply drives prices up for the remaining companies&quot; â€“ <a href=\"https://whoisnnamdi.com/its-valuations/\">It's Valuations (Almost) All the Way Down</a></p>\n</blockquote>\n<h2 id=\"price-check-please\">Price check, please?</h2>\n<p>Economists have a term I think is relevant â€“ <strong>shadow price</strong> â€“ or, the price of something that either isn't typically traded in the market or for which accurate pricing is hard to come by. For example:</p>\n<ul>\n<li>The price of an illicit good (drugs, contraband of various sorts, etc)</li>\n<li>In certain economies like Argentina, the shadow or &quot;black market&quot; price for exchanging the local currency for a foreign currency like the U.S. dollar, which differs from the &quot;official&quot; rate.</li>\n</ul>\n<p>Why is this relevant to venture capital?</p>\n<p>Well, because so many venture transactions <em>don't</em> happen. Most startups fundraise only once in a while. Founders delay fundraising if they can't fetch an attractive price from investors. Down rounds are verboten. Those deals are <em>missing</em> from the quarterly venture activity data:</p>\n<ul>\n<li>Accounting for these phantom fundraises would lower the average venture valuation, since low prices are the whole reason those deals aren't happening. In other words, there's massive <strong>selection bias</strong>.</li>\n<li>Companies also tend to be more public about their valuations the higher they are. Journalists love reporting on high valuations. As a result, the data we have on valuations is also likely skewed too high due to <strong>reporting bias</strong>.</li>\n</ul>\n<p>The prices we see investments getting done at are misleading. Thus, the concept of a shadow price applies to venture â€“ it's the price that would prevail if companies were forced to transact at current prices and we had perfect data on all fundraises.</p>\n<p>I think of the dashed line in the chart above as something akin to the &quot;shadow valuation&quot; of venture capital investment.</p>\n<h2 id=\"wow-thats-a-high-price\">Wow, that's a high price!</h2>\n<p>The reliable relationship between prices and funding has broken down in recent quarters.</p>\n<p>While valuations and funding have both declined since late 2021, funding declined by much more. Valuations have not fallen by nearly as much as the 3:2 ratio would imply. Instead, since the market peaked the ratio has been more like 5:2, or, said differently, valuations have only fallen 0.4% for every 1% drop in funding.</p>\n<p>In other words, even after collapsing, valuations are still too high relative to their historical relationship with funding.</p>\n<p>We can visualize this growing &quot;error&quot; â€“ the percentage difference between actual and predicted valuations â€“ shown below. Above the zero line means valuations are too high, below means valuations are too low:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/06/coint_res.png\" alt=\"coint_res\" loading=\"lazy\"></p>\n<p><strong>Current valuations are ~60% too high relative to the volume of capital being deployed.</strong> There just aren't enough dollars sloshing around to support these prices, at least based on the 10 years of venture history prior to the go-go days of 2021.</p>\n<p>Since 2010 valuations have rarely been &quot;off&quot; by more than 20%. 60% is <em>unprecedented</em>.</p>\n<p>Again, notice how in the past any deviation from equilibrium quickly reverts, nearly always within a quarter or two. Something has changed â€“ &quot;error correction&quot; is <em>totally absent</em> in recent quarters.</p>\n<p><strong>This is worrying.</strong> Never in the last decade-plus of venture activity have valuations and funding flows diverged so meaningfully from their long-run equilibrium, for so long. Could this mean there's a lot more pain ahead?</p>\n<h2 id=\"these-deals-wont-last\">These deals won't last</h2>\n<p>Now, it's totally possible we have it all backwards.</p>\n<p>Till now I've taken for granted the idea that capital flows drive valuations.</p>\n<p>Perhaps valuations have risen for separate, independent reasons and funding volume grew to meet these new prices. Thus, it could be funding that corrects itself, rather than valuations. Perhaps the current gap signals funding is <em>too low</em> rather than warning valuations are <em>too high</em>.</p>\n<p>Let's check what happened in the past. That is, <strong>how have valuations and funding historically reacted to past deviations from their long-run ratio?</strong> That would be a strong clue as to which is the driver and which is the passenger here.</p>\n<p>That's straightforward enough â€“ just run a regression of valuation and funding growth on deviations. If valuations react more, then we know valuations correct for past deviations from equilibrium. If invested capital reacts more, then its funding that corrects.</p>\n<p>Turns out, valuations correct past deviations (left chart), funding does not (right chart):</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/06/err_corr.png\" alt=\"err_corr\" loading=\"lazy\"></p>\n<p>When valuations and funding volume drift apart, it's valuations that come running back:</p>\n<ul>\n<li>If valuations are high relative to funding, valuations tend to fall the following quarter</li>\n<li>If valuations are too low relative to funding, valuations rise next quarter</li>\n</ul>\n<p>Funding doesn't respond at all.</p>\n<p>Deviations reflect unusual valuations rather than abnormal funding. <strong>Valuations are out of whack, not funding volume.</strong></p>\n<p>Pricing &quot;errors&quot; forecast future valuations, since valuations reliably and quickly respond to those deviations in later periods. The implication? <strong>Valuations should fall dramatically from here.</strong> That they haven't yet can be chalked up to a combination of market inefficiency and reluctance.</p>\n<p>Just like in a Keynesian model of the economy, where sticky, slow to adjust prices exacerbate economic downturns, &quot;sticky valuations&quot; lengthen and worsen venture recessions. Deals that could get done at more reasonable valuations don't happen, as founders and existing investors don't want to take the hit:</p>\n<blockquote>\n<p>Private valuations lag public valuations, often by a substantial amount and for a long time â€“ <a href=\"https://whoisnnamdi.com/old-valuations/\">Old Valuations Die Hard</a></p>\n</blockquote>\n<p>We should prefer swift, definitive corrections over slow moving train wrecks. Instead, we drag things out. Everyone suffers as a result.</p>\n<h2 id=\"tourist-prices\">Tourist prices</h2>\n<p>That venture prices are tied so strongly to capital flows is striking:</p>\n<ul>\n<li>This contradicts standard corporate finance which values companies based on fundamentals. The amount of capital in the market shouldn't impact valuations if the intrinsic value hasn't changed.</li>\n<li>However, that's not what we see â€“ there doesn't seem to be anything &quot;fundamental&quot; anchoring the price of startups. Startups are priced based on the amount of capital in the private markets at the time.</li>\n</ul>\n<p><strong>More capital, higher prices.</strong> Again, it's not one-for-one, but it's clear most of the capital goes toward higher prices rather than more deals getting done.</p>\n<p>In my last essay, I was struck by how sensitive private valuations were to interest rates:</p>\n<blockquote>\n<p>â€¦ <strong>seven quarters out valuations are up ~25%</strong>, falling back to their original level after three years â€“ <a href=\"https://whoisnnamdi.com/discount-rates/\">Don't Discount Interest Rates</a></p>\n</blockquote>\n<p>As readers pointed out, a pure discounted cash flow (DCF) analysis would never suggest such a large impact. This is a fair point, and one I too pondered.</p>\n<p>However, these magnitudes make much more sense in the context of capital flows. Low interest rates attract capital to risky assets like venture capital as investors <a href=\"https://www.richmondfed.org/~/media/richmondfedorg/publications/research/econ_focus/2013/q3/pdf/federal_reserve.pdf\">reach for yield</a> unavailable elsewhere. If capital flowing into startups raises prices, then we really have two simultaneous effects:</p>\n<ul>\n<li>The first is traditional, static, corporate finance, which says interest rates (or rather, the discount rate) influence valuations.</li>\n<li>The second is the dynamic effect of interest rates on venture capital funding, which then impacts valuations via the 3:2 relationship I studied above.</li>\n</ul>\n<p>This double whammy is how you end up with such severe valuation swings.</p>\n<p>Ironically, it's the tourists who &quot;price&quot; venture investments on the margin â€“ those much-derided investors who, like birds, cyclically flock to and flee from venture investing with the changing economic winds. Us &quot;locals&quot; have no choice but to live with it.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: The Shadow Price of Venture Capital\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"6489f030fec7d1542d1d2ea9","plaintext":"Venture valuations have fallen off a cliff, but they are still too high.\n\nValuations rise and fall with the volume of dollars invested in startups\naccording to a stable ratio: for every one percent change in funding, valuations\nmove two-thirds of a percent.\n\nBut since peaking in late 2021, valuations have only fallen 0.4% for every 1%\ndrop in funding. This pricing \"error\" has accumulated: today's valuations are\n60% higher than youâ€™d expect for the amount of capital invested.\n\nIn other words, the \"shadow price\" of venture capital is a lot lower than what\nwe're seeing in announced transactions these days. Never before have valuations\nand funding diverged so meaningfully from their long-run equilibrium, for so\nlong.\n\nWhat does it all mean?\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡A 3-for-2 special\nValuations and capital invested in venture have both grown substantially since\n2010:\n\n\n\nInterestingly, they trend together. As one rises, the other does too. Same in\nthe other direction.\n\nIt's not a perfect relationship, but there's clearly something tying them\ntogether.\n\nIn fact, you can predict average valuations from the capital invested each\nquarter. The below chart plots actual valuations over time against what we'd\npredict based on capital deployment â€“ a simple regression of valuations on\nfunding:\n\n\n\nCapital invested predicts the average valuation of deals done each quarter.\n\nMost of the time, the \"errors\" of this capital-based prediction are small.\nFurther, these deviations typically correct themselves within a quarter or two.\n\nIn this sense, venture valuations are a function of capital flows. More capital\ndrives valuations ever higher, in a fairly predictable fashion. There's an\nequilibrium, a balance between the two.\n\nThey don't grow at the same rate, however. For every 1% increase in funding,\nvaluations rise about 0.66% or two-thirds of a percent. If you like clean whole\nnumbers, the ratio is about 3:2.\n\nMost of the increased funding goes to rising prices rather than more individual\ninvestments. This mirrors points I've made previously:\n\n> \"the valuation inflation we've seen \"comes from\" the incredible growth in demand\nand lack of supply of startup equity\"\nâ€¦\n\"Additional capital drives opportunistic company formation at the Seed stage.\nHowever, the additional capital doesn't improvesurvivalto the later stages â€“ it\nsimply drives prices up for the remaining companies\" â€“ It's Valuations (Almost)\nAll the Way Down [https://whoisnnamdi.com/its-valuations/]\n\n\nPrice check, please?\nEconomists have a term I think is relevant â€“ shadow price â€“ or, the price of\nsomething that either isn't typically traded in the market or for which accurate\npricing is hard to come by. For example:\n\n * The price of an illicit good (drugs, contraband of various sorts, etc)\n * In certain economies like Argentina, the shadow or \"black market\" price for\n   exchanging the local currency for a foreign currency like the U.S. dollar,\n   which differs from the \"official\" rate.\n\nWhy is this relevant to venture capital?\n\nWell, because so many venture transactions don't happen. Most startups fundraise\nonly once in a while. Founders delay fundraising if they can't fetch an\nattractive price from investors. Down rounds are verboten. Those deals are \nmissing from the quarterly venture activity data:\n\n * Accounting for these phantom fundraises would lower the average venture\n   valuation, since low prices are the whole reason those deals aren't\n   happening. In other words, there's massive selection bias.\n * Companies also tend to be more public about their valuations the higher they\n   are. Journalists love reporting on high valuations. As a result, the data we\n   have on valuations is also likely skewed too high due to reporting bias.\n\nThe prices we see investments getting done at are misleading. Thus, the concept\nof a shadow price applies to venture â€“ it's the price that would prevail if\ncompanies were forced to transact at current prices and we had perfect data on\nall fundraises.\n\nI think of the dashed line in the chart above as something akin to the \"shadow\nvaluation\" of venture capital investment.\n\nWow, that's a high price!\nThe reliable relationship between prices and funding has broken down in recent\nquarters.\n\nWhile valuations and funding have both declined since late 2021, funding\ndeclined by much more. Valuations have not fallen by nearly as much as the 3:2\nratio would imply. Instead, since the market peaked the ratio has been more like\n5:2, or, said differently, valuations have only fallen 0.4% for every 1% drop in\nfunding.\n\nIn other words, even after collapsing, valuations are still too high relative to\ntheir historical relationship with funding.\n\nWe can visualize this growing \"error\" â€“ the percentage difference between actual\nand predicted valuations â€“ shown below. Above the zero line means valuations are\ntoo high, below means valuations are too low:\n\n\n\nCurrent valuations are ~60% too high relative to the volume of capital being\ndeployed. There just aren't enough dollars sloshing around to support these\nprices, at least based on the 10 years of venture history prior to the go-go\ndays of 2021.\n\nSince 2010 valuations have rarely been \"off\" by more than 20%. 60% is \nunprecedented.\n\nAgain, notice how in the past any deviation from equilibrium quickly reverts,\nnearly always within a quarter or two. Something has changed â€“ \"error\ncorrection\" is totally absent in recent quarters.\n\nThis is worrying. Never in the last decade-plus of venture activity have\nvaluations and funding flows diverged so meaningfully from their long-run\nequilibrium, for so long. Could this mean there's a lot more pain ahead?\n\nThese deals won't last\nNow, it's totally possible we have it all backwards.\n\nTill now I've taken for granted the idea that capital flows drive valuations.\n\nPerhaps valuations have risen for separate, independent reasons and funding\nvolume grew to meet these new prices. Thus, it could be funding that corrects\nitself, rather than valuations. Perhaps the current gap signals funding is too\nlow rather than warning valuations are too high.\n\nLet's check what happened in the past. That is, how have valuations and funding\nhistorically reacted to past deviations from their long-run ratio? That would be\na strong clue as to which is the driver and which is the passenger here.\n\nThat's straightforward enough â€“ just run a regression of valuation and funding\ngrowth on deviations. If valuations react more, then we know valuations correct\nfor past deviations from equilibrium. If invested capital reacts more, then its\nfunding that corrects.\n\nTurns out, valuations correct past deviations (left chart), funding does not\n(right chart):\n\n\n\nWhen valuations and funding volume drift apart, it's valuations that come\nrunning back:\n\n * If valuations are high relative to funding, valuations tend to fall the\n   following quarter\n * If valuations are too low relative to funding, valuations rise next quarter\n\nFunding doesn't respond at all.\n\nDeviations reflect unusual valuations rather than abnormal funding. Valuations\nare out of whack, not funding volume.\n\nPricing \"errors\" forecast future valuations, since valuations reliably and\nquickly respond to those deviations in later periods. The implication? \nValuations should fall dramatically from here. That they haven't yet can be\nchalked up to a combination of market inefficiency and reluctance.\n\nJust like in a Keynesian model of the economy, where sticky, slow to adjust\nprices exacerbate economic downturns, \"sticky valuations\" lengthen and worsen\nventure recessions. Deals that could get done at more reasonable valuations\ndon't happen, as founders and existing investors don't want to take the hit:\n\n> Private valuations lag public valuations, often by a substantial amount and for\na long time â€“ Old Valuations Die Hard [https://whoisnnamdi.com/old-valuations/]\n\n\nWe should prefer swift, definitive corrections over slow moving train wrecks.\nInstead, we drag things out. Everyone suffers as a result.\n\nTourist prices\nThat venture prices are tied so strongly to capital flows is striking:\n\n * This contradicts standard corporate finance which values companies based on\n   fundamentals. The amount of capital in the market shouldn't impact valuations\n   if the intrinsic value hasn't changed.\n * However, that's not what we see â€“ there doesn't seem to be anything\n   \"fundamental\" anchoring the price of startups. Startups are priced based on\n   the amount of capital in the private markets at the time.\n\nMore capital, higher prices. Again, it's not one-for-one, but it's clear most of\nthe capital goes toward higher prices rather than more deals getting done.\n\nIn my last essay, I was struck by how sensitive private valuations were to\ninterest rates:\n\n> â€¦ seven quarters out valuations are up ~25%, falling back to their original\nlevel after three years â€“ Don't Discount Interest Rates\n[https://whoisnnamdi.com/discount-rates/]\n\n\nAs readers pointed out, a pure discounted cash flow (DCF) analysis would never\nsuggest such a large impact. This is a fair point, and one I too pondered.\n\nHowever, these magnitudes make much more sense in the context of capital flows.\nLow interest rates attract capital to risky assets like venture capital as\ninvestors reach for yield\n[https://www.richmondfed.org/~/media/richmondfedorg/publications/research/econ_focus/2013/q3/pdf/federal_reserve.pdf] \nunavailable elsewhere. If capital flowing into startups raises prices, then we\nreally have two simultaneous effects:\n\n * The first is traditional, static, corporate finance, which says interest\n   rates (or rather, the discount rate) influence valuations.\n * The second is the dynamic effect of interest rates on venture capital\n   funding, which then impacts valuations via the 3:2 relationship I studied\n   above.\n\nThis double whammy is how you end up with such severe valuation swings.\n\nIronically, it's the tourists who \"price\" venture investments on the margin â€“\nthose much-derided investors who, like birds, cyclically flock to and flee from\nventure investing with the changing economic winds. Us \"locals\" have no choice\nbut to live with it.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2023/06/header.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2023-06-14T16:52:00.000Z","updated_at":"2023-06-14T17:59:30.000Z","published_at":"2023-06-14T17:45:20.000Z","custom_excerpt":"Valuations are 60% too high relative to the volume of venture funding","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"64bf8645fec7d1542d1d2ee6","uuid":"b66a2b67-d9a1-443f-b8e5-292061514b4f","title":"The Venture Activity Index","slug":"venture-activity-index","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"It's no secret â€“ unless you're building in AI, the venture market isn't very kind right now.\\n\\nAfter a euphoric 2021, funding took a nosedive, falling to the lowest pace we've seen in some time. While economists and politicos debate whether we're in an economic recession, there's no debate in the venture economy â€“ **it ain't pretty out there for founders trying to raise capital right now.**\\n\\nBut that sentiment is somewhat anecdotal, backed by the gut feeling of venture market participants. It'd be great to have a view of the venture cycle that was backed up by the data, some sort of indicator of the phase of the cycle we're currently living through.\\n\\nSo I came up with a methodology for measuring the state of the venture \\\"business cycle\\\" â€“ how the venture market is performing relative to some underlying notion of \\\"trend\\\". Its construction is actually quite simple, and the result is something I think could serve as a useful barometer for the ecosystem as we chart a course from here.\\n\\nIt's called the Venture Activity Index, or \\\"VAI\\\". Let me walk you through how I got there.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: The Venture Activity Index\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## Quick stats\\n\\nTo measure the venture cycle, we need a notion of \\\"trend\\\" â€“ the thing around which the venture market is fluctuating. If we plot funding growth on a logarithmic scale across each stage of venture investment, a clear linear trend emerges. (Note: linear trends in logarithms implies constant percentage growth over time):\\n\\n![detrend](__GHOST_URL__/content/images/2023/07/detrend.png)\\n\\nI could have come up with a fancier notion of trend, but I'll proceed with the linear one as it's nice and simple.\\n\\nVenture activity, as defined by aggregate funding, fluctuates up and down around this trend. The slope varies by stage, but it's a fairly consistent story across stages â€“ **on average, funding grows ~5% each quarter.**\\n\\nOne quick note: I could have focused instead on the number of investments rather than the scale of investment activity measured in dollars. However, working in dollar terms is nice because it implicitly accounts for valuations, which is critical for holistically characterizing the state of the venture market.\\n\\nNext, let's remove that trend and focus on the gyrations around it:\\n\\n![cycles](__GHOST_URL__/content/images/2023/07/cycles.png)\\n\\n* The cycles were only moderately correlated across stages before 2020. The average cross-stage correlation hovered around ~0.25 pre-2020.\\n* However, since 2020, they've moved in lockstep, following one common cycle up and then down.\\n\\nThis is typical in economic data: in volatile times, different parts of the market often become much more tightly correlated. It's interesting to see the same phenomenon in the venture data. Further, it's important that the various stages of venture correlate with one another, as otherwise there'd be no sense in talking about a singular \\\"cycle\\\" for the whole ecosystem.\\n\\nOverall, the correlations are around ~0.65 for the whole period, with the seed stage being the most dissimilar to the other stages of investment:\\n\\n![correl](__GHOST_URL__/content/images/2023/07/correl.png)\\n\\nThe amplitudes of the cycles, however, differ across stages, both historically and more recently:\\n* The seed stage is relatively steady, never more than 50% off trend, with a quarterly standard deviation across time of about 20 percentage points.\\n* Series A is a bit more volatile but not significantly so.\\n* Growth and later stages are the most volatile, ranging from a standard deviation of ~30 p.p. for Series B all the way to ~50 p.p. for Series D+.\\n\\nIn other words, booms and busts are substantially larger at the later stages:\\n\\n![volatility](__GHOST_URL__/content/images/2023/07/volatility.png)\\n\\nAnd in case you're wondering, this was true before 2020 as well. It's not just a recent phenomenon: the late-stage market has always required a bit of a strong stomach.\\n\\n## One metric to rule them all\\n\\nNow let's throw it all together. Again, in the spirit of simplicity and robustness, let's take the simple average of the individual trends to arrive at a blended view of the venture ecosystem.\\n\\nI present to youâ€¦ the Venture Activity Index (VAI):\\n\\n![vai_plot](__GHOST_URL__/content/images/2023/07/vai_plot.png)\\n\\nThe last three years of the VAI are the obvious anomaly:\\n* Capital deployment rose to 90% above trend, exploding over only a few quarters.\\n* The correction was just as vigorous, bottoming out at ~60% below trend and stable for the last two quarters.\\n\\n**We haven't seen anything like this in the prior ten years of activity.** Previous peaks and valleys were at most +/-25%. The volatility of the last three years is *unheard of* in recent memory.\\n\\nWhen knocked off trend, venture activity returns to steady state after ~1.5 years. Only in that sense was the exuberance of 2021 relatively normal â€“ it lasted roughly as long as such booms tend to last. We'll see if that behavior continues.\\n\\nAgain, I want to emphasize this is a measure of the venture business *cycle*, not the trend itself, which we first removed. A rise or decline in the VAI implies funding grew faster or slower than trend, respectively, *not* that funding rose or fell in absolute terms.\\n\\nDue to its cyclic nature, the VAI forecasts future changes in venture activity. When it's high, future venture activity slows. When it's low, venture activity accelerates in the next few quarters. This is true across stages, though it's most accurate for the later stages:\\n\\n![vai_forecast](__GHOST_URL__/content/images/2023/07/vai_forecast.png)\\n\\nOverall, a 10% increase in the VAI forecasts anywhere from a 6.5% decline in seed stage venture funding over the next year to a 21.5% decrease at the Series D+ stage (and vice versa for a decrease in the VAI).\\n\\n## Conclusion\\n\\nThe Venture Activity Index is a simple and informative indicator of the state of the venture \\\"business cycle\\\". In a single number, it quantifies the \\\"gut feelings\\\" we all have about the venture climate today, in the past, and in the future.\\n\\nTo wrap up, a few caveats:\\n* The backward-looking trend updates every quarter, which can slightly change the historical numbers as new data comes in.\\n* A linear trend may not make sense in the long-run. For example, if the rate of capital deployment never returns to its prior trend, at some point we'd have to accept that a new trend has been established, making the old one irrelevant. I may later change my calculation of trend to address this.\\n* My simple average of the various stage-specific trends could be improved upon with some sort of factor analysis technique. Again, I may switch to this at a later date.\\n\\n**I plan to update the VAI quarterly as new data comes in.** For the latest data, look [here](https://whoisnnamdi.com/vai).\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: The Venture Activity Index\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>It's no secret â€“ unless you're building in AI, the venture market isn't very kind right now.</p>\n<p>After a euphoric 2021, funding took a nosedive, falling to the lowest pace we've seen in some time. While economists and politicos debate whether we're in an economic recession, there's no debate in the venture economy â€“ <strong>it ain't pretty out there for founders trying to raise capital right now.</strong></p>\n<p>But that sentiment is somewhat anecdotal, backed by the gut feeling of venture market participants. It'd be great to have a view of the venture cycle that was backed up by the data, some sort of indicator of the phase of the cycle we're currently living through.</p>\n<p>So I came up with a methodology for measuring the state of the venture &quot;business cycle&quot; â€“ how the venture market is performing relative to some underlying notion of &quot;trend&quot;. Its construction is actually quite simple, and the result is something I think could serve as a useful barometer for the ecosystem as we chart a course from here.</p>\n<p>It's called the Venture Activity Index, or &quot;VAI&quot;. Let me walk you through how I got there.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: The Venture Activity Index\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"quick-stats\">Quick stats</h2>\n<p>To measure the venture cycle, we need a notion of &quot;trend&quot; â€“ the thing around which the venture market is fluctuating. If we plot funding growth on a logarithmic scale across each stage of venture investment, a clear linear trend emerges. (Note: linear trends in logarithms implies constant percentage growth over time):</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/07/detrend.png\" alt=\"detrend\" loading=\"lazy\"></p>\n<p>I could have come up with a fancier notion of trend, but I'll proceed with the linear one as it's nice and simple.</p>\n<p>Venture activity, as defined by aggregate funding, fluctuates up and down around this trend. The slope varies by stage, but it's a fairly consistent story across stages â€“ <strong>on average, funding grows ~5% each quarter.</strong></p>\n<p>One quick note: I could have focused instead on the number of investments rather than the scale of investment activity measured in dollars. However, working in dollar terms is nice because it implicitly accounts for valuations, which is critical for holistically characterizing the state of the venture market.</p>\n<p>Next, let's remove that trend and focus on the gyrations around it:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/07/cycles.png\" alt=\"cycles\" loading=\"lazy\"></p>\n<ul>\n<li>The cycles were only moderately correlated across stages before 2020. The average cross-stage correlation hovered around ~0.25 pre-2020.</li>\n<li>However, since 2020, they've moved in lockstep, following one common cycle up and then down.</li>\n</ul>\n<p>This is typical in economic data: in volatile times, different parts of the market often become much more tightly correlated. It's interesting to see the same phenomenon in the venture data. Further, it's important that the various stages of venture correlate with one another, as otherwise there'd be no sense in talking about a singular &quot;cycle&quot; for the whole ecosystem.</p>\n<p>Overall, the correlations are around ~0.65 for the whole period, with the seed stage being the most dissimilar to the other stages of investment:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/07/correl.png\" alt=\"correl\" loading=\"lazy\"></p>\n<p>The amplitudes of the cycles, however, differ across stages, both historically and more recently:</p>\n<ul>\n<li>The seed stage is relatively steady, never more than 50% off trend, with a quarterly standard deviation across time of about 20 percentage points.</li>\n<li>Series A is a bit more volatile but not significantly so.</li>\n<li>Growth and later stages are the most volatile, ranging from a standard deviation of ~30 p.p. for Series B all the way to ~50 p.p. for Series D+.</li>\n</ul>\n<p>In other words, booms and busts are substantially larger at the later stages:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/07/volatility.png\" alt=\"volatility\" loading=\"lazy\"></p>\n<p>And in case you're wondering, this was true before 2020 as well. It's not just a recent phenomenon: the late-stage market has always required a bit of a strong stomach.</p>\n<h2 id=\"one-metric-to-rule-them-all\">One metric to rule them all</h2>\n<p>Now let's throw it all together. Again, in the spirit of simplicity and robustness, let's take the simple average of the individual trends to arrive at a blended view of the venture ecosystem.</p>\n<p>I present to youâ€¦ the Venture Activity Index (VAI):</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/07/vai_plot.png\" alt=\"vai_plot\" loading=\"lazy\"></p>\n<p>The last three years of the VAI are the obvious anomaly:</p>\n<ul>\n<li>Capital deployment rose to 90% above trend, exploding over only a few quarters.</li>\n<li>The correction was just as vigorous, bottoming out at ~60% below trend and stable for the last two quarters.</li>\n</ul>\n<p><strong>We haven't seen anything like this in the prior ten years of activity.</strong> Previous peaks and valleys were at most +/-25%. The volatility of the last three years is <em>unheard of</em> in recent memory.</p>\n<p>When knocked off trend, venture activity returns to steady state after ~1.5 years. Only in that sense was the exuberance of 2021 relatively normal â€“ it lasted roughly as long as such booms tend to last. We'll see if that behavior continues.</p>\n<p>Again, I want to emphasize this is a measure of the venture business <em>cycle</em>, not the trend itself, which we first removed. A rise or decline in the VAI implies funding grew faster or slower than trend, respectively, <em>not</em> that funding rose or fell in absolute terms.</p>\n<p>Due to its cyclic nature, the VAI forecasts future changes in venture activity. When it's high, future venture activity slows. When it's low, venture activity accelerates in the next few quarters. This is true across stages, though it's most accurate for the later stages:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/07/vai_forecast.png\" alt=\"vai_forecast\" loading=\"lazy\"></p>\n<p>Overall, a 10% increase in the VAI forecasts anywhere from a 6.5% decline in seed stage venture funding over the next year to a 21.5% decrease at the Series D+ stage (and vice versa for a decrease in the VAI).</p>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>The Venture Activity Index is a simple and informative indicator of the state of the venture &quot;business cycle&quot;. In a single number, it quantifies the &quot;gut feelings&quot; we all have about the venture climate today, in the past, and in the future.</p>\n<p>To wrap up, a few caveats:</p>\n<ul>\n<li>The backward-looking trend updates every quarter, which can slightly change the historical numbers as new data comes in.</li>\n<li>A linear trend may not make sense in the long-run. For example, if the rate of capital deployment never returns to its prior trend, at some point we'd have to accept that a new trend has been established, making the old one irrelevant. I may later change my calculation of trend to address this.</li>\n<li>My simple average of the various stage-specific trends could be improved upon with some sort of factor analysis technique. Again, I may switch to this at a later date.</li>\n</ul>\n<p><strong>I plan to update the VAI quarterly as new data comes in.</strong> For the latest data, look <a href=\"https://whoisnnamdi.com/vai\">here</a>.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: The Venture Activity Index\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"64bf8645fec7d1542d1d2ee6","plaintext":"It's no secret â€“ unless you're building in AI, the venture market isn't very\nkind right now.\n\nAfter a euphoric 2021, funding took a nosedive, falling to the lowest pace we've\nseen in some time. While economists and politicos debate whether we're in an\neconomic recession, there's no debate in the venture economy â€“ it ain't pretty\nout there for founders trying to raise capital right now.\n\nBut that sentiment is somewhat anecdotal, backed by the gut feeling of venture\nmarket participants. It'd be great to have a view of the venture cycle that was\nbacked up by the data, some sort of indicator of the phase of the cycle we're\ncurrently living through.\n\nSo I came up with a methodology for measuring the state of the venture \"business\ncycle\" â€“ how the venture market is performing relative to some underlying notion\nof \"trend\". Its construction is actually quite simple, and the result is\nsomething I think could serve as a useful barometer for the ecosystem as we\nchart a course from here.\n\nIt's called the Venture Activity Index, or \"VAI\". Let me walk you through how I\ngot there.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Quick stats\nTo measure the venture cycle, we need a notion of \"trend\" â€“ the thing around\nwhich the venture market is fluctuating. If we plot funding growth on a\nlogarithmic scale across each stage of venture investment, a clear linear trend\nemerges. (Note: linear trends in logarithms implies constant percentage growth\nover time):\n\n\n\nI could have come up with a fancier notion of trend, but I'll proceed with the\nlinear one as it's nice and simple.\n\nVenture activity, as defined by aggregate funding, fluctuates up and down around\nthis trend. The slope varies by stage, but it's a fairly consistent story across\nstages â€“ on average, funding grows ~5% each quarter.\n\nOne quick note: I could have focused instead on the number of investments rather\nthan the scale of investment activity measured in dollars. However, working in\ndollar terms is nice because it implicitly accounts for valuations, which is\ncritical for holistically characterizing the state of the venture market.\n\nNext, let's remove that trend and focus on the gyrations around it:\n\n\n\n * The cycles were only moderately correlated across stages before 2020. The\n   average cross-stage correlation hovered around ~0.25 pre-2020.\n * However, since 2020, they've moved in lockstep, following one common cycle up\n   and then down.\n\nThis is typical in economic data: in volatile times, different parts of the\nmarket often become much more tightly correlated. It's interesting to see the\nsame phenomenon in the venture data. Further, it's important that the various\nstages of venture correlate with one another, as otherwise there'd be no sense\nin talking about a singular \"cycle\" for the whole ecosystem.\n\nOverall, the correlations are around ~0.65 for the whole period, with the seed\nstage being the most dissimilar to the other stages of investment:\n\n\n\nThe amplitudes of the cycles, however, differ across stages, both historically\nand more recently:\n\n * The seed stage is relatively steady, never more than 50% off trend, with a\n   quarterly standard deviation across time of about 20 percentage points.\n * Series A is a bit more volatile but not significantly so.\n * Growth and later stages are the most volatile, ranging from a standard\n   deviation of ~30 p.p. for Series B all the way to ~50 p.p. for Series D+.\n\nIn other words, booms and busts are substantially larger at the later stages:\n\n\n\nAnd in case you're wondering, this was true before 2020 as well. It's not just a\nrecent phenomenon: the late-stage market has always required a bit of a strong\nstomach.\n\nOne metric to rule them all\nNow let's throw it all together. Again, in the spirit of simplicity and\nrobustness, let's take the simple average of the individual trends to arrive at\na blended view of the venture ecosystem.\n\nI present to youâ€¦ the Venture Activity Index (VAI):\n\n\n\nThe last three years of the VAI are the obvious anomaly:\n\n * Capital deployment rose to 90% above trend, exploding over only a few\n   quarters.\n * The correction was just as vigorous, bottoming out at ~60% below trend and\n   stable for the last two quarters.\n\nWe haven't seen anything like this in the prior ten years of activity. Previous\npeaks and valleys were at most +/-25%. The volatility of the last three years is \nunheard of in recent memory.\n\nWhen knocked off trend, venture activity returns to steady state after ~1.5\nyears. Only in that sense was the exuberance of 2021 relatively normal â€“ it\nlasted roughly as long as such booms tend to last. We'll see if that behavior\ncontinues.\n\nAgain, I want to emphasize this is a measure of the venture business cycle, not\nthe trend itself, which we first removed. A rise or decline in the VAI implies\nfunding grew faster or slower than trend, respectively, not that funding rose or\nfell in absolute terms.\n\nDue to its cyclic nature, the VAI forecasts future changes in venture activity.\nWhen it's high, future venture activity slows. When it's low, venture activity\naccelerates in the next few quarters. This is true across stages, though it's\nmost accurate for the later stages:\n\n\n\nOverall, a 10% increase in the VAI forecasts anywhere from a 6.5% decline in\nseed stage venture funding over the next year to a 21.5% decrease at the Series\nD+ stage (and vice versa for a decrease in the VAI).\n\nConclusion\nThe Venture Activity Index is a simple and informative indicator of the state of\nthe venture \"business cycle\". In a single number, it quantifies the \"gut\nfeelings\" we all have about the venture climate today, in the past, and in the\nfuture.\n\nTo wrap up, a few caveats:\n\n * The backward-looking trend updates every quarter, which can slightly change\n   the historical numbers as new data comes in.\n * A linear trend may not make sense in the long-run. For example, if the rate\n   of capital deployment never returns to its prior trend, at some point we'd\n   have to accept that a new trend has been established, making the old one\n   irrelevant. I may later change my calculation of trend to address this.\n * My simple average of the various stage-specific trends could be improved upon\n   with some sort of factor analysis technique. Again, I may switch to this at a\n   later date.\n\nI plan to update the VAI quarterly as new data comes in. For the latest data,\nlook here [https://whoisnnamdi.com/vai].\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2023/07/header.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2023-07-25T08:22:29.000Z","updated_at":"2023-07-25T15:36:33.000Z","published_at":"2023-07-25T09:09:47.000Z","custom_excerpt":"Measuring the state of the venture \"business cycle\"","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"64bfe511fec7d1542d1d2f1e","uuid":"a2a21138-968c-458a-9c1a-6789586af4e3","title":"The Venture Activity Index (Q4 2023)","slug":"vai","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"embed\",{\"url\":\"https://datawrapper.dwcdn.net/Y8EOU/4/\",\"html\":\"<iframe title=\\\"The Venture Activity Index\\\" aria-label=\\\"Interactive area chart\\\" id=\\\"datawrapper-chart-Y8EOU\\\" src=\\\"https://datawrapper.dwcdn.net/Y8EOU/4/\\\" scrolling=\\\"no\\\" frameborder=\\\"0\\\" style=\\\"width: 0; min-width: 100% !important; border: none;\\\" height=\\\"600\\\" data-external=\\\"1\\\"></iframe><script type=\\\"text/javascript\\\">!function(){\\\"use strict\\\";window.addEventListener(\\\"message\\\",(function(a){if(void 0!==a.data[\\\"datawrapper-height\\\"]){var e=document.querySelectorAll(\\\"iframe\\\");for(var t in a.data[\\\"datawrapper-height\\\"])for(var r=0;r<e.length;r++)if(e[r].contentWindow===a.source){var i=a.data[\\\"datawrapper-height\\\"][t]+\\\"px\\\";e[r].style.height=i}}}))}();\\n</script>\",\"type\":\"rich\",\"metadata\":{\"version\":\"1.0\",\"provider_name\":\"Datawrapper\",\"provider_url\":\"http://www.datawrapper.de\",\"title\":\"The Venture Activity Index\",\"width\":900,\"height\":600}}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<figure class=\"kg-card kg-embed-card\"><iframe title=\"The Venture Activity Index\" aria-label=\"Interactive area chart\" id=\"datawrapper-chart-Y8EOU\" src=\"https://datawrapper.dwcdn.net/Y8EOU/4/\" scrolling=\"no\" frameborder=\"0\" style=\"width: 0; min-width: 100% !important; border: none;\" height=\"600\" data-external=\"1\"></iframe><script type=\"text/javascript\">!function(){\"use strict\";window.addEventListener(\"message\",(function(a){if(void 0!==a.data[\"datawrapper-height\"]){var e=document.querySelectorAll(\"iframe\");for(var t in a.data[\"datawrapper-height\"])for(var r=0;r<e.length;r++)if(e[r].contentWindow===a.source){var i=a.data[\"datawrapper-height\"][t]+\"px\";e[r].style.height=i}}}))}();\n</script></figure>","comment_id":"64bfe511fec7d1542d1d2f1e","plaintext":null,"feature_image":null,"featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2023-07-25T15:06:57.000Z","updated_at":"2024-03-07T18:34:15.000Z","published_at":"2023-07-25T15:08:41.000Z","custom_excerpt":"The Venture Activity Index","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"page","email_recipient_filter":"none"},{"id":"657139f9fec7d1542d1d2f32","uuid":"62df6d4e-098a-4688-9157-3514daaafb48","title":"How Redpanda is Taking Data Streaming Mainstream","slug":"data-streaming-mainstream","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/03/6687382f21aa7598bd65ede7_blog-lightspeed-img1-1.png\",\"alt\":\"Comparison of infrastructure and admin costs between Redpanda and Kafka\",\"title\":\"\",\"caption\":\"Comparison of infrastructure and admin costs between Redpanda and Kafka\",\"width\":1128,\"height\":636}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/03/6687382d569120c8751b8575_blog-lightspeed-img2.png\",\"alt\":\"Close up of a self-contained Redpanda node \",\"title\":\"\",\"caption\":\"Close up of a self-contained Redpanda node\",\"width\":1340,\"height\":808}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/03/6687382d907eec59adc13e52_blog-lightspeed-img3.png\",\"alt\":\"Diagram of how BYOC keeps the customer cloud separate for data sovereignty and privacy\",\"title\":\"\",\"caption\":\"Diagram of how BYOC keeps the customer cloud separate for data sovereignty and privacy\",\"width\":1076,\"height\":646}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/03/6687382d251781c480c13fdc_blog-lightspeed-img4.gif\",\"alt\":\"Preview of how Redpanda Console serves as a dev-friendly pane of glass.\",\"title\":\"\",\"caption\":\"Preview of how Redpanda Console serves as a dev-friendly pane of glass.\",\"width\":1457,\"height\":870}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/03/6687382d569120c8751b8579_blog-lightspeed-img5.png\",\"alt\":\"Screenshot of the Kafka Access Control interface in Redpanda Console.\",\"title\":\"\",\"caption\":\"Screenshot of the Kafka Access Control interface in Redpanda Console.\",\"width\":1086,\"height\":598}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/03/6687382d1dd2b64747bcf80f_blog-lightspeed-img6.png\",\"alt\":\"Diagram of how Redpandaâ€™s Tiered Storage works with Amazon S3.\",\"title\":\"\",\"caption\":\"Diagram of how Redpandaâ€™s Tiered Storage works with Amazon S3.\",\"width\":1316,\"height\":720}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2025/03/66a3d55edc368c41e27704d1_66873620cc1c1391aec633b1_blog-gaming-img2.png\",\"alt\":\"Diagram of the Redpanda compatibility ecosystem\",\"title\":\"\",\"caption\":\"Diagram of the Redpanda compatibility ecosystem\",\"width\":926,\"height\":457}]],\"markups\":[[\"a\",[\"href\",\"https://redpanda.com/blog/test-driven-development-ci-testing-kafka\"]],[\"a\",[\"href\",\"https://medium.com/lightspeed-venture-partners/why-developers-love-redpanda-30bf2f3b8231\"]],[\"a\",[\"href\",\"https://thenewstack.io/raft-native-the-foundation-for-streaming-datas-best-future/\"]],[\"a\",[\"href\",\"https://redpanda.com/blog/redpanda-vs-kafka-performance-benchmark\"]],[\"a\",[\"href\",\"https://redpanda.com/platform-tco\"]],[\"a\",[\"href\",\"https://redpanda.com/blog/deploy-redpanda-clusters-cloud-aws-gcp\"]],[\"a\",[\"href\",\"https://redpanda.com/blog/single-binary-architecture\"]],[\"a\",[\"href\",\"https://redpanda.com/blog/real-time-security-iot-customer-story\"]],[\"a\",[\"href\",\"https://alpaca.markets/\"]],[\"u\"],[\"a\",[\"href\",\"https://redpanda.com/blog/kafka-redpanda-future\"]],[\"a\",[\"href\",\"https://liveramp.com/\"]],[\"a\",[\"href\",\"https://www.datadoghq.com/state-of-serverless/\"]],[\"a\",[\"href\",\"https://medium.com/lightspeed-venture-partners/webassembly-ing-the-pieces-vectorizeds-data-policy-engine-5ceea983ed5d\"]],[\"a\",[\"href\",\"https://redpanda.com/redpanda-console-kafka-ui\"]],[\"a\",[\"href\",\"https://redpanda.com/blog/kafka-ui-redpanda-console\"]],[\"em\"],[\"a\",[\"href\",\"https://jepsen.io/analyses/redpanda-21.10.1\"]],[\"a\",[\"href\",\"https://jepsen.io/\"]],[\"a\",[\"href\",\"https://redpanda.com/blog/redpanda-official-jepsen-report-and-analysis\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/CAP_theorem\"]],[\"a\",[\"href\",\"https://redpanda.com/blog/cloud-native-streaming-data-lower-cost\"]],[\"a\",[\"href\",\"https://redpanda.com/blog/remote-read-replicas-for-distributing-work\"]],[\"a\",[\"href\",\"https://redpanda.com/blog/high-availability-software-deployment-patterns-part-1\"]],[\"a\",[\"href\",\"https://redpanda.com/blog/engineering-continuous-data-balancing\"]],[\"a\",[\"href\",\"https://redpanda.com/blog/tiered-storage-architecture-shadow-indexing-deep-dive\"]],[\"a\",[\"href\",\"https://docs.redpanda.com/docs/manage/tiered-storage/\"]],[\"a\",[\"href\",\"https://redpanda.com/blog/apache-hudi-iceberg-delta-lake-differences\"]],[\"a\",[\"href\",\"https://medium.com/lightspeed-venture-partners/why-lightspeed-is-leading-redpandas-100-million-series-c-553ffe38d6e\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Real-time data systems tend not to have amazing developer experiences. There are two core reasons.\"]]],[1,\"p\",[[0,[],0,\"One, the developer experience for the engine itself is poor. Streaming engines tend to be difficult to use, difficult to spin up, and difficult to operate on an ongoing basis, as they have a ton of moving parts and complexity to manage. This is especially painful when trying to self-host, develop locally, or integrate into a modern \"],[0,[0],1,\"continuous integration/deployment (CI/CD) pipeline\"],[0,[],0,\". As a result, only the most sophisticated and experienced engineers can make proper use of these systems, leaving behind most software developers and narrowing the market for event-based architectures.\"]]],[1,\"p\",[[0,[],0,\"Second, most streaming data systems donâ€™t integrate well into the rest of the developer workflow, and they lack many of the â€œcreature comfortsâ€ developers are used to seeing in their other tools. The modern developer workflow extends much further out and is much broader in scope than the streaming engine itself. For streaming engines to cement their place in the hearts and minds of developers, they must offer solutions to the rest of the puzzle.\"]]],[1,\"p\",[[0,[],0,\"Weâ€™ve talked before about \"],[0,[1],1,\"why developers love\"],[0,[],0,\" Redpandaâ€™s core developer experience, which is leaps and bounds above whatâ€™s come before in the streaming space. With \"],[0,[2],1,\"native Raft\"],[0,[],0,\", no JVM, and full Kafka compatibility, Redpanda enables developers to do their best work, reducing unnecessary complexity and toil while doing it all at the \"],[0,[3],1,\"highest throughput, lowest latency\"],[0,[],0,\", and, importantly, \"],[0,[4],1,\"lowest cost\"],[0,[],0,\".\"]]],[10,0],[1,\"p\",[[0,[],0,\"But itâ€™s also important to address that second point â€” how Redpanda creates a holistic developer experience that services all aspects of the modern developerâ€™s workflow, from deployment to monitoring and Day 2 operations to long-term storage. These remain unresolved, â€œopen loopsâ€ that have prevented a broader audience of developers and organizations from taking advantage of real-time capabilities.\"]]],[1,\"p\",[[0,[],0,\"At Lightspeed, itâ€™s our core belief that thereâ€™s a potentially massive market expansion opportunity for real-time, streaming data systems. Opening up this opportunity will require thinking much bigger about what a streaming engine can be and do.\"]]],[1,\"p\",[[0,[],0,\"Thatâ€™s where Redpanda comes in.\"]]],[1,\"h2\",[[0,[],0,\"Spinning up without spinning your wheels\"]]],[1,\"p\",[[0,[],0,\"Too often, developers looking to deploy streaming data systems are left to their own devices when it comes to deployment. Deployment is often a mess, involving multiple separate binaries, each with its own peculiarities, requiring engineers to develop expertise in systems they couldn't care less about and in which they have no comparative advantage. Streaming systems can easily become one of the most painful pieces of infrastructure theyâ€™ll deploy.\"]]],[1,\"p\",[[0,[],0,\"Further, developers increasingly see the cloud as their default deployment platform. In the same way that SaaS relieves some of the operational burden of running software by offloading that to the vendor, developers would love to be able to consume cloud-based streaming services with as few wrinkles as possible. Developers want a cloud experience but their organizations donâ€™t want to lose data sovereignty. They need a security model that works within the constraints of the typical enterprise while also getting the ease of use of the cloud â€” \"],[0,[5],1,\"the best of both worlds\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Lastly, developers on the bleeding edge donâ€™t want to think about infrastructure at all, cloud or otherwise. They donâ€™t want to think about servers, machines, nodes, availability zones, or regions. They want access to true streaming as a service rather than streaming as a server. In other words, they want serverless, and they want it now.\"]]],[1,\"p\",[[0,[],0,\"The modern developer experience requires a modern platform. Redpanda is that platform.\"]]],[1,\"p\",[[0,[],0,\"Hereâ€™s how Redpanda makes deployment a breeze.\"]]],[1,\"h2\",[[0,[],0,\"One binary to rule them all\"]]],[1,\"p\",[[0,[],0,\"The core of the Redpanda deployment model is the way its nodes are architected. Redpanda nodes are \"],[0,[6],1,\"fully-contained processes\"],[0,[],0,\" that ship with everything needed in a modern streaming system, including an HTTP proxy, a Raft-based consensus mechanism, and a schema registry. Every node runs the same, single binary, leading to significant operational simplification along with a more efficient overall operating model.\"]]],[10,1],[1,\"p\",[[0,[],0,\"Itâ€™s hard to overstate how game-changing this is. Due to this architecture, running a single Redpanda cluster doesnâ€™t require operating a massive fleet of varying services. This is a massive boon for developer productivity and also enables Redpanda to go where previous streaming systems have struggled, including \"],[0,[7],1,\"edge / IoT deployments\"],[0,[],0,\" and CI/CD pipelines with tight performance requirements and resource constraints.\"]]],[1,\"blockquote\",[[0,[],0,\"â€œThe latency and the throughput we got with almost no configuration was incredible. Redpanda is fast, reliable, friction-free and has very low operational overhead.â€ - \"],[0,[8,9],2,\"Alpaca\"]]],[1,\"h2\",[[0,[],0,\"Hold my cloud\"]]],[1,\"p\",[[0,[],0,\"Redpandaâ€™s cloud turns the table on traditional cloud infrastructure. While the company does offer standard, dedicated, managed clusters in the cloud, they didnâ€™t want to stop there. Redpanda went further, pioneering a deployment model they call \"],[0,[5],1,\"BYOC\"],[0,[],0,\", or, â€œbring your own cloud.â€ BYOC lets customers deploy Redpanda clusters within their own cloud environment, while still being fully managed by Redpanda.\"]]],[1,\"blockquote\",[[0,[],0,\"â€œBYOCâ€™s privacy-first architecture drives compliance for streaming data, and allows you to scale on your own infrastructure while maintaining data sovereignty requirements.â€ - \"],[0,[5,9],2,\"Bring Your Own Cloud (BYOC): best of both worlds\"]]],[1,\"p\",[[0,[],0,\"Redpanda does this by cleanly splitting the control and the data plane. The data plane stays within the customerâ€™s cloud account, while the control plane stays on Redpandaâ€™s side. This creates an incredibly slick and elegant setup, with proper separation of concerns between Redpandaâ€™s and the customerâ€™s cloud environment. With BYOC, organizations get all the benefits of the cloud while retaining \"],[0,[10],1,\"data sovereignty\"],[0,[],0,\" and maintaining privacy.\"]]],[10,2],[1,\"p\",[[0,[],0,\"Redpanda takes care of everything youâ€™d expect in a modern, competent cloud service, like provisioning, monitoring, and maintenance, while sensitive data and credentials never leave the customer environment. Rolling upgrades that the customer can control ensure zero application downtime. For obvious reasons, BYOC has become an incredibly popular deployment paradigm among Redpanda users.\"]]],[1,\"blockquote\",[[0,[],0,\"â€œRedpanda BYOC gives us a fully managed Kafka service running on our own cloud servers, balancing our internal compliance requirements with ease of use, and without compromising performance and compatibility.â€ - \"],[0,[11,9],2,\"LiveRamp\"]]],[1,\"h2\",[[0,[],0,\"Fewer servers, better service\"]]],[1,\"p\",[[0,[],0,\"Lastly, Redpanda is working on a number of exciting features around serverless, a relatively new paradigm within the context of streaming systems. This is their focus on developer experience taken to the logical extreme â€” what a streaming data system could look like from the perspective of a developer who doesnâ€™t want to worry about systems or deployment at all.\"]]],[1,\"p\",[[0,[],0,\"Importantly, serverless isnâ€™t some esoteric technology that is far ahead of where developers are today. Serverless is here now. According to Datadogâ€™s \"],[0,[12],1,\"2022 State of Serverless\"],[0,[],0,\" report, over half of the organizations surveyed in each of the major public clouds have already adopted serverless in some fashion. For AWS in particular that number is over 70%.\"]]],[1,\"p\",[[0,[],0,\"And yet streaming data systems havenâ€™t kept pace. Developers today who want to pair streaming data with a serverless approach are largely figuring it out on their own.\"]]],[1,\"p\",[[0,[],0,\"We believe that serverless, in addition to \"],[0,[13],1,\"Redpandaâ€™s planned WebAssembly capabilities\"],[0,[],0,\", is the last major step toward unlocking accessible streaming and event-based systems for the great majority of developers out there. Developers will be able to talk to a streaming data system in their native tongue and perform data transformations on the fly, almost like a universal Google Translate for streaming data.\"]]],[1,\"p\",[[0,[],0,\"With JavaScript and Python being the worldâ€™s most popular programming languages broadly and most used specifically within serverless functions, Redpandaâ€™s upcoming serverless offerings will expand the relevant, addressable audience for streaming data by an order of magnitude or more.\"]]],[1,\"h2\",[[0,[],0,\"Monitoring that even Franz Kafka would approve of\"]]],[1,\"p\",[[0,[],0,\"Streaming systems can be daunting, intimidating systems that are difficult to manage for the average developer. These difficulties are made no easier by the fact that the command line (i.e. a dark screen with some white text scrawled over it) is often the default way to manage these systems. Ad hoc inspection and analysis is much harder than it should be.\"]]],[1,\"p\",[[0,[],0,\"This is especially frustrating during crisis situations, such as production infrastructure going down. In such situations, time is of the essence, and engineers donâ€™t have time to wrestle information out of their tools, searching for obscure command line invocations that they didnâ€™t even know existed. Once the information is located, it often appears as a torrential downpour of logs and metrics, with little to no organization or formatting. Weâ€™ve all been there.\"]]],[1,\"p\",[[0,[],0,\"This just wonâ€™t do. While many developers swear by their terminals, many would love to have a more visual and intuitive representation of their infrastructure. This is especially true of younger, more junior developers who didnâ€™t grow up writing MS-DOS applications and who have a higher standard for developer experience.\"]]],[1,\"p\",[[0,[14],1,\"Redpanda Console\"],[0,[],0,\" is a single pane of glass for managing the entire Kafka ecosystem. All of your streaming infrastructure in one place, with all the admin capabilities organizations expect:\"]]],[3,\"ul\",[[[0,[],0,\"Observability over clusters, topics, brokers, and partitions\"]],[[0,[],0,\"Ability to easily change consumer group offsets\"]],[[0,[],0,\"Management of schema registry, connectors, and Kafka Connect clusters\"]]]],[10,3],[1,\"p\",[[0,[],0,\"But the most impressive thing about Redpanda Console is that itâ€™s not merely a â€œdashboardâ€ with a slew of charts and numbers â€” it goes so much further than that.\"]]],[1,\"p\",[[0,[],0,\"Redpanda Console gives developers data observability superpowers they arenâ€™t used to. This includes capabilities like push-down JavaScript filter, allowing users to filter their clusterâ€™s data at any level of complexity by writing programmable data filters in JavaScript, with encoding support for JSON, Protobuf, Avro, and more.\"]]],[1,\"p\",[[0,[],0,\"The console also simplifies and strengthens access control. The console presents an easy interface for configuring access control lists (ACLs), setting up fine-grained role-based access control (RBAC), and reviewing comprehensive audit logs. It also integrates tightly with all the identity providers youâ€™d expect, like GitHub, Okta, and Google, enabling Single Sign On (SSO) access.\"]]],[10,4],[1,\"blockquote\",[[0,[],0,\"â€œRedpanda Console delivers a tremendous improvement in the productivity, effectiveness and quality of life of developers and operators who work with Redpanda or Kafkaâ€ - \"],[0,[15,9],2,\"Redpanda Console: Putting the â€œfunâ€ back into Kafka\"]]],[1,\"h2\",[[0,[],0,\"Store more\"]]],[1,\"p\",[[0,[],0,\"Okay, so a developer is running Redpanda. Theyâ€™ve spun it up within their own cloud account as enabled by the BYOC model, and they have the beautiful Redpanda Console setup giving them full observability and control over their cluster. Everything is hooked up and data is flowing through Redpanda.\"]]],[1,\"p\",[[0,[],0,\"But all that data has to go somewhere. Itâ€™s time to talk \"],[0,[16],1,\"storage\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Storage is quite important in the context of event-based architectures:\"]]],[3,\"ul\",[[[0,[],0,\"Systems like Redpanda sit between data producers and consumers, allowing each to go about their business without having to worry about what the other side is doing.\"]],[[0,[],0,\"However, due to severing this tie between producers and consumers, the responsibility of confirming successful writes falls on the streaming system.\"]],[[0,[],0,\"Data can be produced well in advance of being consumed, so streaming systems must guarantee that no data gets lost in the shuffle.\"]]]],[1,\"p\",[[0,[],0,\"This is why Redpanda went out of its way to \"],[0,[17],1,\"submit itself for testing\"],[0,[],0,\" by trusted third parties like \"],[0,[18],1,\"Jepsen\"],[0,[],0,\".\"]]],[1,\"blockquote\",[[0,[],0,\"â€œHow did Redpanda fare in its Jepsen testing? Redpanda is a safe system without known consistency problems. The consensus layer is solid. The idempotency and transactional layers had issues that we have already fixed. The only consistency findings we havenâ€™t addressed reflect unusual properties of the Apache Kafka protocol itself, rather than of a particular implementation.â€ - \"],[0,[19,9],2,\"Redpandaâ€™s official Jepsen report\"]]],[1,\"p\",[[0,[],0,\"But itâ€™s not just about the \"],[0,[20],1,\"CAP theorem\"],[0,[],0,\" and distributed systems. Putting on our investor â€œcapâ€ for a second â€” data gravity is how nearly every mission-critical data system of the past generated significant value for its creators and its customers. For a data infrastructure company to build a large and valuable business, it must hold and retain customer data for extended periods of time. Ephemerality wonâ€™t cut it:\"]]],[3,\"ul\",[[[0,[],0,\"Such a data system cannot merely be a place where data passes through on its way to its final destination. Such architectures and usage patterns have rarely generated multi-billion dollar outcomes. Instead, the system in question must become a trusted place for developers and organizations to store data on an ongoing basis\"]],[[0,[],0,\"Users must be able to trust that once ingested, the data will always be there (or at least as long as their data retention policies demand).\"]],[[0,[],0,\"Users must also trust that, once the data is there, it will be easily queryable and accessible.\"]]]],[1,\"h2\",[[0,[],0,\"A sane default: the cloud\"]]],[1,\"p\",[[0,[],0,\"Here too, Redpanda has it covered. Presciently, the team built Redpanda with the cloud as its default storage tier. This is a stronger statement than merely being â€œcloud-nativeâ€: Redpanda intelligently manages reads and writes behind the scenes to provide the lowest friction and highest performance, effectively becoming an infinite storage destination:\"]]],[1,\"blockquote\",[[0,[],0,\"â€œMaking cloud the default storage tier unlocks new streaming data use cases that were once considered out of reach. The long-term data retention capability encourages businesses to treat Redpanda as the â€œsingle source of truthâ€ for their historical records.â€ - \"],[0,[21,9],2,\"How Redpandaâ€™s cloud-first storage model reduces TCO\"]]],[1,\"p\",[[0,[],0,\"In addition to unlimited data retention, Redpandaâ€™s cloud-first architecture enables:\"]]],[3,\"ul\",[[[0,[22],1,\"Remote read replicas\"],[0,[],0,\" â€” a â€œCDNâ€ for your streaming data, enabling developers to spin up and hydrate a new Redpanda cluster with mirrored data from an existing cluster, even across zones and regions\"]],[[0,[23],1,\"Inexpensive disaster recovery\"],[0,[],0,\" â€” smooth failovers, with no need to maintain a separate data replication mechanism\"]],[[0,[24],1,\"Reduced data management, admin, and toil\"],[0,[],0,\" â€” Continuous data balancing, self-healing clusters, and unified retention controls\"]]]],[1,\"p\",[[0,[],0,\"Redpanda accomplishes this with its \"],[0,[25],1,\"Shadowing Indexing\"],[0,[],0,\" architecture, which was built from scratch to support cloud-native \"],[0,[26],1,\"Tiered Storage\"],[0,[],0,\", enabling Redpanda to seamlessly move data between brokers and reliable, cheap cloud stores like Amazon S3 or Google Cloud Storage (GCS). Users can access their data using the same Redpanda/Kafka APIs theyâ€™re used to, while getting infinite data retention and scalability for free.\"]]],[10,5],[1,\"p\",[[0,[],0,\"The upshot of all this innovation is amazing ease of use and performance at an incredibly low cost.\"]]],[1,\"h2\",[[0,[],0,\"Data unchained\"]]],[1,\"p\",[[0,[],0,\"Weâ€™ve already talked a bit about \"],[0,[10],1,\"data sovereignty\"],[0,[],0,\" in the context of the cloud, where security and retaining control of enterprise data are key concerns. Thatâ€™s a very \"],[0,[16],1,\"literal\"],[0,[],0,\" interpretation of sovereignty. But thereâ€™s another, potentially equally important notion of control that developers and organizations care about, but often give up as a side effect of adopting cloud data stores. Often enough, one doesnâ€™t even realize something has been lost until youâ€™re in too deep.\"]]],[1,\"blockquote\",[[0,[],0,\"â€œData sovereignty is much harder to achieve than data privacy. Privacy can be achieved with policy: delete this, mask that, obfuscate here, index like so. Sovereignty can only be achieved if you, the user, control the hard drive lifecycle where data resides. There are no two ways about it. Data either lives inside the hard drives that you control or it does not.â€ - \"],[0,[10,9],2,\"Data sovereignty is the future of cloud\"]]],[1,\"p\",[[0,[],0,\"Redpanda believes developers should control the data they produce. This goes without saying in the world of on-prem. However, we cannot take this for granted in the era of the cloud:\"]]],[3,\"ul\",[[[0,[],0,\"That hard drive holding your data is no longer running in your data center â€” itâ€™s running in someone elseâ€™s.\"]],[[0,[],0,\"Further, once it ends up in that external store, many vendors erect all sorts of barriers to accessing and manipulating the data: esoteric and proprietary data formats, domain-specific query languages, egregious egress fees, and the like.\"]]]],[1,\"p\",[[0,[],0,\"These arenâ€™t (pleasant sounding) data lakes or even (somewhat less enticing) data warehouses, theyâ€™re \"],[0,[16],1,\"data jails\"],[0,[],0,\", and the vendor holds the only key. As far as Redpanda is concerned, that isnâ€™t true data sovereignty.\"]]],[1,\"p\",[[0,[],0,\"Redpanda wants to fix this. Leveraging popular open data formats like \"],[0,[27],1,\"Apache Iceberg\"],[0,[],0,\" and the unique BYOC architecture we discussed earlier, Redpanda will enable developers to finally regain ownership over their data. Developers will be able to pick their preferred storage vendor while maintaining ownership, queryability, indexing, and portability no matter where the data ends up. Today itâ€™s S3, tomorrow itâ€™s Snowflake and Databricks, and in the future, itâ€™ll be any vendor theyâ€™d like. Organizations will also be able to bring their own query engines to the data, no matter the underlying data format.\"]]],[1,\"p\",[[0,[],0,\"Developers will once again own their data. All enabled by Redpanda.\"]]],[1,\"h2\",[[0,[],0,\"Conclusion\"]]],[1,\"p\",[[0,[],0,\"Redpanda meets developers where they are and then enables them to go even further. That reach will push Redpanda to places no streaming system has gone before, driving a level of mission-criticality beyond most other developer infrastructure. The ease of use and incredible flexibility of Redpanda will generate developer love and appreciation for the product. And, with infinite retention and a strong commitment to data sovereignty, Redpandaâ€™s â€œdata gravityâ€ will only grow.\"]]],[10,6],[1,\"p\",[[0,[],0,\"Itâ€™s why we were so excited to lead their recent \"],[0,[28],1,\"$100M Series C financing\"],[0,[],0,\". The real-time revolution has only just begun, and Redpanda is leading the charge.\"]]]],\"ghostVersion\":\"4.0\"}","html":"<p>Real-time data systems tend not to have amazing developer experiences. There are two core reasons.</p><p>One, the developer experience for the engine itself is poor. Streaming engines tend to be difficult to use, difficult to spin up, and difficult to operate on an ongoing basis, as they have a ton of moving parts and complexity to manage. This is especially painful when trying to self-host, develop locally, or integrate into a modern <a href=\"https://redpanda.com/blog/test-driven-development-ci-testing-kafka\">continuous integration/deployment (CI/CD) pipeline</a>. As a result, only the most sophisticated and experienced engineers can make proper use of these systems, leaving behind most software developers and narrowing the market for event-based architectures.</p><p>Second, most streaming data systems donâ€™t integrate well into the rest of the developer workflow, and they lack many of the â€œcreature comfortsâ€ developers are used to seeing in their other tools. The modern developer workflow extends much further out and is much broader in scope than the streaming engine itself. For streaming engines to cement their place in the hearts and minds of developers, they must offer solutions to the rest of the puzzle.</p><p>Weâ€™ve talked before about <a href=\"https://medium.com/lightspeed-venture-partners/why-developers-love-redpanda-30bf2f3b8231\">why developers love</a> Redpandaâ€™s core developer experience, which is leaps and bounds above whatâ€™s come before in the streaming space. With <a href=\"https://thenewstack.io/raft-native-the-foundation-for-streaming-datas-best-future/\">native Raft</a>, no JVM, and full Kafka compatibility, Redpanda enables developers to do their best work, reducing unnecessary complexity and toil while doing it all at the <a href=\"https://redpanda.com/blog/redpanda-vs-kafka-performance-benchmark\">highest throughput, lowest latency</a>, and, importantly, <a href=\"https://redpanda.com/platform-tco\">lowest cost</a>.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2025/03/6687382f21aa7598bd65ede7_blog-lightspeed-img1-1.png\" class=\"kg-image\" alt=\"Comparison of infrastructure and admin costs between Redpanda and Kafka\" loading=\"lazy\" width=\"1128\" height=\"636\" srcset=\"__GHOST_URL__/content/images/size/w600/2025/03/6687382f21aa7598bd65ede7_blog-lightspeed-img1-1.png 600w, __GHOST_URL__/content/images/size/w1000/2025/03/6687382f21aa7598bd65ede7_blog-lightspeed-img1-1.png 1000w, __GHOST_URL__/content/images/2025/03/6687382f21aa7598bd65ede7_blog-lightspeed-img1-1.png 1128w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Comparison of infrastructure and admin costs between Redpanda and Kafka</figcaption></figure><p>But itâ€™s also important to address that second point â€” how Redpanda creates a holistic developer experience that services all aspects of the modern developerâ€™s workflow, from deployment to monitoring and Day 2 operations to long-term storage. These remain unresolved, â€œopen loopsâ€ that have prevented a broader audience of developers and organizations from taking advantage of real-time capabilities.</p><p>At Lightspeed, itâ€™s our core belief that thereâ€™s a potentially massive market expansion opportunity for real-time, streaming data systems. Opening up this opportunity will require thinking much bigger about what a streaming engine can be and do.</p><p>Thatâ€™s where Redpanda comes in.</p><h2 id=\"spinning-up-without-spinning-your-wheels\">Spinning up without spinning your wheels</h2><p>Too often, developers looking to deploy streaming data systems are left to their own devices when it comes to deployment. Deployment is often a mess, involving multiple separate binaries, each with its own peculiarities, requiring engineers to develop expertise in systems they couldn't care less about and in which they have no comparative advantage. Streaming systems can easily become one of the most painful pieces of infrastructure theyâ€™ll deploy.</p><p>Further, developers increasingly see the cloud as their default deployment platform. In the same way that SaaS relieves some of the operational burden of running software by offloading that to the vendor, developers would love to be able to consume cloud-based streaming services with as few wrinkles as possible. Developers want a cloud experience but their organizations donâ€™t want to lose data sovereignty. They need a security model that works within the constraints of the typical enterprise while also getting the ease of use of the cloud â€” <a href=\"https://redpanda.com/blog/deploy-redpanda-clusters-cloud-aws-gcp\">the best of both worlds</a>.</p><p>Lastly, developers on the bleeding edge donâ€™t want to think about infrastructure at all, cloud or otherwise. They donâ€™t want to think about servers, machines, nodes, availability zones, or regions. They want access to true streaming as a service rather than streaming as a server. In other words, they want serverless, and they want it now.</p><p>The modern developer experience requires a modern platform. Redpanda is that platform.</p><p>Hereâ€™s how Redpanda makes deployment a breeze.</p><h2 id=\"one-binary-to-rule-them-all\">One binary to rule them all</h2><p>The core of the Redpanda deployment model is the way its nodes are architected. Redpanda nodes are <a href=\"https://redpanda.com/blog/single-binary-architecture\">fully-contained processes</a> that ship with everything needed in a modern streaming system, including an HTTP proxy, a Raft-based consensus mechanism, and a schema registry. Every node runs the same, single binary, leading to significant operational simplification along with a more efficient overall operating model.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2025/03/6687382d569120c8751b8575_blog-lightspeed-img2.png\" class=\"kg-image\" alt=\"Close up of a self-contained Redpanda node \" loading=\"lazy\" width=\"1340\" height=\"808\" srcset=\"__GHOST_URL__/content/images/size/w600/2025/03/6687382d569120c8751b8575_blog-lightspeed-img2.png 600w, __GHOST_URL__/content/images/size/w1000/2025/03/6687382d569120c8751b8575_blog-lightspeed-img2.png 1000w, __GHOST_URL__/content/images/2025/03/6687382d569120c8751b8575_blog-lightspeed-img2.png 1340w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Close up of a self-contained Redpanda node</figcaption></figure><p>Itâ€™s hard to overstate how game-changing this is. Due to this architecture, running a single Redpanda cluster doesnâ€™t require operating a massive fleet of varying services. This is a massive boon for developer productivity and also enables Redpanda to go where previous streaming systems have struggled, including <a href=\"https://redpanda.com/blog/real-time-security-iot-customer-story\">edge / IoT deployments</a> and CI/CD pipelines with tight performance requirements and resource constraints.</p><blockquote>â€œThe latency and the throughput we got with almost no configuration was incredible. Redpanda is fast, reliable, friction-free and has very low operational overhead.â€ - <a href=\"https://alpaca.markets/\"><u>Alpaca</u></a></blockquote><h2 id=\"hold-my-cloud\">Hold my cloud</h2><p>Redpandaâ€™s cloud turns the table on traditional cloud infrastructure. While the company does offer standard, dedicated, managed clusters in the cloud, they didnâ€™t want to stop there. Redpanda went further, pioneering a deployment model they call <a href=\"https://redpanda.com/blog/deploy-redpanda-clusters-cloud-aws-gcp\">BYOC</a>, or, â€œbring your own cloud.â€ BYOC lets customers deploy Redpanda clusters within their own cloud environment, while still being fully managed by Redpanda.</p><blockquote>â€œBYOCâ€™s privacy-first architecture drives compliance for streaming data, and allows you to scale on your own infrastructure while maintaining data sovereignty requirements.â€ - <a href=\"https://redpanda.com/blog/deploy-redpanda-clusters-cloud-aws-gcp\"><u>Bring Your Own Cloud (BYOC): best of both worlds</u></a></blockquote><p>Redpanda does this by cleanly splitting the control and the data plane. The data plane stays within the customerâ€™s cloud account, while the control plane stays on Redpandaâ€™s side. This creates an incredibly slick and elegant setup, with proper separation of concerns between Redpandaâ€™s and the customerâ€™s cloud environment. With BYOC, organizations get all the benefits of the cloud while retaining <a href=\"https://redpanda.com/blog/kafka-redpanda-future\">data sovereignty</a> and maintaining privacy.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2025/03/6687382d907eec59adc13e52_blog-lightspeed-img3.png\" class=\"kg-image\" alt=\"Diagram of how BYOC keeps the customer cloud separate for data sovereignty and privacy\" loading=\"lazy\" width=\"1076\" height=\"646\" srcset=\"__GHOST_URL__/content/images/size/w600/2025/03/6687382d907eec59adc13e52_blog-lightspeed-img3.png 600w, __GHOST_URL__/content/images/size/w1000/2025/03/6687382d907eec59adc13e52_blog-lightspeed-img3.png 1000w, __GHOST_URL__/content/images/2025/03/6687382d907eec59adc13e52_blog-lightspeed-img3.png 1076w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Diagram of how BYOC keeps the customer cloud separate for data sovereignty and privacy</figcaption></figure><p>Redpanda takes care of everything youâ€™d expect in a modern, competent cloud service, like provisioning, monitoring, and maintenance, while sensitive data and credentials never leave the customer environment. Rolling upgrades that the customer can control ensure zero application downtime. For obvious reasons, BYOC has become an incredibly popular deployment paradigm among Redpanda users.</p><blockquote>â€œRedpanda BYOC gives us a fully managed Kafka service running on our own cloud servers, balancing our internal compliance requirements with ease of use, and without compromising performance and compatibility.â€ - <a href=\"https://liveramp.com/\"><u>LiveRamp</u></a></blockquote><h2 id=\"fewer-servers-better-service\">Fewer servers, better service</h2><p>Lastly, Redpanda is working on a number of exciting features around serverless, a relatively new paradigm within the context of streaming systems. This is their focus on developer experience taken to the logical extreme â€” what a streaming data system could look like from the perspective of a developer who doesnâ€™t want to worry about systems or deployment at all.</p><p>Importantly, serverless isnâ€™t some esoteric technology that is far ahead of where developers are today. Serverless is here now. According to Datadogâ€™s <a href=\"https://www.datadoghq.com/state-of-serverless/\">2022 State of Serverless</a> report, over half of the organizations surveyed in each of the major public clouds have already adopted serverless in some fashion. For AWS in particular that number is over 70%.</p><p>And yet streaming data systems havenâ€™t kept pace. Developers today who want to pair streaming data with a serverless approach are largely figuring it out on their own.</p><p>We believe that serverless, in addition to <a href=\"https://medium.com/lightspeed-venture-partners/webassembly-ing-the-pieces-vectorizeds-data-policy-engine-5ceea983ed5d\">Redpandaâ€™s planned WebAssembly capabilities</a>, is the last major step toward unlocking accessible streaming and event-based systems for the great majority of developers out there. Developers will be able to talk to a streaming data system in their native tongue and perform data transformations on the fly, almost like a universal Google Translate for streaming data.</p><p>With JavaScript and Python being the worldâ€™s most popular programming languages broadly and most used specifically within serverless functions, Redpandaâ€™s upcoming serverless offerings will expand the relevant, addressable audience for streaming data by an order of magnitude or more.</p><h2 id=\"monitoring-that-even-franz-kafka-would-approve-of\">Monitoring that even Franz Kafka would approve of</h2><p>Streaming systems can be daunting, intimidating systems that are difficult to manage for the average developer. These difficulties are made no easier by the fact that the command line (i.e. a dark screen with some white text scrawled over it) is often the default way to manage these systems. Ad hoc inspection and analysis is much harder than it should be.</p><p>This is especially frustrating during crisis situations, such as production infrastructure going down. In such situations, time is of the essence, and engineers donâ€™t have time to wrestle information out of their tools, searching for obscure command line invocations that they didnâ€™t even know existed. Once the information is located, it often appears as a torrential downpour of logs and metrics, with little to no organization or formatting. Weâ€™ve all been there.</p><p>This just wonâ€™t do. While many developers swear by their terminals, many would love to have a more visual and intuitive representation of their infrastructure. This is especially true of younger, more junior developers who didnâ€™t grow up writing MS-DOS applications and who have a higher standard for developer experience.</p><p><a href=\"https://redpanda.com/redpanda-console-kafka-ui\">Redpanda Console</a> is a single pane of glass for managing the entire Kafka ecosystem. All of your streaming infrastructure in one place, with all the admin capabilities organizations expect:</p><ul><li>Observability over clusters, topics, brokers, and partitions</li><li>Ability to easily change consumer group offsets</li><li>Management of schema registry, connectors, and Kafka Connect clusters</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2025/03/6687382d251781c480c13fdc_blog-lightspeed-img4.gif\" class=\"kg-image\" alt=\"Preview of how Redpanda Console serves as a dev-friendly pane of glass.\" loading=\"lazy\" width=\"1457\" height=\"870\"><figcaption>Preview of how Redpanda Console serves as a dev-friendly pane of glass.</figcaption></figure><p>But the most impressive thing about Redpanda Console is that itâ€™s not merely a â€œdashboardâ€ with a slew of charts and numbers â€” it goes so much further than that.</p><p>Redpanda Console gives developers data observability superpowers they arenâ€™t used to. This includes capabilities like push-down JavaScript filter, allowing users to filter their clusterâ€™s data at any level of complexity by writing programmable data filters in JavaScript, with encoding support for JSON, Protobuf, Avro, and more.</p><p>The console also simplifies and strengthens access control. The console presents an easy interface for configuring access control lists (ACLs), setting up fine-grained role-based access control (RBAC), and reviewing comprehensive audit logs. It also integrates tightly with all the identity providers youâ€™d expect, like GitHub, Okta, and Google, enabling Single Sign On (SSO) access.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2025/03/6687382d569120c8751b8579_blog-lightspeed-img5.png\" class=\"kg-image\" alt=\"Screenshot of the Kafka Access Control interface in Redpanda Console.\" loading=\"lazy\" width=\"1086\" height=\"598\" srcset=\"__GHOST_URL__/content/images/size/w600/2025/03/6687382d569120c8751b8579_blog-lightspeed-img5.png 600w, __GHOST_URL__/content/images/size/w1000/2025/03/6687382d569120c8751b8579_blog-lightspeed-img5.png 1000w, __GHOST_URL__/content/images/2025/03/6687382d569120c8751b8579_blog-lightspeed-img5.png 1086w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Screenshot of the Kafka Access Control interface in Redpanda Console.</figcaption></figure><blockquote>â€œRedpanda Console delivers a tremendous improvement in the productivity, effectiveness and quality of life of developers and operators who work with Redpanda or Kafkaâ€ - <a href=\"https://redpanda.com/blog/kafka-ui-redpanda-console\"><u>Redpanda Console: Putting the â€œfunâ€ back into Kafka</u></a></blockquote><h2 id=\"store-more\">Store more</h2><p>Okay, so a developer is running Redpanda. Theyâ€™ve spun it up within their own cloud account as enabled by the BYOC model, and they have the beautiful Redpanda Console setup giving them full observability and control over their cluster. Everything is hooked up and data is flowing through Redpanda.</p><p>But all that data has to go somewhere. Itâ€™s time to talk <em>storage</em>.</p><p>Storage is quite important in the context of event-based architectures:</p><ul><li>Systems like Redpanda sit between data producers and consumers, allowing each to go about their business without having to worry about what the other side is doing.</li><li>However, due to severing this tie between producers and consumers, the responsibility of confirming successful writes falls on the streaming system.</li><li>Data can be produced well in advance of being consumed, so streaming systems must guarantee that no data gets lost in the shuffle.</li></ul><p>This is why Redpanda went out of its way to <a href=\"https://jepsen.io/analyses/redpanda-21.10.1\">submit itself for testing</a> by trusted third parties like <a href=\"https://jepsen.io/\">Jepsen</a>.</p><blockquote>â€œHow did Redpanda fare in its Jepsen testing? Redpanda is a safe system without known consistency problems. The consensus layer is solid. The idempotency and transactional layers had issues that we have already fixed. The only consistency findings we havenâ€™t addressed reflect unusual properties of the Apache Kafka protocol itself, rather than of a particular implementation.â€ - <a href=\"https://redpanda.com/blog/redpanda-official-jepsen-report-and-analysis\"><u>Redpandaâ€™s official Jepsen report</u></a></blockquote><p>But itâ€™s not just about the <a href=\"https://en.wikipedia.org/wiki/CAP_theorem\">CAP theorem</a> and distributed systems. Putting on our investor â€œcapâ€ for a second â€” data gravity is how nearly every mission-critical data system of the past generated significant value for its creators and its customers. For a data infrastructure company to build a large and valuable business, it must hold and retain customer data for extended periods of time. Ephemerality wonâ€™t cut it:</p><ul><li>Such a data system cannot merely be a place where data passes through on its way to its final destination. Such architectures and usage patterns have rarely generated multi-billion dollar outcomes. Instead, the system in question must become a trusted place for developers and organizations to store data on an ongoing basis</li><li>Users must be able to trust that once ingested, the data will always be there (or at least as long as their data retention policies demand).</li><li>Users must also trust that, once the data is there, it will be easily queryable and accessible.</li></ul><h2 id=\"a-sane-default-the-cloud\">A sane default: the cloud</h2><p>Here too, Redpanda has it covered. Presciently, the team built Redpanda with the cloud as its default storage tier. This is a stronger statement than merely being â€œcloud-nativeâ€: Redpanda intelligently manages reads and writes behind the scenes to provide the lowest friction and highest performance, effectively becoming an infinite storage destination:</p><blockquote>â€œMaking cloud the default storage tier unlocks new streaming data use cases that were once considered out of reach. The long-term data retention capability encourages businesses to treat Redpanda as the â€œsingle source of truthâ€ for their historical records.â€ - <a href=\"https://redpanda.com/blog/cloud-native-streaming-data-lower-cost\"><u>How Redpandaâ€™s cloud-first storage model reduces TCO</u></a></blockquote><p>In addition to unlimited data retention, Redpandaâ€™s cloud-first architecture enables:</p><ul><li><a href=\"https://redpanda.com/blog/remote-read-replicas-for-distributing-work\">Remote read replicas</a> â€” a â€œCDNâ€ for your streaming data, enabling developers to spin up and hydrate a new Redpanda cluster with mirrored data from an existing cluster, even across zones and regions</li><li><a href=\"https://redpanda.com/blog/high-availability-software-deployment-patterns-part-1\">Inexpensive disaster recovery</a> â€” smooth failovers, with no need to maintain a separate data replication mechanism</li><li><a href=\"https://redpanda.com/blog/engineering-continuous-data-balancing\">Reduced data management, admin, and toil</a> â€” Continuous data balancing, self-healing clusters, and unified retention controls</li></ul><p>Redpanda accomplishes this with its <a href=\"https://redpanda.com/blog/tiered-storage-architecture-shadow-indexing-deep-dive\">Shadowing Indexing</a> architecture, which was built from scratch to support cloud-native <a href=\"https://docs.redpanda.com/docs/manage/tiered-storage/\">Tiered Storage</a>, enabling Redpanda to seamlessly move data between brokers and reliable, cheap cloud stores like Amazon S3 or Google Cloud Storage (GCS). Users can access their data using the same Redpanda/Kafka APIs theyâ€™re used to, while getting infinite data retention and scalability for free.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2025/03/6687382d1dd2b64747bcf80f_blog-lightspeed-img6.png\" class=\"kg-image\" alt=\"Diagram of how Redpandaâ€™s Tiered Storage works with Amazon S3.\" loading=\"lazy\" width=\"1316\" height=\"720\" srcset=\"__GHOST_URL__/content/images/size/w600/2025/03/6687382d1dd2b64747bcf80f_blog-lightspeed-img6.png 600w, __GHOST_URL__/content/images/size/w1000/2025/03/6687382d1dd2b64747bcf80f_blog-lightspeed-img6.png 1000w, __GHOST_URL__/content/images/2025/03/6687382d1dd2b64747bcf80f_blog-lightspeed-img6.png 1316w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Diagram of how Redpandaâ€™s Tiered Storage works with Amazon S3.</figcaption></figure><p>The upshot of all this innovation is amazing ease of use and performance at an incredibly low cost.</p><h2 id=\"data-unchained\">Data unchained</h2><p>Weâ€™ve already talked a bit about <a href=\"https://redpanda.com/blog/kafka-redpanda-future\">data sovereignty</a> in the context of the cloud, where security and retaining control of enterprise data are key concerns. Thatâ€™s a very <em>literal</em> interpretation of sovereignty. But thereâ€™s another, potentially equally important notion of control that developers and organizations care about, but often give up as a side effect of adopting cloud data stores. Often enough, one doesnâ€™t even realize something has been lost until youâ€™re in too deep.</p><blockquote>â€œData sovereignty is much harder to achieve than data privacy. Privacy can be achieved with policy: delete this, mask that, obfuscate here, index like so. Sovereignty can only be achieved if you, the user, control the hard drive lifecycle where data resides. There are no two ways about it. Data either lives inside the hard drives that you control or it does not.â€ - <a href=\"https://redpanda.com/blog/kafka-redpanda-future\"><u>Data sovereignty is the future of cloud</u></a></blockquote><p>Redpanda believes developers should control the data they produce. This goes without saying in the world of on-prem. However, we cannot take this for granted in the era of the cloud:</p><ul><li>That hard drive holding your data is no longer running in your data center â€” itâ€™s running in someone elseâ€™s.</li><li>Further, once it ends up in that external store, many vendors erect all sorts of barriers to accessing and manipulating the data: esoteric and proprietary data formats, domain-specific query languages, egregious egress fees, and the like.</li></ul><p>These arenâ€™t (pleasant sounding) data lakes or even (somewhat less enticing) data warehouses, theyâ€™re <em>data jails</em>, and the vendor holds the only key. As far as Redpanda is concerned, that isnâ€™t true data sovereignty.</p><p>Redpanda wants to fix this. Leveraging popular open data formats like <a href=\"https://redpanda.com/blog/apache-hudi-iceberg-delta-lake-differences\">Apache Iceberg</a> and the unique BYOC architecture we discussed earlier, Redpanda will enable developers to finally regain ownership over their data. Developers will be able to pick their preferred storage vendor while maintaining ownership, queryability, indexing, and portability no matter where the data ends up. Today itâ€™s S3, tomorrow itâ€™s Snowflake and Databricks, and in the future, itâ€™ll be any vendor theyâ€™d like. Organizations will also be able to bring their own query engines to the data, no matter the underlying data format.</p><p>Developers will once again own their data. All enabled by Redpanda.</p><h2 id=\"conclusion\">Conclusion</h2><p>Redpanda meets developers where they are and then enables them to go even further. That reach will push Redpanda to places no streaming system has gone before, driving a level of mission-criticality beyond most other developer infrastructure. The ease of use and incredible flexibility of Redpanda will generate developer love and appreciation for the product. And, with infinite retention and a strong commitment to data sovereignty, Redpandaâ€™s â€œdata gravityâ€ will only grow.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2025/03/66a3d55edc368c41e27704d1_66873620cc1c1391aec633b1_blog-gaming-img2.png\" class=\"kg-image\" alt=\"Diagram of the Redpanda compatibility ecosystem\" loading=\"lazy\" width=\"926\" height=\"457\" srcset=\"__GHOST_URL__/content/images/size/w600/2025/03/66a3d55edc368c41e27704d1_66873620cc1c1391aec633b1_blog-gaming-img2.png 600w, __GHOST_URL__/content/images/2025/03/66a3d55edc368c41e27704d1_66873620cc1c1391aec633b1_blog-gaming-img2.png 926w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Diagram of the Redpanda compatibility ecosystem</figcaption></figure><p>Itâ€™s why we were so excited to lead their recent <a href=\"https://medium.com/lightspeed-venture-partners/why-lightspeed-is-leading-redpandas-100-million-series-c-553ffe38d6e\">$100M Series C financing</a>. The real-time revolution has only just begun, and Redpanda is leading the charge.</p>","comment_id":"657139f9fec7d1542d1d2f32","plaintext":"Real-time data systems tend not to have amazing developer experiences. There are\ntwo core reasons.\n\nOne, the developer experience for the engine itself is poor. Streaming engines\ntend to be difficult to use, difficult to spin up, and difficult to operate on\nan ongoing basis, as they have a ton of moving parts and complexity to manage.\nThis is especially painful when trying to self-host, develop locally, or\nintegrate into a modern continuous integration/deployment (CI/CD) pipeline\n[https://redpanda.com/blog/test-driven-development-ci-testing-kafka]. As a\nresult, only the most sophisticated and experienced engineers can make proper\nuse of these systems, leaving behind most software developers and narrowing the\nmarket for event-based architectures.\n\nSecond, most streaming data systems donâ€™t integrate well into the rest of the\ndeveloper workflow, and they lack many of the â€œcreature comfortsâ€ developers are\nused to seeing in their other tools. The modern developer workflow extends much\nfurther out and is much broader in scope than the streaming engine itself. For\nstreaming engines to cement their place in the hearts and minds of developers,\nthey must offer solutions to the rest of the puzzle.\n\nWeâ€™ve talked before about why developers love\n[https://medium.com/lightspeed-venture-partners/why-developers-love-redpanda-30bf2f3b8231] \nRedpandaâ€™s core developer experience, which is leaps and bounds above whatâ€™s\ncome before in the streaming space. With native Raft\n[https://thenewstack.io/raft-native-the-foundation-for-streaming-datas-best-future/]\n, no JVM, and full Kafka compatibility, Redpanda enables developers to do their\nbest work, reducing unnecessary complexity and toil while doing it all at the \nhighest throughput, lowest latency\n[https://redpanda.com/blog/redpanda-vs-kafka-performance-benchmark], and,\nimportantly, lowest cost [https://redpanda.com/platform-tco].\n\nComparison of infrastructure and admin costs between Redpanda and KafkaBut itâ€™s\nalso important to address that second point â€” how Redpanda creates a holistic\ndeveloper experience that services all aspects of the modern developerâ€™s\nworkflow, from deployment to monitoring and Day 2 operations to long-term\nstorage. These remain unresolved, â€œopen loopsâ€ that have prevented a broader\naudience of developers and organizations from taking advantage of real-time\ncapabilities.\n\nAt Lightspeed, itâ€™s our core belief that thereâ€™s a potentially massive market\nexpansion opportunity for real-time, streaming data systems. Opening up this\nopportunity will require thinking much bigger about what a streaming engine can\nbe and do.\n\nThatâ€™s where Redpanda comes in.\n\nSpinning up without spinning your wheels\nToo often, developers looking to deploy streaming data systems are left to their\nown devices when it comes to deployment. Deployment is often a mess, involving\nmultiple separate binaries, each with its own peculiarities, requiring engineers\nto develop expertise in systems they couldn't care less about and in which they\nhave no comparative advantage. Streaming systems can easily become one of the\nmost painful pieces of infrastructure theyâ€™ll deploy.\n\nFurther, developers increasingly see the cloud as their default deployment\nplatform. In the same way that SaaS relieves some of the operational burden of\nrunning software by offloading that to the vendor, developers would love to be\nable to consume cloud-based streaming services with as few wrinkles as possible.\nDevelopers want a cloud experience but their organizations donâ€™t want to lose\ndata sovereignty. They need a security model that works within the constraints\nof the typical enterprise while also getting the ease of use of the cloud â€” the\nbest of both worlds\n[https://redpanda.com/blog/deploy-redpanda-clusters-cloud-aws-gcp].\n\nLastly, developers on the bleeding edge donâ€™t want to think about infrastructure\nat all, cloud or otherwise. They donâ€™t want to think about servers, machines,\nnodes, availability zones, or regions. They want access to true streaming as a\nservice rather than streaming as a server. In other words, they want serverless,\nand they want it now.\n\nThe modern developer experience requires a modern platform. Redpanda is that\nplatform.\n\nHereâ€™s how Redpanda makes deployment a breeze.\n\nOne binary to rule them all\nThe core of the Redpanda deployment model is the way its nodes are architected.\nRedpanda nodes are fully-contained processes\n[https://redpanda.com/blog/single-binary-architecture] that ship with everything\nneeded in a modern streaming system, including an HTTP proxy, a Raft-based\nconsensus mechanism, and a schema registry. Every node runs the same, single\nbinary, leading to significant operational simplification along with a more\nefficient overall operating model.\n\nClose up of a self-contained Redpanda nodeItâ€™s hard to overstate how\ngame-changing this is. Due to this architecture, running a single Redpanda\ncluster doesnâ€™t require operating a massive fleet of varying services. This is a\nmassive boon for developer productivity and also enables Redpanda to go where\nprevious streaming systems have struggled, including edge / IoT deployments\n[https://redpanda.com/blog/real-time-security-iot-customer-story] and CI/CD\npipelines with tight performance requirements and resource constraints.\n\n> â€œThe latency and the throughput we got with almost no configuration was\nincredible. Redpanda is fast, reliable, friction-free and has very low\noperational overhead.â€ - Alpaca [https://alpaca.markets/]\nHold my cloud\nRedpandaâ€™s cloud turns the table on traditional cloud infrastructure. While the\ncompany does offer standard, dedicated, managed clusters in the cloud, they\ndidnâ€™t want to stop there. Redpanda went further, pioneering a deployment model\nthey call BYOC\n[https://redpanda.com/blog/deploy-redpanda-clusters-cloud-aws-gcp], or, â€œbring\nyour own cloud.â€ BYOC lets customers deploy Redpanda clusters within their own\ncloud environment, while still being fully managed by Redpanda.\n\n> â€œBYOCâ€™s privacy-first architecture drives compliance for streaming data, and\nallows you to scale on your own infrastructure while maintaining data\nsovereignty requirements.â€ - Bring Your Own Cloud (BYOC): best of both worlds\n[https://redpanda.com/blog/deploy-redpanda-clusters-cloud-aws-gcp]\nRedpanda does this by cleanly splitting the control and the data plane. The data\nplane stays within the customerâ€™s cloud account, while the control plane stays\non Redpandaâ€™s side. This creates an incredibly slick and elegant setup, with\nproper separation of concerns between Redpandaâ€™s and the customerâ€™s cloud\nenvironment. With BYOC, organizations get all the benefits of the cloud while\nretaining data sovereignty [https://redpanda.com/blog/kafka-redpanda-future] and\nmaintaining privacy.\n\nDiagram of how BYOC keeps the customer cloud separate for data sovereignty and\nprivacyRedpanda takes care of everything youâ€™d expect in a modern, competent\ncloud service, like provisioning, monitoring, and maintenance, while sensitive\ndata and credentials never leave the customer environment. Rolling upgrades that\nthe customer can control ensure zero application downtime. For obvious reasons,\nBYOC has become an incredibly popular deployment paradigm among Redpanda users.\n\n> â€œRedpanda BYOC gives us a fully managed Kafka service running on our own cloud\nservers, balancing our internal compliance requirements with ease of use, and\nwithout compromising performance and compatibility.â€ - LiveRamp\n[https://liveramp.com/]\nFewer servers, better service\nLastly, Redpanda is working on a number of exciting features around serverless,\na relatively new paradigm within the context of streaming systems. This is their\nfocus on developer experience taken to the logical extreme â€” what a streaming\ndata system could look like from the perspective of a developer who doesnâ€™t want\nto worry about systems or deployment at all.\n\nImportantly, serverless isnâ€™t some esoteric technology that is far ahead of\nwhere developers are today. Serverless is here now. According to Datadogâ€™s 2022\nState of Serverless [https://www.datadoghq.com/state-of-serverless/] report,\nover half of the organizations surveyed in each of the major public clouds have\nalready adopted serverless in some fashion. For AWS in particular that number is\nover 70%.\n\nAnd yet streaming data systems havenâ€™t kept pace. Developers today who want to\npair streaming data with a serverless approach are largely figuring it out on\ntheir own.\n\nWe believe that serverless, in addition to Redpandaâ€™s planned WebAssembly\ncapabilities\n[https://medium.com/lightspeed-venture-partners/webassembly-ing-the-pieces-vectorizeds-data-policy-engine-5ceea983ed5d]\n, is the last major step toward unlocking accessible streaming and event-based\nsystems for the great majority of developers out there. Developers will be able\nto talk to a streaming data system in their native tongue and perform data\ntransformations on the fly, almost like a universal Google Translate for\nstreaming data.\n\nWith JavaScript and Python being the worldâ€™s most popular programming languages\nbroadly and most used specifically within serverless functions, Redpandaâ€™s\nupcoming serverless offerings will expand the relevant, addressable audience for\nstreaming data by an order of magnitude or more.\n\nMonitoring that even Franz Kafka would approve of\nStreaming systems can be daunting, intimidating systems that are difficult to\nmanage for the average developer. These difficulties are made no easier by the\nfact that the command line (i.e. a dark screen with some white text scrawled\nover it) is often the default way to manage these systems. Ad hoc inspection and\nanalysis is much harder than it should be.\n\nThis is especially frustrating during crisis situations, such as production\ninfrastructure going down. In such situations, time is of the essence, and\nengineers donâ€™t have time to wrestle information out of their tools, searching\nfor obscure command line invocations that they didnâ€™t even know existed. Once\nthe information is located, it often appears as a torrential downpour of logs\nand metrics, with little to no organization or formatting. Weâ€™ve all been there.\n\nThis just wonâ€™t do. While many developers swear by their terminals, many would\nlove to have a more visual and intuitive representation of their infrastructure.\nThis is especially true of younger, more junior developers who didnâ€™t grow up\nwriting MS-DOS applications and who have a higher standard for developer\nexperience.\n\nRedpanda Console [https://redpanda.com/redpanda-console-kafka-ui] is a single\npane of glass for managing the entire Kafka ecosystem. All of your streaming\ninfrastructure in one place, with all the admin capabilities organizations\nexpect:\n\n * Observability over clusters, topics, brokers, and partitions\n * Ability to easily change consumer group offsets\n * Management of schema registry, connectors, and Kafka Connect clusters\n\nPreview of how Redpanda Console serves as a dev-friendly pane of glass.But the\nmost impressive thing about Redpanda Console is that itâ€™s not merely a\nâ€œdashboardâ€ with a slew of charts and numbers â€” it goes so much further than\nthat.\n\nRedpanda Console gives developers data observability superpowers they arenâ€™t\nused to. This includes capabilities like push-down JavaScript filter, allowing\nusers to filter their clusterâ€™s data at any level of complexity by writing\nprogrammable data filters in JavaScript, with encoding support for JSON,\nProtobuf, Avro, and more.\n\nThe console also simplifies and strengthens access control. The console presents\nan easy interface for configuring access control lists (ACLs), setting up\nfine-grained role-based access control (RBAC), and reviewing comprehensive audit\nlogs. It also integrates tightly with all the identity providers youâ€™d expect,\nlike GitHub, Okta, and Google, enabling Single Sign On (SSO) access.\n\nScreenshot of the Kafka Access Control interface in Redpanda Console.> â€œRedpanda\nConsole delivers a tremendous improvement in the productivity, effectiveness and\nquality of life of developers and operators who work with Redpanda or Kafkaâ€ - \nRedpanda Console: Putting the â€œfunâ€ back into Kafka\n[https://redpanda.com/blog/kafka-ui-redpanda-console]\nStore more\nOkay, so a developer is running Redpanda. Theyâ€™ve spun it up within their own\ncloud account as enabled by the BYOC model, and they have the beautiful Redpanda\nConsole setup giving them full observability and control over their cluster.\nEverything is hooked up and data is flowing through Redpanda.\n\nBut all that data has to go somewhere. Itâ€™s time to talk storage.\n\nStorage is quite important in the context of event-based architectures:\n\n * Systems like Redpanda sit between data producers and consumers, allowing each\n   to go about their business without having to worry about what the other side\n   is doing.\n * However, due to severing this tie between producers and consumers, the\n   responsibility of confirming successful writes falls on the streaming system.\n * Data can be produced well in advance of being consumed, so streaming systems\n   must guarantee that no data gets lost in the shuffle.\n\nThis is why Redpanda went out of its way to submit itself for testing\n[https://jepsen.io/analyses/redpanda-21.10.1] by trusted third parties like \nJepsen [https://jepsen.io/].\n\n> â€œHow did Redpanda fare in its Jepsen testing? Redpanda is a safe system without\nknown consistency problems. The consensus layer is solid. The idempotency and\ntransactional layers had issues that we have already fixed. The only consistency\nfindings we havenâ€™t addressed reflect unusual properties of the Apache Kafka\nprotocol itself, rather than of a particular implementation.â€ - Redpandaâ€™s\nofficial Jepsen report\n[https://redpanda.com/blog/redpanda-official-jepsen-report-and-analysis]\nBut itâ€™s not just about the CAP theorem\n[https://en.wikipedia.org/wiki/CAP_theorem] and distributed systems. Putting on\nour investor â€œcapâ€ for a second â€” data gravity is how nearly every\nmission-critical data system of the past generated significant value for its\ncreators and its customers. For a data infrastructure company to build a large\nand valuable business, it must hold and retain customer data for extended\nperiods of time. Ephemerality wonâ€™t cut it:\n\n * Such a data system cannot merely be a place where data passes through on its\n   way to its final destination. Such architectures and usage patterns have\n   rarely generated multi-billion dollar outcomes. Instead, the system in\n   question must become a trusted place for developers and organizations to\n   store data on an ongoing basis\n * Users must be able to trust that once ingested, the data will always be there\n   (or at least as long as their data retention policies demand).\n * Users must also trust that, once the data is there, it will be easily\n   queryable and accessible.\n\nA sane default: the cloud\nHere too, Redpanda has it covered. Presciently, the team built Redpanda with the\ncloud as its default storage tier. This is a stronger statement than merely\nbeing â€œcloud-nativeâ€: Redpanda intelligently manages reads and writes behind the\nscenes to provide the lowest friction and highest performance, effectively\nbecoming an infinite storage destination:\n\n> â€œMaking cloud the default storage tier unlocks new streaming data use cases that\nwere once considered out of reach. The long-term data retention capability\nencourages businesses to treat Redpanda as the â€œsingle source of truthâ€ for\ntheir historical records.â€ - How Redpandaâ€™s cloud-first storage model reduces\nTCO [https://redpanda.com/blog/cloud-native-streaming-data-lower-cost]\nIn addition to unlimited data retention, Redpandaâ€™s cloud-first architecture\nenables:\n\n * Remote read replicas\n   [https://redpanda.com/blog/remote-read-replicas-for-distributing-work] â€” a\n   â€œCDNâ€ for your streaming data, enabling developers to spin up and hydrate a\n   new Redpanda cluster with mirrored data from an existing cluster, even across\n   zones and regions\n * Inexpensive disaster recovery\n   [https://redpanda.com/blog/high-availability-software-deployment-patterns-part-1] \n   â€” smooth failovers, with no need to maintain a separate data replication\n   mechanism\n * Reduced data management, admin, and toil\n   [https://redpanda.com/blog/engineering-continuous-data-balancing] â€”\n   Continuous data balancing, self-healing clusters, and unified retention\n   controls\n\nRedpanda accomplishes this with its Shadowing Indexing\n[https://redpanda.com/blog/tiered-storage-architecture-shadow-indexing-deep-dive] \narchitecture, which was built from scratch to support cloud-native Tiered\nStorage [https://docs.redpanda.com/docs/manage/tiered-storage/], enabling\nRedpanda to seamlessly move data between brokers and reliable, cheap cloud\nstores like Amazon S3 or Google Cloud Storage (GCS). Users can access their data\nusing the same Redpanda/Kafka APIs theyâ€™re used to, while getting infinite data\nretention and scalability for free.\n\nDiagram of how Redpandaâ€™s Tiered Storage works with Amazon S3.The upshot of all\nthis innovation is amazing ease of use and performance at an incredibly low\ncost.\n\nData unchained\nWeâ€™ve already talked a bit about data sovereignty\n[https://redpanda.com/blog/kafka-redpanda-future] in the context of the cloud,\nwhere security and retaining control of enterprise data are key concerns. Thatâ€™s\na very literal interpretation of sovereignty. But thereâ€™s another, potentially\nequally important notion of control that developers and organizations care\nabout, but often give up as a side effect of adopting cloud data stores. Often\nenough, one doesnâ€™t even realize something has been lost until youâ€™re in too\ndeep.\n\n> â€œData sovereignty is much harder to achieve than data privacy. Privacy can be\nachieved with policy: delete this, mask that, obfuscate here, index like so.\nSovereignty can only be achieved if you, the user, control the hard drive\nlifecycle where data resides. There are no two ways about it. Data either lives\ninside the hard drives that you control or it does not.â€ - Data sovereignty is\nthe future of cloud [https://redpanda.com/blog/kafka-redpanda-future]\nRedpanda believes developers should control the data they produce. This goes\nwithout saying in the world of on-prem. However, we cannot take this for granted\nin the era of the cloud:\n\n * That hard drive holding your data is no longer running in your data center â€”\n   itâ€™s running in someone elseâ€™s.\n * Further, once it ends up in that external store, many vendors erect all sorts\n   of barriers to accessing and manipulating the data: esoteric and proprietary\n   data formats, domain-specific query languages, egregious egress fees, and the\n   like.\n\nThese arenâ€™t (pleasant sounding) data lakes or even (somewhat less enticing)\ndata warehouses, theyâ€™re data jails, and the vendor holds the only key. As far\nas Redpanda is concerned, that isnâ€™t true data sovereignty.\n\nRedpanda wants to fix this. Leveraging popular open data formats like Apache\nIceberg [https://redpanda.com/blog/apache-hudi-iceberg-delta-lake-differences] \nand the unique BYOC architecture we discussed earlier, Redpanda will enable\ndevelopers to finally regain ownership over their data. Developers will be able\nto pick their preferred storage vendor while maintaining ownership,\nqueryability, indexing, and portability no matter where the data ends up. Today\nitâ€™s S3, tomorrow itâ€™s Snowflake and Databricks, and in the future, itâ€™ll be any\nvendor theyâ€™d like. Organizations will also be able to bring their own query\nengines to the data, no matter the underlying data format.\n\nDevelopers will once again own their data. All enabled by Redpanda.\n\nConclusion\nRedpanda meets developers where they are and then enables them to go even\nfurther. That reach will push Redpanda to places no streaming system has gone\nbefore, driving a level of mission-criticality beyond most other developer\ninfrastructure. The ease of use and incredible flexibility of Redpanda will\ngenerate developer love and appreciation for the product. And, with infinite\nretention and a strong commitment to data sovereignty, Redpandaâ€™s â€œdata gravityâ€\nwill only grow.\n\nDiagram of the Redpanda compatibility ecosystemItâ€™s why we were so excited to\nlead their recent $100M Series C financing\n[https://medium.com/lightspeed-venture-partners/why-lightspeed-is-leading-redpandas-100-million-series-c-553ffe38d6e]\n. The real-time revolution has only just begun, and Redpanda is leading the\ncharge.","feature_image":"__GHOST_URL__/content/images/2023/12/blog-lightspeed-hero.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2023-12-07T03:20:25.000Z","updated_at":"2025-03-31T03:48:12.000Z","published_at":"2023-08-10T02:25:00.000Z","custom_excerpt":"Monitoring that even (Franz) Kafka would approve of","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"659337c7fec7d1542d1d2f50","uuid":"02a7d7bd-7b5a-4231-b673-518f97918c39","title":"The Series A Bust","slug":"series-a-bust","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"It's cold out there in Series A land:\\n\\n![deals_a](__GHOST_URL__/content/images/2024/01/deals_a.png)\\n\\nA common explanation for the Series A winter is raised expectations â€“ investors are demanding to see better metrics and traction. Most companies don't meet this new, higher bar, hence fewer deals get done.\\n\\nWhile certainly true, *this can't be the whole story.* Only if we look at Series As in a vacuum does this explanation seem comprehensive. Incorporating what's happening in the rest of the market, however, there's a much richer narrative to explore.\\n\\nThe bigger picture? In addition to raising their expectations for Series A, investors have lost faith in Series A as a sign of product-market fit.\\n\\n**Series A investors expect more but believe less.**\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: The Series A Bust\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## Relatively speaking\\n\\nValuations for both Seed and Series A stage companies rose dramatically over the last decade or so of venture:\\n\\n![valuations](__GHOST_URL__/content/images/2024/01/valuations.png)\\n\\nThe appreciation in Series A valuations seems extreme relative to that of Seed deals. Of course, the scales here are different, so we'd do better to baseline these to the same starting point and track the growth over time:\\n\\n![valuations_growth](__GHOST_URL__/content/images/2024/01/valuations_growth.png)\\n\\nWhile the two grew roughly in line for the first few years, Series A valuations began to accelerate around 2017. That acceleration sustained itself until the recent fall off in venture valuations.\\n\\nNotably, both Seed and Series A valuations are recovering. That's a small point in favor of the \\\"raised expectations\\\" story â€“ investors are funding higher-quality businesses, deserving of stronger valuations.\\n\\nHere's where the expectations story starts to lose its luster. Below I plot the valuation gap or \\\"premium\\\" for Series A relative to Seed, along with a flexible trend line to remove noise:\\n\\n![premiums_a](__GHOST_URL__/content/images/2024/01/premiums_a.png)\\n\\n* From 2010 to 2014, the two grew roughly in line, with Series As being priced 200% higher or 3x Seed rounds \\n* Then, Series A valuations accelerate relative to Seeds to a 325% premium or 4.25x multiple\\n* In 2019, the Series A premium spikes again, peaking in late 2021 at 500% or 6x\\n* Things collapse after that, ending in Q3 2023 at 2010 levels\\n\\nIf investor expectations told the full story, Series A valuations relative to Seed deals would be *higher* today. Since Seed investments remain speculative and standards have risen for Series A investment, we'd expect the typical Series A to be even *more* valuable relative to Seeds, reflecting higher quality. Instead, the gap has compressed.\\n\\nIt's been quite the rollercoaster ride. Notably, this rollercoaster is unique to Series A / Seed. We don't see remotely the same behavior in the premium between later rounds:\\n\\n![premiums](__GHOST_URL__/content/images/2024/01/premiums.png)\\n\\nThe premium for Series B vs. A and the premium for Series C vs. B are both much more stable over time, with little trend once you remove the noise. The Series C / B premium saw a slight bump during the exuberant 2021 days, but that was short lived:\\n* The Series B / A premium has been roughly 200% for the entire period\\n* The Series C / B premium hovers around 125% with few exceptions\\n\\nFor whatever reason, the way investors value Series A companies relative to Seed stage companies has fluctuated substantially over time (slowly rising and then suddenly falling), while their views on relative value in later stages have held steady.\\n\\nWhy?\\n\\n## Series A University\\n\\nWhat is different about graduating from Seed to Series A than going from Series A to B, Series B to C, etc?\\n\\nThere are many potential explanations, but the one that jumps out to me is some notion of **product-market fit (PMF) and business de-risking.** Series A companies tend to have much better PMF than Seed companies, in a way that's distinct from Series B relative to Series A, and so on.\\n\\nThink about it like higher education â€“ a college degree is a signal of one's skills to the labor market. [Employers value them accordingly.](https://www.clevelandfed.org/publications/economic-commentary/2012/ec-201210-the-college-wage-premium) Further, a college degree means more relative to not having one than having a graduate degree means relative to having only an undergraduate education. Again, employers value them accordingly:\\n![Pasted-image-20231227144822](__GHOST_URL__/content/images/2024/01/Pasted-image-20231227144822.png)\\n\\nWhile the probability of a company achieving PMF is certainly not 100% at the time of Series A (many companies raise Series A before that), it's definitely much higher at the A round than at the Seed round, since it's effectively 0% at that point.\\n\\nStartup risk reduces materially once a company graduates to Series A. In a way, that's exactly why a startup successfully raises its Series A â€“ the founders have de-risked the business, so much so that an investor is willing to invest substantial capital, take a board seat, etc.\\n\\nIf we posit that the \\\"price\\\" or \\\"value\\\" of PMF is well-proxied by the Series A / Seed premium, we can think of this premium moving over time due to fluctuations in the supply (among startups) and demand (among investors) for PMF:\\n* A rising price typically indicates either contracting supply â€“ the relative supply of startups with PMF vs those without â€“ or growing demand â€“ the relative demand for post-PMF startups vs pre-PMF startups\\n* Importantly, these are *relative* concepts â€“ the number of pre and post-PMF startups could be both growing over time, but if the number of pre-PMF startups is growing faster, that would imply a *relative decline* in PMF supply\\n\\n$$\\\\text{Relative Supply of PMF} = \\\\frac{\\\\text{Supply of Post-PMF Startups}}{\\\\text{Supply of Pre-PMF Startups}}$$\\n\\nSo what explains the pre-2022 run up in the Series A / Seed premium: declining (relative) *supply* of PMF or rising (relative) *demand* for PMF?\\n\\nMy argument: **rising demand for PMF.**\\n\\nFirst, as I've argued elsewhere, the growth and development of the venture ecosystem has been a mostly demand-side story. That should strongly bias us toward the demand explanation:\\n> Investors are the primary driver of fluctuations in venture activity and equity prices around their long-run trend â€“ [We Don't Have Nearly Enough Startups](https://whoisnnamdi.com/not-enough-startups/)\\n\\n> The venture ecosystem is supply-constrained â€“ there isn't nearly enough startup equity out there to satisfy investor demand.\\n> Additional capital drives opportunistic company formation at the Seed stage. However, the additional capital doesn't improve survival to the later stages â€“ it simply drives prices up for the remaining companies â€“ [It's Valuations (Almost) All the Way Down](https://whoisnnamdi.com/its-valuations/)\\n\\nSecond, the ratio of Series A to Seed transactions has been reasonably stable since about 2014. It's declining somewhat (Seed rounds are growing slightly faster than Series As) but not nearly as rapidly or vigorously as relative prices have moved. In fact, it's remarkably consistent, even through the ups and downs of the last few years:\\n\\n![premiums_deals](__GHOST_URL__/content/images/2024/01/premiums_deals.png)\\n\\n* Seed activity (the denominator) exploded through 2014, bringing down the ratio (A long time ago, Series As were more common than Seeds)\\n* The Series A vs Seed ratio stabilized thereafter, only slightly falling over the years\\n\\nMy read: this is evidence of stable relative supply of pre vs. post PMF companies. More often than not, when quantities are steady (as in the chart) and prices are rising, it's due to constrained supply rather than constrained demand.\\n\\nSo, investor demand for de-risked companies rose substantially, driving higher relative prices for Series A companies. Meanwhile, the supply of such opportunities didn't grow to match that, so we didn't see a dramatic change in Series A relative to Seed activity.\\n\\n## Busted\\n\\nOk, so we have a plausible story for everything that happened up until the 2021 market peak. But things obviously turned after that. For my theory to be credible, it has to offer some explanation for the recent downturn that fits the data.\\n\\nSpeaking of data â€“ everything we've looked at thus far is from the perspective of the overall market. But individual companies and founders don't experience the aggregate, they live their own particular trajectory, raising subsequent rounds spaced apart rather than at the same time. A founder looking to raise Series A cares about how the market looks 18-24 months *after* they raise their Seed:\\n\\n![Pasted-image-20231024140149](__GHOST_URL__/content/images/2024/01/Pasted-image-20231024140149.png)\\n\\nLet's take the founder perspective and compare Series A deal activity to Seed activity 21 months prior, a reasonable (median) estimate for the time it takes to raise that next round. Think about it as a rough proxy for the Seed to Series A \\\"graduation\\\" or \\\"survival\\\" rate. Not every Series A was preceded by a Seed financing, so this is more of an upper bound for the graduation rate:\\n\\n![premiums_deals_a](__GHOST_URL__/content/images/2024/01/premiums_deals_a.png)\\n\\n* From 2014-2020 it's a very similar picture to what we looked at before, a stable \\\"graduation rate\\\"\\n* Conditions improve substantially in 2020, i.e. more Seed companies survive to the next round\\n* However, post 2021 the graduation rate collapses to the lowest levels ever seen, ~20%\\n\\nSo, while the ratio of Seed to Series A deals at any particular point in time has been stable, due to the timing discrepancy (founders raise their Series A some time after the Seed), the numerous startups that raised Seed funding during the boom are now facing a massive bust. Ironically, though 2021 was the \\\"best\\\" time to raise a Seed based purely on venture activity and valuations, **it was the \\\"worst\\\" time to raise Seed funding once you account for today's tough Series A environment.**\\n\\nThis simple analysis doesn't accurately identify the \\\"level\\\" of the graduation rate, but it proxies the \\\"change\\\" over time. It's safe to say  **the graduation or survival rate from Seed to A has fallen by more than half.** Other sources like Charles Hudson, Jamesin Seidel, and [Carta](https://www.linkedin.com/posts/peterjameswalker_cartadata-seed-seriesa-activity-7128075191611523072-twip/) corroborate this:\\n\\n> **Decline in Graduation Rate from Seed to Series A -** Historically, we've seen a strong pipeline of companies moving from seed to Series A. Recent numbers, however, indicate a significant decline in this graduation rate. Measured graduation rates will continue to fall for several quarters as companies go out for and fail to raise Series A rounds. Graduation rates from seed to Series A could drop to 25%, or one-third or one-half of what they were at the peak. â€“ [The Big Reset in Seed to Series A Graduation Rates is Real and Permanent](https://chudson.substack.com/p/the-big-reset-in-seed-to-series-a)\\n\\n> Back in 2020, approximately 23% of Seed-stage startups made it to Series-A within two years. Fast forward to 2022, and the market looks different. Over the past 20 months since the start of 2022, the graduation rates have decreased to 5%. â€“ [A Deep Dive into Q3 2023's Funding Landscape](https://jamesin.substack.com/p/a-deep-dive-into-q3-2023s-funding)\\n\\n![Pasted-image-20231030084014](__GHOST_URL__/content/images/2024/01/Pasted-image-20231030084014.png)\\n\\n> The percentage of companies who make it from seed to Series A within two years fell by a lot for the 2021 seed cohort.\\n> \\n> 27.5% of companies that raised a seed round in 2019 made it to Series A within 2 years.\\n> \\n> Only 17.6% of companies who raised their seed in 2021 have \\\"graduated\\\" to the next round. â€“ [Peter Walker on LinkedIn](https://www.linkedin.com/posts/peterjameswalker_cartadata-seed-seriesa-activity-7128075191611523072-twip/)\\n\\n![Pasted-image-20231108101945](__GHOST_URL__/content/images/2024/01/Pasted-image-20231108101945.png)\\n\\nHow does my theory explain this data? Put simply, **venture investors re-assessed their beliefs about Series A companies.** They no longer see Series A as a substantial indicator of product-market fit, given so much risk still remains. That's why their relative price has fallen off.\\n\\nThis is different in subtle ways from the common \\\"Series A investors have raised their expectations\\\" narrative:\\n* If it was only about loftier expectations, the Series A premium would have *risen*, since only the best companies would be getting funded, and those companies would fetch a high price. \\n* That's *not* what we see â€“ relative prices have fallen, not risen.\\n\\nInvestors haven't only raised their expectations; they just don't see Series A as indicative of PMF to begin with. If they did, the relative price of Series A companies would still be elevated. Instead, **they no longer see the point in paying up for them.**\\n\\nAgain, return to the education analogy:\\n* If the college wage premium plunged, we'd say employers no longer see the college-educated as having \\\"*labor market fit*\\\". In other words, they lost faith in the college degree as a signal of quality in the labor market \\n* You would *not* intuitively connect this to rising employer expectations (though that could certainly be true too)\\n\\nSo sure, investors raised their expectations â€“ you need more revenue to raise your Series A, more users, etc. But the bigger factor is that investors' *beliefs* about Series A changed.\\n\\n**Investors today expect more but believe less.**\\n\\n## If the product doesn't fit, you must acquit\\n\\nI have abused the expression \\\"post-PMF\\\". The reality is most companies do not achieve product-market fit by their Series A, and that's always been true. But that's my entire point â€“ investors have wizened up to the fact that Series A companies still have material risk.\\n\\nPMF is more fleeting than we all had appreciated. Series A valuations corrected to reflect this.\\n\\nBalance has returned to the Force. Maybe that's a good thing. But it's dreadfully volatile if you're living it in first-person as a founder. The Series A market got the wind knocked out of it just as the large 2021 Seed cohort came up for air.\\n\\nWhile it's a tough time for founders, I think it's important to be clear-eyed about the reality of the situation. The bar has been raised, but further, investors are questioning the bar as a meaningful indicator of success in the first place.\\n\\nSo yes, your first priority is still to raise that next round, but there's still much work to be done thereafter. More so than ever, Series A does not mean you have product-market fit. Investors don't believe it and neither should you.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: The Series A Bust\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>It's cold out there in Series A land:</p>\n<p><img src=\"__GHOST_URL__/content/images/2024/01/deals_a.png\" alt=\"deals_a\" loading=\"lazy\"></p>\n<p>A common explanation for the Series A winter is raised expectations â€“ investors are demanding to see better metrics and traction. Most companies don't meet this new, higher bar, hence fewer deals get done.</p>\n<p>While certainly true, <em>this can't be the whole story.</em> Only if we look at Series As in a vacuum does this explanation seem comprehensive. Incorporating what's happening in the rest of the market, however, there's a much richer narrative to explore.</p>\n<p>The bigger picture? In addition to raising their expectations for Series A, investors have lost faith in Series A as a sign of product-market fit.</p>\n<p><strong>Series A investors expect more but believe less.</strong></p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: The Series A Bust\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"relatively-speaking\">Relatively speaking</h2>\n<p>Valuations for both Seed and Series A stage companies rose dramatically over the last decade or so of venture:</p>\n<p><img src=\"__GHOST_URL__/content/images/2024/01/valuations.png\" alt=\"valuations\" loading=\"lazy\"></p>\n<p>The appreciation in Series A valuations seems extreme relative to that of Seed deals. Of course, the scales here are different, so we'd do better to baseline these to the same starting point and track the growth over time:</p>\n<p><img src=\"__GHOST_URL__/content/images/2024/01/valuations_growth.png\" alt=\"valuations_growth\" loading=\"lazy\"></p>\n<p>While the two grew roughly in line for the first few years, Series A valuations began to accelerate around 2017. That acceleration sustained itself until the recent fall off in venture valuations.</p>\n<p>Notably, both Seed and Series A valuations are recovering. That's a small point in favor of the &quot;raised expectations&quot; story â€“ investors are funding higher-quality businesses, deserving of stronger valuations.</p>\n<p>Here's where the expectations story starts to lose its luster. Below I plot the valuation gap or &quot;premium&quot; for Series A relative to Seed, along with a flexible trend line to remove noise:</p>\n<p><img src=\"__GHOST_URL__/content/images/2024/01/premiums_a.png\" alt=\"premiums_a\" loading=\"lazy\"></p>\n<ul>\n<li>From 2010 to 2014, the two grew roughly in line, with Series As being priced 200% higher or 3x Seed rounds</li>\n<li>Then, Series A valuations accelerate relative to Seeds to a 325% premium or 4.25x multiple</li>\n<li>In 2019, the Series A premium spikes again, peaking in late 2021 at 500% or 6x</li>\n<li>Things collapse after that, ending in Q3 2023 at 2010 levels</li>\n</ul>\n<p>If investor expectations told the full story, Series A valuations relative to Seed deals would be <em>higher</em> today. Since Seed investments remain speculative and standards have risen for Series A investment, we'd expect the typical Series A to be even <em>more</em> valuable relative to Seeds, reflecting higher quality. Instead, the gap has compressed.</p>\n<p>It's been quite the rollercoaster ride. Notably, this rollercoaster is unique to Series A / Seed. We don't see remotely the same behavior in the premium between later rounds:</p>\n<p><img src=\"__GHOST_URL__/content/images/2024/01/premiums.png\" alt=\"premiums\" loading=\"lazy\"></p>\n<p>The premium for Series B vs. A and the premium for Series C vs. B are both much more stable over time, with little trend once you remove the noise. The Series C / B premium saw a slight bump during the exuberant 2021 days, but that was short lived:</p>\n<ul>\n<li>The Series B / A premium has been roughly 200% for the entire period</li>\n<li>The Series C / B premium hovers around 125% with few exceptions</li>\n</ul>\n<p>For whatever reason, the way investors value Series A companies relative to Seed stage companies has fluctuated substantially over time (slowly rising and then suddenly falling), while their views on relative value in later stages have held steady.</p>\n<p>Why?</p>\n<h2 id=\"series-a-university\">Series A University</h2>\n<p>What is different about graduating from Seed to Series A than going from Series A to B, Series B to C, etc?</p>\n<p>There are many potential explanations, but the one that jumps out to me is some notion of <strong>product-market fit (PMF) and business de-risking.</strong> Series A companies tend to have much better PMF than Seed companies, in a way that's distinct from Series B relative to Series A, and so on.</p>\n<p>Think about it like higher education â€“ a college degree is a signal of one's skills to the labor market. <a href=\"https://www.clevelandfed.org/publications/economic-commentary/2012/ec-201210-the-college-wage-premium\">Employers value them accordingly.</a> Further, a college degree means more relative to not having one than having a graduate degree means relative to having only an undergraduate education. Again, employers value them accordingly:<br>\n<img src=\"__GHOST_URL__/content/images/2024/01/Pasted-image-20231227144822.png\" alt=\"Pasted-image-20231227144822\" loading=\"lazy\"></p>\n<p>While the probability of a company achieving PMF is certainly not 100% at the time of Series A (many companies raise Series A before that), it's definitely much higher at the A round than at the Seed round, since it's effectively 0% at that point.</p>\n<p>Startup risk reduces materially once a company graduates to Series A. In a way, that's exactly why a startup successfully raises its Series A â€“ the founders have de-risked the business, so much so that an investor is willing to invest substantial capital, take a board seat, etc.</p>\n<p>If we posit that the &quot;price&quot; or &quot;value&quot; of PMF is well-proxied by the Series A / Seed premium, we can think of this premium moving over time due to fluctuations in the supply (among startups) and demand (among investors) for PMF:</p>\n<ul>\n<li>A rising price typically indicates either contracting supply â€“ the relative supply of startups with PMF vs those without â€“ or growing demand â€“ the relative demand for post-PMF startups vs pre-PMF startups</li>\n<li>Importantly, these are <em>relative</em> concepts â€“ the number of pre and post-PMF startups could be both growing over time, but if the number of pre-PMF startups is growing faster, that would imply a <em>relative decline</em> in PMF supply</li>\n</ul>\n<p>$$\\text{Relative Supply of PMF} = \\frac{\\text{Supply of Post-PMF Startups}}{\\text{Supply of Pre-PMF Startups}}$$</p>\n<p>So what explains the pre-2022 run up in the Series A / Seed premium: declining (relative) <em>supply</em> of PMF or rising (relative) <em>demand</em> for PMF?</p>\n<p>My argument: <strong>rising demand for PMF.</strong></p>\n<p>First, as I've argued elsewhere, the growth and development of the venture ecosystem has been a mostly demand-side story. That should strongly bias us toward the demand explanation:</p>\n<blockquote>\n<p>Investors are the primary driver of fluctuations in venture activity and equity prices around their long-run trend â€“ <a href=\"https://whoisnnamdi.com/not-enough-startups/\">We Don't Have Nearly Enough Startups</a></p>\n</blockquote>\n<blockquote>\n<p>The venture ecosystem is supply-constrained â€“ there isn't nearly enough startup equity out there to satisfy investor demand.<br>\nAdditional capital drives opportunistic company formation at the Seed stage. However, the additional capital doesn't improve survival to the later stages â€“ it simply drives prices up for the remaining companies â€“ <a href=\"https://whoisnnamdi.com/its-valuations/\">It's Valuations (Almost) All the Way Down</a></p>\n</blockquote>\n<p>Second, the ratio of Series A to Seed transactions has been reasonably stable since about 2014. It's declining somewhat (Seed rounds are growing slightly faster than Series As) but not nearly as rapidly or vigorously as relative prices have moved. In fact, it's remarkably consistent, even through the ups and downs of the last few years:</p>\n<p><img src=\"__GHOST_URL__/content/images/2024/01/premiums_deals.png\" alt=\"premiums_deals\" loading=\"lazy\"></p>\n<ul>\n<li>Seed activity (the denominator) exploded through 2014, bringing down the ratio (A long time ago, Series As were more common than Seeds)</li>\n<li>The Series A vs Seed ratio stabilized thereafter, only slightly falling over the years</li>\n</ul>\n<p>My read: this is evidence of stable relative supply of pre vs. post PMF companies. More often than not, when quantities are steady (as in the chart) and prices are rising, it's due to constrained supply rather than constrained demand.</p>\n<p>So, investor demand for de-risked companies rose substantially, driving higher relative prices for Series A companies. Meanwhile, the supply of such opportunities didn't grow to match that, so we didn't see a dramatic change in Series A relative to Seed activity.</p>\n<h2 id=\"busted\">Busted</h2>\n<p>Ok, so we have a plausible story for everything that happened up until the 2021 market peak. But things obviously turned after that. For my theory to be credible, it has to offer some explanation for the recent downturn that fits the data.</p>\n<p>Speaking of data â€“ everything we've looked at thus far is from the perspective of the overall market. But individual companies and founders don't experience the aggregate, they live their own particular trajectory, raising subsequent rounds spaced apart rather than at the same time. A founder looking to raise Series A cares about how the market looks 18-24 months <em>after</em> they raise their Seed:</p>\n<p><img src=\"__GHOST_URL__/content/images/2024/01/Pasted-image-20231024140149.png\" alt=\"Pasted-image-20231024140149\" loading=\"lazy\"></p>\n<p>Let's take the founder perspective and compare Series A deal activity to Seed activity 21 months prior, a reasonable (median) estimate for the time it takes to raise that next round. Think about it as a rough proxy for the Seed to Series A &quot;graduation&quot; or &quot;survival&quot; rate. Not every Series A was preceded by a Seed financing, so this is more of an upper bound for the graduation rate:</p>\n<p><img src=\"__GHOST_URL__/content/images/2024/01/premiums_deals_a.png\" alt=\"premiums_deals_a\" loading=\"lazy\"></p>\n<ul>\n<li>From 2014-2020 it's a very similar picture to what we looked at before, a stable &quot;graduation rate&quot;</li>\n<li>Conditions improve substantially in 2020, i.e. more Seed companies survive to the next round</li>\n<li>However, post 2021 the graduation rate collapses to the lowest levels ever seen, ~20%</li>\n</ul>\n<p>So, while the ratio of Seed to Series A deals at any particular point in time has been stable, due to the timing discrepancy (founders raise their Series A some time after the Seed), the numerous startups that raised Seed funding during the boom are now facing a massive bust. Ironically, though 2021 was the &quot;best&quot; time to raise a Seed based purely on venture activity and valuations, <strong>it was the &quot;worst&quot; time to raise Seed funding once you account for today's tough Series A environment.</strong></p>\n<p>This simple analysis doesn't accurately identify the &quot;level&quot; of the graduation rate, but it proxies the &quot;change&quot; over time. It's safe to say  <strong>the graduation or survival rate from Seed to A has fallen by more than half.</strong> Other sources like Charles Hudson, Jamesin Seidel, and <a href=\"https://www.linkedin.com/posts/peterjameswalker_cartadata-seed-seriesa-activity-7128075191611523072-twip/\">Carta</a> corroborate this:</p>\n<blockquote>\n<p><strong>Decline in Graduation Rate from Seed to Series A -</strong> Historically, we've seen a strong pipeline of companies moving from seed to Series A. Recent numbers, however, indicate a significant decline in this graduation rate. Measured graduation rates will continue to fall for several quarters as companies go out for and fail to raise Series A rounds. Graduation rates from seed to Series A could drop to 25%, or one-third or one-half of what they were at the peak. â€“ <a href=\"https://chudson.substack.com/p/the-big-reset-in-seed-to-series-a\">The Big Reset in Seed to Series A Graduation Rates is Real and Permanent</a></p>\n</blockquote>\n<blockquote>\n<p>Back in 2020, approximately 23% of Seed-stage startups made it to Series-A within two years. Fast forward to 2022, and the market looks different. Over the past 20 months since the start of 2022, the graduation rates have decreased to 5%. â€“ <a href=\"https://jamesin.substack.com/p/a-deep-dive-into-q3-2023s-funding\">A Deep Dive into Q3 2023's Funding Landscape</a></p>\n</blockquote>\n<p><img src=\"__GHOST_URL__/content/images/2024/01/Pasted-image-20231030084014.png\" alt=\"Pasted-image-20231030084014\" loading=\"lazy\"></p>\n<blockquote>\n<p>The percentage of companies who make it from seed to Series A within two years fell by a lot for the 2021 seed cohort.</p>\n<p>27.5% of companies that raised a seed round in 2019 made it to Series A within 2 years.</p>\n<p>Only 17.6% of companies who raised their seed in 2021 have &quot;graduated&quot; to the next round. â€“ <a href=\"https://www.linkedin.com/posts/peterjameswalker_cartadata-seed-seriesa-activity-7128075191611523072-twip/\">Peter Walker on LinkedIn</a></p>\n</blockquote>\n<p><img src=\"__GHOST_URL__/content/images/2024/01/Pasted-image-20231108101945.png\" alt=\"Pasted-image-20231108101945\" loading=\"lazy\"></p>\n<p>How does my theory explain this data? Put simply, <strong>venture investors re-assessed their beliefs about Series A companies.</strong> They no longer see Series A as a substantial indicator of product-market fit, given so much risk still remains. That's why their relative price has fallen off.</p>\n<p>This is different in subtle ways from the common &quot;Series A investors have raised their expectations&quot; narrative:</p>\n<ul>\n<li>If it was only about loftier expectations, the Series A premium would have <em>risen</em>, since only the best companies would be getting funded, and those companies would fetch a high price.</li>\n<li>That's <em>not</em> what we see â€“ relative prices have fallen, not risen.</li>\n</ul>\n<p>Investors haven't only raised their expectations; they just don't see Series A as indicative of PMF to begin with. If they did, the relative price of Series A companies would still be elevated. Instead, <strong>they no longer see the point in paying up for them.</strong></p>\n<p>Again, return to the education analogy:</p>\n<ul>\n<li>If the college wage premium plunged, we'd say employers no longer see the college-educated as having &quot;<em>labor market fit</em>&quot;. In other words, they lost faith in the college degree as a signal of quality in the labor market</li>\n<li>You would <em>not</em> intuitively connect this to rising employer expectations (though that could certainly be true too)</li>\n</ul>\n<p>So sure, investors raised their expectations â€“ you need more revenue to raise your Series A, more users, etc. But the bigger factor is that investors' <em>beliefs</em> about Series A changed.</p>\n<p><strong>Investors today expect more but believe less.</strong></p>\n<h2 id=\"if-the-product-doesnt-fit-you-must-acquit\">If the product doesn't fit, you must acquit</h2>\n<p>I have abused the expression &quot;post-PMF&quot;. The reality is most companies do not achieve product-market fit by their Series A, and that's always been true. But that's my entire point â€“ investors have wizened up to the fact that Series A companies still have material risk.</p>\n<p>PMF is more fleeting than we all had appreciated. Series A valuations corrected to reflect this.</p>\n<p>Balance has returned to the Force. Maybe that's a good thing. But it's dreadfully volatile if you're living it in first-person as a founder. The Series A market got the wind knocked out of it just as the large 2021 Seed cohort came up for air.</p>\n<p>While it's a tough time for founders, I think it's important to be clear-eyed about the reality of the situation. The bar has been raised, but further, investors are questioning the bar as a meaningful indicator of success in the first place.</p>\n<p>So yes, your first priority is still to raise that next round, but there's still much work to be done thereafter. More so than ever, Series A does not mean you have product-market fit. Investors don't believe it and neither should you.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: The Series A Bust\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"659337c7fec7d1542d1d2f50","plaintext":"It's cold out there in Series A land:\n\n\n\nA common explanation for the Series A winter is raised expectations â€“ investors\nare demanding to see better metrics and traction. Most companies don't meet this\nnew, higher bar, hence fewer deals get done.\n\nWhile certainly true, this can't be the whole story. Only if we look at Series\nAs in a vacuum does this explanation seem comprehensive. Incorporating what's\nhappening in the rest of the market, however, there's a much richer narrative to\nexplore.\n\nThe bigger picture? In addition to raising their expectations for Series A,\ninvestors have lost faith in Series A as a sign of product-market fit.\n\nSeries A investors expect more but believe less.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Relatively speaking\nValuations for both Seed and Series A stage companies rose dramatically over the\nlast decade or so of venture:\n\n\n\nThe appreciation in Series A valuations seems extreme relative to that of Seed\ndeals. Of course, the scales here are different, so we'd do better to baseline\nthese to the same starting point and track the growth over time:\n\n\n\nWhile the two grew roughly in line for the first few years, Series A valuations\nbegan to accelerate around 2017. That acceleration sustained itself until the\nrecent fall off in venture valuations.\n\nNotably, both Seed and Series A valuations are recovering. That's a small point\nin favor of the \"raised expectations\" story â€“ investors are funding\nhigher-quality businesses, deserving of stronger valuations.\n\nHere's where the expectations story starts to lose its luster. Below I plot the\nvaluation gap or \"premium\" for Series A relative to Seed, along with a flexible\ntrend line to remove noise:\n\n\n\n * From 2010 to 2014, the two grew roughly in line, with Series As being priced\n   200% higher or 3x Seed rounds\n * Then, Series A valuations accelerate relative to Seeds to a 325% premium or\n   4.25x multiple\n * In 2019, the Series A premium spikes again, peaking in late 2021 at 500% or\n   6x\n * Things collapse after that, ending in Q3 2023 at 2010 levels\n\nIf investor expectations told the full story, Series A valuations relative to\nSeed deals would be higher today. Since Seed investments remain speculative and\nstandards have risen for Series A investment, we'd expect the typical Series A\nto be even more valuable relative to Seeds, reflecting higher quality. Instead,\nthe gap has compressed.\n\nIt's been quite the rollercoaster ride. Notably, this rollercoaster is unique to\nSeries A / Seed. We don't see remotely the same behavior in the premium between\nlater rounds:\n\n\n\nThe premium for Series B vs. A and the premium for Series C vs. B are both much\nmore stable over time, with little trend once you remove the noise. The Series C\n/ B premium saw a slight bump during the exuberant 2021 days, but that was short\nlived:\n\n * The Series B / A premium has been roughly 200% for the entire period\n * The Series C / B premium hovers around 125% with few exceptions\n\nFor whatever reason, the way investors value Series A companies relative to Seed\nstage companies has fluctuated substantially over time (slowly rising and then\nsuddenly falling), while their views on relative value in later stages have held\nsteady.\n\nWhy?\n\nSeries A University\nWhat is different about graduating from Seed to Series A than going from Series\nA to B, Series B to C, etc?\n\nThere are many potential explanations, but the one that jumps out to me is some\nnotion of product-market fit (PMF) and business de-risking. Series A companies\ntend to have much better PMF than Seed companies, in a way that's distinct from\nSeries B relative to Series A, and so on.\n\nThink about it like higher education â€“ a college degree is a signal of one's\nskills to the labor market. Employers value them accordingly.\n[https://www.clevelandfed.org/publications/economic-commentary/2012/ec-201210-the-college-wage-premium] \nFurther, a college degree means more relative to not having one than having a\ngraduate degree means relative to having only an undergraduate education. Again,\nemployers value them accordingly:\n\n\nWhile the probability of a company achieving PMF is certainly not 100% at the\ntime of Series A (many companies raise Series A before that), it's definitely\nmuch higher at the A round than at the Seed round, since it's effectively 0% at\nthat point.\n\nStartup risk reduces materially once a company graduates to Series A. In a way,\nthat's exactly why a startup successfully raises its Series A â€“ the founders\nhave de-risked the business, so much so that an investor is willing to invest\nsubstantial capital, take a board seat, etc.\n\nIf we posit that the \"price\" or \"value\" of PMF is well-proxied by the Series A /\nSeed premium, we can think of this premium moving over time due to fluctuations\nin the supply (among startups) and demand (among investors) for PMF:\n\n * A rising price typically indicates either contracting supply â€“ the relative\n   supply of startups with PMF vs those without â€“ or growing demand â€“ the\n   relative demand for post-PMF startups vs pre-PMF startups\n * Importantly, these are relative concepts â€“ the number of pre and post-PMF\n   startups could be both growing over time, but if the number of pre-PMF\n   startups is growing faster, that would imply a relative decline in PMF supply\n\n$$\\text{Relative Supply of PMF} = \\frac{\\text{Supply of Post-PMF\nStartups}}{\\text{Supply of Pre-PMF Startups}}$$\n\nSo what explains the pre-2022 run up in the Series A / Seed premium: declining\n(relative) supply of PMF or rising (relative) demand for PMF?\n\nMy argument: rising demand for PMF.\n\nFirst, as I've argued elsewhere, the growth and development of the venture\necosystem has been a mostly demand-side story. That should strongly bias us\ntoward the demand explanation:\n\n> Investors are the primary driver of fluctuations in venture activity and equity\nprices around their long-run trend â€“ We Don't Have Nearly Enough Startups\n[https://whoisnnamdi.com/not-enough-startups/]\n\n\n> The venture ecosystem is supply-constrained â€“ there isn't nearly enough startup\nequity out there to satisfy investor demand.\nAdditional capital drives opportunistic company formation at the Seed stage.\nHowever, the additional capital doesn't improve survival to the later stages â€“\nit simply drives prices up for the remaining companies â€“ It's Valuations\n(Almost) All the Way Down [https://whoisnnamdi.com/its-valuations/]\n\n\nSecond, the ratio of Series A to Seed transactions has been reasonably stable\nsince about 2014. It's declining somewhat (Seed rounds are growing slightly\nfaster than Series As) but not nearly as rapidly or vigorously as relative\nprices have moved. In fact, it's remarkably consistent, even through the ups and\ndowns of the last few years:\n\n\n\n * Seed activity (the denominator) exploded through 2014, bringing down the\n   ratio (A long time ago, Series As were more common than Seeds)\n * The Series A vs Seed ratio stabilized thereafter, only slightly falling over\n   the years\n\nMy read: this is evidence of stable relative supply of pre vs. post PMF\ncompanies. More often than not, when quantities are steady (as in the chart) and\nprices are rising, it's due to constrained supply rather than constrained\ndemand.\n\nSo, investor demand for de-risked companies rose substantially, driving higher\nrelative prices for Series A companies. Meanwhile, the supply of such\nopportunities didn't grow to match that, so we didn't see a dramatic change in\nSeries A relative to Seed activity.\n\nBusted\nOk, so we have a plausible story for everything that happened up until the 2021\nmarket peak. But things obviously turned after that. For my theory to be\ncredible, it has to offer some explanation for the recent downturn that fits the\ndata.\n\nSpeaking of data â€“ everything we've looked at thus far is from the perspective\nof the overall market. But individual companies and founders don't experience\nthe aggregate, they live their own particular trajectory, raising subsequent\nrounds spaced apart rather than at the same time. A founder looking to raise\nSeries A cares about how the market looks 18-24 months after they raise their\nSeed:\n\n\n\nLet's take the founder perspective and compare Series A deal activity to Seed\nactivity 21 months prior, a reasonable (median) estimate for the time it takes\nto raise that next round. Think about it as a rough proxy for the Seed to Series\nA \"graduation\" or \"survival\" rate. Not every Series A was preceded by a Seed\nfinancing, so this is more of an upper bound for the graduation rate:\n\n\n\n * From 2014-2020 it's a very similar picture to what we looked at before, a\n   stable \"graduation rate\"\n * Conditions improve substantially in 2020, i.e. more Seed companies survive to\n   the next round\n * However, post 2021 the graduation rate collapses to the lowest levels ever\n   seen, ~20%\n\nSo, while the ratio of Seed to Series A deals at any particular point in time\nhas been stable, due to the timing discrepancy (founders raise their Series A\nsome time after the Seed), the numerous startups that raised Seed funding during\nthe boom are now facing a massive bust. Ironically, though 2021 was the \"best\"\ntime to raise a Seed based purely on venture activity and valuations, it was the\n\"worst\" time to raise Seed funding once you account for today's tough Series A\nenvironment.\n\nThis simple analysis doesn't accurately identify the \"level\" of the graduation\nrate, but it proxies the \"change\" over time. It's safe to say the graduation or\nsurvival rate from Seed to A has fallen by more than half. Other sources like\nCharles Hudson, Jamesin Seidel, and Carta\n[https://www.linkedin.com/posts/peterjameswalker_cartadata-seed-seriesa-activity-7128075191611523072-twip/] \ncorroborate this:\n\n> Decline in Graduation Rate from Seed to Series A - Historically, we've seen a\nstrong pipeline of companies moving from seed to Series A. Recent numbers,\nhowever, indicate a significant decline in this graduation rate. Measured\ngraduation rates will continue to fall for several quarters as companies go out\nfor and fail to raise Series A rounds. Graduation rates from seed to Series A\ncould drop to 25%, or one-third or one-half of what they were at the peak. â€“ \nThe\nBig Reset in Seed to Series A Graduation Rates is Real and Permanent\n[https://chudson.substack.com/p/the-big-reset-in-seed-to-series-a]\n\n\n> Back in 2020, approximately 23% of Seed-stage startups made it to Series-A\nwithin two years. Fast forward to 2022, and the market looks different. Over the\npast 20 months since the start of 2022, the graduation rates have decreased to\n5%. â€“ A Deep Dive into Q3 2023's Funding Landscape\n[https://jamesin.substack.com/p/a-deep-dive-into-q3-2023s-funding]\n\n\n\n\n> The percentage of companies who make it from seed to Series A within two years\nfell by a lot for the 2021 seed cohort.\n\n27.5% of companies that raised a seed round in 2019 made it to Series A within 2\nyears.\n\nOnly 17.6% of companies who raised their seed in 2021 have \"graduated\" to the\nnext round. â€“ Peter Walker on LinkedIn\n[https://www.linkedin.com/posts/peterjameswalker_cartadata-seed-seriesa-activity-7128075191611523072-twip/]\n\n\n\n\nHow does my theory explain this data? Put simply, venture investors re-assessed\ntheir beliefs about Series A companies. They no longer see Series A as a\nsubstantial indicator of product-market fit, given so much risk still remains.\nThat's why their relative price has fallen off.\n\nThis is different in subtle ways from the common \"Series A investors have raised\ntheir expectations\" narrative:\n\n * If it was only about loftier expectations, the Series A premium would have \n   risen, since only the best companies would be getting funded, and those\n   companies would fetch a high price.\n * That's not what we see â€“ relative prices have fallen, not risen.\n\nInvestors haven't only raised their expectations; they just don't see Series A\nas indicative of PMF to begin with. If they did, the relative price of Series A\ncompanies would still be elevated. Instead, they no longer see the point in\npaying up for them.\n\nAgain, return to the education analogy:\n\n * If the college wage premium plunged, we'd say employers no longer see the\n   college-educated as having \"labor market fit\". In other words, they lost\n   faith in the college degree as a signal of quality in the labor market\n * You would not intuitively connect this to rising employer expectations\n   (though that could certainly be true too)\n\nSo sure, investors raised their expectations â€“ you need more revenue to raise\nyour Series A, more users, etc. But the bigger factor is that investors' beliefs \nabout Series A changed.\n\nInvestors today expect more but believe less.\n\nIf the product doesn't fit, you must acquit\nI have abused the expression \"post-PMF\". The reality is most companies do not\nachieve product-market fit by their Series A, and that's always been true. But\nthat's my entire point â€“ investors have wizened up to the fact that Series A\ncompanies still have material risk.\n\nPMF is more fleeting than we all had appreciated. Series A valuations corrected\nto reflect this.\n\nBalance has returned to the Force. Maybe that's a good thing. But it's\ndreadfully volatile if you're living it in first-person as a founder. The Series\nA market got the wind knocked out of it just as the large 2021 Seed cohort came\nup for air.\n\nWhile it's a tough time for founders, I think it's important to be clear-eyed\nabout the reality of the situation. The bar has been raised, but further,\ninvestors are questioning the bar as a meaningful indicator of success in the\nfirst place.\n\nSo yes, your first priority is still to raise that next round, but there's still\nmuch work to be done thereafter. More so than ever, Series A does not mean you\nhave product-market fit. Investors don't believe it and neither should you.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2024/01/header.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2024-01-01T22:08:07.000Z","updated_at":"2024-01-04T03:00:36.000Z","published_at":"2024-01-03T15:58:05.000Z","custom_excerpt":"Investors have lost faith in Series A as a sign of product-market fit. In other words, they expect more but believe less.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"65e9fffefec7d1542d1d2f9c","uuid":"446cda22-dad7-428e-974e-1bccad03a0e7","title":"The Venture Activity Index â€“ Q4 2023","slug":"vai-q4-2023","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Iâ€™ve updated the Venture Activity Index for [Q4 2023](https://whoisnnamdi.com/vai/) data.\\n\\nAs a reminder, the VAI is an index measuring current venture investment across stages relative to the long-run trend. Itâ€™s a useful and simple barometer of activity and sentiment in the venture market. The methodology is [here](https://whoisnnamdi.com/venture-activity-index/).\\n\\nSome small modifications since the last version of the index that I published in Q2 2023:\\n* Updated data for Q4 2023\\n* Removed seasonality from the data\\n* Removed super later stage rounds post-Series D. This was causing excess volatility that wasnâ€™t representative of the overall venture market\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: The Venture Activity Index â€“ Q4 2023\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\nWith that out of the way, hereâ€™s where weâ€™re at:\\n![vai_plot](__GHOST_URL__/content/images/2024/03/vai_plot.png)\\n\\n* Capital deployment remains depressed, sitting about 50% below trend\\n* Weâ€™ve hit the trough but remained there rather than recovered to trend. It's a bit of a [dead cat bounce](https://en.wikipedia.org/wiki/Dead_cat_bounce)\\n\\nAnother interesting view of the data is to show the various components by stage:\\n![vai_disagg](__GHOST_URL__/content/images/2024/03/vai_disagg.png)\\n\\n* The later stages spiked the most in 2021, the earliest stages the least. This then reversed, with late stage capital falling somewhat more than early stage capital\\n* However, all stages are similarly depressed at this point relative to their respective trends\\n\\nAs I caveated in the first version of the index, if we continue to stay below trend I may need to update the definition of trend to recognize that weâ€™re on a new trajectory. For now, I'll continue to use a long-term, constant growth rate to define the trend for each stage:\\n![detrend](__GHOST_URL__/content/images/2024/03/detrend.png)\\n\\nThat's it! I think the data mostly speaks for itself here, so I'll keep my commentary light for this one. Will update this again next quarter.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: The Venture Activity Index â€“ Q4 2023\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>Iâ€™ve updated the Venture Activity Index for <a href=\"https://whoisnnamdi.com/vai/\">Q4 2023</a> data.</p>\n<p>As a reminder, the VAI is an index measuring current venture investment across stages relative to the long-run trend. Itâ€™s a useful and simple barometer of activity and sentiment in the venture market. The methodology is <a href=\"https://whoisnnamdi.com/venture-activity-index/\">here</a>.</p>\n<p>Some small modifications since the last version of the index that I published in Q2 2023:</p>\n<ul>\n<li>Updated data for Q4 2023</li>\n<li>Removed seasonality from the data</li>\n<li>Removed super later stage rounds post-Series D. This was causing excess volatility that wasnâ€™t representative of the overall venture market</li>\n</ul>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: The Venture Activity Index â€“ Q4 2023\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<p>With that out of the way, hereâ€™s where weâ€™re at:<br>\n<img src=\"__GHOST_URL__/content/images/2024/03/vai_plot.png\" alt=\"vai_plot\" loading=\"lazy\"></p>\n<ul>\n<li>Capital deployment remains depressed, sitting about 50% below trend</li>\n<li>Weâ€™ve hit the trough but remained there rather than recovered to trend. It's a bit of a <a href=\"https://en.wikipedia.org/wiki/Dead_cat_bounce\">dead cat bounce</a></li>\n</ul>\n<p>Another interesting view of the data is to show the various components by stage:<br>\n<img src=\"__GHOST_URL__/content/images/2024/03/vai_disagg.png\" alt=\"vai_disagg\" loading=\"lazy\"></p>\n<ul>\n<li>The later stages spiked the most in 2021, the earliest stages the least. This then reversed, with late stage capital falling somewhat more than early stage capital</li>\n<li>However, all stages are similarly depressed at this point relative to their respective trends</li>\n</ul>\n<p>As I caveated in the first version of the index, if we continue to stay below trend I may need to update the definition of trend to recognize that weâ€™re on a new trajectory. For now, I'll continue to use a long-term, constant growth rate to define the trend for each stage:<br>\n<img src=\"__GHOST_URL__/content/images/2024/03/detrend.png\" alt=\"detrend\" loading=\"lazy\"></p>\n<p>That's it! I think the data mostly speaks for itself here, so I'll keep my commentary light for this one. Will update this again next quarter.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: The Venture Activity Index â€“ Q4 2023\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"65e9fffefec7d1542d1d2f9c","plaintext":"Iâ€™ve updated the Venture Activity Index for Q4 2023\n[https://whoisnnamdi.com/vai/] data.\n\nAs a reminder, the VAI is an index measuring current venture investment across\nstages relative to the long-run trend. Itâ€™s a useful and simple barometer of\nactivity and sentiment in the venture market. The methodology is here\n[https://whoisnnamdi.com/venture-activity-index/].\n\nSome small modifications since the last version of the index that I published in\nQ2 2023:\n\n * Updated data for Q4 2023\n * Removed seasonality from the data\n * Removed super later stage rounds post-Series D. This was causing excess\n   volatility that wasnâ€™t representative of the overall venture market\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡With that out of the way, hereâ€™s where weâ€™re at:\n\n\n * Capital deployment remains depressed, sitting about 50% below trend\n * Weâ€™ve hit the trough but remained there rather than recovered to trend. It's\n   a bit of a dead cat bounce [https://en.wikipedia.org/wiki/Dead_cat_bounce]\n\nAnother interesting view of the data is to show the various components by stage:\n\n\n * The later stages spiked the most in 2021, the earliest stages the least. This\n   then reversed, with late stage capital falling somewhat more than early stage\n   capital\n * However, all stages are similarly depressed at this point relative to their\n   respective trends\n\nAs I caveated in the first version of the index, if we continue to stay below\ntrend I may need to update the definition of trend to recognize that weâ€™re on a\nnew trajectory. For now, I'll continue to use a long-term, constant growth rate\nto define the trend for each stage:\n\n\nThat's it! I think the data mostly speaks for itself here, so I'll keep my\ncommentary light for this one. Will update this again next quarter.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2024/03/header.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2024-03-07T17:57:18.000Z","updated_at":"2024-03-07T18:43:40.000Z","published_at":"2024-03-07T18:18:09.000Z","custom_excerpt":"Capital deployment remains depressed, sitting about 50% below trend","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"665558b2fec7d1542d1d2fcd","uuid":"b13b3ca0-2200-4010-a1ce-bf03ab05f035","title":"AI Benchmarking Is Broken","slug":"ai-benchmarking-broken","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"*To celebrate [Patronus AIâ€™s $17M Series A](https://www.patronus.ai/blog/announcing-our-17-million-series-a), I wanted to share some thoughts on the current state of AI benchmarking.*\\n\\nImagine a standardized test that works like this:\\n* The questions and answers are freely available on the public internet\\n* Cheating is not regulated, itâ€™s a 100% honor system\\n* The exam never changes, itâ€™s the same questions every time\\n* Scores on the exam seem to be getting better every year\\n\\nIn case youâ€™re wondering, the correct reaction is â€œthis is not a very good exam.â€ Cheating is rampant. The answers can all be memorized. The test isnâ€™t really much of a â€œtest.â€ The scores are meaningless.\\n\\nThis is the current state of AI benchmarking. Ironically, we hold AI benchmarks to a very *low* standard. We allow practices that would never fly in other serious domains. Itâ€™s happening in plain sight, with a nod and a wink every time an AI lab releases a new model that tops the leaderboards.\\n\\nWe must do better.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: AI Benchmarking Is Broken\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## Somethingâ€™s in the water\\n![training-data-contamination](__GHOST_URL__/content/images/2024/05/training-data-contamination.jpeg)\\n\\nThe first dirty secret of AI benchmarks is quite literally, dirty: **training data contamination**.\\n\\nA common refrain among machine learning researchers and engineers â€” â€œdonâ€™t train on the test set.â€ In other words, donâ€™t train a model on the same dataset that you will evaluate it on. If you do, whether on purpose or not, that particular test is useless for evaluating model performance.\\n\\nMost open benchmarks are available on the public internet. In other words, the entire set of questions and answers exists on the open web, likely in multiple places. It is extremely easy for this data to inadvertently make its way into LLM training pipelines. The big AI labs are constantly hoovering up data from the internet via web crawlers, scraping their way across the web. While diligent researchers are careful about what ends up in the training data, applying all sorts of sophisticated filters to the raw data before feeding it to their models, invariably these filters are imperfect, and data from the benchmarks leaks in. It can happen during pre-training, it can happen during fine-tuning, either way, the bad data gets in. This renders invalid the downstream model performance on the benchmark.\\n\\nThe test data from a particular benchmark can appear in many places. It could be in plaintext on a webpage somewhere. It could be a file in a GitHub repo, alongside code which a model is being trained with. It could be in the *comments* of a file or script inside of a repo. It could be on Reddit or X. It could really be anywhere.\\n\\n> An increasingly important issue with evals is test set contamination. After the creation of a good eval, examples of the eval tend to get propagated into various places in the internet, like arxiv papers, ChatGPT examples, or reddit â€” [Jason Wei, OpenAI](https://www.jasonwei.net/blog/evals)\\n\\nItâ€™s been shown that a single training example can meaningfully impact the behavior of a model, so it only takes one mishap to contaminate a model. Model builders routinely train on trillions of tokens, so thereâ€™s no shortage of ways for accidents to occur.\\n\\nYou might wonder, if the entire benchmark makes its way into the training data, then why donâ€™t the models score perfectly on the benchmarks? Remember, these models are complicated mathematical functions of the data â€” they are optimizing for all sorts of criteria that we donâ€™t fully understand ([though weâ€™re making progress](https://www.anthropic.com/research/mapping-mind-language-model)) and have been trained on vast sums of data, so any particular benchmark represents a very small share of the overall training corpus. A model trained on a particular dataset will fail to reproduce that data at times. This complex and non-deterministic mapping of inputs to outputs is arguably the distinguishing feature of LLMs relative to traditional machine learning models. So we shouldnâ€™t necessarily expect to see perfect benchmark performance even in the most blatantly contaminated scenarios.\\n\\n## Itâ€™s not what you think\\n\\nThe next time you hear about how a new model crushes some well-established benchmark, take a moment to actually go to the primary source and review the tasks in the benchmark. Pick any of them, it doesnâ€™t really matter which. I would bet that, even as a non-specialist, you will very quickly begin to question whether the benchmark is really testing what it claims to test.\\n\\nSometimes this is subtle; sometimes itâ€™s not. Many AI coding benchmarks have fairly trivial solutions that donâ€™t require meaningful code understanding or â€œintelligence.â€ Many â€œreasoningâ€ benchmarks donâ€™t require any reasoning.\\n\\nAgain, donâ€™t take my word for it â€” I encourage you to, right now, read through a few examples from the many published benchmarks, and see what you think about the concepts they are purportedly testing. **You will be less than impressed**, and you will leave the exercise with a much reduced opinion of and trust in the performance of the latest and greatest models.\\n\\nThis also relates to my point earlier about contamination, which is especially pernicious in the software development domain. Many â€œbrain twisterâ€ coding tasks are well-represented in the training data for these models, in part because software developers spend so much time preparing for such questions as part of job interviews. Coding competitions abound, which can serve as a signal to employers of an engineerâ€™s talent and skills. Their competition code often ends up on the public internet, where it gets picked up by training data crawlers.\\n\\nAt test time, the model has already seen the question, perhaps in slightly modified form, and has memorized the answer. Itâ€™s not right to say a model regurgitating some code from some repo is â€œreasoningâ€ about software development. Itâ€™s much more akin to an engineer getting stuck and looking up some code on Stack Overflow, pasting it into their editor, and moving on.\\n\\nThereâ€™s nothing wrong with a â€œStack Overflow botâ€! I would and do pay for such things. I just think we need to be very careful and specific about what we call it.\\n\\n## Teaching to the test\\n\\nCritics of standardized tests often complain they encourage teachers to â€œteach to the testâ€, focusing exclusively on material that will improve their studentsâ€™ performance on the test but that perhaps misses other information valuable to their overall edification as human beings and citizens. I think this critique has bite to it in the context of AI models.\\n\\nHereâ€™s why. [Kaggle](https://www.kaggle.com/) is the most famous competition platform for machine learning practitioners. They hold frequent competitions where the goal is to build a machine learning model that can generate accurate predictions in a particular context based on provided (or otherwise procured) inputs. A key feature of Kaggle competitions is the [public leaderboard](https://www.kaggle.com/docs/competitions#leaderboard) â€” the real-time ranking of submitted models on a â€œvalidationâ€ dataset that only Kaggle has access to. Thus, they avoid the problem of data [leaking](https://www.kaggle.com/docs/competitions#leakage) into the training set.\\n\\nHowever, as is well-known among Kagglers, this â€œone weird trickâ€ doesnâ€™t solve all problems. After some time, the competition closes, at which point every model is re-evaluated on a previously closed â€œtest setâ€, the scores for which make up the â€œprivate leaderboardâ€. It is extremely common for the â€œbestâ€ model from the public leaderboard to fall a few places in the rankings on the private leaderboard and for another model to rise to the top. In fact, this happens so often that being in 1st place going into the final evaluation can often be a source of stress rather than relief, since you know thereâ€™s some risk youâ€™ve â€œ[overfit to the public leaderboard.](https://www.kaggle.com/docs/competitions#leaderboard)â€\\n\\n> Many users watch the public leaderboard closely, as breakthroughs in the competition are announced by score gains in the leaderboard. These jumps in turn motivate other teams working on the competition in search of those advancements. But itâ€™s important to keep the public leaderboard in perspective. Itâ€™s very easy to overfit a model, creating something that performs very well on the public leaderboard, but very badly on the private one. This is calledÂ overfitting.\\n\\nEven though your model never saw the validation data directly, you did see its *score* on the data. That score is a noisy proxy for the data itself, so anything you do to improve the score implicitly leverages features of validation data, even if you never saw data directly. Since that score influenced the techniques and tricks you employed during model training, thereâ€™s a sense in which the validation data did â€œleakâ€ into training.\\n\\nYouâ€™ve effectively â€œtaught to the *practice* testâ€. And as anyone whoâ€™s experimented with the materials of various test prep providers, *practice* tests can differ meaningfully from the *actual* test.\\n\\nThe same risk applies to most AI benchmarks, which are the â€œpublic leaderboardâ€ of AI evaluation. At any point during the training process, researchers can check their models against the benchmark to see how itâ€™s doing and ensure that performance is moving in the right direction. Benchmark performance isnâ€™t a â€œsurpriseâ€ at the end of a training run. Itâ€™s the same with Kaggle contests â€” contestants can always check their performance via the public leaderboard. This creates perverse incentives to only do things that drive direct improvement on the benchmarks, leading to overfitting, the curse of all machine learning practitioners.\\n\\nAgain, if you want some intuition, think about the education context. Imagine if teachers knew in real-time how their students would perform on the test â€” a score every day of class rather than one a year. Whatever concerns you have about teaching to the test, you should be only more concerned if teachers had a real-time view of their studentsâ€™ test performance. The dopamine rush of seeing those scores bob up and down every day would drive an even more myopic focus on test performance. Anything a teacher could do to drive up those scores, even if it meant rote memorization of facts, would be extremely tempting. This is the world we live in when it comes to AI benchmarking.\\n\\nThereâ€™s a balance we must strike. To the degree the test actually tests what you think and hope it does, it makes sense to â€œteach to the testâ€, assuming itâ€™s actual learning and not just coerced memorization. However, if the test isnâ€™t perfectly correlated with the true objective, these efforts can drive perverse behaviors in both the teachers (trainers) and students (models).\\n\\n## Closed source benchmarks\\n![closed-source-benchmarks](__GHOST_URL__/content/images/2024/05/closed-source-benchmarks.jpeg)\\n\\n[Iâ€™m a big fan of open source](https://whoisnnamdi.com/portfolio/) when it comes to software. Iâ€™m a big fan of closed source when it comes to standardized testing.\\n\\nOpen benchmarks have an important role to play, and **I donâ€™t think we think we should dispose of them.** A common basis of comparison that is open access, that we can all inspect and contribute to, is certainly valuable. But we also need to round out the ecosystem with **closed, private benchmarks**, a critical complement.\\n\\nJust like in the world of standardized testing, private benchmarks would need to establish themselves as standard-bearers for quality, which requires building up trust with the broad community. In a competitive market where end users of these models really do care about quality and performance, benchmark providers will sprout up and compete for their business, jostling for position as the ultimate arbiter of model performance. In the limit, *the benchmarks will be benchmarked*, in the same way that colleges are ranked for quality in explicit and implicit ways. Trusted â€œbrandsâ€ will emerge.\\n\\nIdeally, these private evaluators would not train and market state-of-the-art foundation models themselves, as there would always be an incentive to either leak the benchmark data to the training pipeline or craft a benchmark that the researchers know their model will perform well on.\\n\\nIn a perfect world, you would have **blind benchmarking**, which is to say benchmarking that is obfuscated from the folks who trained the model, so that there would be no way for the training pipeline to be contaminated. Model trainers would not know in advance what the benchmark is or what the questions are. They would train models to the best of their abilities, and only know how it performs on the benchmark after training is done. This is analogous to pre-registration of scientific studies, where researchers pre-commit to a certain methodology before conducting a trial or analysis. \\n\\nEven better, you would want **one-time benchmarks**: benchmarks crafted \\\\*once\\\\* and then only used \\\\*once\\\\* to test a model or a set of models. At that point, the benchmark would be â€œused upâ€ and no longer valid. Thatâ€™s how Kaggle works, and itâ€™s exactly how most standardized tests work â€” each exam is only given once, on a certain day, and then itâ€™s thrown out or farmed out to test prep providers and tutors who use it as part of their materials. This is fine â€” as long as the score students report to colleges is from a clean, never-before-seen exam.\\n\\nAgain, a college would never accept a studentâ€™s scores from an SAT practice exam as equally valid as the real thing. All Iâ€™m asking for here is a similar level of rigor.\\n\\n## Super serious\\n\\nMy point here is not â€” â€œthis AI stuff is a big conspiracy, these models are just stochastic parrots with no real intellect at allâ€. I think weâ€™re far enough along and the results of these models are way too compelling to short change them like that. We should take these models very seriously; they really are getting better and better all the time.\\n\\nMy point is exactly that â€” **we should take these models seriously, which means taking their evaluation seriously.** We arenâ€™t right now, at least not in the public discourse around model performance.\\n\\nNo exam is perfect â€” as we know, standardized tests have their flaws. But weâ€™re much better off having them than not. Right now, the broader AI community has no form of standardized testing for AI models. This is untenable.\\n\\nItâ€™s why I was so excited to lead [Patronus AIâ€™s](https://www.patronus.ai/) [seed round](https://lsvp.com/stories/building-with-patronus-ai-automated-ai-evaluation/) last year, and itâ€™s why Iâ€™m even more pumped now that theyâ€™ve raised a [$17M Series A](https://www.patronus.ai/blog/announcing-our-17-million-series-a).\\n\\n![patronus-series-a](__GHOST_URL__/content/images/2024/05/patronus-series-a.jpeg)\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: AI Benchmarking Is Broken\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p><em>To celebrate <a href=\"https://www.patronus.ai/blog/announcing-our-17-million-series-a\">Patronus AIâ€™s $17M Series A</a>, I wanted to share some thoughts on the current state of AI benchmarking.</em></p>\n<p>Imagine a standardized test that works like this:</p>\n<ul>\n<li>The questions and answers are freely available on the public internet</li>\n<li>Cheating is not regulated, itâ€™s a 100% honor system</li>\n<li>The exam never changes, itâ€™s the same questions every time</li>\n<li>Scores on the exam seem to be getting better every year</li>\n</ul>\n<p>In case youâ€™re wondering, the correct reaction is â€œthis is not a very good exam.â€ Cheating is rampant. The answers can all be memorized. The test isnâ€™t really much of a â€œtest.â€ The scores are meaningless.</p>\n<p>This is the current state of AI benchmarking. Ironically, we hold AI benchmarks to a very <em>low</em> standard. We allow practices that would never fly in other serious domains. Itâ€™s happening in plain sight, with a nod and a wink every time an AI lab releases a new model that tops the leaderboards.</p>\n<p>We must do better.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: AI Benchmarking Is Broken\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"something%E2%80%99s-in-the-water\">Somethingâ€™s in the water</h2>\n<p><img src=\"__GHOST_URL__/content/images/2024/05/training-data-contamination.jpeg\" alt=\"training-data-contamination\" loading=\"lazy\"></p>\n<p>The first dirty secret of AI benchmarks is quite literally, dirty: <strong>training data contamination</strong>.</p>\n<p>A common refrain among machine learning researchers and engineers â€” â€œdonâ€™t train on the test set.â€ In other words, donâ€™t train a model on the same dataset that you will evaluate it on. If you do, whether on purpose or not, that particular test is useless for evaluating model performance.</p>\n<p>Most open benchmarks are available on the public internet. In other words, the entire set of questions and answers exists on the open web, likely in multiple places. It is extremely easy for this data to inadvertently make its way into LLM training pipelines. The big AI labs are constantly hoovering up data from the internet via web crawlers, scraping their way across the web. While diligent researchers are careful about what ends up in the training data, applying all sorts of sophisticated filters to the raw data before feeding it to their models, invariably these filters are imperfect, and data from the benchmarks leaks in. It can happen during pre-training, it can happen during fine-tuning, either way, the bad data gets in. This renders invalid the downstream model performance on the benchmark.</p>\n<p>The test data from a particular benchmark can appear in many places. It could be in plaintext on a webpage somewhere. It could be a file in a GitHub repo, alongside code which a model is being trained with. It could be in the <em>comments</em> of a file or script inside of a repo. It could be on Reddit or X. It could really be anywhere.</p>\n<blockquote>\n<p>An increasingly important issue with evals is test set contamination. After the creation of a good eval, examples of the eval tend to get propagated into various places in the internet, like arxiv papers, ChatGPT examples, or reddit â€” <a href=\"https://www.jasonwei.net/blog/evals\">Jason Wei, OpenAI</a></p>\n</blockquote>\n<p>Itâ€™s been shown that a single training example can meaningfully impact the behavior of a model, so it only takes one mishap to contaminate a model. Model builders routinely train on trillions of tokens, so thereâ€™s no shortage of ways for accidents to occur.</p>\n<p>You might wonder, if the entire benchmark makes its way into the training data, then why donâ€™t the models score perfectly on the benchmarks? Remember, these models are complicated mathematical functions of the data â€” they are optimizing for all sorts of criteria that we donâ€™t fully understand (<a href=\"https://www.anthropic.com/research/mapping-mind-language-model\">though weâ€™re making progress</a>) and have been trained on vast sums of data, so any particular benchmark represents a very small share of the overall training corpus. A model trained on a particular dataset will fail to reproduce that data at times. This complex and non-deterministic mapping of inputs to outputs is arguably the distinguishing feature of LLMs relative to traditional machine learning models. So we shouldnâ€™t necessarily expect to see perfect benchmark performance even in the most blatantly contaminated scenarios.</p>\n<h2 id=\"it%E2%80%99s-not-what-you-think\">Itâ€™s not what you think</h2>\n<p>The next time you hear about how a new model crushes some well-established benchmark, take a moment to actually go to the primary source and review the tasks in the benchmark. Pick any of them, it doesnâ€™t really matter which. I would bet that, even as a non-specialist, you will very quickly begin to question whether the benchmark is really testing what it claims to test.</p>\n<p>Sometimes this is subtle; sometimes itâ€™s not. Many AI coding benchmarks have fairly trivial solutions that donâ€™t require meaningful code understanding or â€œintelligence.â€ Many â€œreasoningâ€ benchmarks donâ€™t require any reasoning.</p>\n<p>Again, donâ€™t take my word for it â€” I encourage you to, right now, read through a few examples from the many published benchmarks, and see what you think about the concepts they are purportedly testing. <strong>You will be less than impressed</strong>, and you will leave the exercise with a much reduced opinion of and trust in the performance of the latest and greatest models.</p>\n<p>This also relates to my point earlier about contamination, which is especially pernicious in the software development domain. Many â€œbrain twisterâ€ coding tasks are well-represented in the training data for these models, in part because software developers spend so much time preparing for such questions as part of job interviews. Coding competitions abound, which can serve as a signal to employers of an engineerâ€™s talent and skills. Their competition code often ends up on the public internet, where it gets picked up by training data crawlers.</p>\n<p>At test time, the model has already seen the question, perhaps in slightly modified form, and has memorized the answer. Itâ€™s not right to say a model regurgitating some code from some repo is â€œreasoningâ€ about software development. Itâ€™s much more akin to an engineer getting stuck and looking up some code on Stack Overflow, pasting it into their editor, and moving on.</p>\n<p>Thereâ€™s nothing wrong with a â€œStack Overflow botâ€! I would and do pay for such things. I just think we need to be very careful and specific about what we call it.</p>\n<h2 id=\"teaching-to-the-test\">Teaching to the test</h2>\n<p>Critics of standardized tests often complain they encourage teachers to â€œteach to the testâ€, focusing exclusively on material that will improve their studentsâ€™ performance on the test but that perhaps misses other information valuable to their overall edification as human beings and citizens. I think this critique has bite to it in the context of AI models.</p>\n<p>Hereâ€™s why. <a href=\"https://www.kaggle.com/\">Kaggle</a> is the most famous competition platform for machine learning practitioners. They hold frequent competitions where the goal is to build a machine learning model that can generate accurate predictions in a particular context based on provided (or otherwise procured) inputs. A key feature of Kaggle competitions is the <a href=\"https://www.kaggle.com/docs/competitions#leaderboard\">public leaderboard</a> â€” the real-time ranking of submitted models on a â€œvalidationâ€ dataset that only Kaggle has access to. Thus, they avoid the problem of data <a href=\"https://www.kaggle.com/docs/competitions#leakage\">leaking</a> into the training set.</p>\n<p>However, as is well-known among Kagglers, this â€œone weird trickâ€ doesnâ€™t solve all problems. After some time, the competition closes, at which point every model is re-evaluated on a previously closed â€œtest setâ€, the scores for which make up the â€œprivate leaderboardâ€. It is extremely common for the â€œbestâ€ model from the public leaderboard to fall a few places in the rankings on the private leaderboard and for another model to rise to the top. In fact, this happens so often that being in 1st place going into the final evaluation can often be a source of stress rather than relief, since you know thereâ€™s some risk youâ€™ve â€œ<a href=\"https://www.kaggle.com/docs/competitions#leaderboard\">overfit to the public leaderboard.</a>â€</p>\n<blockquote>\n<p>Many users watch the public leaderboard closely, as breakthroughs in the competition are announced by score gains in the leaderboard. These jumps in turn motivate other teams working on the competition in search of those advancements. But itâ€™s important to keep the public leaderboard in perspective. Itâ€™s very easy to overfit a model, creating something that performs very well on the public leaderboard, but very badly on the private one. This is calledÂ overfitting.</p>\n</blockquote>\n<p>Even though your model never saw the validation data directly, you did see its <em>score</em> on the data. That score is a noisy proxy for the data itself, so anything you do to improve the score implicitly leverages features of validation data, even if you never saw data directly. Since that score influenced the techniques and tricks you employed during model training, thereâ€™s a sense in which the validation data did â€œleakâ€ into training.</p>\n<p>Youâ€™ve effectively â€œtaught to the <em>practice</em> testâ€. And as anyone whoâ€™s experimented with the materials of various test prep providers, <em>practice</em> tests can differ meaningfully from the <em>actual</em> test.</p>\n<p>The same risk applies to most AI benchmarks, which are the â€œpublic leaderboardâ€ of AI evaluation. At any point during the training process, researchers can check their models against the benchmark to see how itâ€™s doing and ensure that performance is moving in the right direction. Benchmark performance isnâ€™t a â€œsurpriseâ€ at the end of a training run. Itâ€™s the same with Kaggle contests â€” contestants can always check their performance via the public leaderboard. This creates perverse incentives to only do things that drive direct improvement on the benchmarks, leading to overfitting, the curse of all machine learning practitioners.</p>\n<p>Again, if you want some intuition, think about the education context. Imagine if teachers knew in real-time how their students would perform on the test â€” a score every day of class rather than one a year. Whatever concerns you have about teaching to the test, you should be only more concerned if teachers had a real-time view of their studentsâ€™ test performance. The dopamine rush of seeing those scores bob up and down every day would drive an even more myopic focus on test performance. Anything a teacher could do to drive up those scores, even if it meant rote memorization of facts, would be extremely tempting. This is the world we live in when it comes to AI benchmarking.</p>\n<p>Thereâ€™s a balance we must strike. To the degree the test actually tests what you think and hope it does, it makes sense to â€œteach to the testâ€, assuming itâ€™s actual learning and not just coerced memorization. However, if the test isnâ€™t perfectly correlated with the true objective, these efforts can drive perverse behaviors in both the teachers (trainers) and students (models).</p>\n<h2 id=\"closed-source-benchmarks\">Closed source benchmarks</h2>\n<p><img src=\"__GHOST_URL__/content/images/2024/05/closed-source-benchmarks.jpeg\" alt=\"closed-source-benchmarks\" loading=\"lazy\"></p>\n<p><a href=\"https://whoisnnamdi.com/portfolio/\">Iâ€™m a big fan of open source</a> when it comes to software. Iâ€™m a big fan of closed source when it comes to standardized testing.</p>\n<p>Open benchmarks have an important role to play, and <strong>I donâ€™t think we think we should dispose of them.</strong> A common basis of comparison that is open access, that we can all inspect and contribute to, is certainly valuable. But we also need to round out the ecosystem with <strong>closed, private benchmarks</strong>, a critical complement.</p>\n<p>Just like in the world of standardized testing, private benchmarks would need to establish themselves as standard-bearers for quality, which requires building up trust with the broad community. In a competitive market where end users of these models really do care about quality and performance, benchmark providers will sprout up and compete for their business, jostling for position as the ultimate arbiter of model performance. In the limit, <em>the benchmarks will be benchmarked</em>, in the same way that colleges are ranked for quality in explicit and implicit ways. Trusted â€œbrandsâ€ will emerge.</p>\n<p>Ideally, these private evaluators would not train and market state-of-the-art foundation models themselves, as there would always be an incentive to either leak the benchmark data to the training pipeline or craft a benchmark that the researchers know their model will perform well on.</p>\n<p>In a perfect world, you would have <strong>blind benchmarking</strong>, which is to say benchmarking that is obfuscated from the folks who trained the model, so that there would be no way for the training pipeline to be contaminated. Model trainers would not know in advance what the benchmark is or what the questions are. They would train models to the best of their abilities, and only know how it performs on the benchmark after training is done. This is analogous to pre-registration of scientific studies, where researchers pre-commit to a certain methodology before conducting a trial or analysis.</p>\n<p>Even better, you would want <strong>one-time benchmarks</strong>: benchmarks crafted *once* and then only used *once* to test a model or a set of models. At that point, the benchmark would be â€œused upâ€ and no longer valid. Thatâ€™s how Kaggle works, and itâ€™s exactly how most standardized tests work â€” each exam is only given once, on a certain day, and then itâ€™s thrown out or farmed out to test prep providers and tutors who use it as part of their materials. This is fine â€” as long as the score students report to colleges is from a clean, never-before-seen exam.</p>\n<p>Again, a college would never accept a studentâ€™s scores from an SAT practice exam as equally valid as the real thing. All Iâ€™m asking for here is a similar level of rigor.</p>\n<h2 id=\"super-serious\">Super serious</h2>\n<p>My point here is not â€” â€œthis AI stuff is a big conspiracy, these models are just stochastic parrots with no real intellect at allâ€. I think weâ€™re far enough along and the results of these models are way too compelling to short change them like that. We should take these models very seriously; they really are getting better and better all the time.</p>\n<p>My point is exactly that â€” <strong>we should take these models seriously, which means taking their evaluation seriously.</strong> We arenâ€™t right now, at least not in the public discourse around model performance.</p>\n<p>No exam is perfect â€” as we know, standardized tests have their flaws. But weâ€™re much better off having them than not. Right now, the broader AI community has no form of standardized testing for AI models. This is untenable.</p>\n<p>Itâ€™s why I was so excited to lead <a href=\"https://www.patronus.ai/\">Patronus AIâ€™s</a> <a href=\"https://lsvp.com/stories/building-with-patronus-ai-automated-ai-evaluation/\">seed round</a> last year, and itâ€™s why Iâ€™m even more pumped now that theyâ€™ve raised a <a href=\"https://www.patronus.ai/blog/announcing-our-17-million-series-a\">$17M Series A</a>.</p>\n<p><img src=\"__GHOST_URL__/content/images/2024/05/patronus-series-a.jpeg\" alt=\"patronus-series-a\" loading=\"lazy\"></p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: AI Benchmarking Is Broken\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"665558b2fec7d1542d1d2fcd","plaintext":"To celebrate Patronus AIâ€™s $17M Series A\n[https://www.patronus.ai/blog/announcing-our-17-million-series-a], I wanted to\nshare some thoughts on the current state of AI benchmarking.\n\nImagine a standardized test that works like this:\n\n * The questions and answers are freely available on the public internet\n * Cheating is not regulated, itâ€™s a 100% honor system\n * The exam never changes, itâ€™s the same questions every time\n * Scores on the exam seem to be getting better every year\n\nIn case youâ€™re wondering, the correct reaction is â€œthis is not a very good\nexam.â€ Cheating is rampant. The answers can all be memorized. The test isnâ€™t\nreally much of a â€œtest.â€ The scores are meaningless.\n\nThis is the current state of AI benchmarking. Ironically, we hold AI benchmarks\nto a very low standard. We allow practices that would never fly in other serious\ndomains. Itâ€™s happening in plain sight, with a nod and a wink every time an AI\nlab releases a new model that tops the leaderboards.\n\nWe must do better.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Somethingâ€™s in the water\n\n\nThe first dirty secret of AI benchmarks is quite literally, dirty: training data\ncontamination.\n\nA common refrain among machine learning researchers and engineers â€” â€œdonâ€™t train\non the test set.â€ In other words, donâ€™t train a model on the same dataset that\nyou will evaluate it on. If you do, whether on purpose or not, that particular\ntest is useless for evaluating model performance.\n\nMost open benchmarks are available on the public internet. In other words, the\nentire set of questions and answers exists on the open web, likely in multiple\nplaces. It is extremely easy for this data to inadvertently make its way into\nLLM training pipelines. The big AI labs are constantly hoovering up data from\nthe internet via web crawlers, scraping their way across the web. While diligent\nresearchers are careful about what ends up in the training data, applying all\nsorts of sophisticated filters to the raw data before feeding it to their\nmodels, invariably these filters are imperfect, and data from the benchmarks\nleaks in. It can happen during pre-training, it can happen during fine-tuning,\neither way, the bad data gets in. This renders invalid the downstream model\nperformance on the benchmark.\n\nThe test data from a particular benchmark can appear in many places. It could be\nin plaintext on a webpage somewhere. It could be a file in a GitHub repo,\nalongside code which a model is being trained with. It could be in the comments \nof a file or script inside of a repo. It could be on Reddit or X. It could\nreally be anywhere.\n\n> An increasingly important issue with evals is test set contamination. After the\ncreation of a good eval, examples of the eval tend to get propagated into\nvarious places in the internet, like arxiv papers, ChatGPT examples, or reddit â€” \nJason Wei, OpenAI [https://www.jasonwei.net/blog/evals]\n\n\nItâ€™s been shown that a single training example can meaningfully impact the\nbehavior of a model, so it only takes one mishap to contaminate a model. Model\nbuilders routinely train on trillions of tokens, so thereâ€™s no shortage of ways\nfor accidents to occur.\n\nYou might wonder, if the entire benchmark makes its way into the training data,\nthen why donâ€™t the models score perfectly on the benchmarks? Remember, these\nmodels are complicated mathematical functions of the data â€” they are optimizing\nfor all sorts of criteria that we donâ€™t fully understand (though weâ€™re making\nprogress [https://www.anthropic.com/research/mapping-mind-language-model]) and\nhave been trained on vast sums of data, so any particular benchmark represents a\nvery small share of the overall training corpus. A model trained on a particular\ndataset will fail to reproduce that data at times. This complex and\nnon-deterministic mapping of inputs to outputs is arguably the distinguishing\nfeature of LLMs relative to traditional machine learning models. So we shouldnâ€™t\nnecessarily expect to see perfect benchmark performance even in the most\nblatantly contaminated scenarios.\n\nItâ€™s not what you think\nThe next time you hear about how a new model crushes some well-established\nbenchmark, take a moment to actually go to the primary source and review the\ntasks in the benchmark. Pick any of them, it doesnâ€™t really matter which. I\nwould bet that, even as a non-specialist, you will very quickly begin to\nquestion whether the benchmark is really testing what it claims to test.\n\nSometimes this is subtle; sometimes itâ€™s not. Many AI coding benchmarks have\nfairly trivial solutions that donâ€™t require meaningful code understanding or\nâ€œintelligence.â€ Many â€œreasoningâ€ benchmarks donâ€™t require any reasoning.\n\nAgain, donâ€™t take my word for it â€” I encourage you to, right now, read through a\nfew examples from the many published benchmarks, and see what you think about\nthe concepts they are purportedly testing. You will be less than impressed, and\nyou will leave the exercise with a much reduced opinion of and trust in the\nperformance of the latest and greatest models.\n\nThis also relates to my point earlier about contamination, which is especially\npernicious in the software development domain. Many â€œbrain twisterâ€ coding tasks\nare well-represented in the training data for these models, in part because\nsoftware developers spend so much time preparing for such questions as part of\njob interviews. Coding competitions abound, which can serve as a signal to\nemployers of an engineerâ€™s talent and skills. Their competition code often ends\nup on the public internet, where it gets picked up by training data crawlers.\n\nAt test time, the model has already seen the question, perhaps in slightly\nmodified form, and has memorized the answer. Itâ€™s not right to say a model\nregurgitating some code from some repo is â€œreasoningâ€ about software\ndevelopment. Itâ€™s much more akin to an engineer getting stuck and looking up\nsome code on Stack Overflow, pasting it into their editor, and moving on.\n\nThereâ€™s nothing wrong with a â€œStack Overflow botâ€! I would and do pay for such\nthings. I just think we need to be very careful and specific about what we call\nit.\n\nTeaching to the test\nCritics of standardized tests often complain they encourage teachers to â€œteach\nto the testâ€, focusing exclusively on material that will improve their studentsâ€™\nperformance on the test but that perhaps misses other information valuable to\ntheir overall edification as human beings and citizens. I think this critique\nhas bite to it in the context of AI models.\n\nHereâ€™s why. Kaggle [https://www.kaggle.com/] is the most famous competition\nplatform for machine learning practitioners. They hold frequent competitions\nwhere the goal is to build a machine learning model that can generate accurate\npredictions in a particular context based on provided (or otherwise procured)\ninputs. A key feature of Kaggle competitions is the public leaderboard\n[https://www.kaggle.com/docs/competitions#leaderboard] â€” the real-time ranking\nof submitted models on a â€œvalidationâ€ dataset that only Kaggle has access to.\nThus, they avoid the problem of data leaking\n[https://www.kaggle.com/docs/competitions#leakage] into the training set.\n\nHowever, as is well-known among Kagglers, this â€œone weird trickâ€ doesnâ€™t solve\nall problems. After some time, the competition closes, at which point every\nmodel is re-evaluated on a previously closed â€œtest setâ€, the scores for which\nmake up the â€œprivate leaderboardâ€. It is extremely common for the â€œbestâ€ model\nfrom the public leaderboard to fall a few places in the rankings on the private\nleaderboard and for another model to rise to the top. In fact, this happens so\noften that being in 1st place going into the final evaluation can often be a\nsource of stress rather than relief, since you know thereâ€™s some risk youâ€™ve â€œ\noverfit to the public leaderboard.\n[https://www.kaggle.com/docs/competitions#leaderboard]â€\n\n> Many users watch the public leaderboard closely, as breakthroughs in the\ncompetition are announced by score gains in the leaderboard. These jumps in turn\nmotivate other teams working on the competition in search of those advancements.\nBut itâ€™s important to keep the public leaderboard in perspective. Itâ€™s very easy\nto overfit a model, creating something that performs very well on the public\nleaderboard, but very badly on the private one. This is calledÂ overfitting.\n\n\nEven though your model never saw the validation data directly, you did see its \nscore on the data. That score is a noisy proxy for the data itself, so anything\nyou do to improve the score implicitly leverages features of validation data,\neven if you never saw data directly. Since that score influenced the techniques\nand tricks you employed during model training, thereâ€™s a sense in which the\nvalidation data did â€œleakâ€ into training.\n\nYouâ€™ve effectively â€œtaught to the practice testâ€. And as anyone whoâ€™s\nexperimented with the materials of various test prep providers, practice tests\ncan differ meaningfully from the actual test.\n\nThe same risk applies to most AI benchmarks, which are the â€œpublic leaderboardâ€\nof AI evaluation. At any point during the training process, researchers can\ncheck their models against the benchmark to see how itâ€™s doing and ensure that\nperformance is moving in the right direction. Benchmark performance isnâ€™t a\nâ€œsurpriseâ€ at the end of a training run. Itâ€™s the same with Kaggle contests â€”\ncontestants can always check their performance via the public leaderboard. This\ncreates perverse incentives to only do things that drive direct improvement on\nthe benchmarks, leading to overfitting, the curse of all machine learning\npractitioners.\n\nAgain, if you want some intuition, think about the education context. Imagine if\nteachers knew in real-time how their students would perform on the test â€” a\nscore every day of class rather than one a year. Whatever concerns you have\nabout teaching to the test, you should be only more concerned if teachers had a\nreal-time view of their studentsâ€™ test performance. The dopamine rush of seeing\nthose scores bob up and down every day would drive an even more myopic focus on\ntest performance. Anything a teacher could do to drive up those scores, even if\nit meant rote memorization of facts, would be extremely tempting. This is the\nworld we live in when it comes to AI benchmarking.\n\nThereâ€™s a balance we must strike. To the degree the test actually tests what you\nthink and hope it does, it makes sense to â€œteach to the testâ€, assuming itâ€™s\nactual learning and not just coerced memorization. However, if the test isnâ€™t\nperfectly correlated with the true objective, these efforts can drive perverse\nbehaviors in both the teachers (trainers) and students (models).\n\nClosed source benchmarks\n\n\nIâ€™m a big fan of open source [https://whoisnnamdi.com/portfolio/] when it comes\nto software. Iâ€™m a big fan of closed source when it comes to standardized\ntesting.\n\nOpen benchmarks have an important role to play, and I donâ€™t think we think we\nshould dispose of them. A common basis of comparison that is open access, that\nwe can all inspect and contribute to, is certainly valuable. But we also need to\nround out the ecosystem with closed, private benchmarks, a critical complement.\n\nJust like in the world of standardized testing, private benchmarks would need to\nestablish themselves as standard-bearers for quality, which requires building up\ntrust with the broad community. In a competitive market where end users of these\nmodels really do care about quality and performance, benchmark providers will\nsprout up and compete for their business, jostling for position as the ultimate\narbiter of model performance. In the limit, the benchmarks will be benchmarked,\nin the same way that colleges are ranked for quality in explicit and implicit\nways. Trusted â€œbrandsâ€ will emerge.\n\nIdeally, these private evaluators would not train and market state-of-the-art\nfoundation models themselves, as there would always be an incentive to either\nleak the benchmark data to the training pipeline or craft a benchmark that the\nresearchers know their model will perform well on.\n\nIn a perfect world, you would have blind benchmarking, which is to say\nbenchmarking that is obfuscated from the folks who trained the model, so that\nthere would be no way for the training pipeline to be contaminated. Model\ntrainers would not know in advance what the benchmark is or what the questions\nare. They would train models to the best of their abilities, and only know how\nit performs on the benchmark after training is done. This is analogous to\npre-registration of scientific studies, where researchers pre-commit to a\ncertain methodology before conducting a trial or analysis.\n\nEven better, you would want one-time benchmarks: benchmarks crafted *once* and\nthen only used *once* to test a model or a set of models. At that point, the\nbenchmark would be â€œused upâ€ and no longer valid. Thatâ€™s how Kaggle works, and\nitâ€™s exactly how most standardized tests work â€” each exam is only given once, on\na certain day, and then itâ€™s thrown out or farmed out to test prep providers and\ntutors who use it as part of their materials. This is fine â€” as long as the\nscore students report to colleges is from a clean, never-before-seen exam.\n\nAgain, a college would never accept a studentâ€™s scores from an SAT practice exam\nas equally valid as the real thing. All Iâ€™m asking for here is a similar level\nof rigor.\n\nSuper serious\nMy point here is not â€” â€œthis AI stuff is a big conspiracy, these models are just\nstochastic parrots with no real intellect at allâ€. I think weâ€™re far enough\nalong and the results of these models are way too compelling to short change\nthem like that. We should take these models very seriously; they really are\ngetting better and better all the time.\n\nMy point is exactly that â€” we should take these models seriously, which means\ntaking their evaluation seriously. We arenâ€™t right now, at least not in the\npublic discourse around model performance.\n\nNo exam is perfect â€” as we know, standardized tests have their flaws. But weâ€™re\nmuch better off having them than not. Right now, the broader AI community has no\nform of standardized testing for AI models. This is untenable.\n\nItâ€™s why I was so excited to lead Patronus AIâ€™s [https://www.patronus.ai/] seed\nround\n[https://lsvp.com/stories/building-with-patronus-ai-automated-ai-evaluation/] \nlast year, and itâ€™s why Iâ€™m even more pumped now that theyâ€™ve raised a $17M\nSeries A [https://www.patronus.ai/blog/announcing-our-17-million-series-a].\n\n\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2024/05/header-ai-benchmarking-broken.jpg","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2024-05-28T04:08:18.000Z","updated_at":"2024-05-30T05:40:31.000Z","published_at":"2024-05-28T13:29:17.000Z","custom_excerpt":"We should take AI models seriously, which means taking their evaluation seriously","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"},{"id":"66fd79c6fec7d1542d1d300b","uuid":"ec18c99d-85ae-456d-977b-86cb1f6d73b4","title":"Seed Valuations Arenâ€™t Valuations","slug":"seed-valuations","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Seed valuations don't behave like valuations:\\n* They are too stable over time for such a speculative asset\\n* They are impervious to shifting interest rates\\n* They donâ€™t follow public tech valuations\\n\\nIn short, seed valuations are a bit of an enigma â€” itâ€™s not at all obvious what drives them. However investors arrive at these numbers, they arenâ€™t doing so based on typical Finance 101 factors like discount rates or comparable company analysis.\\n\\nSeed companies donâ€™t seem to be priced as businesses with intrinsic value derived from future cash flows. Rather than *venture capital*, they seem to be a proxy for the **human capital** of the founders and early team.\\n\\nSeed valuations arenâ€™t valuations.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Top: Seed Valuations Arenâ€™t Valuations\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\\n\\n## Non-standard deviations\\n\\n**First: seed valuations arenâ€™t volatile enough.**\\n\\nThis really stood out when constructing my [Venture Activity Index](https://whoisnnamdi.com/venture-activity-index/) â€“ the volatility of the late stage is much higher than the early stage, which is true even if you exclude the pandemic era:\\n\\n![vol](__GHOST_URL__/content/images/2024/10/vol.png)\\n\\nThis is strange. If seed stage investments are as speculative as theyâ€™re purported to be, we'd expect wild valuation fluctuations over time. Late-stage valuations should be more stable, since they have an existing business model, revenues, and potentially even cash flows (hard to believe, I know).\\n\\nImagine if large, blue chip stocks were more volatile than small caps. That wouldn't make much sense. The stability of seed valuations relative to more mature startups makes no sense either.\\n\\nAs Iâ€™ve previously covered, [capital flows affect valuations](https://whoisnnamdi.com/shadow-price/), and this force is most extreme at the later stages where the so-called \\\"crossover funds\\\" (funds who've crossed over from public market to private market investing) are most active. Thus, capital flows drive excess volatility at the later stages. However, I don't think that can explain everything going on here.\\n\\nAnd yes, there are many more seed deals getting done each quarter than later-stage rounds, so due to some [fundamental laws of statistics](https://en.wikipedia.org/wiki/Central_limit_theorem) weâ€™d expect less variability with a larger sample. Even so, seed valuations seem too stable on a relative basis.\\n\\n## Discount rates donâ€™t matter if thereâ€™s nothing to discount\\n\\n**Second: interest rates donâ€™t affect seed valuations.**\\n\\nIn the standard corporate finance logic, early stage companies should be the most sensitive to interest rates because they have the highest *duration*. Think of duration as a measure of distance, measured in years, to the average dollar of cash flow for a business. For early stage companies, all cash flow the business will ever produce is far into the future, so they definitionally have high duration. In a discounted cash flow model, seed valuations would be extremely sensitive to movements in the discount rate, similar to a long-dated bond:\\n\\n> Duration measures the sensitivity of the value of a bond to a change in interest rates, which is tied to the lifetime of the bond. Bonds with longer tenure or back-loaded cash flows are more sensitive to changes in interest rates\\n> \\n> Due to theÂ [multiplicative nature](https://whoisnnamdi.com/you-dont-understand-compound-growth/)Â of discounting, the present value of far-away payments is more sensitive to a change in interest rates than the value of soon-to-come payments â€“ [High Retention = High Volatility](https://whoisnnamdi.com/high-retention-high-volatility/)\\n\\n**That's not what we see.** [Some time ago](https://whoisnnamdi.com/discount-rates/) I investigated the â€œaverageâ€ impact of interest rate surprises on venture valuations across all stages. I've since revisited and refined that analysis, adding more granularity to the estimates. I've also stripped out the COVID era, where the impact of fund flows contaminates the estimates.\\n\\nWhat I found was fascinating. Here's the impact of a surprise 1% increase in the one-year Treasury yield across seed, Series A / B, and Series C / D, along with a measure of uncertainty around these estimates, going twelve quarters out:\\n\\n![sv-1](__GHOST_URL__/content/images/2024/10/sv-1.png)\\n\\n* **Interest rates have no effect on seed valuations.** Not only is the impact zero, itâ€™s *precisely zero*. There isn't a ton of uncertainty around these estimates.\\n* For Series A / B, we start to see some effect, maxing out at a 16% decline seven quarters after impact before recovering.\\n* For proper growth stage rounds like Series C / D, the impact is even quicker and more severe, peaking at 19% six quarters out.\\n\\nThis is the most striking evidence â€” the clearest indication that investors value seed stage startups in a totally distinct way to the rest of the venture market. Itâ€™s hard to rationalize this evidence within the usual frameworks.\\n\\n## They not like us\\n\\n**Third: public tech valuations donâ€™t influence seed valuations.**\\n\\nWhen the big tech (â€œFANGâ€, the â€œMagnificent 7, etc) valuations move around, private valuations typically follow, with a lag. This makes intuitive sense given venture investors use comparable public company valuations to decide how much theyâ€™re willing to pay for private companies. In a rational market weâ€™d expect some correlation between public and private valuations, even if imperfect. This is â€œcomps analysisâ€ in a nutshell.\\n\\nAnd thatâ€™s what we see â€” *except* for seed companies:\\n\\n![nv-1](__GHOST_URL__/content/images/2024/10/nv-1.png)\\n\\nWhen the Nasdaq rises 1%:\\n* Series A through D valuations rise, matching the bump in the Nasdaq within about a year.\\n* Seed valuations donâ€™t move at all, marching to the beat of their own, relatively quiet drummer\\n\\nWhile thereâ€™s a very clear pass-through effect of public prices on private valuations for most stages, seed startups are the exception, seeing no pass-through at all. It turns out, **investors donâ€™t care about public comps when pricing seed stage companies.**\\n\\nItâ€™s clear that seed valuations are not really valuations in the traditional sense. They don't behave like valuations in either their volatility over time or their sensitivity to interest rates. Something else must be going on here.\\n\\n## These prices are sticky too\\n\\nIt struck me that seed valuations were incredibly *sticky* (an early working title for this essay was \\\"Why are Seed Valuations so Sticky?â€). Seed valuations neither rise nor fall dramatically far from trend, whereas other stages see much strong gyrations: \\n\\n![sticky](__GHOST_URL__/content/images/2024/10/sticky.png)\\n\\nThis \\\"stickiness\\\" is unique to seed valuations and doesn't mirror the behavior of free-floating financial assets, which are typically much more volatile and difficult to forecast.\\n\\nI stared at the seed valuation data for a long time as I contemplated this essay. As my eyes glazed over, I tried to come up with analogues, other phenomena that mimic the behavior of seed valuations.\\n\\nThen it hit me â€“ wages. [Wages are often said to be â€œstickyâ€](https://www.richmondfed.org/~/media/richmondfedorg/publications/research/econ_focus/2013/q1/pdf/jargon_alert.pdf), and seed stage valuations look eerily similar to wages over time, which also tend to be quite stable around a long-term, upward trend.\\n\\nThe simplest thing to do is plot compensation against seed stage valuations. I found a wage series called the â€œEmployment Cost Indexâ€ (ECI) that measures compensation growth over time, and I pulled out a [version](https://fred.stlouisfed.org/series/CIU2015400000000I) of this thatâ€™s specific to â€œprofessional, scientific, and technical services,â€ which I take to be a good proxy for tech workers:\\n\\n![cbs-1](__GHOST_URL__/content/images/2024/10/cbs-1.png)\\n\\n* The first thing that stands out is the obvious difference in growth rates. Seed stage valuations have risen much faster than wages for the typical tech worker. **For every 1% increase in tech worker wages, seed stage valuations grow 4-5%.**\\n* We can predict seed stage valuations from the wage data. I regress seed valuations on the ECI using pre-2020 data. The fit is tight pre-2020 (which is frankly easy since theyâ€™re both roughly straight lines).\\n* Then I evaluate its forecasts on post-2020 data, â€œout of sampleâ€. The model returns to a reasonably close fit once valuations settle down after the 2021-2022 bonanza.\\n* Notably, **seed valuations bottomed out at exactly the level you would have predicted using the employment cost index.**\\n\\nThis feels like more than coincidence. Regressions do have a high risk of being spurious, which is to say, total nonsense. I was skeptical the first time I ran these numbers. But after multiple sanity checks, this seems to be the real deal. There is a tight connection between seed valuations and wages for tech workers; the two follow the same trend, one an accelerated version of the other. Thus we have a [scaling law](https://arxiv.org/abs/2001.08361) between tech wages and seed valuations:\\n\\n$$\\\\text{ Seed Valuations} \\\\propto \\\\text{ Tech Wages}^{4.5}$$\\n\\nThe inverse of [stock-based compensation](https://corporatefinanceinstitute.com/resources/accounting/share-stock-based-compensation/), seed companies appear to be **compensation-based stocks**, at least in how theyâ€™re valued.\\n\\n## Google is my [BATNA](https://www.pon.harvard.edu/daily/batna/translate-your-batna-to-the-current-deal/)\\n\\nThis analysis doesn't *prove* anything, but it does suggest an interesting link between tech wages and seed valuations.\\n\\nWhy would seed valuations be linked to the cost of tech labor? And why would those valuations grow so much faster than wages? Iâ€™m not even 100% convinced that itâ€™s a direct, causal connection â€” perhaps thereâ€™s some third variable that drives both. Totally plausible. I plan to explore this in a future piece.\\n\\nRegardless, itâ€™s quite clear to me after crunching the numbers that seed valuations donâ€™t behave anything like valuations, at least not valuations of *companies* or speculative assets. Their stability suggests investors have a precise sense of their worth, despite their riskiness. The value investors place on these companies does not fluctuate wildly over time.\\n\\nThis is odd only if your mental model values these fledging enterprises asâ€¦ enterprises. What if seed stage valuations instead represent the value of the labor and human capital of founders and early employees? The behavior of seed valuations would make a lot more sense if we saw them as proxies for the opportunity cost of talented tech workers.\\n\\nIâ€™ll explore this hypothesis in a future essay.\\n\\n<section class=\\\"subscribe-form\\\">\\n    <h3 class=\\\"subscribe-form-title\\\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\\n                <p></p>\\n<form action=\\\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\\\" method=\\\"post\\\" id=\\\"mc-embedded-subscribe-form\\\" name=\\\"mc-embedded-subscribe-form\\\" class=\\\"validate\\\" target=\\\"_blank\\\" novalidate>\\n    <div class=\\\"form-group\\\">\\n        \\t<input class=\\\"subscribe-email\\\" type=\\\"email\\\" name=\\\"EMAIL\\\" value=\\\"\\\" name=\\\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\\\" tabindex=\\\"-1\\\" placeholder=\\\"Enter your email\\\" id=\\\"mce-EMAIL\\\" required>\\n        <input type=\\\"hidden\\\" name=\\\"SOURCE\\\" id=\\\"SOURCE\\\" value=\\\"Bottom: Seed Valuations Arenâ€™t Valuations\\\">\\n    </div>\\n    <button id=\\\"\\\" class=\\\"\\\" type=\\\"submit\\\" name=\\\"subscribe\\\" id=\\\"mc-embedded-subscribe\\\"><span class=\\\"sub-button\\\">Go âš¡</span></button>\\n</form>\\n</section>\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<!--kg-card-begin: markdown--><p>Seed valuations don't behave like valuations:</p>\n<ul>\n<li>They are too stable over time for such a speculative asset</li>\n<li>They are impervious to shifting interest rates</li>\n<li>They donâ€™t follow public tech valuations</li>\n</ul>\n<p>In short, seed valuations are a bit of an enigma â€” itâ€™s not at all obvious what drives them. However investors arrive at these numbers, they arenâ€™t doing so based on typical Finance 101 factors like discount rates or comparable company analysis.</p>\n<p>Seed companies donâ€™t seem to be priced as businesses with intrinsic value derived from future cash flows. Rather than <em>venture capital</em>, they seem to be a proxy for the <strong>human capital</strong> of the founders and early team.</p>\n<p>Seed valuations arenâ€™t valuations.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Top: Seed Valuations Arenâ€™t Valuations\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section>\n<h2 id=\"non-standard-deviations\">Non-standard deviations</h2>\n<p><strong>First: seed valuations arenâ€™t volatile enough.</strong></p>\n<p>This really stood out when constructing my <a href=\"https://whoisnnamdi.com/venture-activity-index/\">Venture Activity Index</a> â€“ the volatility of the late stage is much higher than the early stage, which is true even if you exclude the pandemic era:</p>\n<p><img src=\"__GHOST_URL__/content/images/2024/10/vol.png\" alt=\"vol\" loading=\"lazy\"></p>\n<p>This is strange. If seed stage investments are as speculative as theyâ€™re purported to be, we'd expect wild valuation fluctuations over time. Late-stage valuations should be more stable, since they have an existing business model, revenues, and potentially even cash flows (hard to believe, I know).</p>\n<p>Imagine if large, blue chip stocks were more volatile than small caps. That wouldn't make much sense. The stability of seed valuations relative to more mature startups makes no sense either.</p>\n<p>As Iâ€™ve previously covered, <a href=\"https://whoisnnamdi.com/shadow-price/\">capital flows affect valuations</a>, and this force is most extreme at the later stages where the so-called &quot;crossover funds&quot; (funds who've crossed over from public market to private market investing) are most active. Thus, capital flows drive excess volatility at the later stages. However, I don't think that can explain everything going on here.</p>\n<p>And yes, there are many more seed deals getting done each quarter than later-stage rounds, so due to some <a href=\"https://en.wikipedia.org/wiki/Central_limit_theorem\">fundamental laws of statistics</a> weâ€™d expect less variability with a larger sample. Even so, seed valuations seem too stable on a relative basis.</p>\n<h2 id=\"discount-rates-don%E2%80%99t-matter-if-there%E2%80%99s-nothing-to-discount\">Discount rates donâ€™t matter if thereâ€™s nothing to discount</h2>\n<p><strong>Second: interest rates donâ€™t affect seed valuations.</strong></p>\n<p>In the standard corporate finance logic, early stage companies should be the most sensitive to interest rates because they have the highest <em>duration</em>. Think of duration as a measure of distance, measured in years, to the average dollar of cash flow for a business. For early stage companies, all cash flow the business will ever produce is far into the future, so they definitionally have high duration. In a discounted cash flow model, seed valuations would be extremely sensitive to movements in the discount rate, similar to a long-dated bond:</p>\n<blockquote>\n<p>Duration measures the sensitivity of the value of a bond to a change in interest rates, which is tied to the lifetime of the bond. Bonds with longer tenure or back-loaded cash flows are more sensitive to changes in interest rates</p>\n<p>Due to theÂ <a href=\"https://whoisnnamdi.com/you-dont-understand-compound-growth/\">multiplicative nature</a>Â of discounting, the present value of far-away payments is more sensitive to a change in interest rates than the value of soon-to-come payments â€“ <a href=\"https://whoisnnamdi.com/high-retention-high-volatility/\">High Retention = High Volatility</a></p>\n</blockquote>\n<p><strong>That's not what we see.</strong> <a href=\"https://whoisnnamdi.com/discount-rates/\">Some time ago</a> I investigated the â€œaverageâ€ impact of interest rate surprises on venture valuations across all stages. I've since revisited and refined that analysis, adding more granularity to the estimates. I've also stripped out the COVID era, where the impact of fund flows contaminates the estimates.</p>\n<p>What I found was fascinating. Here's the impact of a surprise 1% increase in the one-year Treasury yield across seed, Series A / B, and Series C / D, along with a measure of uncertainty around these estimates, going twelve quarters out:</p>\n<p><img src=\"__GHOST_URL__/content/images/2024/10/sv-1.png\" alt=\"sv-1\" loading=\"lazy\"></p>\n<ul>\n<li><strong>Interest rates have no effect on seed valuations.</strong> Not only is the impact zero, itâ€™s <em>precisely zero</em>. There isn't a ton of uncertainty around these estimates.</li>\n<li>For Series A / B, we start to see some effect, maxing out at a 16% decline seven quarters after impact before recovering.</li>\n<li>For proper growth stage rounds like Series C / D, the impact is even quicker and more severe, peaking at 19% six quarters out.</li>\n</ul>\n<p>This is the most striking evidence â€” the clearest indication that investors value seed stage startups in a totally distinct way to the rest of the venture market. Itâ€™s hard to rationalize this evidence within the usual frameworks.</p>\n<h2 id=\"they-not-like-us\">They not like us</h2>\n<p><strong>Third: public tech valuations donâ€™t influence seed valuations.</strong></p>\n<p>When the big tech (â€œFANGâ€, the â€œMagnificent 7, etc) valuations move around, private valuations typically follow, with a lag. This makes intuitive sense given venture investors use comparable public company valuations to decide how much theyâ€™re willing to pay for private companies. In a rational market weâ€™d expect some correlation between public and private valuations, even if imperfect. This is â€œcomps analysisâ€ in a nutshell.</p>\n<p>And thatâ€™s what we see â€” <em>except</em> for seed companies:</p>\n<p><img src=\"__GHOST_URL__/content/images/2024/10/nv-1.png\" alt=\"nv-1\" loading=\"lazy\"></p>\n<p>When the Nasdaq rises 1%:</p>\n<ul>\n<li>Series A through D valuations rise, matching the bump in the Nasdaq within about a year.</li>\n<li>Seed valuations donâ€™t move at all, marching to the beat of their own, relatively quiet drummer</li>\n</ul>\n<p>While thereâ€™s a very clear pass-through effect of public prices on private valuations for most stages, seed startups are the exception, seeing no pass-through at all. It turns out, <strong>investors donâ€™t care about public comps when pricing seed stage companies.</strong></p>\n<p>Itâ€™s clear that seed valuations are not really valuations in the traditional sense. They don't behave like valuations in either their volatility over time or their sensitivity to interest rates. Something else must be going on here.</p>\n<h2 id=\"these-prices-are-sticky-too\">These prices are sticky too</h2>\n<p>It struck me that seed valuations were incredibly <em>sticky</em> (an early working title for this essay was &quot;Why are Seed Valuations so Sticky?â€). Seed valuations neither rise nor fall dramatically far from trend, whereas other stages see much strong gyrations:</p>\n<p><img src=\"__GHOST_URL__/content/images/2024/10/sticky.png\" alt=\"sticky\" loading=\"lazy\"></p>\n<p>This &quot;stickiness&quot; is unique to seed valuations and doesn't mirror the behavior of free-floating financial assets, which are typically much more volatile and difficult to forecast.</p>\n<p>I stared at the seed valuation data for a long time as I contemplated this essay. As my eyes glazed over, I tried to come up with analogues, other phenomena that mimic the behavior of seed valuations.</p>\n<p>Then it hit me â€“ wages. <a href=\"https://www.richmondfed.org/~/media/richmondfedorg/publications/research/econ_focus/2013/q1/pdf/jargon_alert.pdf\">Wages are often said to be â€œstickyâ€</a>, and seed stage valuations look eerily similar to wages over time, which also tend to be quite stable around a long-term, upward trend.</p>\n<p>The simplest thing to do is plot compensation against seed stage valuations. I found a wage series called the â€œEmployment Cost Indexâ€ (ECI) that measures compensation growth over time, and I pulled out a <a href=\"https://fred.stlouisfed.org/series/CIU2015400000000I\">version</a> of this thatâ€™s specific to â€œprofessional, scientific, and technical services,â€ which I take to be a good proxy for tech workers:</p>\n<p><img src=\"__GHOST_URL__/content/images/2024/10/cbs-1.png\" alt=\"cbs-1\" loading=\"lazy\"></p>\n<ul>\n<li>The first thing that stands out is the obvious difference in growth rates. Seed stage valuations have risen much faster than wages for the typical tech worker. <strong>For every 1% increase in tech worker wages, seed stage valuations grow 4-5%.</strong></li>\n<li>We can predict seed stage valuations from the wage data. I regress seed valuations on the ECI using pre-2020 data. The fit is tight pre-2020 (which is frankly easy since theyâ€™re both roughly straight lines).</li>\n<li>Then I evaluate its forecasts on post-2020 data, â€œout of sampleâ€. The model returns to a reasonably close fit once valuations settle down after the 2021-2022 bonanza.</li>\n<li>Notably, <strong>seed valuations bottomed out at exactly the level you would have predicted using the employment cost index.</strong></li>\n</ul>\n<p>This feels like more than coincidence. Regressions do have a high risk of being spurious, which is to say, total nonsense. I was skeptical the first time I ran these numbers. But after multiple sanity checks, this seems to be the real deal. There is a tight connection between seed valuations and wages for tech workers; the two follow the same trend, one an accelerated version of the other. Thus we have a <a href=\"https://arxiv.org/abs/2001.08361\">scaling law</a> between tech wages and seed valuations:</p>\n<p>$$\\text{ Seed Valuations} \\propto \\text{ Tech Wages}^{4.5}$$</p>\n<p>The inverse of <a href=\"https://corporatefinanceinstitute.com/resources/accounting/share-stock-based-compensation/\">stock-based compensation</a>, seed companies appear to be <strong>compensation-based stocks</strong>, at least in how theyâ€™re valued.</p>\n<h2 id=\"google-is-my-batna\">Google is my <a href=\"https://www.pon.harvard.edu/daily/batna/translate-your-batna-to-the-current-deal/\">BATNA</a></h2>\n<p>This analysis doesn't <em>prove</em> anything, but it does suggest an interesting link between tech wages and seed valuations.</p>\n<p>Why would seed valuations be linked to the cost of tech labor? And why would those valuations grow so much faster than wages? Iâ€™m not even 100% convinced that itâ€™s a direct, causal connection â€” perhaps thereâ€™s some third variable that drives both. Totally plausible. I plan to explore this in a future piece.</p>\n<p>Regardless, itâ€™s quite clear to me after crunching the numbers that seed valuations donâ€™t behave anything like valuations, at least not valuations of <em>companies</em> or speculative assets. Their stability suggests investors have a precise sense of their worth, despite their riskiness. The value investors place on these companies does not fluctuate wildly over time.</p>\n<p>This is odd only if your mental model values these fledging enterprises asâ€¦ enterprises. What if seed stage valuations instead represent the value of the labor and human capital of founders and early employees? The behavior of seed valuations would make a lot more sense if we saw them as proxies for the opportunity cost of talented tech workers.</p>\n<p>Iâ€™ll explore this hypothesis in a future essay.</p>\n<section class=\"subscribe-form\">\n    <h3 class=\"subscribe-form-title\">Receive my new long-form essays</h3><p>Thoughtful analysis of the business and economics of tech</p>\n                <p></p>\n<form action=\"https://whoisnnamdi.us19.list-manage.com/subscribe/post?u=5ccf9576ceb276d2efb6610b8&amp;id=e2b399febf\" method=\"post\" id=\"mc-embedded-subscribe-form\" name=\"mc-embedded-subscribe-form\" class=\"validate\" target=\"_blank\" novalidate>\n    <div class=\"form-group\">\n        \t<input class=\"subscribe-email\" type=\"email\" name=\"EMAIL\" value=\"\" name=\"b_5ccf9576ceb276d2efb6610b8_e2b399febf\" tabindex=\"-1\" placeholder=\"Enter your email\" id=\"mce-EMAIL\" required>\n        <input type=\"hidden\" name=\"SOURCE\" id=\"SOURCE\" value=\"Bottom: Seed Valuations Arenâ€™t Valuations\">\n    </div>\n    <button id=\"\" class=\"\" type=\"submit\" name=\"subscribe\" id=\"mc-embedded-subscribe\"><span class=\"sub-button\">Go âš¡</span></button>\n</form>\n</section><!--kg-card-end: markdown-->","comment_id":"66fd79c6fec7d1542d1d300b","plaintext":"Seed valuations don't behave like valuations:\n\n * They are too stable over time for such a speculative asset\n * They are impervious to shifting interest rates\n * They donâ€™t follow public tech valuations\n\nIn short, seed valuations are a bit of an enigma â€” itâ€™s not at all obvious what\ndrives them. However investors arrive at these numbers, they arenâ€™t doing so\nbased on typical Finance 101 factors like discount rates or comparable company\nanalysis.\n\nSeed companies donâ€™t seem to be priced as businesses with intrinsic value\nderived from future cash flows. Rather than venture capital, they seem to be a\nproxy for the human capital of the founders and early team.\n\nSeed valuations arenâ€™t valuations.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡Non-standard deviations\nFirst: seed valuations arenâ€™t volatile enough.\n\nThis really stood out when constructing my Venture Activity Index\n[https://whoisnnamdi.com/venture-activity-index/] â€“ the volatility of the late\nstage is much higher than the early stage, which is true even if you exclude the\npandemic era:\n\n\n\nThis is strange. If seed stage investments are as speculative as theyâ€™re\npurported to be, we'd expect wild valuation fluctuations over time. Late-stage\nvaluations should be more stable, since they have an existing business model,\nrevenues, and potentially even cash flows (hard to believe, I know).\n\nImagine if large, blue chip stocks were more volatile than small caps. That\nwouldn't make much sense. The stability of seed valuations relative to more\nmature startups makes no sense either.\n\nAs Iâ€™ve previously covered, capital flows affect valuations\n[https://whoisnnamdi.com/shadow-price/], and this force is most extreme at the\nlater stages where the so-called \"crossover funds\" (funds who've crossed over\nfrom public market to private market investing) are most active. Thus, capital\nflows drive excess volatility at the later stages. However, I don't think that\ncan explain everything going on here.\n\nAnd yes, there are many more seed deals getting done each quarter than\nlater-stage rounds, so due to some fundamental laws of statistics\n[https://en.wikipedia.org/wiki/Central_limit_theorem] weâ€™d expect less\nvariability with a larger sample. Even so, seed valuations seem too stable on a\nrelative basis.\n\nDiscount rates donâ€™t matter if thereâ€™s nothing to discount\nSecond: interest rates donâ€™t affect seed valuations.\n\nIn the standard corporate finance logic, early stage companies should be the\nmost sensitive to interest rates because they have the highest duration. Think\nof duration as a measure of distance, measured in years, to the average dollar\nof cash flow for a business. For early stage companies, all cash flow the\nbusiness will ever produce is far into the future, so they definitionally have\nhigh duration. In a discounted cash flow model, seed valuations would be\nextremely sensitive to movements in the discount rate, similar to a long-dated\nbond:\n\n> Duration measures the sensitivity of the value of a bond to a change in interest\nrates, which is tied to the lifetime of the bond. Bonds with longer tenure or\nback-loaded cash flows are more sensitive to changes in interest rates\n\nDue to themultiplicative nature\n[https://whoisnnamdi.com/you-dont-understand-compound-growth/]of discounting,\nthe present value of far-away payments is more sensitive to a change in interest\nrates than the value of soon-to-come payments â€“ High Retention = High Volatility\n[https://whoisnnamdi.com/high-retention-high-volatility/]\n\n\nThat's not what we see. Some time ago [https://whoisnnamdi.com/discount-rates/] \nI investigated the â€œaverageâ€ impact of interest rate surprises on venture\nvaluations across all stages. I've since revisited and refined that analysis,\nadding more granularity to the estimates. I've also stripped out the COVID era,\nwhere the impact of fund flows contaminates the estimates.\n\nWhat I found was fascinating. Here's the impact of a surprise 1% increase in the\none-year Treasury yield across seed, Series A / B, and Series C / D, along with\na measure of uncertainty around these estimates, going twelve quarters out:\n\n\n\n * Interest rates have no effect on seed valuations. Not only is the impact\n   zero, itâ€™s precisely zero. There isn't a ton of uncertainty around these\n   estimates.\n * For Series A / B, we start to see some effect, maxing out at a 16% decline\n   seven quarters after impact before recovering.\n * For proper growth stage rounds like Series C / D, the impact is even quicker\n   and more severe, peaking at 19% six quarters out.\n\nThis is the most striking evidence â€” the clearest indication that investors\nvalue seed stage startups in a totally distinct way to the rest of the venture\nmarket. Itâ€™s hard to rationalize this evidence within the usual frameworks.\n\nThey not like us\nThird: public tech valuations donâ€™t influence seed valuations.\n\nWhen the big tech (â€œFANGâ€, the â€œMagnificent 7, etc) valuations move around,\nprivate valuations typically follow, with a lag. This makes intuitive sense\ngiven venture investors use comparable public company valuations to decide how\nmuch theyâ€™re willing to pay for private companies. In a rational market weâ€™d\nexpect some correlation between public and private valuations, even if\nimperfect. This is â€œcomps analysisâ€ in a nutshell.\n\nAnd thatâ€™s what we see â€” except for seed companies:\n\n\n\nWhen the Nasdaq rises 1%:\n\n * Series A through D valuations rise, matching the bump in the Nasdaq within\n   about a year.\n * Seed valuations donâ€™t move at all, marching to the beat of their own,\n   relatively quiet drummer\n\nWhile thereâ€™s a very clear pass-through effect of public prices on private\nvaluations for most stages, seed startups are the exception, seeing no\npass-through at all. It turns out, investors donâ€™t care about public comps when\npricing seed stage companies.\n\nItâ€™s clear that seed valuations are not really valuations in the traditional\nsense. They don't behave like valuations in either their volatility over time or\ntheir sensitivity to interest rates. Something else must be going on here.\n\nThese prices are sticky too\nIt struck me that seed valuations were incredibly sticky (an early working title\nfor this essay was \"Why are Seed Valuations so Sticky?â€). Seed valuations\nneither rise nor fall dramatically far from trend, whereas other stages see much\nstrong gyrations:\n\n\n\nThis \"stickiness\" is unique to seed valuations and doesn't mirror the behavior\nof free-floating financial assets, which are typically much more volatile and\ndifficult to forecast.\n\nI stared at the seed valuation data for a long time as I contemplated this\nessay. As my eyes glazed over, I tried to come up with analogues, other\nphenomena that mimic the behavior of seed valuations.\n\nThen it hit me â€“ wages. Wages are often said to be â€œstickyâ€\n[https://www.richmondfed.org/~/media/richmondfedorg/publications/research/econ_focus/2013/q1/pdf/jargon_alert.pdf]\n, and seed stage valuations look eerily similar to wages over time, which also\ntend to be quite stable around a long-term, upward trend.\n\nThe simplest thing to do is plot compensation against seed stage valuations. I\nfound a wage series called the â€œEmployment Cost Indexâ€ (ECI) that measures\ncompensation growth over time, and I pulled out a version\n[https://fred.stlouisfed.org/series/CIU2015400000000I] of this thatâ€™s specific\nto â€œprofessional, scientific, and technical services,â€ which I take to be a good\nproxy for tech workers:\n\n\n\n * The first thing that stands out is the obvious difference in growth rates.\n   Seed stage valuations have risen much faster than wages for the typical tech\n   worker. For every 1% increase in tech worker wages, seed stage valuations\n   grow 4-5%.\n * We can predict seed stage valuations from the wage data. I regress seed\n   valuations on the ECI using pre-2020 data. The fit is tight pre-2020 (which\n   is frankly easy since theyâ€™re both roughly straight lines).\n * Then I evaluate its forecasts on post-2020 data, â€œout of sampleâ€. The model\n   returns to a reasonably close fit once valuations settle down after the\n   2021-2022 bonanza.\n * Notably, seed valuations bottomed out at exactly the level you would have\n   predicted using the employment cost index.\n\nThis feels like more than coincidence. Regressions do have a high risk of being\nspurious, which is to say, total nonsense. I was skeptical the first time I ran\nthese numbers. But after multiple sanity checks, this seems to be the real deal.\nThere is a tight connection between seed valuations and wages for tech workers;\nthe two follow the same trend, one an accelerated version of the other. Thus we\nhave a scaling law [https://arxiv.org/abs/2001.08361] between tech wages and\nseed valuations:\n\n$$\\text{ Seed Valuations} \\propto \\text{ Tech Wages}^{4.5}$$\n\nThe inverse of stock-based compensation\n[https://corporatefinanceinstitute.com/resources/accounting/share-stock-based-compensation/]\n, seed companies appear to be compensation-based stocks, at least in how theyâ€™re\nvalued.\n\nGoogle is my BATNA\n[https://www.pon.harvard.edu/daily/batna/translate-your-batna-to-the-current-deal/]\nThis analysis doesn't prove anything, but it does suggest an interesting link\nbetween tech wages and seed valuations.\n\nWhy would seed valuations be linked to the cost of tech labor? And why would\nthose valuations grow so much faster than wages? Iâ€™m not even 100% convinced\nthat itâ€™s a direct, causal connection â€” perhaps thereâ€™s some third variable that\ndrives both. Totally plausible. I plan to explore this in a future piece.\n\nRegardless, itâ€™s quite clear to me after crunching the numbers that seed\nvaluations donâ€™t behave anything like valuations, at least not valuations of \ncompanies or speculative assets. Their stability suggests investors have a\nprecise sense of their worth, despite their riskiness. The value investors place\non these companies does not fluctuate wildly over time.\n\nThis is odd only if your mental model values these fledging enterprises asâ€¦\nenterprises. What if seed stage valuations instead represent the value of the\nlabor and human capital of founders and early employees? The behavior of seed\nvaluations would make a lot more sense if we saw them as proxies for the\nopportunity cost of talented tech workers.\n\nIâ€™ll explore this hypothesis in a future essay.\n\nReceive my new long-form essays\nThoughtful analysis of the business and economics of tech\n\n\n\nGo âš¡","feature_image":"__GHOST_URL__/content/images/2024/10/header.png","featured":0,"status":"published","locale":null,"visibility":"public","author_id":"1","created_at":"2024-10-02T16:50:14.000Z","updated_at":"2024-10-02T18:04:14.000Z","published_at":"2024-10-02T17:51:14.000Z","custom_excerpt":"Itâ€™s not obvious what drives them","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null,"type":"post","email_recipient_filter":"none"}],"posts_authors":[{"id":"5ad44f4c27dc680f0fe26876","post_id":"5ad44f4c27dc680f0fe26875","author_id":"1","sort_order":0},{"id":"5bb11e148a06ff33062ced73","post_id":"5bb11e148a06ff33062ced72","author_id":"1","sort_order":0},{"id":"5be9ff528307ee772c1bbb07","post_id":"5be9ff528307ee772c1bbb06","author_id":"1","sort_order":0},{"id":"5c3705e19e310a4f2c5532b7","post_id":"5c3705e19e310a4f2c5532b6","author_id":"1","sort_order":0},{"id":"5c566a9d391457241b37a2df","post_id":"5c566a9d391457241b37a2de","author_id":"1","sort_order":0},{"id":"5cefa8c0f9f4410ef2e73d87","post_id":"5cefa8c0f9f4410ef2e73d86","author_id":"1","sort_order":0},{"id":"5d34c61cf9f4410ef2e73e4c","post_id":"5d34c61cf9f4410ef2e73e4b","author_id":"1","sort_order":0},{"id":"5db52ef411e40f15bb24f9a1","post_id":"5db52ef411e40f15bb24f9a0","author_id":"1","sort_order":0},{"id":"5de426f9b468c5277c1750ff","post_id":"5de426f9b468c5277c1750fe","author_id":"1","sort_order":0},{"id":"5e2ff75468a43d4de0d20932","post_id":"5e2ff75468a43d4de0d20931","author_id":"1","sort_order":0},{"id":"5e52c49cd2341b714b9b6d89","post_id":"5e52c49cd2341b714b9b6d88","author_id":"1","sort_order":0},{"id":"5e52de08d2341b714b9b6e5c","post_id":"5e52de08d2341b714b9b6e5b","author_id":"1","sort_order":0},{"id":"5e540531d2341b714b9b6ed4","post_id":"5e540531d2341b714b9b6ed3","author_id":"1","sort_order":0},{"id":"5e7567292115750c14ed2d4b","post_id":"5e7567292115750c14ed2d4a","author_id":"1","sort_order":0},{"id":"5e81aca3a1b4a869a793155f","post_id":"5e81aca3a1b4a869a793155e","author_id":"1","sort_order":0},{"id":"5e976b9c78b03e501b8d069f","post_id":"5e976b9c78b03e501b8d069e","author_id":"1","sort_order":0},{"id":"5ec4903e78b03e501b8d06d6","post_id":"5ec4903e78b03e501b8d06d5","author_id":"1","sort_order":0},{"id":"5eea4c812fa60d0ab28d5ca6","post_id":"5eea4c812fa60d0ab28d5ca5","author_id":"1","sort_order":0},{"id":"5eff048a2fa60d0ab28d5cd5","post_id":"5eff048a2fa60d0ab28d5cd4","author_id":"1","sort_order":0},{"id":"5f0d75ab2fc931237d113878","post_id":"5f0d75ab2fc931237d113877","author_id":"1","sort_order":0},{"id":"5f3bec2d17b26d3ef80d621c","post_id":"5f3bec2d17b26d3ef80d621b","author_id":"1","sort_order":0},{"id":"5f6d214f17b26d3ef80d624d","post_id":"5f6d214f17b26d3ef80d624c","author_id":"1","sort_order":0},{"id":"5f6ffd0617b26d3ef80d62bc","post_id":"5f6ffd0617b26d3ef80d62bb","author_id":"1","sort_order":0},{"id":"5f73972a17b26d3ef80d62cc","post_id":"5f73972a17b26d3ef80d62cb","author_id":"1","sort_order":0},{"id":"5f7a463517b26d3ef80d635b","post_id":"5f7a463517b26d3ef80d635a","author_id":"1","sort_order":0},{"id":"5f7c16ab17b26d3ef80d63eb","post_id":"5f7c16ab17b26d3ef80d63ea","author_id":"1","sort_order":0},{"id":"5f90896a17b26d3ef80d6491","post_id":"5f90896a17b26d3ef80d6490","author_id":"1","sort_order":0},{"id":"5f928e0717b26d3ef80d64b7","post_id":"5f928e0717b26d3ef80d64b6","author_id":"1","sort_order":0},{"id":"5fdaf66417b26d3ef80d657f","post_id":"5fdaf66417b26d3ef80d657e","author_id":"1","sort_order":0},{"id":"601c1e4e17b26d3ef80d65e0","post_id":"601c1e4e17b26d3ef80d65df","author_id":"1","sort_order":0},{"id":"603c97fd17b26d3ef80d665d","post_id":"603c97fd17b26d3ef80d665c","author_id":"1","sort_order":0},{"id":"6046922f17b26d3ef80d6687","post_id":"6046922f17b26d3ef80d6686","author_id":"1","sort_order":0},{"id":"609990d417b26d3ef80d66db","post_id":"609990d417b26d3ef80d66da","author_id":"1","sort_order":0},{"id":"609b6a4317b26d3ef80d6723","post_id":"609b6a4317b26d3ef80d6722","author_id":"1","sort_order":0},{"id":"609b702517b26d3ef80d677f","post_id":"609b702517b26d3ef80d677e","author_id":"1","sort_order":0},{"id":"609b71db17b26d3ef80d67a9","post_id":"609b71db17b26d3ef80d67a8","author_id":"1","sort_order":0},{"id":"60acfa5595eadd54d31a7b9b","post_id":"60acfa5595eadd54d31a7b9a","author_id":"1","sort_order":0},{"id":"60e5cd58c1d1894be7adc8f8","post_id":"60e5cd58c1d1894be7adc8f7","author_id":"1","sort_order":0},{"id":"611cb8f616c7fe4443b14022","post_id":"611cb8f616c7fe4443b14021","author_id":"1","sort_order":0},{"id":"614bd8c316c7fe4443b14070","post_id":"614bd8c316c7fe4443b1406f","author_id":"1","sort_order":0},{"id":"618a976bfec7d1542d1d29af","post_id":"618a976bfec7d1542d1d29ae","author_id":"1","sort_order":0},{"id":"6192052ffec7d1542d1d2a18","post_id":"6192052ffec7d1542d1d2a17","author_id":"1","sort_order":0},{"id":"61d40a02fec7d1542d1d2a77","post_id":"61d40a02fec7d1542d1d2a76","author_id":"1","sort_order":0},{"id":"62008a02fec7d1542d1d2af3","post_id":"62008a02fec7d1542d1d2af2","author_id":"1","sort_order":0},{"id":"621fdf62fec7d1542d1d2b2f","post_id":"621fdf62fec7d1542d1d2b2e","author_id":"1","sort_order":0},{"id":"6262a2e8fec7d1542d1d2b79","post_id":"6262a2e8fec7d1542d1d2b78","author_id":"1","sort_order":0},{"id":"62b9dd89fec7d1542d1d2bd5","post_id":"62b9dd89fec7d1542d1d2bd4","author_id":"1","sort_order":0},{"id":"62d5ca2dfec7d1542d1d2c28","post_id":"62d5ca2dfec7d1542d1d2c27","author_id":"1","sort_order":0},{"id":"62e93fd1fec7d1542d1d2c72","post_id":"62e93fd1fec7d1542d1d2c71","author_id":"1","sort_order":0},{"id":"630f3947fec7d1542d1d2cc6","post_id":"630f3947fec7d1542d1d2cc5","author_id":"1","sort_order":0},{"id":"63219ca4fec7d1542d1d2d1e","post_id":"63219ca4fec7d1542d1d2d1d","author_id":"1","sort_order":0},{"id":"6360bd1afec7d1542d1d2d51","post_id":"6360bd1afec7d1542d1d2d50","author_id":"1","sort_order":0},{"id":"6398b3ccfec7d1542d1d2da7","post_id":"6398b3ccfec7d1542d1d2da6","author_id":"1","sort_order":0},{"id":"63bf0c12fec7d1542d1d2dfc","post_id":"63bf0c12fec7d1542d1d2dfb","author_id":"1","sort_order":0},{"id":"645bc999fec7d1542d1d2e4f","post_id":"645bc999fec7d1542d1d2e4e","author_id":"1","sort_order":0},{"id":"6489f030fec7d1542d1d2eaa","post_id":"6489f030fec7d1542d1d2ea9","author_id":"1","sort_order":0},{"id":"64bf8645fec7d1542d1d2ee7","post_id":"64bf8645fec7d1542d1d2ee6","author_id":"1","sort_order":0},{"id":"64bfe511fec7d1542d1d2f1f","post_id":"64bfe511fec7d1542d1d2f1e","author_id":"1","sort_order":0},{"id":"657139f9fec7d1542d1d2f33","post_id":"657139f9fec7d1542d1d2f32","author_id":"1","sort_order":0},{"id":"659337c7fec7d1542d1d2f51","post_id":"659337c7fec7d1542d1d2f50","author_id":"1","sort_order":0},{"id":"65e9fffefec7d1542d1d2f9d","post_id":"65e9fffefec7d1542d1d2f9c","author_id":"1","sort_order":0},{"id":"665558b2fec7d1542d1d2fce","post_id":"665558b2fec7d1542d1d2fcd","author_id":"1","sort_order":0},{"id":"66fd79c6fec7d1542d1d300c","post_id":"66fd79c6fec7d1542d1d300b","author_id":"1","sort_order":0}],"posts_meta":[{"id":"5daffb49801ee451cd03a347","post_id":"5ad44f4c27dc680f0fe26875","og_image":"__GHOST_URL__/content/images/2018/10/einstein-1.jpg","og_title":"You Don't Understand Compound Growth","og_description":"Einstein once (supposedly) said: Compound interest is the most powerful force in the universe Of compound interest, Warren Buffet proclaims: Over time it accomplishes extraordinary things Compound interest, or growth, is one of the, if not the most","twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"You Don't Understand Compound Growth","meta_description":"Compound interest, or growth, is one of the, if not the most, powerful and impactful forces in nature.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5daffb49801ee451cd03a348","post_id":"5bb11e148a06ff33062ced72","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"About Me - Nnamdi Iregbulem","meta_description":"I support entrepreneurs building next-generation, productivity enhancing software for developers and other skilled knowledge workers - Nnamdi Iregbulem","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5daffb49801ee451cd03a349","post_id":"5be9ff528307ee772c1bbb06","og_image":"__GHOST_URL__/content/images/2018/11/growth_share_matrix_no_title-1.png","og_title":"Use this framework to pick your next programming language","og_description":"A framework for developing technical proficiency in today's software development environment","twitter_image":"__GHOST_URL__/content/images/2018/11/growth_share_matrix_no_title-2.png","twitter_title":"How to decide which programming language to learn next","twitter_description":"A framework for developing technical proficiency in today's software development environment","meta_title":"The Growth-Share Matrix of Software Development","meta_description":"A framework for developing technical proficiency in today's software development environment","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5daffb49801ee451cd03a34a","post_id":"5c3705e19e310a4f2c5532b6","og_image":"__GHOST_URL__/content/images/2019/01/ryoji-iwata-697773-unsplash_2-1.jpg","og_title":"What I learned about developer pay from analyzing the earnings of 11,037 software engineers","og_description":"Why some developers make so much more than others","twitter_image":"__GHOST_URL__/content/images/2019/01/ryoji-iwata-697773-unsplash_2.jpg","twitter_title":"What I learned about developer pay from analyzing the earnings of 11,037 software engineers","twitter_description":"Why some developers make so much more than others","meta_title":"Meet Dev, the Highest-Paid Software Developer in America","meta_description":"Why some developers make so much more than others","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5daffb49801ee451cd03a34b","post_id":"5c566a9d391457241b37a2de","og_image":"__GHOST_URL__/content/images/2019/02/jonathan-petersson-614702-unsplash-1.jpg","og_title":"Entrepreneur's Ruin, or How Not to Go Bust","og_description":"Why survival trumps \"success\", and what to do about it","twitter_image":"__GHOST_URL__/content/images/2019/02/jonathan-petersson-614702-unsplash-2.jpg","twitter_title":"Entrepreneur's Ruin, or How Not to Go Bust","twitter_description":"Why survival trumps \"success\", and what to do about it","meta_title":"Entrepreneur's Ruin, or How Not to Go Bust","meta_description":"Why survival trumps \"success\", and what to do about it","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5daffb49801ee451cd03a34c","post_id":"5cefa8c0f9f4410ef2e73d86","og_image":"__GHOST_URL__/content/images/2019/06/preview-1.png","og_title":"How to Conquer Cohort Analysis With a Powerful Clinical Research Tool","og_description":"Why your doctor understands customer retention better than you do","twitter_image":"__GHOST_URL__/content/images/2019/06/preview.png","twitter_title":"How to Conquer Cohort Analysis With a Powerful Clinical Research Tool","twitter_description":"Why your doctor understands customer retention better than you do","meta_title":"How to Conquer Cohort Analysis With a Powerful Clinical Research Tool","meta_description":"Why your doctor understands customer retention better than you do","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5daffb49801ee451cd03a34d","post_id":"5d34c61cf9f4410ef2e73e4b","og_image":"__GHOST_URL__/content/images/2019/07/vanity-3.jpg","og_title":"Waitlists are a Vanity Metric","og_description":"Waitlists, registered users, and other cumulative measures better measure the size of your pride than the size of your business","twitter_image":"__GHOST_URL__/content/images/2019/07/vanity.jpg","twitter_title":"Waitlists are a Vanity Metric","twitter_description":"Waitlists, registered users, and other cumulative measures better measure the size of your pride than the size of your business","meta_title":"Waitlists are a Vanity Metric","meta_description":"Waitlists, registered users, and other cumulative measures better measure the size of your pride than the size of your business","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5db5371e11e40f15bb24f9c5","post_id":"5db52ef411e40f15bb24f9a0","og_image":null,"og_title":"High Retention = High Volatility","og_description":"Why SaaS revenue retention is a double-edge sword","twitter_image":null,"twitter_title":"High Retention = High Volatility","twitter_description":"Why SaaS revenue retention is a double-edge sword","meta_title":"High Retention = High Volatility","meta_description":"Why SaaS revenue retention is a double-edge sword","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5de42758b468c5277c175103","post_id":"5de426f9b468c5277c1750fe","og_image":"__GHOST_URL__/content/images/2019/12/people-matching-2-cropped-1.png","og_title":"Pattern Matching is Dead. Long Live People Matching","og_description":"Venture capital is changing â€” for the better","twitter_image":"__GHOST_URL__/content/images/2019/12/people-matching-2-cropped.png","twitter_title":"Pattern Matching is Dead. Long Live People Matching","twitter_description":"Venture capital is changing â€” for the better","meta_title":"Pattern Matching is Dead. Long Live People Matching","meta_description":"Venture capital is changing â€” for the better","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5e2ffaf868a43d4de0d20959","post_id":"5e2ff75468a43d4de0d20931","og_image":"__GHOST_URL__/content/images/2020/01/91YCWH4jFdL-2.jpg","og_title":"How Uber and Lyft Dominated Ridesharing By Seeing Red Where Others Saw Blue","og_description":"A quick visit to the Red Sea","twitter_image":"__GHOST_URL__/content/images/2020/01/91YCWH4jFdL-1.jpg","twitter_title":"How Uber and Lyft Dominated Ridesharing By Seeing Red Where Others Saw Blue","twitter_description":"A quick visit to the Red Sea","meta_title":"How Uber and Lyft Dominated Ridesharing By Seeing Red Where Others Saw Blue","meta_description":"A quick visit to the Red Sea","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5e54016fd2341b714b9b6e9a","post_id":"5e52de08d2341b714b9b6e5b","og_image":"__GHOST_URL__/content/images/2020/02/clip-programming-2.png","og_title":"The Highest-Paid Software Engineers: 2020 Edition","og_description":"Who will be the highest-earning software developers of 2020?","twitter_image":"__GHOST_URL__/content/images/2020/02/clip-programming-1.png","twitter_title":"The Highest-Paid Software Engineers: 2020 Edition","twitter_description":"Who will be the highest-earning software developers of 2020?","meta_title":"The Highest-Paid Software Engineers: 2020 Edition","meta_description":"Who will be the highest-earning software developers of 2020?","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5e540edfd2341b714b9b6f3b","post_id":"5e52c49cd2341b714b9b6d88","og_image":"__GHOST_URL__/content/images/2020/02/Ethnicity-8.jpg","og_title":"How Age, Race, and Gender Affect Software Engineering Pay","og_description":"Progress on narrowing pay gaps among software developers","twitter_image":"__GHOST_URL__/content/images/2020/02/Ethnicity-9.jpg","twitter_title":"How Age, Race, and Gender Affect Software Engineering Pay","twitter_description":"Progress on narrowing pay gaps among software developers","meta_title":"How Age, Race, and Gender Affect Software Engineering Pay","meta_description":"Progress on narrowing pay gaps among software developers","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5e756fa72115750c14ed2d74","post_id":"5e7567292115750c14ed2d4a","og_image":"__GHOST_URL__/content/images/2020/03/WorkRemote-4.jpg","og_title":"Remote Software Developers Earn 22% More Than Non-Remote Developers","og_description":"Working remote even just a few days per month leads to higher pay","twitter_image":"__GHOST_URL__/content/images/2020/03/WorkRemote-3.jpg","twitter_title":"Remote Software Developers Earn 22% More Than Non-Remote Developers","twitter_description":"Working remote even just a few days per month leads to higher pay","meta_title":"Remote Software Developers Earn 22% More Than Non-Remote Developers","meta_description":"Working remote even just a few days per month leads to higher pay","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5e81aebda1b4a869a7931578","post_id":"5e81aca3a1b4a869a793155e","og_image":"__GHOST_URL__/content/images/2020/03/cover-2.png","og_title":"Byron Deeter and Jason Lemkin on the State of VC and the Cloud","og_description":"When to raise capital, what to expect from VCs, and the \"new normal\"","twitter_image":"__GHOST_URL__/content/images/2020/03/cover-1.png","twitter_title":"Byron Deeter and Jason Lemkin on the State of VC and the Cloud","twitter_description":"When to raise capital, what to expect from VCs, and the \"new normal\"","meta_title":"Byron Deeter and Jason Lemkin on the State of VC and the Cloud","meta_description":"When to raise capital, what to expect from VCs, and the \"new normal\"","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5e976d7078b03e501b8d06aa","post_id":"5e976b9c78b03e501b8d069e","og_image":"__GHOST_URL__/content/images/2020/04/header-social-1.png","og_title":"Pandemiconomics: Viral Volatility","og_description":"How the virus rocked stocks","twitter_image":"__GHOST_URL__/content/images/2020/04/header-social.png","twitter_title":"Pandemiconomics: Viral Volatility","twitter_description":"How the virus rocked stocks","meta_title":"Pandemiconomics: Viral Volatility","meta_description":"How the virus rocked stocks","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5ec4973c78b03e501b8d06d9","post_id":"5ec4903e78b03e501b8d06d5","og_image":"__GHOST_URL__/content/images/2020/05/EdLevel_header-5.png","og_title":"Do College Degrees Matter for Software Engineers? Maybe","og_description":"Do college-educated developers earn more? Yes, but not much.","twitter_image":"__GHOST_URL__/content/images/2020/05/EdLevel_header-4.png","twitter_title":"Do College Degrees Matter for Software Engineers? Maybe","twitter_description":"Do college-educated developers earn more? Yes, but not much.","meta_title":"Do College Degrees Matter for Software Engineers? Maybe","meta_description":"Do college-educated developers earn more? Yes, but not much.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5eea4d1f2fa60d0ab28d5caf","post_id":"5eea4c812fa60d0ab28d5ca5","og_image":"__GHOST_URL__/content/images/2020/06/black-college-wealth-2.png","og_title":"The Value of College May Be Negative for the COVID Generation","og_description":"You might think the value of a college degree has been increasing. You would be wrong.","twitter_image":"__GHOST_URL__/content/images/2020/06/black-college-wealth-1.png","twitter_title":"The Value of College May Be Negative for the COVID Generation","twitter_description":"You might think the value of a college degree has been increasing. You would be wrong.","meta_title":"The Value of College May Be Negative for the COVID Generation","meta_description":"You might think the value of a college degree has been increasing. You would be wrong.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5eff148c2fc931237d113858","post_id":"5eff048a2fa60d0ab28d5cd4","og_image":null,"og_title":"Why Don't VCs Index Invest?","og_description":"VCs are picky, not because they have so many options but because they have so few.","twitter_image":null,"twitter_title":"Why Don't VCs Index Invest?","twitter_description":"VCs are picky, not because they have so many options but because they have so few.","meta_title":"Why Don't VCs Index Invest?","meta_description":"VCs are picky, not because they have so many options but because they have so few.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5f0e02602fc931237d1138bc","post_id":"5f0d75ab2fc931237d113877","og_image":"__GHOST_URL__/content/images/2020/07/social-header-4.png","og_title":"Six Trends Shaping Developer Productivity","og_description":"We interviewed developer productivity leaders. Here's what they said.","twitter_image":"__GHOST_URL__/content/images/2020/07/social-header-4-2.png","twitter_title":"Six Trends Shaping Developer Productivity","twitter_description":"We interviewed developer productivity leaders. Here's what they said.","meta_title":"Six Trends Shaping Developer Productivity","meta_description":"We interviewed developer productivity leaders. Here's what they said.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5f3becac17b26d3ef80d6221","post_id":"5f3bec2d17b26d3ef80d621b","og_image":"__GHOST_URL__/content/images/2020/08/social-header-2-1.png","og_title":"Top Three Strategic Priorities of Developer Productivity Startups","og_description":"What's top of mind for developer productivity leaders","twitter_image":"__GHOST_URL__/content/images/2020/08/social-header-2.png","twitter_title":"Top Three Strategic Priorities of Developer Productivity Startups","twitter_description":"What's top of mind for developer productivity leaders","meta_title":"Top Three Strategic Priorities of Developer Productivity Startups","meta_description":"What's top of mind for developer productivity leaders","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5f739faf17b26d3ef80d6344","post_id":"5f73972a17b26d3ef80d62cb","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":"Transformer model pre-trained on document retrieval and reconstruction performs well on both fine-tuned and zero-shot downstream tasks","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5f7a57aa17b26d3ef80d63e7","post_id":"5f7a463517b26d3ef80d635a","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":"(Paper Explained) An Image is Worth 16x16 Words: Transformers for Image Recognition","meta_description":"Large Transformer trained on large datasets outperform CNN-based architectures and achieve state of the art results on image recognition tasks","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5f985e8817b26d3ef80d654b","post_id":"5f928e0717b26d3ef80d64b6","og_image":"__GHOST_URL__/content/images/2020/10/header-v2-resized-twitter-1.png","og_title":"Why We Will Never Have Enough Software Developers","og_description":"Developers are dropping out of the profession in large numbers","twitter_image":"__GHOST_URL__/content/images/2020/10/header-v2-resized-twitter.png","twitter_title":"Why We Will Never Have Enough Software Developers","twitter_description":"Developers are dropping out of the profession in large numbers","meta_title":"Why We Will Never Have Enough Software Developers","meta_description":"Developers are dropping out of the profession in large numbers","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"5fdba0a017b26d3ef80d65b1","post_id":"5fdaf66417b26d3ef80d657e","og_image":"__GHOST_URL__/content/images/2020/12/header-2.png","og_title":"Product-Market Fit is Lindy","og_description":"The longer you search for product-market fit, the less likely you will find it.","twitter_image":"__GHOST_URL__/content/images/2020/12/header-1.png","twitter_title":"Product-Market Fit is Lindy","twitter_description":"The longer you search for product-market fit, the less likely you will find it.","meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"601c735117b26d3ef80d6643","post_id":"601c1e4e17b26d3ef80d65df","og_image":"__GHOST_URL__/content/images/2021/02/1yocKpYAcw-2.png","og_title":"There's Nothing Magical About the SaaS Magic Number","og_description":"Magic number is a bad metric. Sales and marketing drives much less revenue than the not-so-magical number implies","twitter_image":"__GHOST_URL__/content/images/2021/02/1yocKpYAcw-1.png","twitter_title":"There's Nothing Magical About the SaaS Magic Number","twitter_description":"Magic number is a bad metric. Sales and marketing drives much less revenue than the not-so-magical number implies","meta_title":"There's Nothing Magical About the SaaS Magic Number","meta_description":"Magic number is a bad metric. Sales and marketing drives much less revenue than the not-so-magical number implies","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"603ca40e17b26d3ef80d667d","post_id":"603c97fd17b26d3ef80d665c","og_image":null,"og_title":"Robinhood Traders are Last to the Party","og_description":"Robinhood traders get fleeced not by HFTs front-running milliseconds before their order hits but by other retail investors, days earlier.","twitter_image":null,"twitter_title":"Robinhood Traders are Last to the Party","twitter_description":"Robinhood traders get fleeced not by HFTs front-running milliseconds before their order hits but by other retail investors, days earlier.","meta_title":"Robinhood Traders are Last to the Party","meta_description":"Robinhood traders get fleeced not by HFTs front-running milliseconds before their order hits but by other retail investors, days earlier.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6046929e17b26d3ef80d668f","post_id":"6046922f17b26d3ef80d6686","og_image":"__GHOST_URL__/content/images/2021/03/social-header-1.png","og_title":"Four Challenges Facing Developer Productivity Startups","og_description":"The biggest challenges facing developer productivity startups today","twitter_image":"__GHOST_URL__/content/images/2021/03/social-header.png","twitter_title":"Four Challenges Facing Developer Productivity Startups","twitter_description":"The biggest challenges facing developer productivity startups today","meta_title":"Four Challenges Facing Developer Productivity Startups","meta_description":"The biggest challenges facing developer productivity startups today","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"609990e617b26d3ef80d66de","post_id":"609990d417b26d3ef80d66da","og_image":null,"og_title":"Why Developers Love Redpanda","og_description":"Why Vectorized's focus on developer experience will unlock real-time streaming for the great majority of developers","twitter_image":null,"twitter_title":"Why Developers Love Redpanda","twitter_description":"Why Vectorized's focus on developer experience will unlock real-time streaming for the great majority of developers","meta_title":"Why Developers Love Redpanda","meta_description":"Why Vectorized's focus on developer experience will unlock real-time streaming for the great majority of developers","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"609b6a7417b26d3ef80d6728","post_id":"609b6a4317b26d3ef80d6722","og_image":null,"og_title":"The Developer Productivity Manifesto â€” The Flywheel","og_description":"Developer productivity is falling. But it doesn't have to. The solution? The Developer Productivity Flywheel","twitter_image":null,"twitter_title":"The Developer Productivity Manifesto â€” The Flywheel","twitter_description":"Developer productivity is falling. But it doesn't have to. The solution? The Developer Productivity Flywheel","meta_title":"The Developer Productivity Flywheel","meta_description":"Developer productivity is falling. But it doesn't have to. The solution? The Developer Productivity Flywheel","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"609b702917b26d3ef80d6782","post_id":"609b702517b26d3ef80d677e","og_image":null,"og_title":"More (Developers) Isnâ€™t Always More","og_description":"Adding more cooks to the kitchen rarely helps","twitter_image":null,"twitter_title":"More (Developers) Isnâ€™t Always More","twitter_description":"Adding more cooks to the kitchen rarely helps","meta_title":"More (Developers) Isnâ€™t Always More","meta_description":"Adding more cooks to the kitchen rarely helps","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"609b71eb17b26d3ef80d67ad","post_id":"609b71db17b26d3ef80d67a8","og_image":null,"og_title":"The Developer Productivity Manifesto â€” Leaving Software on the Table","og_description":"Quantifying the billion dollar impact of developer inefficiency","twitter_image":null,"twitter_title":"The Developer Productivity Manifesto â€” Leaving Software on the Table","twitter_description":"Quantifying the billion dollar impact of developer inefficiency","meta_title":"Leaving Software on the Table","meta_description":"Quantifying the billion dollar impact of developer inefficiency","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"60acfabe95eadd54d31a7ba7","post_id":"60acfa5595eadd54d31a7b9a","og_image":null,"og_title":"Awesome Developer Advocates Are Hiding in Plain Sight","og_description":"Why you shouldnâ€™t filter for social media following or prior experience","twitter_image":null,"twitter_title":"Awesome Developer Advocates Are Hiding in Plain Sight","twitter_description":"Why you shouldnâ€™t filter for social media following or prior experience","meta_title":"Awesome Developer Advocates Are Hiding in Plain Sight","meta_description":"Why you shouldnâ€™t filter for social media following or prior experience","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"60e5f9bb13adf073068e41d4","post_id":"60e5cd58c1d1894be7adc8f7","og_image":null,"og_title":"PhDs Aren't Starting Companies Like They Used To","og_description":"The burden of scientific knowledge and managerial complexity is crushing our best and brightest.","twitter_image":null,"twitter_title":"PhDs Aren't Starting Companies Like They Used To","twitter_description":"The burden of scientific knowledge and managerial complexity is crushing our best and brightest.","meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"611cb93d16c7fe4443b1402a","post_id":"611cb8f616c7fe4443b14021","og_image":null,"og_title":"Do Wealthy Investors Have an Edge?","og_description":"The super-rich earn more on their investments than the rest of us. \n\nSomething nefarious, or something else?","twitter_image":null,"twitter_title":"Do Wealthy Investors Have an Edge?","twitter_description":"The super-rich earn more on their investments than the rest of us. \n\nSomething nefarious, or something else?","meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"614c048916c7fe4443b1409a","post_id":"614bd8c316c7fe4443b1406f","og_image":null,"og_title":"You Can't Eat Relative Growth","og_description":"In startup land, we talk way too much about relative growth. We'd do better to ground our thinking in absolute growth.","twitter_image":null,"twitter_title":"You Can't Eat Relative Growth","twitter_description":"In startup land, we talk way too much about relative growth. We'd do better to ground our thinking in absolute growth.","meta_title":"You Can't Eat Relative Growth","meta_description":"In startup land, we talk way too much about relative growth. We'd do better to ground our thinking in absolute growth.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"618a9f9efec7d1542d1d29fb","post_id":"618a976bfec7d1542d1d29ae","og_image":null,"og_title":"Companies Rarely Grow Into Their Valuations","og_description":"Companies don't catch up to their valuations; their valuations catch up to them.","twitter_image":null,"twitter_title":"Companies Rarely Grow Into Their Valuations","twitter_description":"Companies don't catch up to their valuations; their valuations catch up to them.","meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"61920e51fec7d1542d1d2a54","post_id":"6192052ffec7d1542d1d2a17","og_image":null,"og_title":"WebAssembly-ing the Pieces: Vectorizedâ€™s Data Policy Engine","og_description":"Rather than ship data to code, which is expensive and latency-prone, why not ship code to the data?","twitter_image":null,"twitter_title":"WebAssembly-ing the Pieces: Vectorizedâ€™s Data Policy Engine","twitter_description":"Rather than ship data to code, which is expensive and latency-prone, why not ship code to the data?","meta_title":"WebAssembly-ing the Pieces: Vectorizedâ€™s Data Policy Engine","meta_description":"Rather than ship data to code, which is expensive and latency-prone, why not ship code to the data?","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"61dc7c77fec7d1542d1d2ac1","post_id":"61d40a02fec7d1542d1d2a76","og_image":null,"og_title":null,"og_description":"ACV isn't as useful a concept as people think. We need a different SaaS monetization metric.","twitter_image":null,"twitter_title":null,"twitter_description":"ACV isn't as useful a concept as people think. We need a different SaaS monetization metric.","meta_title":null,"meta_description":"ACV isn't as useful a concept as people think. We need a different SaaS monetization metric.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"62009317fec7d1542d1d2b19","post_id":"62008a02fec7d1542d1d2af2","og_image":null,"og_title":"Schrodinger's Balance Sheet: When Equity Becomes a Liability","og_description":"Preferred equity exists in a constant state of quantum superposition. It's neither equity nor debt, until it is.","twitter_image":null,"twitter_title":"Schrodinger's Balance Sheet: When Equity Becomes a Liability","twitter_description":"Preferred equity exists in a constant state of quantum superposition. It's neither equity nor debt, until it is.","meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6220f767fec7d1542d1d2b60","post_id":"621fdf62fec7d1542d1d2b2e","og_image":null,"og_title":"Breaking Apart the Rule of 40","og_description":"Rules are meant to be broken, and the Rule of 40 is no exception","twitter_image":null,"twitter_title":"Breaking Apart the Rule of 40","twitter_description":"Rules are meant to be broken, and the Rule of 40 is no exception","meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6262a52afec7d1542d1d2ba1","post_id":"6262a2e8fec7d1542d1d2b78","og_image":"__GHOST_URL__/content/images/2022/04/Funding-Simply-Shifts-the-Bottleneck_2022-04-18-15.51.14.excalidraw-4.png","og_title":"Funding Simply Shifts the Bottleneck","og_description":"A frothy funding environment means more competition for talent. Funding gets easier; hiring gets harder.","twitter_image":"__GHOST_URL__/content/images/2022/04/Funding-Simply-Shifts-the-Bottleneck_2022-04-18-15.51.14.excalidraw-3.png","twitter_title":"Funding Simply Shifts the Bottleneck","twitter_description":"A frothy funding environment means more competition for talent. Funding gets easier; hiring gets harder.","meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"62b9dfb4fec7d1542d1d2bee","post_id":"62b9dd89fec7d1542d1d2bd4","og_image":"__GHOST_URL__/content/images/2022/06/header-1.jpg","og_title":"Series A Rounds Are a Math Test","og_description":"Low monetization requires extraordinary traction, and vice versa.","twitter_image":"__GHOST_URL__/content/images/2022/06/header-2.jpg","twitter_title":"Series A Rounds Are a Math Test","twitter_description":"Low monetization requires extraordinary traction, and vice versa.","meta_title":"Series A Rounds Are a Math Test","meta_description":"Low monetization requires extraordinary traction, and vice versa.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"62d5ca4efec7d1542d1d2c2f","post_id":"62d5ca2dfec7d1542d1d2c27","og_image":"__GHOST_URL__/content/images/2022/07/varexp-3.png","og_title":"The Dark Matter of Software Valuations","og_description":"Exploring the vast \"dark matter\" of the software universe","twitter_image":"__GHOST_URL__/content/images/2022/07/varexp-2.png","twitter_title":"The Dark Matter of Software Valuations","twitter_description":"Exploring the vast \"dark matter\" of the software universe","meta_title":"The Dark Matter of Software Valuations","meta_description":"Exploring the vast \"dark matter\" of the software universe","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"62e93fe9fec7d1542d1d2c77","post_id":"62e93fd1fec7d1542d1d2c71","og_image":null,"og_title":"COVID Hurt Most Software Companies","og_description":"COVID put software companies on a permanently lower growth trajectory.","twitter_image":null,"twitter_title":"COVID Hurt Most Software Companies","twitter_description":"COVID put software companies on a permanently lower growth trajectory.","meta_title":"COVID Hurt Most Software Companies","meta_description":"COVID put software companies on a permanently lower growth trajectory.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"630f395cfec7d1542d1d2ccc","post_id":"630f3947fec7d1542d1d2cc5","og_image":"__GHOST_URL__/content/images/2022/08/exit-3.png","og_title":"Layoffs Don't Tell the Whole Story","og_description":"Hiring freezes matter more than layoffs","twitter_image":"__GHOST_URL__/content/images/2022/08/exit-2.png","twitter_title":"Layoffs Don't Tell the Whole Story","twitter_description":"Hiring freezes matter more than layoffs","meta_title":"Layoffs Don't Tell the Whole Story","meta_description":"Hiring freezes matter more than layoffs","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"63219d80fec7d1542d1d2d30","post_id":"63219ca4fec7d1542d1d2d1d","og_image":"__GHOST_URL__/content/images/2022/09/forever-2.png","og_title":"Beats and Misses Are Forever","og_description":"Revenue surprises permanently shift the trajectory of SaaS companies","twitter_image":"__GHOST_URL__/content/images/2022/09/forever-1.png","twitter_title":"Beats and Misses Are Forever","twitter_description":"Revenue surprises permanently shift the trajectory of SaaS companies","meta_title":"Beats and Misses Are Forever","meta_description":"Revenue surprises permanently shift the trajectory of SaaS companies","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6360bd42fec7d1542d1d2d58","post_id":"6360bd1afec7d1542d1d2d50","og_image":"__GHOST_URL__/content/images/2022/11/decomp_g-3.png","og_title":"It's Valuations (Almost) All the Way Down","og_description":"Venture funding hasn't grown as much as you think","twitter_image":"__GHOST_URL__/content/images/2022/11/decomp_g-2.png","twitter_title":"It's Valuations (Almost) All the Way Down","twitter_description":"Venture funding hasn't grown as much as you think","meta_title":"It's Valuations (Almost) All the Way Down","meta_description":"Venture funding hasn't grown as much as you think","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6398b8dbfec7d1542d1d2dd0","post_id":"6398b3ccfec7d1542d1d2da6","og_image":"__GHOST_URL__/content/images/2022/12/header-8.png","og_title":"Old Valuations Die Hard","og_description":"Private valuations substantially lag public tech valuations","twitter_image":"__GHOST_URL__/content/images/2022/12/header-7.png","twitter_title":"Old Valuations Die Hard","twitter_description":"Private valuations substantially lag public tech valuations","meta_title":"Old Valuations Die Hard","meta_description":"Private valuations substantially lag public tech valuations","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"63bf0c39fec7d1542d1d2e02","post_id":"63bf0c12fec7d1542d1d2dfb","og_image":"__GHOST_URL__/content/images/2023/01/header-2.png","og_title":"We Don't Have Nearly Enough Startups","og_description":"Where did the explosive growth in venture activity come from?","twitter_image":"__GHOST_URL__/content/images/2023/01/header-1.png","twitter_title":"We Don't Have Nearly Enough Startups","twitter_description":"Where did the explosive growth in venture activity come from?","meta_title":"We Don't Have Nearly Enough Startups","meta_description":"Where did the explosive growth in venture activity come from?","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"645bca25fec7d1542d1d2e5e","post_id":"645bc999fec7d1542d1d2e4e","og_image":null,"og_title":"Don't Discount Interest Rates","og_description":"It's Jay Powell's world. We're just living in it.","twitter_image":null,"twitter_title":"Don't Discount Interest Rates","twitter_description":"It's Jay Powell's world. We're just living in it.","meta_title":"Don't Discount Interest Rates","meta_description":"It's Jay Powell's world. We're just living in it.","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6489f054fec7d1542d1d2eaf","post_id":"6489f030fec7d1542d1d2ea9","og_image":null,"og_title":"The Shadow Price of Venture Capital","og_description":"Valuations are 60% too high relative to the volume of venture funding","twitter_image":null,"twitter_title":"The Shadow Price of Venture Capital","twitter_description":"Valuations are 60% too high relative to the volume of venture funding","meta_title":"The Shadow Price of Venture Capital","meta_description":"Valuations are 60% too high relative to the volume of venture funding","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"64bf8f3dfec7d1542d1d2f11","post_id":"64bf8645fec7d1542d1d2ee6","og_image":null,"og_title":"The Venture Activity Index","og_description":"Measuring the state of the venture \"business cycle\"","twitter_image":null,"twitter_title":"The Venture Activity Index","twitter_description":"Measuring the state of the venture \"business cycle\"","meta_title":"The Venture Activity Index","meta_description":"Measuring the state of the venture \"business cycle\"","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"6681bc5afec7d1542d1d2ffd","post_id":"665558b2fec7d1542d1d2fcd","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":"AI Benchmarking Is Broken","twitter_description":"We should take AI models seriously, which means taking their evaluation seriously","meta_title":null,"meta_description":null,"email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null},{"id":"66fd856efec7d1542d1d303a","post_id":"66fd79c6fec7d1542d1d300b","og_image":null,"og_title":"Seed Valuations Arenâ€™t Valuations","og_description":"Itâ€™s not obvious what drives them","twitter_image":null,"twitter_title":"Seed Valuations Arenâ€™t Valuations","twitter_description":"Itâ€™s not obvious what drives them","meta_title":"Seed Valuations Arenâ€™t Valuations","meta_description":"Itâ€™s not obvious what drives them","email_subject":null,"frontmatter":null,"feature_image_alt":null,"feature_image_caption":null}],"posts_tags":[{"id":"5f739f0517b26d3ef80d633b","post_id":"5f73972a17b26d3ef80d62cb","tag_id":"5f739f0517b26d3ef80d6339","sort_order":0},{"id":"5f739f0517b26d3ef80d633c","post_id":"5f73972a17b26d3ef80d62cb","tag_id":"5f739f0517b26d3ef80d633a","sort_order":1},{"id":"5f7a474017b26d3ef80d6363","post_id":"5f7a463517b26d3ef80d635a","tag_id":"5f739f0517b26d3ef80d6339","sort_order":0},{"id":"5f7a474017b26d3ef80d6364","post_id":"5f7a463517b26d3ef80d635a","tag_id":"5f739f0517b26d3ef80d633a","sort_order":1},{"id":"60d4d25f95eadd54d31a7bd1","post_id":"60acfa5595eadd54d31a7b9a","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"60d4d2d595eadd54d31a7bd8","post_id":"60acfa5595eadd54d31a7b9a","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":1},{"id":"60d4d2e095eadd54d31a7bda","post_id":"609b71db17b26d3ef80d67a8","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"60d4d2e095eadd54d31a7bdb","post_id":"609b71db17b26d3ef80d67a8","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":1},{"id":"60d4d2e095eadd54d31a7bdc","post_id":"609b71db17b26d3ef80d67a8","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":2},{"id":"60d4d2e995eadd54d31a7bde","post_id":"609b702517b26d3ef80d677e","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"60d4d2e995eadd54d31a7bdf","post_id":"609b702517b26d3ef80d677e","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":1},{"id":"60d4d2e995eadd54d31a7be0","post_id":"609b702517b26d3ef80d677e","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":2},{"id":"60d4d2f095eadd54d31a7be2","post_id":"609b6a4317b26d3ef80d6722","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"60d4d2f095eadd54d31a7be3","post_id":"609b6a4317b26d3ef80d6722","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":1},{"id":"60d4d2f095eadd54d31a7be4","post_id":"609b6a4317b26d3ef80d6722","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":2},{"id":"60d4d4e995eadd54d31a7be6","post_id":"6046922f17b26d3ef80d6686","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"60d4d4e995eadd54d31a7be7","post_id":"6046922f17b26d3ef80d6686","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":1},{"id":"60d4d4e995eadd54d31a7be8","post_id":"6046922f17b26d3ef80d6686","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":2},{"id":"60d4d4f895eadd54d31a7bea","post_id":"603c97fd17b26d3ef80d665c","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":0},{"id":"60d4d4fe95eadd54d31a7bec","post_id":"609990d417b26d3ef80d66da","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":0},{"id":"60d4d50595eadd54d31a7bee","post_id":"601c1e4e17b26d3ef80d65df","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"60d4d50595eadd54d31a7bef","post_id":"601c1e4e17b26d3ef80d65df","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"60d4d51795eadd54d31a7bf1","post_id":"5fdaf66417b26d3ef80d657e","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"60d4d52795eadd54d31a7bf3","post_id":"5f928e0717b26d3ef80d64b6","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":0},{"id":"60d4d53a95eadd54d31a7bf5","post_id":"5f928e0717b26d3ef80d64b6","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":1},{"id":"60d4d54595eadd54d31a7bf7","post_id":"5f7c16ab17b26d3ef80d63ea","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":0},{"id":"60d4d54595eadd54d31a7bf8","post_id":"5f7c16ab17b26d3ef80d63ea","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":1},{"id":"60d4d55095eadd54d31a7bfa","post_id":"5f3bec2d17b26d3ef80d621b","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"60d4d55095eadd54d31a7bfb","post_id":"5f3bec2d17b26d3ef80d621b","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":1},{"id":"60d4d55095eadd54d31a7bfc","post_id":"5f3bec2d17b26d3ef80d621b","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":2},{"id":"60d4d56d95eadd54d31a7bfe","post_id":"5f0d75ab2fc931237d113877","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"60d4d56d95eadd54d31a7bff","post_id":"5f0d75ab2fc931237d113877","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":1},{"id":"60d4d56d95eadd54d31a7c00","post_id":"5f0d75ab2fc931237d113877","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":2},{"id":"60d4d57495eadd54d31a7c02","post_id":"5eff048a2fa60d0ab28d5cd4","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":0},{"id":"60d4d58b95eadd54d31a7c04","post_id":"5ec4903e78b03e501b8d06d5","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":0},{"id":"60d4d58b95eadd54d31a7c05","post_id":"5ec4903e78b03e501b8d06d5","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":1},{"id":"60d4d59395eadd54d31a7c07","post_id":"5e976b9c78b03e501b8d069e","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":0},{"id":"60d4d59a95eadd54d31a7c09","post_id":"5e81aca3a1b4a869a793155e","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":0},{"id":"60d4d59a95eadd54d31a7c0a","post_id":"5e81aca3a1b4a869a793155e","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":1},{"id":"60d4d5a195eadd54d31a7c0c","post_id":"5e7567292115750c14ed2d4a","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":0},{"id":"60d4d5a195eadd54d31a7c0d","post_id":"5e7567292115750c14ed2d4a","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":1},{"id":"60d4d5a895eadd54d31a7c0f","post_id":"5e52c49cd2341b714b9b6d88","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":0},{"id":"60d4d5a895eadd54d31a7c10","post_id":"5e52c49cd2341b714b9b6d88","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":1},{"id":"60d4d5b195eadd54d31a7c12","post_id":"5e52de08d2341b714b9b6e5b","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":0},{"id":"60d4d5b195eadd54d31a7c13","post_id":"5e52de08d2341b714b9b6e5b","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":1},{"id":"60d4d5bf95eadd54d31a7c15","post_id":"5e2ff75468a43d4de0d20931","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"60d4d5bf95eadd54d31a7c16","post_id":"5e2ff75468a43d4de0d20931","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"60d4d5c695eadd54d31a7c18","post_id":"5de426f9b468c5277c1750fe","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"60d4d5c695eadd54d31a7c19","post_id":"5de426f9b468c5277c1750fe","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"60d4d5cb95eadd54d31a7c1b","post_id":"5db52ef411e40f15bb24f9a0","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":0},{"id":"60d4d5cb95eadd54d31a7c1c","post_id":"5db52ef411e40f15bb24f9a0","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":1},{"id":"60d4d5d195eadd54d31a7c1e","post_id":"5d34c61cf9f4410ef2e73e4b","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"60d4d5d195eadd54d31a7c1f","post_id":"5d34c61cf9f4410ef2e73e4b","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"60d4d5d995eadd54d31a7c21","post_id":"5cefa8c0f9f4410ef2e73d86","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":0},{"id":"60d4d5d995eadd54d31a7c22","post_id":"5cefa8c0f9f4410ef2e73d86","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":1},{"id":"60d4d5e395eadd54d31a7c24","post_id":"5c566a9d391457241b37a2de","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"60d4d5ee95eadd54d31a7c26","post_id":"5c3705e19e310a4f2c5532b6","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":0},{"id":"60d4d5ee95eadd54d31a7c27","post_id":"5c3705e19e310a4f2c5532b6","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":1},{"id":"60d4d5f895eadd54d31a7c29","post_id":"5be9ff528307ee772c1bbb06","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":0},{"id":"60d4d5fe95eadd54d31a7c2c","post_id":"5ad44f4c27dc680f0fe26875","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"60d4d5fe95eadd54d31a7c2d","post_id":"5ad44f4c27dc680f0fe26875","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"60e5ddf913adf073068e41cc","post_id":"60e5cd58c1d1894be7adc8f7","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"611cb91e16c7fe4443b14026","post_id":"611cb8f616c7fe4443b14021","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":0},{"id":"614bd8d816c7fe4443b14073","post_id":"614bd8c316c7fe4443b1406f","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"614bd8d816c7fe4443b14074","post_id":"614bd8c316c7fe4443b1406f","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"618a982efec7d1542d1d29c2","post_id":"618a976bfec7d1542d1d29ae","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":0},{"id":"618a982efec7d1542d1d29c3","post_id":"618a976bfec7d1542d1d29ae","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":1},{"id":"6192056dfec7d1542d1d2a1c","post_id":"6192052ffec7d1542d1d2a17","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":0},{"id":"61ad4525fec7d1542d1d2a5f","post_id":"5f7a463517b26d3ef80d635a","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":2},{"id":"61ad4537fec7d1542d1d2a61","post_id":"5f73972a17b26d3ef80d62cb","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":2},{"id":"61d40a1efec7d1542d1d2a7a","post_id":"61d40a02fec7d1542d1d2a76","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":0},{"id":"61dc6fbafec7d1542d1d2abe","post_id":"61d40a02fec7d1542d1d2a76","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":1},{"id":"6200540afec7d1542d1d2aeb","post_id":"5f73972a17b26d3ef80d62cb","tag_id":"6200540afec7d1542d1d2aea","sort_order":3},{"id":"6200541dfec7d1542d1d2aee","post_id":"5f7a463517b26d3ef80d635a","tag_id":"6200540afec7d1542d1d2aea","sort_order":3},{"id":"6200900afec7d1542d1d2b0d","post_id":"62008a02fec7d1542d1d2af2","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"6200900afec7d1542d1d2b0e","post_id":"62008a02fec7d1542d1d2af2","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"62202529fec7d1542d1d2b33","post_id":"621fdf62fec7d1542d1d2b2e","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":0},{"id":"62202529fec7d1542d1d2b34","post_id":"621fdf62fec7d1542d1d2b2e","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":1},{"id":"6262a512fec7d1542d1d2b9d","post_id":"6262a2e8fec7d1542d1d2b78","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"6262a512fec7d1542d1d2b9e","post_id":"6262a2e8fec7d1542d1d2b78","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"62b9dda3fec7d1542d1d2bd9","post_id":"62b9dd89fec7d1542d1d2bd4","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"62cdcd1efec7d1542d1d2c19","post_id":"5eea4c812fa60d0ab28d5ca5","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":0},{"id":"62ce2899fec7d1542d1d2c20","post_id":"60e5cd58c1d1894be7adc8f7","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":1},{"id":"62d5ca4cfec7d1542d1d2c2c","post_id":"62d5ca2dfec7d1542d1d2c27","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":0},{"id":"62d5ca4cfec7d1542d1d2c2d","post_id":"62d5ca2dfec7d1542d1d2c27","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":1},{"id":"62e9408dfec7d1542d1d2c7f","post_id":"62e93fd1fec7d1542d1d2c71","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"62e9408dfec7d1542d1d2c80","post_id":"62e93fd1fec7d1542d1d2c71","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"630f395cfec7d1542d1d2cca","post_id":"630f3947fec7d1542d1d2cc5","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"630f395cfec7d1542d1d2ccb","post_id":"630f3947fec7d1542d1d2cc5","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"63219cc1fec7d1542d1d2d22","post_id":"63219ca4fec7d1542d1d2d1d","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"63219cc1fec7d1542d1d2d23","post_id":"63219ca4fec7d1542d1d2d1d","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"6360bd37fec7d1542d1d2d54","post_id":"6360bd1afec7d1542d1d2d50","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":0},{"id":"6360bd37fec7d1542d1d2d55","post_id":"6360bd1afec7d1542d1d2d50","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":1},{"id":"6398b3f0fec7d1542d1d2dab","post_id":"6398b3ccfec7d1542d1d2da6","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"6398b3f0fec7d1542d1d2dac","post_id":"6398b3ccfec7d1542d1d2da6","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"63bf0c39fec7d1542d1d2e00","post_id":"63bf0c12fec7d1542d1d2dfb","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":0},{"id":"63bf0c39fec7d1542d1d2e01","post_id":"63bf0c12fec7d1542d1d2dfb","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":1},{"id":"645bca14fec7d1542d1d2e5a","post_id":"645bc999fec7d1542d1d2e4e","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"645bca14fec7d1542d1d2e5b","post_id":"645bc999fec7d1542d1d2e4e","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"6489f1c4fec7d1542d1d2edb","post_id":"6489f030fec7d1542d1d2ea9","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"6489f1c4fec7d1542d1d2edc","post_id":"6489f030fec7d1542d1d2ea9","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"64bf8f35fec7d1542d1d2f0e","post_id":"64bf8645fec7d1542d1d2ee6","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"64bf8f35fec7d1542d1d2f0f","post_id":"64bf8645fec7d1542d1d2ee6","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"65713a4afec7d1542d1d2f38","post_id":"657139f9fec7d1542d1d2f32","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":0},{"id":"659338abfec7d1542d1d2f59","post_id":"659337c7fec7d1542d1d2f50","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"659338abfec7d1542d1d2f5a","post_id":"659337c7fec7d1542d1d2f50","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"65ea001efec7d1542d1d2fa1","post_id":"65e9fffefec7d1542d1d2f9c","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"65ea001efec7d1542d1d2fa2","post_id":"65e9fffefec7d1542d1d2f9c","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1},{"id":"665558fffec7d1542d1d2fd6","post_id":"665558b2fec7d1542d1d2fcd","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"665558fffec7d1542d1d2fd7","post_id":"665558b2fec7d1542d1d2fcd","tag_id":"60d4d2b995eadd54d31a7bd4","sort_order":1},{"id":"66fd79f5fec7d1542d1d3010","post_id":"66fd79c6fec7d1542d1d300b","tag_id":"60d4d25f95eadd54d31a7bd0","sort_order":0},{"id":"66fd79f5fec7d1542d1d3011","post_id":"66fd79c6fec7d1542d1d300b","tag_id":"60d4d2c495eadd54d31a7bd6","sort_order":1}],"roles":[{"id":"5ac794f8d55d8108635e37d9","name":"Administrator","description":"Administrators","created_at":"2018-04-06T15:40:40.000Z","updated_at":"2018-04-06T15:40:40.000Z"},{"id":"5ac794f8d55d8108635e37da","name":"Editor","description":"Editors","created_at":"2018-04-06T15:40:40.000Z","updated_at":"2018-04-06T15:40:40.000Z"},{"id":"5ac794f8d55d8108635e37db","name":"Author","description":"Authors","created_at":"2018-04-06T15:40:40.000Z","updated_at":"2018-04-06T15:40:40.000Z"},{"id":"5ac794f8d55d8108635e37dc","name":"Contributor","description":"Contributors","created_at":"2018-04-06T15:40:40.000Z","updated_at":"2018-04-06T15:40:40.000Z"},{"id":"5ac794f8d55d8108635e37dd","name":"Owner","description":"Blog Owner","created_at":"2018-04-06T15:40:40.000Z","updated_at":"2018-04-06T15:40:40.000Z"},{"id":"5c3b898a7b3c2f0eb4b38c0a","name":"Admin Integration","description":"External Apps","created_at":"2019-01-13T18:55:06.000Z","updated_at":"2019-01-13T18:55:06.000Z"},{"id":"5daffb48801ee451cd03a336","name":"DB Backup Integration","description":"Internal DB Backup Client","created_at":"2019-10-23T07:03:36.000Z","updated_at":"2019-10-23T07:03:36.000Z"},{"id":"5daffb48801ee451cd03a33f","name":"Scheduler Integration","description":"Internal Scheduler Client","created_at":"2019-10-23T07:03:36.000Z","updated_at":"2019-10-23T07:03:36.000Z"}],"roles_users":[{"id":"5ac794f9d55d8108635e3813","role_id":"5ac794f8d55d8108635e37db","user_id":"5951f5fca366002ebd5dbef7"},{"id":"5ac794fad55d8108635e38a3","role_id":"5ac794f8d55d8108635e37dd","user_id":"1"}],"settings":[{"id":"5ac794fd7599f908b8a89da3","key":"db_hash","value":"3d4809ed-716d-4a85-8b10-601e76b3fad9","type":"string","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2018-04-06T15:40:45.000Z","group":"core","flags":null},{"id":"5ac794fd7599f908b8a89da4","key":"next_update_check","value":"1766596432","type":"number","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2025-12-23T17:13:51.000Z","group":"core","flags":null},{"id":"5ac794fd7599f908b8a89da5","key":"notifications","value":"[{\"dismissible\":true,\"location\":\"bottom\",\"status\":\"alert\",\"id\":\"31adffd0-17e1-11ec-8568-49e104045b27\",\"custom\":false,\"createdAt\":\"2021-09-17T17:00:51.000Z\",\"type\":\"info\",\"top\":false,\"message\":\"Ghost <a href=\\\"https://github.com/TryGhost/Ghost/releases\\\">4.15.0</a> has been released, <a href=\\\"https://ghost.org/update/?v=4.8.4\\\">click here</a> to upgrade.\",\"seen\":false,\"addedAt\":\"2021-09-23T01:29:37.927Z\"},{\"dismissible\":true,\"location\":\"bottom\",\"status\":\"alert\",\"id\":\"42f1b99a-efae-45a9-8f5c-ff6a041e165f\",\"custom\":true,\"createdAt\":\"2025-08-28T09:16:12.000Z\",\"type\":\"info\",\"top\":true,\"message\":\"<strong>Ghost 4.0 is now end-of-life as of January 2023</strong> - You are using an old version of Ghost, which means you don't have access to the latest features. <a href=\\\"https://ghost.org/changelog/6/\\\" target=\\\"_blank\\\" rel=\\\"noopener\\\">Read more!</a>\",\"seen\":false,\"addedAt\":\"2025-10-04T02:09:53.408Z\"}]","type":"array","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2025-10-04T02:09:53.000Z","group":"core","flags":null},{"id":"5ac794fd7599f908b8a89da6","key":"title","value":"Who is Nnamdi?","type":"string","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2018-04-06T15:51:10.000Z","group":"site","flags":"PUBLIC"},{"id":"5ac794fd7599f908b8a89da7","key":"description","value":"Thoughts on technology, venture capital, and the economics of both","type":"string","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2019-11-06T19:15:18.000Z","group":"site","flags":"PUBLIC"},{"id":"5ac794fd7599f908b8a89da8","key":"logo","value":null,"type":"string","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2019-10-23T07:11:27.000Z","group":"site","flags":"PUBLIC"},{"id":"5ac794fd7599f908b8a89da9","key":"cover_image","value":null,"type":"string","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2019-10-23T07:11:27.000Z","group":"site","flags":null},{"id":"5ac794fd7599f908b8a89daa","key":"icon","value":null,"type":"string","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2019-10-23T07:11:27.000Z","group":"site","flags":null},{"id":"5ac794fd7599f908b8a89daf","key":"amp","value":"true","type":"boolean","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2018-04-06T15:40:45.000Z","group":"amp","flags":null},{"id":"5ac794fd7599f908b8a89db2","key":"facebook","value":"nnamdi.iregbulem","type":"string","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2018-09-30T20:59:18.000Z","group":"site","flags":null},{"id":"5ac794fd7599f908b8a89db3","key":"twitter","value":"@whoisnnamdi","type":"string","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2018-12-27T04:01:27.000Z","group":"site","flags":null},{"id":"5ac794fd7599f908b8a89db5","key":"navigation","value":"[{\"label\":\"About Me\",\"url\":\"/about-me/\"},{\"label\":\"Portfolio\",\"url\":\"/portfolio/\"},{\"label\":\"Newsletter\",\"url\":\"/newsletter/\"},{\"label\":\"Talks\",\"url\":\"/talks/\"},{\"label\":\"The Developer Productivity Manifesto\",\"url\":\"/the-developer-productivity-flywheel/\"},{\"label\":\"The Highest-Paid Engineers\",\"url\":\"/highest-paid-software-engineers-2020/\"}]","type":"array","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2021-05-14T00:55:46.000Z","group":"site","flags":null},{"id":"5ac794fd7599f908b8a89db7","key":"unsplash","value":"true","type":"boolean","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2018-04-07T18:14:14.000Z","group":"unsplash","flags":null},{"id":"5ac794fd7599f908b8a89db8","key":"active_theme","value":"casper2","type":"string","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2019-12-10T19:04:19.000Z","group":"theme","flags":"RO"},{"id":"5ac794fd7599f908b8a89dbb","key":"is_private","value":"false","type":"boolean","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2021-07-20T06:39:10.000Z","group":"private","flags":null},{"id":"5ac794fd7599f908b8a89dbc","key":"password","value":"jiwute617","type":"string","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2021-07-20T05:25:21.000Z","group":"private","flags":null},{"id":"5ac794fd7599f908b8a89dbd","key":"public_hash","value":"f7d038e1912fb3a4c601cccbf14a7a","type":"string","created_at":"2018-04-06T15:40:45.000Z","updated_at":"2018-04-06T15:40:45.000Z","group":"private","flags":null},{"id":"5c3b89877b3c2f0eb4b38c06","key":"session_secret","value":"81e5d9ce829946177b4dca09052f0559e99833e8b9498d0f4e74f7d1b7a446bf","type":"string","created_at":"2019-01-13T18:55:03.000Z","updated_at":"2019-01-13T18:55:03.000Z","group":"core","flags":null},{"id":"5c3b89877b3c2f0eb4b38c07","key":"members_public_key","value":"-----BEGIN RSA PUBLIC KEY-----\nMIGJAoGBAKKpbR1ss4CwomHEraHzag09izFrXRaQz38U567eyk6UwJBPfHITWf1CtHCmokIl\n6PivrozL8/UdAIOBqQYZNNOr6Dffy2A5PTyQNDwgi91NkEul67flBhcxLJKANqyUJymZST6p\nlgVa05UhXYGqn5rkM1A02a/24WK92EAuyNAPAgMBAAE=\n-----END RSA PUBLIC KEY-----\n","type":"string","created_at":"2019-01-13T18:55:03.000Z","updated_at":"2019-01-13T18:55:03.000Z","group":"core","flags":null},{"id":"5c3b89877b3c2f0eb4b38c08","key":"members_private_key","value":"-----BEGIN RSA PRIVATE KEY-----\nMIICXAIBAAKBgQCiqW0dbLOAsKJhxK2h82oNPYsxa10WkM9/FOeu3spOlMCQT3xyE1n9QrRw\npqJCJej4r66My/P1HQCDgakGGTTTq+g338tgOT08kDQ8IIvdTZBLpeu35QYXMSySgDaslCcp\nmUk+qZYFWtOVIV2Bqp+a5DNQNNmv9uFivdhALsjQDwIDAQABAoGAUCDeG4ycsFxS4Y6dahYa\nvAMBOosFBES5soR9zOr7BdLJOU2upBNcVSIy+PtdGvDJ3xfMCJe/yZNL2XxZ4yMvnfyp7TQq\nKwUieC+Xnoi+WBOqD+FI7VqfuyBiouqZxZZGj6S/7nWGBTKUTP8eUPmxPALeu8/qN00X0Dul\nuS8cv6ECQQDZ5simP3jmke0lJZ7WgGzfhuLbuuUe+I1x8aqyqfJzHL1Q1AHqSlU78JbrIxbh\n+0lTRgXw3lOd+/c3rniN2ysbAkEAvxog3Q9yWcMm7dWBFq97EkIYCikYRb4yPBeDX1KNyUZC\ntJ8UjGI33v5msnmZgUoZAt6lh8eqcZSG/x8+H0+qHQJAdKEoKIO0rITSz50xRVJ787B44G9K\nj6ct3h0h5ns8QAzT791qIQMkV+7QeI7RgqdDegTyzRfS3a6theomsJbsnQJBAKOhh8pBU7Sw\neUDks+fs0gDMPzFUBsiRFwqFR6PzWByj4LIwFLQv1Y9HXkAsBtjBzbC7XBlrSfJ/Lyh8ZAED\ngbECQHhdQf3I2HZwMAwKHlX47URkaVEDM/nbsnLwlhcayjUDR85MXeJTuFHRFfnh1ZoyLRhy\nbu69ntLDE2KEFXz434Q=\n-----END RSA PRIVATE KEY-----\n","type":"string","created_at":"2019-01-13T18:55:03.000Z","updated_at":"2019-01-13T18:55:03.000Z","group":"core","flags":null},{"id":"5cecf781a9841159a72df5de","key":"theme_session_secret","value":"74c68320717c8a5aaf3bd10ea5246c78576def491a7ffd2fe376659ef70d2f1c","type":"string","created_at":"2019-05-28T08:55:29.000Z","updated_at":"2019-05-28T08:55:29.000Z","group":"core","flags":null},{"id":"5daffb45801ee451cd03a315","key":"meta_title","value":null,"type":"string","created_at":"2019-10-23T07:03:33.000Z","updated_at":"2019-10-23T07:03:33.000Z","group":"site","flags":null},{"id":"5daffb45801ee451cd03a316","key":"meta_description","value":null,"type":"string","created_at":"2019-10-23T07:03:33.000Z","updated_at":"2019-10-23T07:03:33.000Z","group":"site","flags":null},{"id":"5daffb45801ee451cd03a317","key":"og_image","value":null,"type":"string","created_at":"2019-10-23T07:03:33.000Z","updated_at":"2019-10-23T07:03:33.000Z","group":"site","flags":null},{"id":"5daffb45801ee451cd03a318","key":"og_title","value":null,"type":"string","created_at":"2019-10-23T07:03:33.000Z","updated_at":"2019-10-23T07:03:33.000Z","group":"site","flags":null},{"id":"5daffb45801ee451cd03a319","key":"og_description","value":null,"type":"string","created_at":"2019-10-23T07:03:33.000Z","updated_at":"2019-10-23T07:03:33.000Z","group":"site","flags":null},{"id":"5daffb45801ee451cd03a31a","key":"twitter_image","value":null,"type":"string","created_at":"2019-10-23T07:03:33.000Z","updated_at":"2019-10-23T07:03:33.000Z","group":"site","flags":null},{"id":"5daffb45801ee451cd03a31b","key":"twitter_title","value":null,"type":"string","created_at":"2019-10-23T07:03:33.000Z","updated_at":"2019-10-23T07:03:33.000Z","group":"site","flags":null},{"id":"5daffb45801ee451cd03a31c","key":"twitter_description","value":null,"type":"string","created_at":"2019-10-23T07:03:33.000Z","updated_at":"2019-10-23T07:03:33.000Z","group":"site","flags":null},{"id":"5daffb45801ee451cd03a31d","key":"members_email_auth_secret","value":"dee69e88571fec37a2c61e3b09f688b3dfa945dec545f004e84b69be3ee76532a1bbae54b7fd360cb9b01e9efc4402cd40502e680e2c7cc238e64fb90d3e1600","type":"string","created_at":"2019-10-23T07:03:33.000Z","updated_at":"2019-10-23T07:03:33.000Z","group":"core","flags":null},{"id":"5daffb45801ee451cd03a31e","key":"default_content_visibility","value":"public","type":"string","created_at":"2019-10-23T07:03:33.000Z","updated_at":"2019-10-23T07:03:33.000Z","group":"members","flags":null},{"id":"60e3f22a61dad02a4dab0cb2","key":"routes_hash","value":"3d180d52c663d173a6be791ef411ed01","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:29.000Z","group":"core","flags":null},{"id":"60e3f22a61dad02a4dab0cb3","key":"ghost_public_key","value":"-----BEGIN RSA PUBLIC KEY-----\nMIGJAoGBAJ8oslZYGQ9nZFQbiIjgYiSn92yB1qLseBn/aG6u2UAiY5S9BU/C6OpVbHacNHI5\nzhb5KPSlY8IFjNUOThr/Tm/T0sCStLZFkEB1A5diAfBRtZVcIY7MoXSw+cky2WO1Gih5kMBE\nx02ptefeX4JyEsLW85oXvZjLvcKjRfxE+q8hAgMBAAE=\n-----END RSA PUBLIC KEY-----\n","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"core","flags":null},{"id":"60e3f22a61dad02a4dab0cb4","key":"ghost_private_key","value":"-----BEGIN RSA PRIVATE KEY-----\nMIICXAIBAAKBgQCfKLJWWBkPZ2RUG4iI4GIkp/dsgdai7HgZ/2hurtlAImOUvQVPwujqVWx2\nnDRyOc4W+Sj0pWPCBYzVDk4a/05v09LAkrS2RZBAdQOXYgHwUbWVXCGOzKF0sPnJMtljtRoo\neZDARMdNqbXn3l+CchLC1vOaF72Yy73Co0X8RPqvIQIDAQABAoGBAIg4EaKa1h/78r+VrR7R\nRM5wv/ArlCNvVj+R/LS2i5Q7mpUjzlb8z9I3+JPvj2ewF7ZL3AS/RQk7LNTw4GJ03pCz9HYF\nYyQR5itUjUpJPGygK6YLDgovBUttcjPelXEmSFxA320LC5QEfI8zov2W7n4ed2xHxgEiEVM8\n+mJV3DoRAkEA6s4Ceb0NXPVNyEFVyHRpRdXpUvR66YknaaZvT2huFQ7Hh+0KYg3+SkN3ZX7G\noFDQN3Z8iK0EOrKJGbTJPGDEVQJBAK2GoBXUyeWpDw9Iq/UH2SZ2X+1/4afBiuKEcwcqusvb\nTIcr84G8W8g3QlxvHuUyAyPt6DRj5sAbGNSNEnIIK50CQFXQlPcJMSkYPiVCO6fXY+IyG+RF\nleZkShNC0MukzxbDIAl9iJ3tn1Jk9e4SN2XAI1kh5MHO+gy504GhoSp/80ECQFNNDmqMhQOH\n/d/DbjEpvFfXecOEoWor4iVNmf61x4h3VSyKr9H2/0SFKok/GuDB+nn0CoWj87EDEQ9wTYuK\nWo0CQCtjtDpyyrjJMOQWa3GQzWdfV09iKLwC0SvzV82KTPzEdhXCQZ46PLbSMC/RJX36F1N/\ns401EntVxrcWO3DHvvU=\n-----END RSA PRIVATE KEY-----\n","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"core","flags":null},{"id":"60e3f22a61dad02a4dab0cb7","key":"accent_color","value":"#15171A","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"site","flags":"PUBLIC"},{"id":"60e3f22a61dad02a4dab0cb8","key":"lang","value":"en","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"site","flags":null},{"id":"60e3f22a61dad02a4dab0cb9","key":"timezone","value":"America/Los_Angeles","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"site","flags":null},{"id":"60e3f22a61dad02a4dab0cba","key":"codeinjection_head","value":"<!-- Matomo -->\n<script type=\"text/javascript\">\n  var _paq = _paq || [];\n  /* tracker methods like \"setCustomDimension\" should be called before \"trackPageView\" */\n  _paq.push(['trackPageView']);\n  _paq.push(['enableLinkTracking']);\n  (function() {\n    var u=\"https://analyticsnnamdi.com/\";\n    _paq.push(['setTrackerUrl', u+'piwik.php']);\n    _paq.push(['setSiteId', '1']);\n    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];\n    g.type='text/javascript'; g.async=true; g.defer=true; g.src=u+'piwik.js'; s.parentNode.insertBefore(g,s);\n  })();\n</script>\n<!-- End Matomo Code -->\n<!-- Google Tag Manager -->\n<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\nnew Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\nj=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n})(window,document,'script','dataLayer','GTM-TFC3767');</script>\n<!-- End Google Tag Manager -->\n<!-- Global site tag (gtag.js) - Google Analytics -->\n<script async src=\"https://www.googletagmanager.com/gtag/js?id=UA-117108825-1\"></script>\n<script>\n  window.dataLayer = window.dataLayer || [];\n  function gtag(){dataLayer.push(arguments);}\n  gtag('js', new Date());\n\n  gtag('config', 'UA-117108825-1');\n</script>\n\n<!--<script type=\"text/javascript\" async src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML\">\n</script>-->\n<script id=\"MathJax-script\" async src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js\"></script>\n\n<script type='text/javascript' src='//platform-api.sharethis.com/js/sharethis.js#property=5c459fbffffaa700112f3d62&product=social-ab' async='async'></script>","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"site","flags":null},{"id":"60e3f22a61dad02a4dab0cbb","key":"codeinjection_foot","value":"<script>\nvar links = document.querySelectorAll('a');\n\nfor (var i = 0, length = links.length; i < length; i++) \n    {\n        if (links[i].hostname != window.location.hostname)\n            {\n                links[i].target = \"_blank\";\n                links[i].rel = \"noopener\";\n            }\n    }\n</script>\n<script async>(function(s,u,m,o,j,v){j=u.createElement(m);v=u.getElementsByTagName(m)[0];j.async=1;j.src=o;j.dataset.sumoSiteId='1faf02ea2882c9344411237c16fc052441e2f8d9f5bbfb6ebcd511ec85827585';v.parentNode.insertBefore(j,v)})(window,document,'script','//load.sumo.com/');</script>","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"site","flags":null},{"id":"60e3f22a61dad02a4dab0cbc","key":"secondary_navigation","value":"[]","type":"array","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"site","flags":null},{"id":"60e3f22a61dad02a4dab0cbe","key":"members_from_address","value":"noreply","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"members","flags":"RO"},{"id":"60e3f22a61dad02a4dab0cbf","key":"members_support_address","value":"noreply","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"members","flags":"PUBLIC,RO"},{"id":"60e3f22a61dad02a4dab0cc0","key":"members_reply_address","value":"newsletter","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"members","flags":null},{"id":"60e3f22a61dad02a4dab0cc1","key":"members_free_signup_redirect","value":"/","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"members","flags":null},{"id":"60e3f22a61dad02a4dab0cc2","key":"members_paid_signup_redirect","value":"/","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"members","flags":null},{"id":"60e3f22a61dad02a4dab0cc3","key":"stripe_product_name","value":"Ghost Subscription","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"members","flags":""},{"id":"60e3f22a61dad02a4dab0cc6","key":"stripe_plans","value":"[{\"name\":\"Monthly\",\"currency\":\"usd\",\"interval\":\"month\",\"amount\":0},{\"name\":\"Yearly\",\"currency\":\"usd\",\"interval\":\"year\",\"amount\":0}]","type":"array","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"members","flags":""},{"id":"60e3f22a61dad02a4dab0cc9","key":"stripe_connect_livemode","value":null,"type":"boolean","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"members","flags":""},{"id":"60e3f22a61dad02a4dab0cca","key":"stripe_connect_display_name","value":null,"type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"members","flags":""},{"id":"60e3f22a61dad02a4dab0ccc","key":"portal_name","value":"true","type":"boolean","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"portal","flags":null},{"id":"60e3f22a61dad02a4dab0ccd","key":"portal_button","value":"false","type":"boolean","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"portal","flags":null},{"id":"60e3f22a61dad02a4dab0cce","key":"portal_plans","value":"[\"free\",\"monthly\",\"yearly\"]","type":"array","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T20:27:34.000Z","group":"portal","flags":null},{"id":"60e3f22a61dad02a4dab0ccf","key":"portal_button_style","value":"icon-and-text","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"portal","flags":null},{"id":"60e3f22a61dad02a4dab0cd0","key":"portal_button_icon","value":null,"type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"portal","flags":null},{"id":"60e3f22a61dad02a4dab0cd1","key":"portal_button_signup_text","value":"Subscribe","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"portal","flags":null},{"id":"60e3f22a61dad02a4dab0cd2","key":"mailgun_domain","value":null,"type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"email","flags":null},{"id":"60e3f22a61dad02a4dab0cd3","key":"mailgun_api_key","value":null,"type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"email","flags":null},{"id":"60e3f22a61dad02a4dab0cd4","key":"mailgun_base_url","value":null,"type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"email","flags":null},{"id":"60e3f22a61dad02a4dab0cd5","key":"email_track_opens","value":"true","type":"boolean","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"email","flags":null},{"id":"60e3f22a61dad02a4dab0cd6","key":"amp_gtag_id","value":null,"type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"amp","flags":null},{"id":"60e3f22a61dad02a4dab0cd7","key":"firstpromoter","value":"false","type":"boolean","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"firstpromoter","flags":null},{"id":"60e3f22a61dad02a4dab0cd8","key":"firstpromoter_id","value":null,"type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"firstpromoter","flags":null},{"id":"60e3f22a61dad02a4dab0cd9","key":"shared_views","value":"[]","type":"array","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"views","flags":null},{"id":"60e3f22a61dad02a4dab0cda","key":"newsletter_show_badge","value":"true","type":"boolean","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"newsletter","flags":null},{"id":"60e3f22a61dad02a4dab0cdc","key":"newsletter_body_font_category","value":"sans_serif","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"newsletter","flags":null},{"id":"60e3f22a61dad02a4dab0cdd","key":"newsletter_footer_content","value":"","type":"string","created_at":"2021-07-06T06:03:22.000Z","updated_at":"2021-07-06T06:03:22.000Z","group":"newsletter","flags":null},{"id":"60e3f48d2eb0f73af1cfda86","key":"slack_url","value":"","type":"string","created_at":"2021-07-06T06:13:33.000Z","updated_at":"2021-07-20T06:39:10.000Z","group":"slack","flags":null},{"id":"60e3f48d2eb0f73af1cfda87","key":"slack_username","value":"Ghost","type":"string","created_at":"2021-07-06T06:13:33.000Z","updated_at":"2021-07-20T06:39:10.000Z","group":"slack","flags":null},{"id":"60e3f48f2eb0f73af1cfdaaa","key":"members_signup_access","value":"all","type":"string","created_at":"2021-07-06T06:13:35.000Z","updated_at":"2021-07-06T06:13:35.000Z","group":"members","flags":null},{"id":"60e3f48f2eb0f73af1cfdaad","key":"labs","value":"{}","type":"object","created_at":"2021-07-06T06:13:35.000Z","updated_at":"2021-07-06T06:13:35.000Z","group":"labs","flags":null},{"id":"60e3f4902eb0f73af1cfdaae","key":"portal_products","value":"[\"60e3f48f2eb0f73af1cfda9b\"]","type":"array","created_at":"2021-07-06T06:13:36.000Z","updated_at":"2021-07-06T06:13:36.000Z","group":"portal","flags":null},{"id":"60e3f4902eb0f73af1cfdaaf","key":"members_free_price_name","value":"Free","type":"string","created_at":"2021-07-06T06:13:36.000Z","updated_at":"2021-07-06T06:13:36.000Z","group":"members","flags":null},{"id":"60e3f4902eb0f73af1cfdab0","key":"members_free_price_description","value":"Free preview","type":"string","created_at":"2021-07-06T06:13:36.000Z","updated_at":"2021-07-06T06:13:36.000Z","group":"members","flags":null},{"id":"60e3f4902eb0f73af1cfdab1","key":"members_monthly_price_id","value":null,"type":"string","created_at":"2021-07-06T06:13:36.000Z","updated_at":"2021-07-06T06:13:36.000Z","group":"members","flags":null},{"id":"60e3f4902eb0f73af1cfdab2","key":"members_yearly_price_id","value":null,"type":"string","created_at":"2021-07-06T06:13:36.000Z","updated_at":"2021-07-06T06:13:36.000Z","group":"members","flags":null},{"id":"60e3f4902eb0f73af1cfdab3","key":"newsletter_header_image","value":null,"type":"string","created_at":"2021-07-06T06:13:36.000Z","updated_at":"2021-07-06T06:13:36.000Z","group":"newsletter","flags":null},{"id":"60e3f4902eb0f73af1cfdab4","key":"newsletter_show_header_icon","value":"true","type":"boolean","created_at":"2021-07-06T06:13:36.000Z","updated_at":"2021-07-06T06:13:36.000Z","group":"newsletter","flags":null},{"id":"60e3f4902eb0f73af1cfdab5","key":"newsletter_show_header_title","value":"true","type":"boolean","created_at":"2021-07-06T06:13:36.000Z","updated_at":"2021-07-06T06:13:36.000Z","group":"newsletter","flags":null},{"id":"60e3f4902eb0f73af1cfdab6","key":"newsletter_title_alignment","value":"center","type":"string","created_at":"2021-07-06T06:13:36.000Z","updated_at":"2021-07-06T06:13:36.000Z","group":"newsletter","flags":null},{"id":"60e3f4902eb0f73af1cfdab7","key":"newsletter_title_font_category","value":"sans_serif","type":"string","created_at":"2021-07-06T06:13:36.000Z","updated_at":"2021-07-06T06:13:36.000Z","group":"newsletter","flags":null},{"id":"60e3f4902eb0f73af1cfdab8","key":"newsletter_show_feature_image","value":"true","type":"boolean","created_at":"2021-07-06T06:13:36.000Z","updated_at":"2021-07-06T06:13:36.000Z","group":"newsletter","flags":null},{"id":"60e3f4902eb0f73af1cfdabb","key":"editor_default_email_recipients","value":"visibility","type":"string","created_at":"2021-07-06T06:13:36.000Z","updated_at":"2021-07-06T06:13:36.000Z","group":"editor","flags":null},{"id":"60e3f4902eb0f73af1cfdabc","key":"editor_default_email_recipients_filter","value":"all","type":"string","created_at":"2021-07-06T06:13:36.000Z","updated_at":"2021-07-06T06:13:36.000Z","group":"editor","flags":null}],"tags":[{"id":"5ac794f8d55d8108635e37d4","name":"Getting Started","slug":"getting-started","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2018-04-06T15:40:40.000Z","updated_at":"2018-04-06T15:40:40.000Z","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null},{"id":"5f739f0517b26d3ef80d6339","name":"Research","slug":"research","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2020-09-29T20:54:29.000Z","updated_at":"2020-09-29T20:55:11.000Z","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null},{"id":"5f739f0517b26d3ef80d633a","name":"Machine Learning","slug":"machine-learning","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2020-09-29T20:54:29.000Z","updated_at":"2020-09-29T20:55:22.000Z","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null},{"id":"60d4d25f95eadd54d31a7bd0","name":"Founders","slug":"founders","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2021-06-24T18:43:43.000Z","updated_at":"2021-06-24T18:43:43.000Z","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null},{"id":"60d4d2b995eadd54d31a7bd4","name":"Developers","slug":"developers","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2021-06-24T18:45:13.000Z","updated_at":"2021-06-24T18:45:13.000Z","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null},{"id":"60d4d2c495eadd54d31a7bd6","name":"Investors","slug":"investors","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2021-06-24T18:45:24.000Z","updated_at":"2021-06-24T18:45:24.000Z","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null},{"id":"6200540afec7d1542d1d2aea","name":"Notes","slug":"notes","description":null,"feature_image":null,"parent_id":null,"visibility":"public","meta_title":null,"meta_description":null,"created_at":"2022-02-06T23:04:42.000Z","updated_at":"2022-02-06T23:04:42.000Z","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null}],"users":[{"id":"1","name":"Nnamdi Iregbulem","slug":"nnamdi","password":"$2a$10$/KGY98HvfYirf3HSaaVuteIOutuIWMHMQ18JpWqs2ktznDg9mj4fK","email":"nnamdi.iregbulem@gmail.com","profile_image":"__GHOST_URL__/content/images/2019/10/DSC_0562_cropped_2.jpg","cover_image":null,"bio":"Partner @LightspeedVP | DevOps, app infra, and ML nerd. Soft spot for devs â¤ï¸ | Former: Product @confluentinc | VC @ICONIQGrowth | MBA @Stanford | Economics @Yale","website":"https://whoisnnamdi.com","location":null,"facebook":"nnamdi.iregbulem","twitter":"@whoisnnamdi","accessibility":"{\"nightShift\":false,\"whatsNew\":{\"lastSeenDate\":\"2020-06-29T16:11:36.000+00:00\"},\"launchComplete\":true}","status":"active","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"tour":"[\"getting-started\",\"using-the-editor\",\"upload-a-theme\",\"static-post\",\"featured-post\"]","last_seen":"2025-12-23T17:17:09.000Z","created_at":"2018-04-06T15:40:40.000Z","updated_at":"2025-12-23T17:17:09.000Z"}]}}]}